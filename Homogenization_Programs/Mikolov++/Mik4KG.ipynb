{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345a6474",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on device: cpu\n",
      "Necessary Files Loaded...\n"
     ]
    }
   ],
   "source": [
    "import pickle5 as pickle\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel, logging\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "logging.set_verbosity(50)\n",
    "\n",
    "with open('KGT.pkl', 'rb') as file:\n",
    "    KGT = pickle.load(file)\n",
    "\n",
    "with open('entity2idx.pkl', 'rb') as file:\n",
    "    entity2id = pickle.load(file)\n",
    "\n",
    "using_triples = False\n",
    "using_hidden_states = False\n",
    "using_pooler_output = True\n",
    "\n",
    "ent_embeddings = pd.read_csv('ent_embedding.tsv', sep='\\t', header=None)\n",
    "if using_triples == True:\n",
    "    MRREL_rel2desc = pd.read_pickle('MRREL_rel2desc.pkl')\n",
    "    SEM_NW_rel2desc = pd.read_pickle('SEM_NW_rel2desc.pkl')\n",
    "    total_rel2desc = pd.concat([MRREL_rel2desc, SEM_NW_rel2desc], ignore_index=True).drop_duplicates()\n",
    "\n",
    "model_name = 'phiyodr/bert-base-finetuned-squad2'\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model_embeddings = model.get_input_embeddings()\n",
    "\n",
    "device = ('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(f'Model loaded on device: {device}')\n",
    "\n",
    "print('Necessary Files Loaded...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a0c9db",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2104/2104 [00:01<00:00, 1960.07it/s]\n"
     ]
    }
   ],
   "source": [
    "#Breaking entities using tokenizer approach & NOT passing THROUGH the model\n",
    "src = []\n",
    "tgt = []\n",
    "for ent_name, ent_index in tqdm(entity2id.items()):\n",
    "    entity_tokens = tokenizer(ent_name, return_tensors='pt')['input_ids'][0]\n",
    "    sw_embds = []\n",
    "    for index in range(1, len(entity_tokens)-1):\n",
    "        sw_embds.append(model_embeddings(entity_tokens[index]))\n",
    "    src.append(ent_embeddings.iloc[ent_index].to_numpy())\n",
    "    tgt.append(torch.mean(torch.vstack(sw_embds), dim=0).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460cd95",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Triples & Entity THROUGH the model approach\n",
    "src = []\n",
    "tgt = []\n",
    "number_of_layers = 4\n",
    "\n",
    "with torch.no_grad():\n",
    "    if using_triples == True:\n",
    "        for triple in tqdm(KGT.itertuples()):\n",
    "            natural_text = triple.E1 + ' ' + total_rel2desc.query('REL==@triple.Rel').Description.values[0] + ' ' + triple.E2\n",
    "            inputs = tokenizer(natural_text, return_tensors='pt')\n",
    "            inputs.to(device)\n",
    "            output = model(**inputs)\n",
    "            if using_pooler_output == True:\n",
    "                src.append(ent_embeddings.iloc[entity2id[triple.E1]].to_numpy())\n",
    "                tgt.append(output['pooler_output'].detach().cpu().numpy().reshape(1,-1))\n",
    "            else:#[CLS] output\n",
    "                src.append(ent_embeddings.iloc[entity2id[triple.E1]].to_numpy())\n",
    "                tgt.append(output['last_hidden_state'][0][0].detach().cpu().numpy().reshape(1,-1))\n",
    "    else:\n",
    "        for ent_name, ent_index in tqdm(entity2id.items()):\n",
    "            inputs = tokenizer(ent_name, return_tensors='pt')\n",
    "            inputs.to(device)\n",
    "            output = model(**inputs, output_hidden_states=True)\n",
    "            if using_hidden_states == True:\n",
    "                entity_tokens = output['hidden_states'][0][0].shape[0] - 2\n",
    "                vecs = []\n",
    "                for layer_idx in range(number_of_layers):\n",
    "                    vecs.append([output['hidden_states'][layer_idx][0][i] for i in range(1,  entity_tokens + 1)])\n",
    "                c = torch.vstack([torch.hstack(vecs[x]).reshape(1, entity_tokens, 768) for x in range(number_of_layers)])\n",
    "                src.append(ent_embeddings.iloc[ent_index].to_numpy())\n",
    "                tgt.append(torch.mean(torch.mean(c, dim=0), dim=0).detach().cpu().numpy().reshape(1,-1))\n",
    "            else:          \n",
    "                if using_pooler_output == True:\n",
    "                    src.append(ent_embeddings.iloc[ent_index].to_numpy())\n",
    "                    tgt.append(output['pooler_output'].detach().cpu().numpy().reshape(1,-1))\n",
    "                else: #[CLS] output\n",
    "                    src.append(ent_embeddings.iloc[ent_index].to_numpy())\n",
    "                    tgt.append(output['last_hidden_state'][0][0].detach().cpu().numpy().reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a76f4567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2104/2104 [00:00<00:00, 6901.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Homogenized Embeddings for phiyodr/bert-base-finetuned-squad2...\n"
     ]
    }
   ],
   "source": [
    "weight_matrix = np.linalg.lstsq(np.vstack(src),np.vstack(tgt), rcond=None)[0]\n",
    "\n",
    "homogenized_embeddings = {}\n",
    "for entity_name, index in tqdm(entity2id.items()):\n",
    "    homogenized_embeddings[entity_name] = torch.FloatTensor(np.matmul(weight_matrix.T, ent_embeddings.iloc[index].to_numpy()).reshape(1,-1))\n",
    "\n",
    "print(f'Saving Homogenized Embeddings for {model_name}...')\n",
    "pd.DataFrame(list(homogenized_embeddings.items()), columns = ['Entity', 'Embedding']).to_pickle(f'Mikolov++_to_{model_name.replace(\"/\",\"_\")}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
