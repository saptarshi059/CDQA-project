{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316e6bd",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Importing necessary files\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "from MyNN import FFNN\n",
    "\n",
    "BERT_variant = 'navteca/roberta-base-squad2'\n",
    "\n",
    "vocab_size = AutoTokenizer.from_pretrained(BERT_variant).vocab_size\n",
    "ent_embeddings_size = len(pd.read_csv(os.path.join(os.path.join(os.path.abspath('../../UMLS_KG'), \\\n",
    "                                                            os.path.relpath('embeddings/distmult')), \\\n",
    "                                               'ent_embedding.tsv'), sep='\\t', header=None).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd72fc8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Creating dataset object & dataloader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "class FFN_Data(Dataset):\n",
    "    def __init__(self):\n",
    "        data = pd.read_pickle('Homogenization_data.pkl')\n",
    "        self.x = data['train']\n",
    "        self.y = data['test']\n",
    "        self.n_samples = data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        true_output = np.zeros(vocab_size)\n",
    "        np.put(true_output, self.y[index], 1) #Creating true target representation here\n",
    "        return self.x[index], true_output\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "homogenization_dataset = FFN_Data()\n",
    "print('Dataset object created...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bceca1",
   "metadata": {
    "code_folding": [
     47,
     57,
     60
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Code adapted from \n",
    "https://www.machinecurve.com/index.php/2021/02/03/how-to-use-k-fold-cross-validation-with-pytorch/\n",
    "'''\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def reset_weights(m):\n",
    "    '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "    '''\n",
    "    for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            print(f'Reset trainable parameters of layer = {layer}')\n",
    "            layer.reset_parameters()\n",
    "\n",
    "# Configuration options\n",
    "k_folds = 5\n",
    "num_epochs = 1\n",
    "loss_function = torch.nn.BCELoss()\n",
    "batch_size = 10\n",
    "#1 X [dim of 1 KGE], since we are doing mean(triple)\n",
    "input_dimension = ent_embeddings_size\n",
    "\n",
    "#Size of BERT variant vocabulary\n",
    "output_dimension = vocab_size\n",
    "\n",
    "#Play with this\n",
    "number_of_hidden_layers = 5\n",
    "\n",
    "#Size of embedding required by BERT variant (usually 768)\n",
    "hidden_dimension = 768\n",
    "  \n",
    "# For fold results\n",
    "test_fold_loss = {}\n",
    "train_fold_loss = {}\n",
    "\n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "  \n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "# Start print\n",
    "print('--------------------------------')\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(homogenization_dataset)):\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      homogenization_dataset, \n",
    "                      batch_size=batch_size, sampler=train_subsampler)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      homogenization_dataset,\n",
    "                      batch_size=batch_size, sampler=test_subsampler)\n",
    "\n",
    "    # Init the neural network\n",
    "    model = FFNN(input_dimension, output_dimension, number_of_hidden_layers, hidden_dimension)\n",
    "    model.apply(reset_weights)\n",
    "    '''\n",
    "    We have to make send the model to device before creating the optimizer since parameters of a model after \n",
    "    .cuda() will be different objects with those before the call (https://pytorch.org/docs/stable/optim.html)\n",
    "    '''\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    epoch_loss_list = []\n",
    "    for epoch in range(0, num_epochs):\n",
    "        # Print epoch\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "        # Set current loss value\n",
    "        current_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        # Iterate over the DataLoader for training data\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Perform forward pass\n",
    "            #'_' for hidden_states[-3] since we don't need that for training\n",
    "            softmax_output, _ = model(inputs.to(device))\n",
    "\n",
    "            #Compute Loss\n",
    "            loss = loss_function(softmax_output.double().to(device), targets.double().to(device))\n",
    "\n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            current_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            if i % 500 == 499:\n",
    "                print('Loss after mini-batch %5d: %.3f' % (i + 1, current_loss / 500))\n",
    "                current_loss = 0.0\n",
    "        \n",
    "        epoch_loss_list.append(epoch_loss)\n",
    "    \n",
    "    #Average training loss over all epochs.\n",
    "    train_fold_loss[fold] = sum(epoch_loss_list)/num_epochs        \n",
    "    \n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "\n",
    "    # Saving the model\n",
    "    save_path = f'./model-fold-{fold}.pth'\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    # Evaluation for this fold\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        # Iterate over the test data and generate predictions\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "\n",
    "            # Generate outputs\n",
    "            softmax_output, _ = model(inputs.to(device))\n",
    "\n",
    "            loss = loss_function(softmax_output.double().to(device), targets.double().to(device))\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "\n",
    "        test_fold_loss[fold] = test_loss\n",
    "\n",
    "# Print fold results\n",
    "print(f'K-FOLD CROSS VALIDATION TRAIN LOSS FOR {k_folds} FOLDS')\n",
    "print('--------------------------------')\n",
    "sum = 0.0\n",
    "for key, value in train_fold_loss.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "print(f'Average training loss: {sum/len(train_fold_loss.items())} %')\n",
    "\n",
    "print(f'K-FOLD CROSS VALIDATION TEST LOSS FOR {k_folds} FOLDS')\n",
    "print('--------------------------------')\n",
    "sum = 0.0\n",
    "for key, value in test_fold_loss.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "print(f'Average test loss: {sum/len(test_fold_loss.items())} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261ea91c",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plotting loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = list(range(k_folds))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "# create line plot of training loss\n",
    "line1, = ax1.plot(x, list(train_fold_loss.values()), 'g', label=\"Training Loss\")\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Training Loss', color='g')\n",
    "\n",
    "# create shared axis for y2(x)\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# create line plot of y2(x)\n",
    "line2, = ax2.plot(x, list(test_fold_loss.values()), 'r', label=\"Test Loss\")\n",
    "ax2.set_ylabel('Test Loss', color='r')\n",
    "\n",
    "# set title, plot limits, etc\n",
    "plt.title('Tracking Loss over K-Folds')\n",
    "\n",
    "# add a legend, and position it on the upper right\n",
    "plt.legend((line1, line2), ('Training Loss', 'Test Loss'))\n",
    "\n",
    "plt.savefig('KFold_Loss_Plot.png', bbox_inches='tight', dpi=600)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
