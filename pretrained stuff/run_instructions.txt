remove excess spaces
captialize acronyms
remove duplicate words
fix spellings
fix grammar

pipeline for PT programs

1st 4 programs & 8 - run on dgx1
6 - local

A. Now use CUI_PC+MM_Tokenizations_gen.py to generate the tokenizations table and CUI_PC for respective task.
B. scp CUI_PC.csv to dgx

1. train_test_gen.py - once (to generate the train/test samples overall) - for the resp. task
2. train_test_gen_NN.py - can repeat this to get the desired number of samples for the NN
3. trainer.py - trains the NN, can run multiple times
4. converter.py - generates the homogenized UMLS_Embeddings, can run multiple times depending on trainer.py -- stop here for only converted UMLS_Embeddings; Continue for dictionary_embeds too
5. scp NN-DTE-to-ktrapeznikov-biobert_v1.1_pubmed_squad_v2.pkl to local
6. ent_def_gen.py - once to add defintions to our NN matrix
7. scp Entity_Definition.pkl to dgx1
8. def_embed.py - run once to generate definition embeddings


export CUDA_VISIBLE_DEVICES=3

python run_pubmed_qa.py --data /home/CDQA-project/data/ --model_name phiyodr/bert-base-finetuned-squad2 --use_kge True --concat_kge True --dte_lookup_table_fp /home/CDQA-project/pretrained\ stuff/for_pubmed/NN-DTE-to-phiyodr-bert-base-finetuned-squad2.pkl --gpus 3 --n_epochs 10 --port 12349


vanilla

python run_pubmed_qa.py --data /home/CDQA-project/data/ --model_name phiyodr/bert-base-finetuned-squad2 --gpus 3 --n_epochs 7 --port 12347


python apply_pubmed_qa.py --data /home/CDQA-project/data/test_set.json --model_id 20220218-162931 --epoch 4

roberta - 20220216-180225

