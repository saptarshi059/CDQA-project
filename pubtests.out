Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[ 1.3939e-03, -6.8716e-02, -2.5557e-01,  2.8171e-02, -8.7808e-03,
         -2.5491e-01,  2.4635e-01, -1.7451e-01, -2.3248e-02,  2.3335e-01,
          2.6176e-01,  1.3909e-01, -1.2589e-01,  1.6319e-01,  2.4349e-02,
         -1.3283e-01,  4.8036e-02,  4.0980e-01, -2.1196e-01, -2.3831e-01,
         -9.6281e-03, -5.5775e-02,  1.1464e-02, -2.9264e-01,  9.9885e-02,
         -2.0102e-01, -1.9214e-01, -3.0318e-01, -4.2442e-02, -5.4449e-02,
         -1.2967e-04, -7.1719e-02,  2.0007e-01,  9.2549e-03,  5.3880e-02,
         -6.0826e-02,  8.9025e-02,  2.9168e-01,  2.3036e-01, -1.1622e-01,
         -6.1775e-02,  1.8710e-01, -1.6608e-01, -2.2137e-01,  1.6387e-01,
         -1.2285e-01,  3.0026e-01,  2.8564e-01, -3.5229e-01, -1.0878e-01,
          4.0280e-01,  1.5114e-01,  1.1360e-02, -2.0095e-02, -1.3847e-01,
          7.2091e-04, -1.1731e-01, -2.7096e-01,  2.7509e-02,  1.0600e-01,
          4.5664e-02,  1.3611e-01, -1.6287e-01, -2.6011e-01, -8.1596e-02,
          1.9391e-01, -6.8843e-02,  6.6795e-02,  3.0044e-01,  1.4518e-04,
          1.3836e-01, -2.1662e-01, -1.4751e-01, -4.5692e-03,  7.7596e-03,
          1.5091e-01, -1.9701e-01,  3.9364e-02,  2.4326e-02, -1.4290e-01,
         -2.3443e-01, -2.8338e-01,  2.4571e-01, -3.4772e-01, -2.1874e-01,
          4.0258e-02,  1.0768e-01,  2.4987e-01,  2.3627e-01, -1.1554e-01,
          2.1028e-01,  1.6711e-01, -1.5543e-01, -1.8313e-02, -3.3042e-01,
         -2.3139e-01,  1.1625e-01, -3.2922e-01, -1.7406e-01, -2.3016e-01,
         -1.3942e-01, -4.9668e-02, -2.7628e-01,  1.0165e-02,  8.2532e-02,
          6.4771e-02,  1.9546e-01, -3.2410e-01,  1.8964e-01, -1.6898e-01,
         -2.2098e-01, -1.2092e-01, -1.3189e-02,  2.6864e-02,  2.7784e-01,
         -6.3231e-02,  6.4781e-02,  3.4362e-01, -2.2732e-02, -3.5275e-01,
          9.8142e-03, -2.4852e-01, -2.7906e-02, -5.1745e-02, -9.5929e-02,
          1.7100e-02,  4.3980e-02, -4.3783e-02,  3.7871e-01,  1.2682e-01,
         -3.2154e-01, -2.1401e-01,  6.4307e-02,  7.8588e-02,  2.3951e-01,
          1.3997e-02, -7.8034e-02, -2.2260e-03,  1.9591e-02, -2.4945e-01,
          8.2607e-02, -3.2764e-02,  1.7143e-02,  2.0525e-01, -5.7016e-02,
          1.8229e-01, -2.7006e-02,  1.1357e-01,  9.7994e-02,  5.1746e-02,
          7.9860e-02,  3.8248e-02, -2.3227e-01, -1.3862e-01,  6.6153e-02,
          2.6249e-01, -5.7370e-02, -1.3890e-01, -4.0898e-01, -2.8864e-01,
         -2.3905e-02,  2.0195e-01,  1.1847e-01, -2.4378e-01, -1.7138e-01,
         -1.7932e-01,  2.7026e-01, -1.0431e-01,  8.6107e-02, -1.0131e-01,
         -8.2868e-02,  9.2653e-02, -3.3071e-02, -3.0312e-01, -2.7937e-01,
         -4.0222e-01, -3.8210e-01,  1.1642e-01, -3.3853e-02,  7.7303e-02,
          1.2355e-01, -2.2809e-01,  4.3379e-02,  1.0617e-02, -1.7532e-01,
         -1.5698e-01,  1.7562e-01, -6.4621e-02, -2.2386e-01, -5.4332e-02,
         -1.4223e-01,  1.1155e-01,  2.3546e-01,  3.8853e-02,  1.1227e-01,
         -2.9981e-02, -3.5384e-02, -1.3603e-01,  3.1001e-01, -1.4615e-01,
          2.5058e-02, -9.1489e-02, -2.1435e-01,  3.0697e-02, -2.5929e-02,
          3.2241e-01,  3.7920e-01,  2.0833e-01,  2.8212e-01, -1.0324e-01,
         -1.6585e-01, -1.8386e-01,  2.0189e-02,  2.7767e-01, -1.3822e-01,
         -1.3711e-01,  9.5865e-03,  1.1056e-02, -1.0575e-01, -5.5155e-02,
          1.1809e-01, -1.2300e-01,  2.4179e-01, -2.8298e-02,  7.4502e-02,
         -3.0307e-01,  2.4275e-02,  7.3545e-02, -6.9410e-02,  1.2794e-01,
          7.5693e-02,  1.5065e-01, -9.7550e-02,  3.4761e-01,  2.7095e-01,
         -4.5170e-02, -1.2539e-01,  3.8548e-03,  2.8808e-01, -9.7298e-02,
          3.0336e-02, -3.0973e-01,  7.9866e-02,  2.3738e-01,  1.2550e-01,
          7.3314e-03, -1.5217e-01,  2.0428e-01, -3.5740e-02,  1.4864e-01,
         -3.2093e-01, -5.4270e-02,  1.2042e-02, -1.4123e-01, -1.0701e-01,
         -3.3997e-01, -3.5408e-02, -1.8080e-01,  1.0898e-01,  1.1176e-01,
          1.4616e-01,  5.3214e-02, -8.9582e-02, -2.4846e-01, -2.1512e-01,
         -1.8585e-01, -7.4543e-02,  1.8495e-01,  1.3112e-01, -2.9189e-01,
         -2.3716e-01,  1.4231e-01,  1.8316e-01,  1.1146e-01,  1.0917e-01,
         -7.8276e-02, -3.5784e-01, -2.0579e-01, -1.9995e-01, -2.0056e-02,
          1.9377e-01,  2.1209e-01,  1.1557e-01,  1.5575e-01,  3.7109e-02,
         -1.9799e-01,  1.2692e-01, -1.2687e-01,  3.2986e-01, -4.0038e-01,
         -5.4040e-02,  1.9603e-01, -1.0432e-01, -4.4281e-02, -9.4947e-02,
          1.9225e-01,  2.4538e-01,  1.6693e-01,  1.7623e-02,  2.7655e-01,
         -2.7252e-01, -3.5374e-02,  2.1649e-01,  1.1542e-01, -3.2575e-01,
         -9.5898e-02, -1.7769e-01, -1.7478e-01,  1.2413e-02, -9.4918e-02,
         -1.7591e-01, -7.7178e-02,  8.4715e-02,  1.1410e-01,  2.3401e-01,
          4.6640e-02,  1.6343e-02,  8.4249e-02, -9.6963e-02,  4.9761e-03,
         -1.2689e-01, -8.9776e-02,  1.4109e-01, -2.3152e-01,  3.0876e-01,
         -2.1192e-01,  2.8687e-01, -1.6530e-01,  1.0156e-01,  1.3087e-01,
         -1.3041e-01,  2.9489e-01, -1.7078e-01,  2.2375e-01,  1.1248e-01,
          7.6252e-02, -2.7074e-02,  7.4888e-02, -2.2466e-01,  5.8946e-02,
         -1.5730e-01,  1.9001e-01,  1.6656e-01,  2.3558e-01,  8.8893e-02,
          4.6385e-02, -4.6853e-03, -3.9195e-02, -6.8834e-02,  6.7098e-02,
         -2.5421e-01, -1.3098e-01,  3.3280e-01, -1.1145e-01,  3.0578e-01,
          1.4134e-01, -7.8914e-02,  1.6024e-01, -2.5977e-01,  4.2665e-02,
          1.7734e-01, -1.5616e-01, -3.0725e-01, -1.6099e-01, -9.4044e-02,
          5.9506e-02,  2.2976e-01, -1.7763e-01, -2.6950e-01,  3.8000e-01,
          1.7562e-01,  3.7771e-02,  1.0278e-01,  3.2222e-01, -2.1560e-02,
         -1.5225e-01, -2.3036e-01, -1.3021e-01, -3.0180e-01,  2.4546e-01,
          6.7754e-02, -3.0570e-01, -2.9963e-01,  1.5654e-02, -1.8943e-01,
         -2.3144e-01,  2.8879e-01,  7.4722e-02, -1.5568e-01, -2.0820e-01,
          4.9041e-02,  3.9942e-01,  4.3492e-02,  8.4227e-02,  1.3005e-01,
         -9.3410e-02,  2.1089e-01,  8.5407e-02, -2.3646e-01,  1.1235e-01,
          2.1036e-01, -1.5971e-01,  7.9207e-02,  4.4568e-03, -2.2224e-01,
          3.1588e-02, -2.5247e-01, -1.8240e-01, -8.3811e-02, -3.5396e-01,
         -9.2816e-02,  3.5115e-02,  2.7964e-01, -9.2329e-02, -3.5224e-01,
         -2.4336e-01,  1.5316e-01, -1.8951e-01, -1.5665e-01, -2.2028e-01,
         -2.0556e-01, -1.5417e-01,  4.3107e-02, -1.4996e-01, -1.7838e-01,
         -1.0692e-01, -1.7765e-01, -8.7658e-03,  1.6875e-01, -2.1353e-01,
          1.7508e-01, -8.9377e-02, -1.9662e-01,  2.5831e-02, -5.6539e-02,
          5.4678e-02,  2.4562e-01,  9.2557e-02, -5.1224e-02, -2.1296e-02,
         -2.0423e-01,  4.4212e-03, -1.5627e-01,  1.5368e-01, -9.0215e-02,
          4.5537e-02,  2.7957e-01, -1.7029e-01,  2.9199e-01, -9.2008e-02,
         -1.1972e-01, -1.1973e-01, -3.9062e-01, -6.3714e-03, -1.8681e-02,
          4.3476e-02,  1.0941e-01,  1.5459e-02, -2.8024e-02, -2.9083e-01,
         -2.1282e-01,  1.7896e-01, -1.1782e-01, -2.9580e-01,  9.5791e-02,
         -1.6213e-01, -1.0290e-03,  9.6139e-02, -6.0271e-02,  7.4006e-02,
          1.4452e-01, -6.5647e-02,  2.0084e-01, -1.4069e-02, -1.2897e-01,
          2.6349e-01, -2.3983e-01,  1.7705e-02,  1.7037e-01,  3.0223e-02,
         -2.9845e-01,  1.0508e-01, -1.6406e-01, -3.5936e-02, -8.8760e-02,
         -2.6679e-01,  3.3564e-01,  3.7482e-04,  5.0903e-02, -7.3588e-02,
         -1.6273e-01, -5.2870e-02, -2.3405e-01, -7.3421e-02,  6.7705e-03,
         -1.6738e-01, -3.5341e-02,  1.6683e-01, -1.5272e-01,  3.9206e-01,
          2.2943e-01, -1.5948e-01, -2.8566e-02, -1.0889e-02, -2.4224e-01,
          6.9751e-02,  9.7223e-03, -2.8483e-01, -6.3500e-02,  1.8432e-01,
          4.8258e-02,  3.6758e-01, -1.7792e-01,  1.7039e-02,  3.1149e-01,
          9.3328e-02, -2.3158e-01, -3.5395e-01, -1.0560e-01,  2.2844e-01,
          8.0793e-02,  1.4810e-01, -3.0206e-01, -3.4022e-01,  1.7620e-01,
          4.3809e-02,  9.0087e-02,  1.5914e-01, -6.8204e-02,  2.5665e-01,
         -1.8012e-01,  3.7484e-02,  4.8088e-02,  2.3510e-02, -1.1832e-01,
          1.0292e-01,  1.4461e-01,  9.2944e-02, -1.4286e-03,  1.8287e-01,
          1.7623e-01,  6.0158e-02,  1.7079e-01,  1.9798e-01, -1.8351e-01,
         -4.1477e-01,  2.4582e-01,  1.0249e-01, -3.3297e-02, -2.0311e-01,
         -2.5807e-01, -2.9441e-02,  2.5160e-01, -2.8196e-01, -2.2125e-01,
         -1.3952e-01, -5.6166e-02,  2.8915e-02, -1.9787e-01, -1.6558e-01,
         -1.7816e-01, -3.1428e-01, -1.7320e-01,  1.2468e-02, -3.4252e-01,
         -2.5784e-01, -7.1416e-02, -9.2996e-02,  1.6461e-01, -3.2702e-01,
          1.4028e-01,  2.0673e-01, -5.7455e-02, -2.6848e-01,  1.1147e-01,
         -4.8179e-02,  9.7699e-02, -2.2503e-01, -1.3832e-01,  1.9701e-02,
         -8.6869e-02, -4.8751e-02,  6.2277e-02, -3.3196e-01,  2.0513e-01,
          4.2906e-02, -3.1485e-01, -1.9783e-01, -1.8252e-01,  8.9203e-03,
          2.3651e-01, -1.7068e-01,  9.3493e-02,  1.2389e-01, -2.1146e-01,
          8.2649e-03,  1.5572e-01, -2.2668e-01,  6.7394e-02,  1.9482e-02,
          7.9862e-02, -7.1562e-02,  8.8041e-02,  2.9078e-01, -2.9057e-01,
          1.9924e-01,  7.9529e-02,  2.3030e-01, -1.8758e-01, -2.1552e-01,
          1.6985e-01, -1.6580e-01, -2.1389e-01, -2.4635e-01, -1.9783e-01,
          7.4881e-02, -9.2235e-02,  5.3853e-02, -2.7720e-01, -4.0823e-02,
          2.2342e-01,  1.6657e-01, -1.2662e-01, -1.9808e-02,  5.6801e-02,
          2.1904e-02,  6.3948e-02, -2.0601e-01, -2.2994e-01, -1.4389e-01,
          5.3174e-02,  6.4131e-02,  4.4927e-02, -3.7137e-01, -1.5741e-01,
         -2.5703e-01,  1.2718e-01,  2.0193e-02,  3.8737e-02, -7.7474e-02,
          1.9992e-02, -1.8949e-01, -1.0489e-01, -6.3354e-02, -2.5072e-01,
         -2.2850e-01, -1.9215e-01, -2.7560e-01, -5.5963e-02, -1.2828e-01,
          1.2989e-01,  8.0240e-02,  1.1768e-01,  3.6903e-01,  3.2748e-01,
          2.8244e-01,  7.6465e-02, -1.3270e-01,  1.6062e-01,  1.6020e-02,
          1.8847e-01, -1.0488e-01, -2.7101e-01,  2.8572e-01,  2.2558e-01,
         -1.0301e-01,  1.4395e-01,  1.6343e-01, -2.3641e-01, -1.2907e-01,
         -2.7267e-02,  2.6302e-01, -1.8550e-01,  2.4225e-01,  1.8058e-01,
         -2.0332e-01, -1.1652e-01,  2.2879e-01, -6.5583e-02,  3.0162e-02,
          5.5261e-02,  3.3168e-02,  1.4287e-03,  2.4233e-01, -2.5623e-01,
          1.4555e-01, -9.7221e-02, -1.4414e-01,  2.5351e-01, -1.6486e-01,
          8.8751e-03, -1.3138e-01, -5.0337e-02, -2.3413e-01, -1.2613e-01,
          1.0165e-01,  1.7950e-01, -4.9932e-02,  1.9990e-01, -2.5763e-01,
         -3.1997e-01, -1.8444e-01, -2.4811e-01, -6.7918e-02,  2.8393e-01,
          3.9342e-02, -3.8641e-01, -2.4957e-01, -4.2098e-02,  1.2375e-01,
         -2.3292e-01, -1.2942e-01, -9.9817e-02,  2.1444e-02, -2.8142e-02,
         -6.4317e-02, -2.3902e-01, -3.0746e-01, -8.9892e-02, -1.2646e-01,
         -3.2790e-01,  2.3242e-01,  9.5534e-02, -1.0982e-01,  2.6479e-01,
          1.5996e-01, -3.1966e-01, -1.9431e-01,  7.6029e-02, -2.0056e-01,
         -4.4122e-02, -1.9894e-01, -3.2973e-01,  1.0175e-01, -3.6016e-02,
         -1.1808e-01, -1.6042e-01, -2.7750e-01,  4.7654e-02, -6.1258e-02,
         -4.5565e-01, -1.4322e-01, -1.6719e-01,  1.1150e-01, -6.1786e-02,
         -1.3581e-01, -1.2923e-01, -8.6849e-02, -2.0869e-01, -9.5694e-02,
         -3.2178e-01,  4.5601e-02,  9.0810e-02, -3.4218e-01, -1.2418e-01,
         -2.1381e-01, -1.2038e-01, -4.3754e-02,  6.3526e-02,  9.4710e-02,
          1.8775e-02, -2.5421e-01,  9.3967e-03,  2.0880e-01,  1.6493e-01,
         -2.8366e-01, -1.0564e-01,  2.7419e-01]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.0000% F1: 0.2750
Applying ckpt from fold 1 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.8000% F1: 0.2659
Applying ckpt from fold 2 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2758
Applying ckpt from fold 3 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.2000% F1: 0.3016
Applying ckpt from fold 4 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.6000% F1: 0.2734
Applying ckpt from fold 5 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2811
Applying ckpt from fold 6 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.4000% F1: 0.2852
Applying ckpt from fold 7 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.8000% F1: 0.2685
Applying ckpt from fold 8 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.4000% F1: 0.2727
Applying ckpt from fold 9 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.6000% F1: 0.2733
Metrics by fold:
Fold 0 - Acc: 0.55 F1: 0.28
Fold 1 - Acc: 0.55 F1: 0.27
Fold 2 - Acc: 0.55 F1: 0.28
Fold 3 - Acc: 0.52 F1: 0.30
Fold 4 - Acc: 0.55 F1: 0.27
Fold 5 - Acc: 0.55 F1: 0.28
Fold 6 - Acc: 0.54 F1: 0.29
Fold 7 - Acc: 0.55 F1: 0.27
Fold 8 - Acc: 0.54 F1: 0.27
Fold 9 - Acc: 0.55 F1: 0.27
agg_acc: 0.5452 agg_f1: 0.2772
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[ 1.3939e-03, -6.8716e-02, -2.5557e-01,  2.8171e-02, -8.7808e-03,
         -2.5491e-01,  2.4635e-01, -1.7451e-01, -2.3248e-02,  2.3335e-01,
          2.6176e-01,  1.3909e-01, -1.2589e-01,  1.6319e-01,  2.4349e-02,
         -1.3283e-01,  4.8036e-02,  4.0980e-01, -2.1196e-01, -2.3831e-01,
         -9.6281e-03, -5.5775e-02,  1.1464e-02, -2.9264e-01,  9.9885e-02,
         -2.0102e-01, -1.9214e-01, -3.0318e-01, -4.2442e-02, -5.4449e-02,
         -1.2967e-04, -7.1719e-02,  2.0007e-01,  9.2549e-03,  5.3880e-02,
         -6.0826e-02,  8.9025e-02,  2.9168e-01,  2.3036e-01, -1.1622e-01,
         -6.1775e-02,  1.8710e-01, -1.6608e-01, -2.2137e-01,  1.6387e-01,
         -1.2285e-01,  3.0026e-01,  2.8564e-01, -3.5229e-01, -1.0878e-01,
          4.0280e-01,  1.5114e-01,  1.1360e-02, -2.0095e-02, -1.3847e-01,
          7.2091e-04, -1.1731e-01, -2.7096e-01,  2.7509e-02,  1.0600e-01,
          4.5664e-02,  1.3611e-01, -1.6287e-01, -2.6011e-01, -8.1596e-02,
          1.9391e-01, -6.8843e-02,  6.6795e-02,  3.0044e-01,  1.4518e-04,
          1.3836e-01, -2.1662e-01, -1.4751e-01, -4.5692e-03,  7.7596e-03,
          1.5091e-01, -1.9701e-01,  3.9364e-02,  2.4326e-02, -1.4290e-01,
         -2.3443e-01, -2.8338e-01,  2.4571e-01, -3.4772e-01, -2.1874e-01,
          4.0258e-02,  1.0768e-01,  2.4987e-01,  2.3627e-01, -1.1554e-01,
          2.1028e-01,  1.6711e-01, -1.5543e-01, -1.8313e-02, -3.3042e-01,
         -2.3139e-01,  1.1625e-01, -3.2922e-01, -1.7406e-01, -2.3016e-01,
         -1.3942e-01, -4.9668e-02, -2.7628e-01,  1.0165e-02,  8.2532e-02,
          6.4771e-02,  1.9546e-01, -3.2410e-01,  1.8964e-01, -1.6898e-01,
         -2.2098e-01, -1.2092e-01, -1.3189e-02,  2.6864e-02,  2.7784e-01,
         -6.3231e-02,  6.4781e-02,  3.4362e-01, -2.2732e-02, -3.5275e-01,
          9.8142e-03, -2.4852e-01, -2.7906e-02, -5.1745e-02, -9.5929e-02,
          1.7100e-02,  4.3980e-02, -4.3783e-02,  3.7871e-01,  1.2682e-01,
         -3.2154e-01, -2.1401e-01,  6.4307e-02,  7.8588e-02,  2.3951e-01,
          1.3997e-02, -7.8034e-02, -2.2260e-03,  1.9591e-02, -2.4945e-01,
          8.2607e-02, -3.2764e-02,  1.7143e-02,  2.0525e-01, -5.7016e-02,
          1.8229e-01, -2.7006e-02,  1.1357e-01,  9.7994e-02,  5.1746e-02,
          7.9860e-02,  3.8248e-02, -2.3227e-01, -1.3862e-01,  6.6153e-02,
          2.6249e-01, -5.7370e-02, -1.3890e-01, -4.0898e-01, -2.8864e-01,
         -2.3905e-02,  2.0195e-01,  1.1847e-01, -2.4378e-01, -1.7138e-01,
         -1.7932e-01,  2.7026e-01, -1.0431e-01,  8.6107e-02, -1.0131e-01,
         -8.2868e-02,  9.2653e-02, -3.3071e-02, -3.0312e-01, -2.7937e-01,
         -4.0222e-01, -3.8210e-01,  1.1642e-01, -3.3853e-02,  7.7303e-02,
          1.2355e-01, -2.2809e-01,  4.3379e-02,  1.0617e-02, -1.7532e-01,
         -1.5698e-01,  1.7562e-01, -6.4621e-02, -2.2386e-01, -5.4332e-02,
         -1.4223e-01,  1.1155e-01,  2.3546e-01,  3.8853e-02,  1.1227e-01,
         -2.9981e-02, -3.5384e-02, -1.3603e-01,  3.1001e-01, -1.4615e-01,
          2.5058e-02, -9.1489e-02, -2.1435e-01,  3.0697e-02, -2.5929e-02,
          3.2241e-01,  3.7920e-01,  2.0833e-01,  2.8212e-01, -1.0324e-01,
         -1.6585e-01, -1.8386e-01,  2.0189e-02,  2.7767e-01, -1.3822e-01,
         -1.3711e-01,  9.5865e-03,  1.1056e-02, -1.0575e-01, -5.5155e-02,
          1.1809e-01, -1.2300e-01,  2.4179e-01, -2.8298e-02,  7.4502e-02,
         -3.0307e-01,  2.4275e-02,  7.3545e-02, -6.9410e-02,  1.2794e-01,
          7.5693e-02,  1.5065e-01, -9.7550e-02,  3.4761e-01,  2.7095e-01,
         -4.5170e-02, -1.2539e-01,  3.8548e-03,  2.8808e-01, -9.7298e-02,
          3.0336e-02, -3.0973e-01,  7.9866e-02,  2.3738e-01,  1.2550e-01,
          7.3314e-03, -1.5217e-01,  2.0428e-01, -3.5740e-02,  1.4864e-01,
         -3.2093e-01, -5.4270e-02,  1.2042e-02, -1.4123e-01, -1.0701e-01,
         -3.3997e-01, -3.5408e-02, -1.8080e-01,  1.0898e-01,  1.1176e-01,
          1.4616e-01,  5.3214e-02, -8.9582e-02, -2.4846e-01, -2.1512e-01,
         -1.8585e-01, -7.4543e-02,  1.8495e-01,  1.3112e-01, -2.9189e-01,
         -2.3716e-01,  1.4231e-01,  1.8316e-01,  1.1146e-01,  1.0917e-01,
         -7.8276e-02, -3.5784e-01, -2.0579e-01, -1.9995e-01, -2.0056e-02,
          1.9377e-01,  2.1209e-01,  1.1557e-01,  1.5575e-01,  3.7109e-02,
         -1.9799e-01,  1.2692e-01, -1.2687e-01,  3.2986e-01, -4.0038e-01,
         -5.4040e-02,  1.9603e-01, -1.0432e-01, -4.4281e-02, -9.4947e-02,
          1.9225e-01,  2.4538e-01,  1.6693e-01,  1.7623e-02,  2.7655e-01,
         -2.7252e-01, -3.5374e-02,  2.1649e-01,  1.1542e-01, -3.2575e-01,
         -9.5898e-02, -1.7769e-01, -1.7478e-01,  1.2413e-02, -9.4918e-02,
         -1.7591e-01, -7.7178e-02,  8.4715e-02,  1.1410e-01,  2.3401e-01,
          4.6640e-02,  1.6343e-02,  8.4249e-02, -9.6963e-02,  4.9761e-03,
         -1.2689e-01, -8.9776e-02,  1.4109e-01, -2.3152e-01,  3.0876e-01,
         -2.1192e-01,  2.8687e-01, -1.6530e-01,  1.0156e-01,  1.3087e-01,
         -1.3041e-01,  2.9489e-01, -1.7078e-01,  2.2375e-01,  1.1248e-01,
          7.6252e-02, -2.7074e-02,  7.4888e-02, -2.2466e-01,  5.8946e-02,
         -1.5730e-01,  1.9001e-01,  1.6656e-01,  2.3558e-01,  8.8893e-02,
          4.6385e-02, -4.6853e-03, -3.9195e-02, -6.8834e-02,  6.7098e-02,
         -2.5421e-01, -1.3098e-01,  3.3280e-01, -1.1145e-01,  3.0578e-01,
          1.4134e-01, -7.8914e-02,  1.6024e-01, -2.5977e-01,  4.2665e-02,
          1.7734e-01, -1.5616e-01, -3.0725e-01, -1.6099e-01, -9.4044e-02,
          5.9506e-02,  2.2976e-01, -1.7763e-01, -2.6950e-01,  3.8000e-01,
          1.7562e-01,  3.7771e-02,  1.0278e-01,  3.2222e-01, -2.1560e-02,
         -1.5225e-01, -2.3036e-01, -1.3021e-01, -3.0180e-01,  2.4546e-01,
          6.7754e-02, -3.0570e-01, -2.9963e-01,  1.5654e-02, -1.8943e-01,
         -2.3144e-01,  2.8879e-01,  7.4722e-02, -1.5568e-01, -2.0820e-01,
          4.9041e-02,  3.9942e-01,  4.3492e-02,  8.4227e-02,  1.3005e-01,
         -9.3410e-02,  2.1089e-01,  8.5407e-02, -2.3646e-01,  1.1235e-01,
          2.1036e-01, -1.5971e-01,  7.9207e-02,  4.4568e-03, -2.2224e-01,
          3.1588e-02, -2.5247e-01, -1.8240e-01, -8.3811e-02, -3.5396e-01,
         -9.2816e-02,  3.5115e-02,  2.7964e-01, -9.2329e-02, -3.5224e-01,
         -2.4336e-01,  1.5316e-01, -1.8951e-01, -1.5665e-01, -2.2028e-01,
         -2.0556e-01, -1.5417e-01,  4.3107e-02, -1.4996e-01, -1.7838e-01,
         -1.0692e-01, -1.7765e-01, -8.7658e-03,  1.6875e-01, -2.1353e-01,
          1.7508e-01, -8.9377e-02, -1.9662e-01,  2.5831e-02, -5.6539e-02,
          5.4678e-02,  2.4562e-01,  9.2557e-02, -5.1224e-02, -2.1296e-02,
         -2.0423e-01,  4.4212e-03, -1.5627e-01,  1.5368e-01, -9.0215e-02,
          4.5537e-02,  2.7957e-01, -1.7029e-01,  2.9199e-01, -9.2008e-02,
         -1.1972e-01, -1.1973e-01, -3.9062e-01, -6.3714e-03, -1.8681e-02,
          4.3476e-02,  1.0941e-01,  1.5459e-02, -2.8024e-02, -2.9083e-01,
         -2.1282e-01,  1.7896e-01, -1.1782e-01, -2.9580e-01,  9.5791e-02,
         -1.6213e-01, -1.0290e-03,  9.6139e-02, -6.0271e-02,  7.4006e-02,
          1.4452e-01, -6.5647e-02,  2.0084e-01, -1.4069e-02, -1.2897e-01,
          2.6349e-01, -2.3983e-01,  1.7705e-02,  1.7037e-01,  3.0223e-02,
         -2.9845e-01,  1.0508e-01, -1.6406e-01, -3.5936e-02, -8.8760e-02,
         -2.6679e-01,  3.3564e-01,  3.7482e-04,  5.0903e-02, -7.3588e-02,
         -1.6273e-01, -5.2870e-02, -2.3405e-01, -7.3421e-02,  6.7705e-03,
         -1.6738e-01, -3.5341e-02,  1.6683e-01, -1.5272e-01,  3.9206e-01,
          2.2943e-01, -1.5948e-01, -2.8566e-02, -1.0889e-02, -2.4224e-01,
          6.9751e-02,  9.7223e-03, -2.8483e-01, -6.3500e-02,  1.8432e-01,
          4.8258e-02,  3.6758e-01, -1.7792e-01,  1.7039e-02,  3.1149e-01,
          9.3328e-02, -2.3158e-01, -3.5395e-01, -1.0560e-01,  2.2844e-01,
          8.0793e-02,  1.4810e-01, -3.0206e-01, -3.4022e-01,  1.7620e-01,
          4.3809e-02,  9.0087e-02,  1.5914e-01, -6.8204e-02,  2.5665e-01,
         -1.8012e-01,  3.7484e-02,  4.8088e-02,  2.3510e-02, -1.1832e-01,
          1.0292e-01,  1.4461e-01,  9.2944e-02, -1.4286e-03,  1.8287e-01,
          1.7623e-01,  6.0158e-02,  1.7079e-01,  1.9798e-01, -1.8351e-01,
         -4.1477e-01,  2.4582e-01,  1.0249e-01, -3.3297e-02, -2.0311e-01,
         -2.5807e-01, -2.9441e-02,  2.5160e-01, -2.8196e-01, -2.2125e-01,
         -1.3952e-01, -5.6166e-02,  2.8915e-02, -1.9787e-01, -1.6558e-01,
         -1.7816e-01, -3.1428e-01, -1.7320e-01,  1.2468e-02, -3.4252e-01,
         -2.5784e-01, -7.1416e-02, -9.2996e-02,  1.6461e-01, -3.2702e-01,
          1.4028e-01,  2.0673e-01, -5.7455e-02, -2.6848e-01,  1.1147e-01,
         -4.8179e-02,  9.7699e-02, -2.2503e-01, -1.3832e-01,  1.9701e-02,
         -8.6869e-02, -4.8751e-02,  6.2277e-02, -3.3196e-01,  2.0513e-01,
          4.2906e-02, -3.1485e-01, -1.9783e-01, -1.8252e-01,  8.9203e-03,
          2.3651e-01, -1.7068e-01,  9.3493e-02,  1.2389e-01, -2.1146e-01,
          8.2649e-03,  1.5572e-01, -2.2668e-01,  6.7394e-02,  1.9482e-02,
          7.9862e-02, -7.1562e-02,  8.8041e-02,  2.9078e-01, -2.9057e-01,
          1.9924e-01,  7.9529e-02,  2.3030e-01, -1.8758e-01, -2.1552e-01,
          1.6985e-01, -1.6580e-01, -2.1389e-01, -2.4635e-01, -1.9783e-01,
          7.4881e-02, -9.2235e-02,  5.3853e-02, -2.7720e-01, -4.0823e-02,
          2.2342e-01,  1.6657e-01, -1.2662e-01, -1.9808e-02,  5.6801e-02,
          2.1904e-02,  6.3948e-02, -2.0601e-01, -2.2994e-01, -1.4389e-01,
          5.3174e-02,  6.4131e-02,  4.4927e-02, -3.7137e-01, -1.5741e-01,
         -2.5703e-01,  1.2718e-01,  2.0193e-02,  3.8737e-02, -7.7474e-02,
          1.9992e-02, -1.8949e-01, -1.0489e-01, -6.3354e-02, -2.5072e-01,
         -2.2850e-01, -1.9215e-01, -2.7560e-01, -5.5963e-02, -1.2828e-01,
          1.2989e-01,  8.0240e-02,  1.1768e-01,  3.6903e-01,  3.2748e-01,
          2.8244e-01,  7.6465e-02, -1.3270e-01,  1.6062e-01,  1.6020e-02,
          1.8847e-01, -1.0488e-01, -2.7101e-01,  2.8572e-01,  2.2558e-01,
         -1.0301e-01,  1.4395e-01,  1.6343e-01, -2.3641e-01, -1.2907e-01,
         -2.7267e-02,  2.6302e-01, -1.8550e-01,  2.4225e-01,  1.8058e-01,
         -2.0332e-01, -1.1652e-01,  2.2879e-01, -6.5583e-02,  3.0162e-02,
          5.5261e-02,  3.3168e-02,  1.4287e-03,  2.4233e-01, -2.5623e-01,
          1.4555e-01, -9.7221e-02, -1.4414e-01,  2.5351e-01, -1.6486e-01,
          8.8751e-03, -1.3138e-01, -5.0337e-02, -2.3413e-01, -1.2613e-01,
          1.0165e-01,  1.7950e-01, -4.9932e-02,  1.9990e-01, -2.5763e-01,
         -3.1997e-01, -1.8444e-01, -2.4811e-01, -6.7918e-02,  2.8393e-01,
          3.9342e-02, -3.8641e-01, -2.4957e-01, -4.2098e-02,  1.2375e-01,
         -2.3292e-01, -1.2942e-01, -9.9817e-02,  2.1444e-02, -2.8142e-02,
         -6.4317e-02, -2.3902e-01, -3.0746e-01, -8.9892e-02, -1.2646e-01,
         -3.2790e-01,  2.3242e-01,  9.5534e-02, -1.0982e-01,  2.6479e-01,
          1.5996e-01, -3.1966e-01, -1.9431e-01,  7.6029e-02, -2.0056e-01,
         -4.4122e-02, -1.9894e-01, -3.2973e-01,  1.0175e-01, -3.6016e-02,
         -1.1808e-01, -1.6042e-01, -2.7750e-01,  4.7654e-02, -6.1258e-02,
         -4.5565e-01, -1.4322e-01, -1.6719e-01,  1.1150e-01, -6.1786e-02,
         -1.3581e-01, -1.2923e-01, -8.6849e-02, -2.0869e-01, -9.5694e-02,
         -3.2178e-01,  4.5601e-02,  9.0810e-02, -3.4218e-01, -1.2418e-01,
         -2.1381e-01, -1.2038e-01, -4.3754e-02,  6.3526e-02,  9.4710e-02,
          1.8775e-02, -2.5421e-01,  9.3967e-03,  2.0880e-01,  1.6493e-01,
         -2.8366e-01, -1.0564e-01,  2.7419e-01]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.6000% F1: 0.3204
Applying ckpt from fold 1 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2549
Applying ckpt from fold 2 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.0000% F1: 0.3130
Applying ckpt from fold 3 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.4000% F1: 0.2413
Applying ckpt from fold 4 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.4000% F1: 0.3179
Applying ckpt from fold 5 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.2000% F1: 0.2968
Applying ckpt from fold 6 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.4000% F1: 0.2936
Applying ckpt from fold 7 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.0000% F1: 0.3248
Applying ckpt from fold 8 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.4000% F1: 0.3274
Applying ckpt from fold 9 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.2000% F1: 0.3032
Metrics by fold:
Fold 0 - Acc: 0.53 F1: 0.32
Fold 1 - Acc: 0.55 F1: 0.25
Fold 2 - Acc: 0.52 F1: 0.31
Fold 3 - Acc: 0.55 F1: 0.24
Fold 4 - Acc: 0.51 F1: 0.32
Fold 5 - Acc: 0.51 F1: 0.30
Fold 6 - Acc: 0.52 F1: 0.29
Fold 7 - Acc: 0.52 F1: 0.32
Fold 8 - Acc: 0.51 F1: 0.33
Fold 9 - Acc: 0.53 F1: 0.30
agg_acc: 0.5268 agg_f1: 0.2993
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[ 1.3939e-03, -6.8716e-02, -2.5557e-01,  2.8171e-02, -8.7808e-03,
         -2.5491e-01,  2.4635e-01, -1.7451e-01, -2.3248e-02,  2.3335e-01,
          2.6176e-01,  1.3909e-01, -1.2589e-01,  1.6319e-01,  2.4349e-02,
         -1.3283e-01,  4.8036e-02,  4.0980e-01, -2.1196e-01, -2.3831e-01,
         -9.6281e-03, -5.5775e-02,  1.1464e-02, -2.9264e-01,  9.9885e-02,
         -2.0102e-01, -1.9214e-01, -3.0318e-01, -4.2442e-02, -5.4449e-02,
         -1.2967e-04, -7.1719e-02,  2.0007e-01,  9.2549e-03,  5.3880e-02,
         -6.0826e-02,  8.9025e-02,  2.9168e-01,  2.3036e-01, -1.1622e-01,
         -6.1775e-02,  1.8710e-01, -1.6608e-01, -2.2137e-01,  1.6387e-01,
         -1.2285e-01,  3.0026e-01,  2.8564e-01, -3.5229e-01, -1.0878e-01,
          4.0280e-01,  1.5114e-01,  1.1360e-02, -2.0095e-02, -1.3847e-01,
          7.2091e-04, -1.1731e-01, -2.7096e-01,  2.7509e-02,  1.0600e-01,
          4.5664e-02,  1.3611e-01, -1.6287e-01, -2.6011e-01, -8.1596e-02,
          1.9391e-01, -6.8843e-02,  6.6795e-02,  3.0044e-01,  1.4518e-04,
          1.3836e-01, -2.1662e-01, -1.4751e-01, -4.5692e-03,  7.7596e-03,
          1.5091e-01, -1.9701e-01,  3.9364e-02,  2.4326e-02, -1.4290e-01,
         -2.3443e-01, -2.8338e-01,  2.4571e-01, -3.4772e-01, -2.1874e-01,
          4.0258e-02,  1.0768e-01,  2.4987e-01,  2.3627e-01, -1.1554e-01,
          2.1028e-01,  1.6711e-01, -1.5543e-01, -1.8313e-02, -3.3042e-01,
         -2.3139e-01,  1.1625e-01, -3.2922e-01, -1.7406e-01, -2.3016e-01,
         -1.3942e-01, -4.9668e-02, -2.7628e-01,  1.0165e-02,  8.2532e-02,
          6.4771e-02,  1.9546e-01, -3.2410e-01,  1.8964e-01, -1.6898e-01,
         -2.2098e-01, -1.2092e-01, -1.3189e-02,  2.6864e-02,  2.7784e-01,
         -6.3231e-02,  6.4781e-02,  3.4362e-01, -2.2732e-02, -3.5275e-01,
          9.8142e-03, -2.4852e-01, -2.7906e-02, -5.1745e-02, -9.5929e-02,
          1.7100e-02,  4.3980e-02, -4.3783e-02,  3.7871e-01,  1.2682e-01,
         -3.2154e-01, -2.1401e-01,  6.4307e-02,  7.8588e-02,  2.3951e-01,
          1.3997e-02, -7.8034e-02, -2.2260e-03,  1.9591e-02, -2.4945e-01,
          8.2607e-02, -3.2764e-02,  1.7143e-02,  2.0525e-01, -5.7016e-02,
          1.8229e-01, -2.7006e-02,  1.1357e-01,  9.7994e-02,  5.1746e-02,
          7.9860e-02,  3.8248e-02, -2.3227e-01, -1.3862e-01,  6.6153e-02,
          2.6249e-01, -5.7370e-02, -1.3890e-01, -4.0898e-01, -2.8864e-01,
         -2.3905e-02,  2.0195e-01,  1.1847e-01, -2.4378e-01, -1.7138e-01,
         -1.7932e-01,  2.7026e-01, -1.0431e-01,  8.6107e-02, -1.0131e-01,
         -8.2868e-02,  9.2653e-02, -3.3071e-02, -3.0312e-01, -2.7937e-01,
         -4.0222e-01, -3.8210e-01,  1.1642e-01, -3.3853e-02,  7.7303e-02,
          1.2355e-01, -2.2809e-01,  4.3379e-02,  1.0617e-02, -1.7532e-01,
         -1.5698e-01,  1.7562e-01, -6.4621e-02, -2.2386e-01, -5.4332e-02,
         -1.4223e-01,  1.1155e-01,  2.3546e-01,  3.8853e-02,  1.1227e-01,
         -2.9981e-02, -3.5384e-02, -1.3603e-01,  3.1001e-01, -1.4615e-01,
          2.5058e-02, -9.1489e-02, -2.1435e-01,  3.0697e-02, -2.5929e-02,
          3.2241e-01,  3.7920e-01,  2.0833e-01,  2.8212e-01, -1.0324e-01,
         -1.6585e-01, -1.8386e-01,  2.0189e-02,  2.7767e-01, -1.3822e-01,
         -1.3711e-01,  9.5865e-03,  1.1056e-02, -1.0575e-01, -5.5155e-02,
          1.1809e-01, -1.2300e-01,  2.4179e-01, -2.8298e-02,  7.4502e-02,
         -3.0307e-01,  2.4275e-02,  7.3545e-02, -6.9410e-02,  1.2794e-01,
          7.5693e-02,  1.5065e-01, -9.7550e-02,  3.4761e-01,  2.7095e-01,
         -4.5170e-02, -1.2539e-01,  3.8548e-03,  2.8808e-01, -9.7298e-02,
          3.0336e-02, -3.0973e-01,  7.9866e-02,  2.3738e-01,  1.2550e-01,
          7.3314e-03, -1.5217e-01,  2.0428e-01, -3.5740e-02,  1.4864e-01,
         -3.2093e-01, -5.4270e-02,  1.2042e-02, -1.4123e-01, -1.0701e-01,
         -3.3997e-01, -3.5408e-02, -1.8080e-01,  1.0898e-01,  1.1176e-01,
          1.4616e-01,  5.3214e-02, -8.9582e-02, -2.4846e-01, -2.1512e-01,
         -1.8585e-01, -7.4543e-02,  1.8495e-01,  1.3112e-01, -2.9189e-01,
         -2.3716e-01,  1.4231e-01,  1.8316e-01,  1.1146e-01,  1.0917e-01,
         -7.8276e-02, -3.5784e-01, -2.0579e-01, -1.9995e-01, -2.0056e-02,
          1.9377e-01,  2.1209e-01,  1.1557e-01,  1.5575e-01,  3.7109e-02,
         -1.9799e-01,  1.2692e-01, -1.2687e-01,  3.2986e-01, -4.0038e-01,
         -5.4040e-02,  1.9603e-01, -1.0432e-01, -4.4281e-02, -9.4947e-02,
          1.9225e-01,  2.4538e-01,  1.6693e-01,  1.7623e-02,  2.7655e-01,
         -2.7252e-01, -3.5374e-02,  2.1649e-01,  1.1542e-01, -3.2575e-01,
         -9.5898e-02, -1.7769e-01, -1.7478e-01,  1.2413e-02, -9.4918e-02,
         -1.7591e-01, -7.7178e-02,  8.4715e-02,  1.1410e-01,  2.3401e-01,
          4.6640e-02,  1.6343e-02,  8.4249e-02, -9.6963e-02,  4.9761e-03,
         -1.2689e-01, -8.9776e-02,  1.4109e-01, -2.3152e-01,  3.0876e-01,
         -2.1192e-01,  2.8687e-01, -1.6530e-01,  1.0156e-01,  1.3087e-01,
         -1.3041e-01,  2.9489e-01, -1.7078e-01,  2.2375e-01,  1.1248e-01,
          7.6252e-02, -2.7074e-02,  7.4888e-02, -2.2466e-01,  5.8946e-02,
         -1.5730e-01,  1.9001e-01,  1.6656e-01,  2.3558e-01,  8.8893e-02,
          4.6385e-02, -4.6853e-03, -3.9195e-02, -6.8834e-02,  6.7098e-02,
         -2.5421e-01, -1.3098e-01,  3.3280e-01, -1.1145e-01,  3.0578e-01,
          1.4134e-01, -7.8914e-02,  1.6024e-01, -2.5977e-01,  4.2665e-02,
          1.7734e-01, -1.5616e-01, -3.0725e-01, -1.6099e-01, -9.4044e-02,
          5.9506e-02,  2.2976e-01, -1.7763e-01, -2.6950e-01,  3.8000e-01,
          1.7562e-01,  3.7771e-02,  1.0278e-01,  3.2222e-01, -2.1560e-02,
         -1.5225e-01, -2.3036e-01, -1.3021e-01, -3.0180e-01,  2.4546e-01,
          6.7754e-02, -3.0570e-01, -2.9963e-01,  1.5654e-02, -1.8943e-01,
         -2.3144e-01,  2.8879e-01,  7.4722e-02, -1.5568e-01, -2.0820e-01,
          4.9041e-02,  3.9942e-01,  4.3492e-02,  8.4227e-02,  1.3005e-01,
         -9.3410e-02,  2.1089e-01,  8.5407e-02, -2.3646e-01,  1.1235e-01,
          2.1036e-01, -1.5971e-01,  7.9207e-02,  4.4568e-03, -2.2224e-01,
          3.1588e-02, -2.5247e-01, -1.8240e-01, -8.3811e-02, -3.5396e-01,
         -9.2816e-02,  3.5115e-02,  2.7964e-01, -9.2329e-02, -3.5224e-01,
         -2.4336e-01,  1.5316e-01, -1.8951e-01, -1.5665e-01, -2.2028e-01,
         -2.0556e-01, -1.5417e-01,  4.3107e-02, -1.4996e-01, -1.7838e-01,
         -1.0692e-01, -1.7765e-01, -8.7658e-03,  1.6875e-01, -2.1353e-01,
          1.7508e-01, -8.9377e-02, -1.9662e-01,  2.5831e-02, -5.6539e-02,
          5.4678e-02,  2.4562e-01,  9.2557e-02, -5.1224e-02, -2.1296e-02,
         -2.0423e-01,  4.4212e-03, -1.5627e-01,  1.5368e-01, -9.0215e-02,
          4.5537e-02,  2.7957e-01, -1.7029e-01,  2.9199e-01, -9.2008e-02,
         -1.1972e-01, -1.1973e-01, -3.9062e-01, -6.3714e-03, -1.8681e-02,
          4.3476e-02,  1.0941e-01,  1.5459e-02, -2.8024e-02, -2.9083e-01,
         -2.1282e-01,  1.7896e-01, -1.1782e-01, -2.9580e-01,  9.5791e-02,
         -1.6213e-01, -1.0290e-03,  9.6139e-02, -6.0271e-02,  7.4006e-02,
          1.4452e-01, -6.5647e-02,  2.0084e-01, -1.4069e-02, -1.2897e-01,
          2.6349e-01, -2.3983e-01,  1.7705e-02,  1.7037e-01,  3.0223e-02,
         -2.9845e-01,  1.0508e-01, -1.6406e-01, -3.5936e-02, -8.8760e-02,
         -2.6679e-01,  3.3564e-01,  3.7482e-04,  5.0903e-02, -7.3588e-02,
         -1.6273e-01, -5.2870e-02, -2.3405e-01, -7.3421e-02,  6.7705e-03,
         -1.6738e-01, -3.5341e-02,  1.6683e-01, -1.5272e-01,  3.9206e-01,
          2.2943e-01, -1.5948e-01, -2.8566e-02, -1.0889e-02, -2.4224e-01,
          6.9751e-02,  9.7223e-03, -2.8483e-01, -6.3500e-02,  1.8432e-01,
          4.8258e-02,  3.6758e-01, -1.7792e-01,  1.7039e-02,  3.1149e-01,
          9.3328e-02, -2.3158e-01, -3.5395e-01, -1.0560e-01,  2.2844e-01,
          8.0793e-02,  1.4810e-01, -3.0206e-01, -3.4022e-01,  1.7620e-01,
          4.3809e-02,  9.0087e-02,  1.5914e-01, -6.8204e-02,  2.5665e-01,
         -1.8012e-01,  3.7484e-02,  4.8088e-02,  2.3510e-02, -1.1832e-01,
          1.0292e-01,  1.4461e-01,  9.2944e-02, -1.4286e-03,  1.8287e-01,
          1.7623e-01,  6.0158e-02,  1.7079e-01,  1.9798e-01, -1.8351e-01,
         -4.1477e-01,  2.4582e-01,  1.0249e-01, -3.3297e-02, -2.0311e-01,
         -2.5807e-01, -2.9441e-02,  2.5160e-01, -2.8196e-01, -2.2125e-01,
         -1.3952e-01, -5.6166e-02,  2.8915e-02, -1.9787e-01, -1.6558e-01,
         -1.7816e-01, -3.1428e-01, -1.7320e-01,  1.2468e-02, -3.4252e-01,
         -2.5784e-01, -7.1416e-02, -9.2996e-02,  1.6461e-01, -3.2702e-01,
          1.4028e-01,  2.0673e-01, -5.7455e-02, -2.6848e-01,  1.1147e-01,
         -4.8179e-02,  9.7699e-02, -2.2503e-01, -1.3832e-01,  1.9701e-02,
         -8.6869e-02, -4.8751e-02,  6.2277e-02, -3.3196e-01,  2.0513e-01,
          4.2906e-02, -3.1485e-01, -1.9783e-01, -1.8252e-01,  8.9203e-03,
          2.3651e-01, -1.7068e-01,  9.3493e-02,  1.2389e-01, -2.1146e-01,
          8.2649e-03,  1.5572e-01, -2.2668e-01,  6.7394e-02,  1.9482e-02,
          7.9862e-02, -7.1562e-02,  8.8041e-02,  2.9078e-01, -2.9057e-01,
          1.9924e-01,  7.9529e-02,  2.3030e-01, -1.8758e-01, -2.1552e-01,
          1.6985e-01, -1.6580e-01, -2.1389e-01, -2.4635e-01, -1.9783e-01,
          7.4881e-02, -9.2235e-02,  5.3853e-02, -2.7720e-01, -4.0823e-02,
          2.2342e-01,  1.6657e-01, -1.2662e-01, -1.9808e-02,  5.6801e-02,
          2.1904e-02,  6.3948e-02, -2.0601e-01, -2.2994e-01, -1.4389e-01,
          5.3174e-02,  6.4131e-02,  4.4927e-02, -3.7137e-01, -1.5741e-01,
         -2.5703e-01,  1.2718e-01,  2.0193e-02,  3.8737e-02, -7.7474e-02,
          1.9992e-02, -1.8949e-01, -1.0489e-01, -6.3354e-02, -2.5072e-01,
         -2.2850e-01, -1.9215e-01, -2.7560e-01, -5.5963e-02, -1.2828e-01,
          1.2989e-01,  8.0240e-02,  1.1768e-01,  3.6903e-01,  3.2748e-01,
          2.8244e-01,  7.6465e-02, -1.3270e-01,  1.6062e-01,  1.6020e-02,
          1.8847e-01, -1.0488e-01, -2.7101e-01,  2.8572e-01,  2.2558e-01,
         -1.0301e-01,  1.4395e-01,  1.6343e-01, -2.3641e-01, -1.2907e-01,
         -2.7267e-02,  2.6302e-01, -1.8550e-01,  2.4225e-01,  1.8058e-01,
         -2.0332e-01, -1.1652e-01,  2.2879e-01, -6.5583e-02,  3.0162e-02,
          5.5261e-02,  3.3168e-02,  1.4287e-03,  2.4233e-01, -2.5623e-01,
          1.4555e-01, -9.7221e-02, -1.4414e-01,  2.5351e-01, -1.6486e-01,
          8.8751e-03, -1.3138e-01, -5.0337e-02, -2.3413e-01, -1.2613e-01,
          1.0165e-01,  1.7950e-01, -4.9932e-02,  1.9990e-01, -2.5763e-01,
         -3.1997e-01, -1.8444e-01, -2.4811e-01, -6.7918e-02,  2.8393e-01,
          3.9342e-02, -3.8641e-01, -2.4957e-01, -4.2098e-02,  1.2375e-01,
         -2.3292e-01, -1.2942e-01, -9.9817e-02,  2.1444e-02, -2.8142e-02,
         -6.4317e-02, -2.3902e-01, -3.0746e-01, -8.9892e-02, -1.2646e-01,
         -3.2790e-01,  2.3242e-01,  9.5534e-02, -1.0982e-01,  2.6479e-01,
          1.5996e-01, -3.1966e-01, -1.9431e-01,  7.6029e-02, -2.0056e-01,
         -4.4122e-02, -1.9894e-01, -3.2973e-01,  1.0175e-01, -3.6016e-02,
         -1.1808e-01, -1.6042e-01, -2.7750e-01,  4.7654e-02, -6.1258e-02,
         -4.5565e-01, -1.4322e-01, -1.6719e-01,  1.1150e-01, -6.1786e-02,
         -1.3581e-01, -1.2923e-01, -8.6849e-02, -2.0869e-01, -9.5694e-02,
         -3.2178e-01,  4.5601e-02,  9.0810e-02, -3.4218e-01, -1.2418e-01,
         -2.1381e-01, -1.2038e-01, -4.3754e-02,  6.3526e-02,  9.4710e-02,
          1.8775e-02, -2.5421e-01,  9.3967e-03,  2.0880e-01,  1.6493e-01,
         -2.8366e-01, -1.0564e-01,  2.7419e-01]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.0000% F1: 0.3461
Applying ckpt from fold 1 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.6000% F1: 0.2815
Applying ckpt from fold 2 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.8000% F1: 0.3317
Applying ckpt from fold 3 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.8000% F1: 0.3093
Applying ckpt from fold 4 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.4000% F1: 0.3134
Applying ckpt from fold 5 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.6000% F1: 0.3146
Applying ckpt from fold 6 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.4000% F1: 0.3210
Applying ckpt from fold 7 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.6000% F1: 0.3105
Applying ckpt from fold 8 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.2000% F1: 0.3090
Applying ckpt from fold 9 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.4000% F1: 0.3164
Metrics by fold:
Fold 0 - Acc: 0.48 F1: 0.35
Fold 1 - Acc: 0.55 F1: 0.28
Fold 2 - Acc: 0.51 F1: 0.33
Fold 3 - Acc: 0.56 F1: 0.31
Fold 4 - Acc: 0.50 F1: 0.31
Fold 5 - Acc: 0.52 F1: 0.31
Fold 6 - Acc: 0.50 F1: 0.32
Fold 7 - Acc: 0.53 F1: 0.31
Fold 8 - Acc: 0.51 F1: 0.31
Fold 9 - Acc: 0.53 F1: 0.32
agg_acc: 0.5188 agg_f1: 0.3154
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[ 1.3939e-03, -6.8716e-02, -2.5557e-01,  2.8171e-02, -8.7808e-03,
         -2.5491e-01,  2.4635e-01, -1.7451e-01, -2.3248e-02,  2.3335e-01,
          2.6176e-01,  1.3909e-01, -1.2589e-01,  1.6319e-01,  2.4349e-02,
         -1.3283e-01,  4.8036e-02,  4.0980e-01, -2.1196e-01, -2.3831e-01,
         -9.6281e-03, -5.5775e-02,  1.1464e-02, -2.9264e-01,  9.9885e-02,
         -2.0102e-01, -1.9214e-01, -3.0318e-01, -4.2442e-02, -5.4449e-02,
         -1.2967e-04, -7.1719e-02,  2.0007e-01,  9.2549e-03,  5.3880e-02,
         -6.0826e-02,  8.9025e-02,  2.9168e-01,  2.3036e-01, -1.1622e-01,
         -6.1775e-02,  1.8710e-01, -1.6608e-01, -2.2137e-01,  1.6387e-01,
         -1.2285e-01,  3.0026e-01,  2.8564e-01, -3.5229e-01, -1.0878e-01,
          4.0280e-01,  1.5114e-01,  1.1360e-02, -2.0095e-02, -1.3847e-01,
          7.2091e-04, -1.1731e-01, -2.7096e-01,  2.7509e-02,  1.0600e-01,
          4.5664e-02,  1.3611e-01, -1.6287e-01, -2.6011e-01, -8.1596e-02,
          1.9391e-01, -6.8843e-02,  6.6795e-02,  3.0044e-01,  1.4518e-04,
          1.3836e-01, -2.1662e-01, -1.4751e-01, -4.5692e-03,  7.7596e-03,
          1.5091e-01, -1.9701e-01,  3.9364e-02,  2.4326e-02, -1.4290e-01,
         -2.3443e-01, -2.8338e-01,  2.4571e-01, -3.4772e-01, -2.1874e-01,
          4.0258e-02,  1.0768e-01,  2.4987e-01,  2.3627e-01, -1.1554e-01,
          2.1028e-01,  1.6711e-01, -1.5543e-01, -1.8313e-02, -3.3042e-01,
         -2.3139e-01,  1.1625e-01, -3.2922e-01, -1.7406e-01, -2.3016e-01,
         -1.3942e-01, -4.9668e-02, -2.7628e-01,  1.0165e-02,  8.2532e-02,
          6.4771e-02,  1.9546e-01, -3.2410e-01,  1.8964e-01, -1.6898e-01,
         -2.2098e-01, -1.2092e-01, -1.3189e-02,  2.6864e-02,  2.7784e-01,
         -6.3231e-02,  6.4781e-02,  3.4362e-01, -2.2732e-02, -3.5275e-01,
          9.8142e-03, -2.4852e-01, -2.7906e-02, -5.1745e-02, -9.5929e-02,
          1.7100e-02,  4.3980e-02, -4.3783e-02,  3.7871e-01,  1.2682e-01,
         -3.2154e-01, -2.1401e-01,  6.4307e-02,  7.8588e-02,  2.3951e-01,
          1.3997e-02, -7.8034e-02, -2.2260e-03,  1.9591e-02, -2.4945e-01,
          8.2607e-02, -3.2764e-02,  1.7143e-02,  2.0525e-01, -5.7016e-02,
          1.8229e-01, -2.7006e-02,  1.1357e-01,  9.7994e-02,  5.1746e-02,
          7.9860e-02,  3.8248e-02, -2.3227e-01, -1.3862e-01,  6.6153e-02,
          2.6249e-01, -5.7370e-02, -1.3890e-01, -4.0898e-01, -2.8864e-01,
         -2.3905e-02,  2.0195e-01,  1.1847e-01, -2.4378e-01, -1.7138e-01,
         -1.7932e-01,  2.7026e-01, -1.0431e-01,  8.6107e-02, -1.0131e-01,
         -8.2868e-02,  9.2653e-02, -3.3071e-02, -3.0312e-01, -2.7937e-01,
         -4.0222e-01, -3.8210e-01,  1.1642e-01, -3.3853e-02,  7.7303e-02,
          1.2355e-01, -2.2809e-01,  4.3379e-02,  1.0617e-02, -1.7532e-01,
         -1.5698e-01,  1.7562e-01, -6.4621e-02, -2.2386e-01, -5.4332e-02,
         -1.4223e-01,  1.1155e-01,  2.3546e-01,  3.8853e-02,  1.1227e-01,
         -2.9981e-02, -3.5384e-02, -1.3603e-01,  3.1001e-01, -1.4615e-01,
          2.5058e-02, -9.1489e-02, -2.1435e-01,  3.0697e-02, -2.5929e-02,
          3.2241e-01,  3.7920e-01,  2.0833e-01,  2.8212e-01, -1.0324e-01,
         -1.6585e-01, -1.8386e-01,  2.0189e-02,  2.7767e-01, -1.3822e-01,
         -1.3711e-01,  9.5865e-03,  1.1056e-02, -1.0575e-01, -5.5155e-02,
          1.1809e-01, -1.2300e-01,  2.4179e-01, -2.8298e-02,  7.4502e-02,
         -3.0307e-01,  2.4275e-02,  7.3545e-02, -6.9410e-02,  1.2794e-01,
          7.5693e-02,  1.5065e-01, -9.7550e-02,  3.4761e-01,  2.7095e-01,
         -4.5170e-02, -1.2539e-01,  3.8548e-03,  2.8808e-01, -9.7298e-02,
          3.0336e-02, -3.0973e-01,  7.9866e-02,  2.3738e-01,  1.2550e-01,
          7.3314e-03, -1.5217e-01,  2.0428e-01, -3.5740e-02,  1.4864e-01,
         -3.2093e-01, -5.4270e-02,  1.2042e-02, -1.4123e-01, -1.0701e-01,
         -3.3997e-01, -3.5408e-02, -1.8080e-01,  1.0898e-01,  1.1176e-01,
          1.4616e-01,  5.3214e-02, -8.9582e-02, -2.4846e-01, -2.1512e-01,
         -1.8585e-01, -7.4543e-02,  1.8495e-01,  1.3112e-01, -2.9189e-01,
         -2.3716e-01,  1.4231e-01,  1.8316e-01,  1.1146e-01,  1.0917e-01,
         -7.8276e-02, -3.5784e-01, -2.0579e-01, -1.9995e-01, -2.0056e-02,
          1.9377e-01,  2.1209e-01,  1.1557e-01,  1.5575e-01,  3.7109e-02,
         -1.9799e-01,  1.2692e-01, -1.2687e-01,  3.2986e-01, -4.0038e-01,
         -5.4040e-02,  1.9603e-01, -1.0432e-01, -4.4281e-02, -9.4947e-02,
          1.9225e-01,  2.4538e-01,  1.6693e-01,  1.7623e-02,  2.7655e-01,
         -2.7252e-01, -3.5374e-02,  2.1649e-01,  1.1542e-01, -3.2575e-01,
         -9.5898e-02, -1.7769e-01, -1.7478e-01,  1.2413e-02, -9.4918e-02,
         -1.7591e-01, -7.7178e-02,  8.4715e-02,  1.1410e-01,  2.3401e-01,
          4.6640e-02,  1.6343e-02,  8.4249e-02, -9.6963e-02,  4.9761e-03,
         -1.2689e-01, -8.9776e-02,  1.4109e-01, -2.3152e-01,  3.0876e-01,
         -2.1192e-01,  2.8687e-01, -1.6530e-01,  1.0156e-01,  1.3087e-01,
         -1.3041e-01,  2.9489e-01, -1.7078e-01,  2.2375e-01,  1.1248e-01,
          7.6252e-02, -2.7074e-02,  7.4888e-02, -2.2466e-01,  5.8946e-02,
         -1.5730e-01,  1.9001e-01,  1.6656e-01,  2.3558e-01,  8.8893e-02,
          4.6385e-02, -4.6853e-03, -3.9195e-02, -6.8834e-02,  6.7098e-02,
         -2.5421e-01, -1.3098e-01,  3.3280e-01, -1.1145e-01,  3.0578e-01,
          1.4134e-01, -7.8914e-02,  1.6024e-01, -2.5977e-01,  4.2665e-02,
          1.7734e-01, -1.5616e-01, -3.0725e-01, -1.6099e-01, -9.4044e-02,
          5.9506e-02,  2.2976e-01, -1.7763e-01, -2.6950e-01,  3.8000e-01,
          1.7562e-01,  3.7771e-02,  1.0278e-01,  3.2222e-01, -2.1560e-02,
         -1.5225e-01, -2.3036e-01, -1.3021e-01, -3.0180e-01,  2.4546e-01,
          6.7754e-02, -3.0570e-01, -2.9963e-01,  1.5654e-02, -1.8943e-01,
         -2.3144e-01,  2.8879e-01,  7.4722e-02, -1.5568e-01, -2.0820e-01,
          4.9041e-02,  3.9942e-01,  4.3492e-02,  8.4227e-02,  1.3005e-01,
         -9.3410e-02,  2.1089e-01,  8.5407e-02, -2.3646e-01,  1.1235e-01,
          2.1036e-01, -1.5971e-01,  7.9207e-02,  4.4568e-03, -2.2224e-01,
          3.1588e-02, -2.5247e-01, -1.8240e-01, -8.3811e-02, -3.5396e-01,
         -9.2816e-02,  3.5115e-02,  2.7964e-01, -9.2329e-02, -3.5224e-01,
         -2.4336e-01,  1.5316e-01, -1.8951e-01, -1.5665e-01, -2.2028e-01,
         -2.0556e-01, -1.5417e-01,  4.3107e-02, -1.4996e-01, -1.7838e-01,
         -1.0692e-01, -1.7765e-01, -8.7658e-03,  1.6875e-01, -2.1353e-01,
          1.7508e-01, -8.9377e-02, -1.9662e-01,  2.5831e-02, -5.6539e-02,
          5.4678e-02,  2.4562e-01,  9.2557e-02, -5.1224e-02, -2.1296e-02,
         -2.0423e-01,  4.4212e-03, -1.5627e-01,  1.5368e-01, -9.0215e-02,
          4.5537e-02,  2.7957e-01, -1.7029e-01,  2.9199e-01, -9.2008e-02,
         -1.1972e-01, -1.1973e-01, -3.9062e-01, -6.3714e-03, -1.8681e-02,
          4.3476e-02,  1.0941e-01,  1.5459e-02, -2.8024e-02, -2.9083e-01,
         -2.1282e-01,  1.7896e-01, -1.1782e-01, -2.9580e-01,  9.5791e-02,
         -1.6213e-01, -1.0290e-03,  9.6139e-02, -6.0271e-02,  7.4006e-02,
          1.4452e-01, -6.5647e-02,  2.0084e-01, -1.4069e-02, -1.2897e-01,
          2.6349e-01, -2.3983e-01,  1.7705e-02,  1.7037e-01,  3.0223e-02,
         -2.9845e-01,  1.0508e-01, -1.6406e-01, -3.5936e-02, -8.8760e-02,
         -2.6679e-01,  3.3564e-01,  3.7482e-04,  5.0903e-02, -7.3588e-02,
         -1.6273e-01, -5.2870e-02, -2.3405e-01, -7.3421e-02,  6.7705e-03,
         -1.6738e-01, -3.5341e-02,  1.6683e-01, -1.5272e-01,  3.9206e-01,
          2.2943e-01, -1.5948e-01, -2.8566e-02, -1.0889e-02, -2.4224e-01,
          6.9751e-02,  9.7223e-03, -2.8483e-01, -6.3500e-02,  1.8432e-01,
          4.8258e-02,  3.6758e-01, -1.7792e-01,  1.7039e-02,  3.1149e-01,
          9.3328e-02, -2.3158e-01, -3.5395e-01, -1.0560e-01,  2.2844e-01,
          8.0793e-02,  1.4810e-01, -3.0206e-01, -3.4022e-01,  1.7620e-01,
          4.3809e-02,  9.0087e-02,  1.5914e-01, -6.8204e-02,  2.5665e-01,
         -1.8012e-01,  3.7484e-02,  4.8088e-02,  2.3510e-02, -1.1832e-01,
          1.0292e-01,  1.4461e-01,  9.2944e-02, -1.4286e-03,  1.8287e-01,
          1.7623e-01,  6.0158e-02,  1.7079e-01,  1.9798e-01, -1.8351e-01,
         -4.1477e-01,  2.4582e-01,  1.0249e-01, -3.3297e-02, -2.0311e-01,
         -2.5807e-01, -2.9441e-02,  2.5160e-01, -2.8196e-01, -2.2125e-01,
         -1.3952e-01, -5.6166e-02,  2.8915e-02, -1.9787e-01, -1.6558e-01,
         -1.7816e-01, -3.1428e-01, -1.7320e-01,  1.2468e-02, -3.4252e-01,
         -2.5784e-01, -7.1416e-02, -9.2996e-02,  1.6461e-01, -3.2702e-01,
          1.4028e-01,  2.0673e-01, -5.7455e-02, -2.6848e-01,  1.1147e-01,
         -4.8179e-02,  9.7699e-02, -2.2503e-01, -1.3832e-01,  1.9701e-02,
         -8.6869e-02, -4.8751e-02,  6.2277e-02, -3.3196e-01,  2.0513e-01,
          4.2906e-02, -3.1485e-01, -1.9783e-01, -1.8252e-01,  8.9203e-03,
          2.3651e-01, -1.7068e-01,  9.3493e-02,  1.2389e-01, -2.1146e-01,
          8.2649e-03,  1.5572e-01, -2.2668e-01,  6.7394e-02,  1.9482e-02,
          7.9862e-02, -7.1562e-02,  8.8041e-02,  2.9078e-01, -2.9057e-01,
          1.9924e-01,  7.9529e-02,  2.3030e-01, -1.8758e-01, -2.1552e-01,
          1.6985e-01, -1.6580e-01, -2.1389e-01, -2.4635e-01, -1.9783e-01,
          7.4881e-02, -9.2235e-02,  5.3853e-02, -2.7720e-01, -4.0823e-02,
          2.2342e-01,  1.6657e-01, -1.2662e-01, -1.9808e-02,  5.6801e-02,
          2.1904e-02,  6.3948e-02, -2.0601e-01, -2.2994e-01, -1.4389e-01,
          5.3174e-02,  6.4131e-02,  4.4927e-02, -3.7137e-01, -1.5741e-01,
         -2.5703e-01,  1.2718e-01,  2.0193e-02,  3.8737e-02, -7.7474e-02,
          1.9992e-02, -1.8949e-01, -1.0489e-01, -6.3354e-02, -2.5072e-01,
         -2.2850e-01, -1.9215e-01, -2.7560e-01, -5.5963e-02, -1.2828e-01,
          1.2989e-01,  8.0240e-02,  1.1768e-01,  3.6903e-01,  3.2748e-01,
          2.8244e-01,  7.6465e-02, -1.3270e-01,  1.6062e-01,  1.6020e-02,
          1.8847e-01, -1.0488e-01, -2.7101e-01,  2.8572e-01,  2.2558e-01,
         -1.0301e-01,  1.4395e-01,  1.6343e-01, -2.3641e-01, -1.2907e-01,
         -2.7267e-02,  2.6302e-01, -1.8550e-01,  2.4225e-01,  1.8058e-01,
         -2.0332e-01, -1.1652e-01,  2.2879e-01, -6.5583e-02,  3.0162e-02,
          5.5261e-02,  3.3168e-02,  1.4287e-03,  2.4233e-01, -2.5623e-01,
          1.4555e-01, -9.7221e-02, -1.4414e-01,  2.5351e-01, -1.6486e-01,
          8.8751e-03, -1.3138e-01, -5.0337e-02, -2.3413e-01, -1.2613e-01,
          1.0165e-01,  1.7950e-01, -4.9932e-02,  1.9990e-01, -2.5763e-01,
         -3.1997e-01, -1.8444e-01, -2.4811e-01, -6.7918e-02,  2.8393e-01,
          3.9342e-02, -3.8641e-01, -2.4957e-01, -4.2098e-02,  1.2375e-01,
         -2.3292e-01, -1.2942e-01, -9.9817e-02,  2.1444e-02, -2.8142e-02,
         -6.4317e-02, -2.3902e-01, -3.0746e-01, -8.9892e-02, -1.2646e-01,
         -3.2790e-01,  2.3242e-01,  9.5534e-02, -1.0982e-01,  2.6479e-01,
          1.5996e-01, -3.1966e-01, -1.9431e-01,  7.6029e-02, -2.0056e-01,
         -4.4122e-02, -1.9894e-01, -3.2973e-01,  1.0175e-01, -3.6016e-02,
         -1.1808e-01, -1.6042e-01, -2.7750e-01,  4.7654e-02, -6.1258e-02,
         -4.5565e-01, -1.4322e-01, -1.6719e-01,  1.1150e-01, -6.1786e-02,
         -1.3581e-01, -1.2923e-01, -8.6849e-02, -2.0869e-01, -9.5694e-02,
         -3.2178e-01,  4.5601e-02,  9.0810e-02, -3.4218e-01, -1.2418e-01,
         -2.1381e-01, -1.2038e-01, -4.3754e-02,  6.3526e-02,  9.4710e-02,
          1.8775e-02, -2.5421e-01,  9.3967e-03,  2.0880e-01,  1.6493e-01,
         -2.8366e-01, -1.0564e-01,  2.7419e-01]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 43.0000% F1: 0.3493
Applying ckpt from fold 1 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.6000% F1: 0.3853
Applying ckpt from fold 2 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.8000% F1: 0.3594
Applying ckpt from fold 3 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.2000% F1: 0.3394
Applying ckpt from fold 4 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.0000% F1: 0.3543
Applying ckpt from fold 5 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.8000% F1: 0.3695
Applying ckpt from fold 6 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.8000% F1: 0.3665
Applying ckpt from fold 7 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.2000% F1: 0.3486
Applying ckpt from fold 8 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 42.4000% F1: 0.3430
Applying ckpt from fold 9 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.4000% F1: 0.3609
Metrics by fold:
Fold 0 - Acc: 0.43 F1: 0.35
Fold 1 - Acc: 0.51 F1: 0.39
Fold 2 - Acc: 0.46 F1: 0.36
Fold 3 - Acc: 0.47 F1: 0.34
Fold 4 - Acc: 0.45 F1: 0.35
Fold 5 - Acc: 0.46 F1: 0.37
Fold 6 - Acc: 0.48 F1: 0.37
Fold 7 - Acc: 0.47 F1: 0.35
Fold 8 - Acc: 0.42 F1: 0.34
Fold 9 - Acc: 0.50 F1: 0.36
agg_acc: 0.4652 agg_f1: 0.3576
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[ 1.3939e-03, -6.8716e-02, -2.5557e-01,  2.8171e-02, -8.7808e-03,
         -2.5491e-01,  2.4635e-01, -1.7451e-01, -2.3248e-02,  2.3335e-01,
          2.6176e-01,  1.3909e-01, -1.2589e-01,  1.6319e-01,  2.4349e-02,
         -1.3283e-01,  4.8036e-02,  4.0980e-01, -2.1196e-01, -2.3831e-01,
         -9.6281e-03, -5.5775e-02,  1.1464e-02, -2.9264e-01,  9.9885e-02,
         -2.0102e-01, -1.9214e-01, -3.0318e-01, -4.2442e-02, -5.4449e-02,
         -1.2967e-04, -7.1719e-02,  2.0007e-01,  9.2549e-03,  5.3880e-02,
         -6.0826e-02,  8.9025e-02,  2.9168e-01,  2.3036e-01, -1.1622e-01,
         -6.1775e-02,  1.8710e-01, -1.6608e-01, -2.2137e-01,  1.6387e-01,
         -1.2285e-01,  3.0026e-01,  2.8564e-01, -3.5229e-01, -1.0878e-01,
          4.0280e-01,  1.5114e-01,  1.1360e-02, -2.0095e-02, -1.3847e-01,
          7.2091e-04, -1.1731e-01, -2.7096e-01,  2.7509e-02,  1.0600e-01,
          4.5664e-02,  1.3611e-01, -1.6287e-01, -2.6011e-01, -8.1596e-02,
          1.9391e-01, -6.8843e-02,  6.6795e-02,  3.0044e-01,  1.4518e-04,
          1.3836e-01, -2.1662e-01, -1.4751e-01, -4.5692e-03,  7.7596e-03,
          1.5091e-01, -1.9701e-01,  3.9364e-02,  2.4326e-02, -1.4290e-01,
         -2.3443e-01, -2.8338e-01,  2.4571e-01, -3.4772e-01, -2.1874e-01,
          4.0258e-02,  1.0768e-01,  2.4987e-01,  2.3627e-01, -1.1554e-01,
          2.1028e-01,  1.6711e-01, -1.5543e-01, -1.8313e-02, -3.3042e-01,
         -2.3139e-01,  1.1625e-01, -3.2922e-01, -1.7406e-01, -2.3016e-01,
         -1.3942e-01, -4.9668e-02, -2.7628e-01,  1.0165e-02,  8.2532e-02,
          6.4771e-02,  1.9546e-01, -3.2410e-01,  1.8964e-01, -1.6898e-01,
         -2.2098e-01, -1.2092e-01, -1.3189e-02,  2.6864e-02,  2.7784e-01,
         -6.3231e-02,  6.4781e-02,  3.4362e-01, -2.2732e-02, -3.5275e-01,
          9.8142e-03, -2.4852e-01, -2.7906e-02, -5.1745e-02, -9.5929e-02,
          1.7100e-02,  4.3980e-02, -4.3783e-02,  3.7871e-01,  1.2682e-01,
         -3.2154e-01, -2.1401e-01,  6.4307e-02,  7.8588e-02,  2.3951e-01,
          1.3997e-02, -7.8034e-02, -2.2260e-03,  1.9591e-02, -2.4945e-01,
          8.2607e-02, -3.2764e-02,  1.7143e-02,  2.0525e-01, -5.7016e-02,
          1.8229e-01, -2.7006e-02,  1.1357e-01,  9.7994e-02,  5.1746e-02,
          7.9860e-02,  3.8248e-02, -2.3227e-01, -1.3862e-01,  6.6153e-02,
          2.6249e-01, -5.7370e-02, -1.3890e-01, -4.0898e-01, -2.8864e-01,
         -2.3905e-02,  2.0195e-01,  1.1847e-01, -2.4378e-01, -1.7138e-01,
         -1.7932e-01,  2.7026e-01, -1.0431e-01,  8.6107e-02, -1.0131e-01,
         -8.2868e-02,  9.2653e-02, -3.3071e-02, -3.0312e-01, -2.7937e-01,
         -4.0222e-01, -3.8210e-01,  1.1642e-01, -3.3853e-02,  7.7303e-02,
          1.2355e-01, -2.2809e-01,  4.3379e-02,  1.0617e-02, -1.7532e-01,
         -1.5698e-01,  1.7562e-01, -6.4621e-02, -2.2386e-01, -5.4332e-02,
         -1.4223e-01,  1.1155e-01,  2.3546e-01,  3.8853e-02,  1.1227e-01,
         -2.9981e-02, -3.5384e-02, -1.3603e-01,  3.1001e-01, -1.4615e-01,
          2.5058e-02, -9.1489e-02, -2.1435e-01,  3.0697e-02, -2.5929e-02,
          3.2241e-01,  3.7920e-01,  2.0833e-01,  2.8212e-01, -1.0324e-01,
         -1.6585e-01, -1.8386e-01,  2.0189e-02,  2.7767e-01, -1.3822e-01,
         -1.3711e-01,  9.5865e-03,  1.1056e-02, -1.0575e-01, -5.5155e-02,
          1.1809e-01, -1.2300e-01,  2.4179e-01, -2.8298e-02,  7.4502e-02,
         -3.0307e-01,  2.4275e-02,  7.3545e-02, -6.9410e-02,  1.2794e-01,
          7.5693e-02,  1.5065e-01, -9.7550e-02,  3.4761e-01,  2.7095e-01,
         -4.5170e-02, -1.2539e-01,  3.8548e-03,  2.8808e-01, -9.7298e-02,
          3.0336e-02, -3.0973e-01,  7.9866e-02,  2.3738e-01,  1.2550e-01,
          7.3314e-03, -1.5217e-01,  2.0428e-01, -3.5740e-02,  1.4864e-01,
         -3.2093e-01, -5.4270e-02,  1.2042e-02, -1.4123e-01, -1.0701e-01,
         -3.3997e-01, -3.5408e-02, -1.8080e-01,  1.0898e-01,  1.1176e-01,
          1.4616e-01,  5.3214e-02, -8.9582e-02, -2.4846e-01, -2.1512e-01,
         -1.8585e-01, -7.4543e-02,  1.8495e-01,  1.3112e-01, -2.9189e-01,
         -2.3716e-01,  1.4231e-01,  1.8316e-01,  1.1146e-01,  1.0917e-01,
         -7.8276e-02, -3.5784e-01, -2.0579e-01, -1.9995e-01, -2.0056e-02,
          1.9377e-01,  2.1209e-01,  1.1557e-01,  1.5575e-01,  3.7109e-02,
         -1.9799e-01,  1.2692e-01, -1.2687e-01,  3.2986e-01, -4.0038e-01,
         -5.4040e-02,  1.9603e-01, -1.0432e-01, -4.4281e-02, -9.4947e-02,
          1.9225e-01,  2.4538e-01,  1.6693e-01,  1.7623e-02,  2.7655e-01,
         -2.7252e-01, -3.5374e-02,  2.1649e-01,  1.1542e-01, -3.2575e-01,
         -9.5898e-02, -1.7769e-01, -1.7478e-01,  1.2413e-02, -9.4918e-02,
         -1.7591e-01, -7.7178e-02,  8.4715e-02,  1.1410e-01,  2.3401e-01,
          4.6640e-02,  1.6343e-02,  8.4249e-02, -9.6963e-02,  4.9761e-03,
         -1.2689e-01, -8.9776e-02,  1.4109e-01, -2.3152e-01,  3.0876e-01,
         -2.1192e-01,  2.8687e-01, -1.6530e-01,  1.0156e-01,  1.3087e-01,
         -1.3041e-01,  2.9489e-01, -1.7078e-01,  2.2375e-01,  1.1248e-01,
          7.6252e-02, -2.7074e-02,  7.4888e-02, -2.2466e-01,  5.8946e-02,
         -1.5730e-01,  1.9001e-01,  1.6656e-01,  2.3558e-01,  8.8893e-02,
          4.6385e-02, -4.6853e-03, -3.9195e-02, -6.8834e-02,  6.7098e-02,
         -2.5421e-01, -1.3098e-01,  3.3280e-01, -1.1145e-01,  3.0578e-01,
          1.4134e-01, -7.8914e-02,  1.6024e-01, -2.5977e-01,  4.2665e-02,
          1.7734e-01, -1.5616e-01, -3.0725e-01, -1.6099e-01, -9.4044e-02,
          5.9506e-02,  2.2976e-01, -1.7763e-01, -2.6950e-01,  3.8000e-01,
          1.7562e-01,  3.7771e-02,  1.0278e-01,  3.2222e-01, -2.1560e-02,
         -1.5225e-01, -2.3036e-01, -1.3021e-01, -3.0180e-01,  2.4546e-01,
          6.7754e-02, -3.0570e-01, -2.9963e-01,  1.5654e-02, -1.8943e-01,
         -2.3144e-01,  2.8879e-01,  7.4722e-02, -1.5568e-01, -2.0820e-01,
          4.9041e-02,  3.9942e-01,  4.3492e-02,  8.4227e-02,  1.3005e-01,
         -9.3410e-02,  2.1089e-01,  8.5407e-02, -2.3646e-01,  1.1235e-01,
          2.1036e-01, -1.5971e-01,  7.9207e-02,  4.4568e-03, -2.2224e-01,
          3.1588e-02, -2.5247e-01, -1.8240e-01, -8.3811e-02, -3.5396e-01,
         -9.2816e-02,  3.5115e-02,  2.7964e-01, -9.2329e-02, -3.5224e-01,
         -2.4336e-01,  1.5316e-01, -1.8951e-01, -1.5665e-01, -2.2028e-01,
         -2.0556e-01, -1.5417e-01,  4.3107e-02, -1.4996e-01, -1.7838e-01,
         -1.0692e-01, -1.7765e-01, -8.7658e-03,  1.6875e-01, -2.1353e-01,
          1.7508e-01, -8.9377e-02, -1.9662e-01,  2.5831e-02, -5.6539e-02,
          5.4678e-02,  2.4562e-01,  9.2557e-02, -5.1224e-02, -2.1296e-02,
         -2.0423e-01,  4.4212e-03, -1.5627e-01,  1.5368e-01, -9.0215e-02,
          4.5537e-02,  2.7957e-01, -1.7029e-01,  2.9199e-01, -9.2008e-02,
         -1.1972e-01, -1.1973e-01, -3.9062e-01, -6.3714e-03, -1.8681e-02,
          4.3476e-02,  1.0941e-01,  1.5459e-02, -2.8024e-02, -2.9083e-01,
         -2.1282e-01,  1.7896e-01, -1.1782e-01, -2.9580e-01,  9.5791e-02,
         -1.6213e-01, -1.0290e-03,  9.6139e-02, -6.0271e-02,  7.4006e-02,
          1.4452e-01, -6.5647e-02,  2.0084e-01, -1.4069e-02, -1.2897e-01,
          2.6349e-01, -2.3983e-01,  1.7705e-02,  1.7037e-01,  3.0223e-02,
         -2.9845e-01,  1.0508e-01, -1.6406e-01, -3.5936e-02, -8.8760e-02,
         -2.6679e-01,  3.3564e-01,  3.7482e-04,  5.0903e-02, -7.3588e-02,
         -1.6273e-01, -5.2870e-02, -2.3405e-01, -7.3421e-02,  6.7705e-03,
         -1.6738e-01, -3.5341e-02,  1.6683e-01, -1.5272e-01,  3.9206e-01,
          2.2943e-01, -1.5948e-01, -2.8566e-02, -1.0889e-02, -2.4224e-01,
          6.9751e-02,  9.7223e-03, -2.8483e-01, -6.3500e-02,  1.8432e-01,
          4.8258e-02,  3.6758e-01, -1.7792e-01,  1.7039e-02,  3.1149e-01,
          9.3328e-02, -2.3158e-01, -3.5395e-01, -1.0560e-01,  2.2844e-01,
          8.0793e-02,  1.4810e-01, -3.0206e-01, -3.4022e-01,  1.7620e-01,
          4.3809e-02,  9.0087e-02,  1.5914e-01, -6.8204e-02,  2.5665e-01,
         -1.8012e-01,  3.7484e-02,  4.8088e-02,  2.3510e-02, -1.1832e-01,
          1.0292e-01,  1.4461e-01,  9.2944e-02, -1.4286e-03,  1.8287e-01,
          1.7623e-01,  6.0158e-02,  1.7079e-01,  1.9798e-01, -1.8351e-01,
         -4.1477e-01,  2.4582e-01,  1.0249e-01, -3.3297e-02, -2.0311e-01,
         -2.5807e-01, -2.9441e-02,  2.5160e-01, -2.8196e-01, -2.2125e-01,
         -1.3952e-01, -5.6166e-02,  2.8915e-02, -1.9787e-01, -1.6558e-01,
         -1.7816e-01, -3.1428e-01, -1.7320e-01,  1.2468e-02, -3.4252e-01,
         -2.5784e-01, -7.1416e-02, -9.2996e-02,  1.6461e-01, -3.2702e-01,
          1.4028e-01,  2.0673e-01, -5.7455e-02, -2.6848e-01,  1.1147e-01,
         -4.8179e-02,  9.7699e-02, -2.2503e-01, -1.3832e-01,  1.9701e-02,
         -8.6869e-02, -4.8751e-02,  6.2277e-02, -3.3196e-01,  2.0513e-01,
          4.2906e-02, -3.1485e-01, -1.9783e-01, -1.8252e-01,  8.9203e-03,
          2.3651e-01, -1.7068e-01,  9.3493e-02,  1.2389e-01, -2.1146e-01,
          8.2649e-03,  1.5572e-01, -2.2668e-01,  6.7394e-02,  1.9482e-02,
          7.9862e-02, -7.1562e-02,  8.8041e-02,  2.9078e-01, -2.9057e-01,
          1.9924e-01,  7.9529e-02,  2.3030e-01, -1.8758e-01, -2.1552e-01,
          1.6985e-01, -1.6580e-01, -2.1389e-01, -2.4635e-01, -1.9783e-01,
          7.4881e-02, -9.2235e-02,  5.3853e-02, -2.7720e-01, -4.0823e-02,
          2.2342e-01,  1.6657e-01, -1.2662e-01, -1.9808e-02,  5.6801e-02,
          2.1904e-02,  6.3948e-02, -2.0601e-01, -2.2994e-01, -1.4389e-01,
          5.3174e-02,  6.4131e-02,  4.4927e-02, -3.7137e-01, -1.5741e-01,
         -2.5703e-01,  1.2718e-01,  2.0193e-02,  3.8737e-02, -7.7474e-02,
          1.9992e-02, -1.8949e-01, -1.0489e-01, -6.3354e-02, -2.5072e-01,
         -2.2850e-01, -1.9215e-01, -2.7560e-01, -5.5963e-02, -1.2828e-01,
          1.2989e-01,  8.0240e-02,  1.1768e-01,  3.6903e-01,  3.2748e-01,
          2.8244e-01,  7.6465e-02, -1.3270e-01,  1.6062e-01,  1.6020e-02,
          1.8847e-01, -1.0488e-01, -2.7101e-01,  2.8572e-01,  2.2558e-01,
         -1.0301e-01,  1.4395e-01,  1.6343e-01, -2.3641e-01, -1.2907e-01,
         -2.7267e-02,  2.6302e-01, -1.8550e-01,  2.4225e-01,  1.8058e-01,
         -2.0332e-01, -1.1652e-01,  2.2879e-01, -6.5583e-02,  3.0162e-02,
          5.5261e-02,  3.3168e-02,  1.4287e-03,  2.4233e-01, -2.5623e-01,
          1.4555e-01, -9.7221e-02, -1.4414e-01,  2.5351e-01, -1.6486e-01,
          8.8751e-03, -1.3138e-01, -5.0337e-02, -2.3413e-01, -1.2613e-01,
          1.0165e-01,  1.7950e-01, -4.9932e-02,  1.9990e-01, -2.5763e-01,
         -3.1997e-01, -1.8444e-01, -2.4811e-01, -6.7918e-02,  2.8393e-01,
          3.9342e-02, -3.8641e-01, -2.4957e-01, -4.2098e-02,  1.2375e-01,
         -2.3292e-01, -1.2942e-01, -9.9817e-02,  2.1444e-02, -2.8142e-02,
         -6.4317e-02, -2.3902e-01, -3.0746e-01, -8.9892e-02, -1.2646e-01,
         -3.2790e-01,  2.3242e-01,  9.5534e-02, -1.0982e-01,  2.6479e-01,
          1.5996e-01, -3.1966e-01, -1.9431e-01,  7.6029e-02, -2.0056e-01,
         -4.4122e-02, -1.9894e-01, -3.2973e-01,  1.0175e-01, -3.6016e-02,
         -1.1808e-01, -1.6042e-01, -2.7750e-01,  4.7654e-02, -6.1258e-02,
         -4.5565e-01, -1.4322e-01, -1.6719e-01,  1.1150e-01, -6.1786e-02,
         -1.3581e-01, -1.2923e-01, -8.6849e-02, -2.0869e-01, -9.5694e-02,
         -3.2178e-01,  4.5601e-02,  9.0810e-02, -3.4218e-01, -1.2418e-01,
         -2.1381e-01, -1.2038e-01, -4.3754e-02,  6.3526e-02,  9.4710e-02,
          1.8775e-02, -2.5421e-01,  9.3967e-03,  2.0880e-01,  1.6493e-01,
         -2.8366e-01, -1.0564e-01,  2.7419e-01]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 43.2000% F1: 0.3514
Applying ckpt from fold 1 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.6000% F1: 0.3732
Applying ckpt from fold 2 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 43.2000% F1: 0.3495
Applying ckpt from fold 3 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 43.2000% F1: 0.3304
Applying ckpt from fold 4 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 40.6000% F1: 0.3562
Applying ckpt from fold 5 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 42.6000% F1: 0.3643
Applying ckpt from fold 6 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.8000% F1: 0.3847
Applying ckpt from fold 7 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 42.6000% F1: 0.3513
Applying ckpt from fold 8 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 43.6000% F1: 0.3631
Applying ckpt from fold 9 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.6000% F1: 0.3607
Metrics by fold:
Fold 0 - Acc: 0.43 F1: 0.35
Fold 1 - Acc: 0.49 F1: 0.37
Fold 2 - Acc: 0.43 F1: 0.35
Fold 3 - Acc: 0.43 F1: 0.33
Fold 4 - Acc: 0.41 F1: 0.36
Fold 5 - Acc: 0.43 F1: 0.36
Fold 6 - Acc: 0.51 F1: 0.38
Fold 7 - Acc: 0.43 F1: 0.35
Fold 8 - Acc: 0.44 F1: 0.36
Fold 9 - Acc: 0.46 F1: 0.36
agg_acc: 0.4440 agg_f1: 0.3585
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-4.3606e-02, -1.5910e-01, -4.8581e-01, -3.8263e-01, -5.1680e-01,
         -1.8935e-01,  4.8751e-01,  2.9280e-01, -1.0607e-01, -2.6697e-01,
         -4.9493e-01, -1.1257e-01, -1.9788e-01, -1.3184e-01, -2.6747e-01,
         -5.4098e-01,  1.0436e-01, -7.9363e-02,  2.6787e-01, -3.4898e-01,
         -5.5895e-01, -4.0749e-01, -2.7529e-01, -5.5366e-01,  7.3051e-01,
         -4.5888e-01, -7.5373e-02, -1.4036e-01,  4.2218e-02, -9.4052e-02,
         -4.0497e-01,  6.7652e-01, -1.5242e-02,  2.2938e-01,  3.3972e-01,
          2.6711e-01, -5.7348e-03, -3.8172e-01,  3.7646e-01, -4.6330e-01,
          6.0895e-01, -1.1278e-01,  9.5125e-02,  1.5848e-01, -8.8011e-02,
          2.1012e-01,  3.2058e-01, -1.2087e-01,  1.9975e-01, -3.9109e-01,
          1.9737e-01,  1.5232e-01,  7.0129e-01, -9.8670e-02,  6.9456e-01,
         -3.5982e-01,  6.0930e-01,  1.1148e-01,  8.1908e-02,  2.7244e-01,
          1.1667e-01, -5.8989e-01, -2.2864e-01, -5.4887e-01,  4.0342e-01,
          6.6261e-02,  6.1714e-01,  2.9520e-03,  3.1208e-01, -4.7937e-01,
         -6.9867e-01, -2.6097e-01,  3.9696e-01, -2.9471e-01, -5.4417e-01,
          5.6128e-02,  2.0631e-01,  1.4236e-01, -1.7459e-01, -1.3846e-01,
         -1.5302e-01, -2.8679e-01,  7.9617e-02, -5.5280e-01, -5.8188e-02,
         -3.5297e-01,  1.7067e-01,  3.2233e-02, -7.4358e-01,  5.5985e-01,
          1.5651e-01, -7.1408e-01,  2.1729e-01, -6.5467e-01, -3.5687e-01,
          4.0038e-01,  5.3516e-01,  1.2456e-01, -5.9177e-01, -4.7869e-01,
          1.4700e-01, -2.3916e-01, -3.3883e-01, -6.4858e-02,  1.4353e-01,
         -4.7894e-01,  4.1543e-01, -3.2510e-01, -4.1771e-01, -1.3029e-01,
          5.5638e-01, -1.1075e-01, -3.2858e-02,  7.4421e-02, -3.2686e-01,
         -4.8930e-01, -7.5107e-01,  3.2951e-01,  1.4170e-01,  2.4140e-01,
         -6.4900e-02, -3.8840e-01, -2.9613e-02, -2.1750e-02,  1.2730e-01,
         -7.6223e-01, -1.4084e-01,  2.8811e-01, -1.2155e-01,  6.5782e-01,
          1.4252e-01,  2.7522e-01,  5.6607e-01, -3.5640e-01, -1.6254e-01,
         -5.6422e-01, -4.1899e-01,  7.1397e-01, -2.5976e-01,  3.7979e-01,
          6.9408e-01, -9.6555e-02, -5.7445e-01, -8.3463e-02,  6.6205e-02,
          7.3398e-01, -1.4064e-01,  4.6967e-02,  1.7280e-01,  4.3330e-01,
          5.1674e-01,  2.0085e-01, -2.8088e-01, -4.8809e-01, -6.1372e-02,
          1.7789e-01,  8.4561e-02, -2.2256e-01, -8.8882e-02, -2.0205e-01,
          7.9238e-01, -3.7167e-01, -4.3697e-01, -5.5123e-01,  3.4803e-01,
          3.3974e-01, -3.6795e-03, -9.4672e-02,  4.4612e-01,  7.0981e-02,
          1.4914e-01, -1.1917e-01, -1.3173e-01,  5.9845e-02,  4.2897e-01,
          2.7345e-01,  4.5077e-01, -9.3647e-02, -2.5648e-01, -3.4603e-01,
          3.8954e-01,  4.3317e-01, -3.7800e-01,  1.2969e-01,  8.4454e-02,
          1.5298e-01,  3.3882e-01,  1.2758e-01, -2.0599e-01, -2.6551e-01,
          1.8176e-01, -8.8421e-02, -3.2220e-01, -8.8067e-02,  2.1718e-01,
         -3.6291e-01, -4.9237e-01,  2.1455e-01, -1.8674e-02,  3.9949e-01,
         -2.2519e-01, -1.4739e-01, -2.2509e-01,  2.9665e-01, -3.3978e-01,
         -4.4125e-01,  5.8753e-01,  2.4695e-01, -9.5062e-02,  9.9014e-03,
         -1.6486e-01,  2.4021e-01,  3.2167e-02, -2.2061e-01, -4.3971e-01,
          5.9503e-01, -1.8055e-01, -8.3522e-02,  1.0926e-01,  3.9749e-02,
          1.6904e-01,  7.3836e-02,  9.2030e-02,  2.3969e-01,  2.4693e-02,
          3.4840e-01,  3.3886e-02, -2.7562e-01, -4.2305e-01, -1.4418e-01,
          3.3536e-01, -2.7491e-01,  5.2891e-01,  3.0901e-01, -4.6127e-01,
          7.0903e-02, -1.1390e-01,  4.2822e-01, -4.7448e-01, -1.9457e-01,
          1.7779e-01, -3.3084e-01, -4.7311e-01, -4.2679e-01,  7.1815e-02,
          2.4915e-01, -4.4569e-01,  1.6466e-01,  4.1354e-02, -2.4865e-01,
         -4.2151e-01, -2.8002e-01,  8.4000e-02, -1.1305e-01,  3.2736e-01,
          1.0333e-01, -2.9267e-01, -3.9020e-02,  3.9709e-01, -3.1718e-01,
          4.5334e-01,  6.2500e-01, -2.3732e-01,  1.5878e-01, -3.1546e-01,
          1.4519e-01, -3.7691e-01,  4.5056e-01,  3.8429e-01,  1.1904e-01,
          4.6546e-01,  8.9835e-02, -3.4235e-02,  7.0945e-02,  5.7647e-02,
          3.2093e-01, -7.4279e-02,  1.9812e-01,  6.6854e-01,  8.3255e-03,
          5.2060e-01,  1.4760e-01,  4.9135e-02, -5.2057e-01,  8.4303e-02,
          2.5593e-02,  3.9829e-01, -3.1141e-01,  6.5268e-02, -4.9857e-02,
         -4.5633e-02, -6.8734e-01, -2.6750e-03, -2.4190e-01, -2.8735e-01,
         -3.2288e-02,  5.3618e-01,  3.4173e-01, -3.6855e-01, -4.1932e-01,
         -3.2033e-01, -2.7842e-01,  4.4021e-01,  8.6230e-01,  9.1970e-02,
         -1.1976e-01, -3.8733e-01, -9.0361e-02, -5.4882e-02,  1.3525e-01,
          3.8096e-02,  6.2839e-01,  4.1826e-01,  4.6406e-01, -2.4304e-01,
         -4.5163e-01, -2.7172e-01, -1.2460e-01,  2.3671e-01, -3.1206e-01,
         -1.7764e-02,  1.3673e-03, -2.0460e-02, -6.8924e-02, -3.0854e-01,
         -2.8193e-02, -1.2100e-01,  2.0054e-01, -8.8251e-02, -1.1931e-01,
         -1.0426e-01, -6.4048e-01, -3.0713e-01,  2.0817e-01,  6.5585e-02,
         -1.4141e-01,  2.0945e-01, -7.4820e-04, -2.2530e-01, -3.7012e-01,
          1.6271e-01, -4.9095e-01, -2.2408e-01, -3.8781e-01,  2.5892e-01,
         -3.5237e-01,  6.4705e-03, -4.4271e-01,  5.8282e-01,  1.8517e-01,
          3.0051e-02,  5.0570e-02,  2.0626e-01, -1.3862e-01,  1.3162e-01,
          1.2967e-01,  2.0172e-01, -4.2257e-01,  8.3080e-02,  2.6301e-01,
          1.8749e-01, -3.6900e-01,  2.6178e-01,  3.2177e-01, -2.0241e-01,
         -5.9555e-01,  1.7245e-01, -7.6558e-02, -8.9417e-02,  1.7406e-01,
         -3.0616e-01, -5.1685e-02,  1.4586e-01,  5.1845e-01,  3.5010e-01,
         -4.0866e-01, -6.4725e-01,  1.4885e-01,  3.5427e-01, -7.2978e-02,
         -6.2830e-01, -2.0126e-01, -2.4575e-01,  2.5788e-01, -6.6602e-01,
          1.4807e-01,  5.9979e-01,  3.1298e-01, -2.1984e-02, -2.1055e-01,
          4.2543e-01, -4.2785e-01,  2.8597e-01, -4.6195e-02, -4.4302e-01,
         -1.6596e-01,  4.3690e-01,  8.2672e-03,  8.6318e-02,  2.6571e-01,
          3.8568e-01,  7.2709e-02, -5.9491e-01, -3.6851e-01,  3.6038e-01,
          3.4782e-03,  4.1766e-01,  5.5036e-01,  2.9479e-02, -3.7907e-01,
          1.8382e-03, -1.4601e-01,  1.6616e-01,  5.3503e-01,  1.3591e-02,
          1.2013e-01, -8.5887e-02,  3.7715e-01, -3.4969e-01,  4.3805e-01,
          3.1855e-01, -3.6571e-01, -1.7446e-01,  4.0240e-01, -1.6065e-01,
         -3.6733e-01,  1.7065e-01,  9.1335e-02,  3.1418e-01, -1.3760e-01,
         -4.5394e-01, -2.5068e-01,  8.7604e-02, -6.2930e-01,  1.2898e-02,
         -3.7761e-01,  5.9227e-02, -2.4603e-01,  1.9747e-01, -7.6524e-01,
          4.1795e-01, -3.2705e-01, -4.8150e-01, -1.3054e-01, -1.7629e-02,
         -7.9984e-02,  3.5556e-01,  4.0054e-01, -2.2257e-01, -4.4133e-03,
         -2.0015e-01, -1.1900e-01, -2.7484e-01, -5.1239e-01, -6.3264e-01,
         -1.7553e-01, -3.6384e-02,  1.4799e-01,  4.2550e-01,  4.8262e-01,
         -4.1353e-01,  1.6462e-01, -3.8982e-01,  3.9817e-02,  2.0532e-01,
         -1.9002e-01, -1.7682e-01,  8.7832e-01,  1.1802e-01, -4.0827e-01,
          4.1533e-01,  5.2921e-01, -3.8746e-01,  5.6729e-01,  2.9954e-01,
         -4.1602e-01, -1.2003e-01, -1.2318e-01,  6.4842e-02,  7.1454e-01,
         -3.3365e-01, -8.2613e-03, -9.7548e-02,  6.7619e-01, -2.0094e-01,
          6.8275e-02, -1.9088e-01,  2.5895e-01, -1.8892e-02,  8.5494e-02,
          4.3036e-01,  2.0538e-01,  5.8892e-01,  6.2417e-01,  4.8445e-01,
         -2.7654e-01,  3.1131e-01,  3.5275e-01,  3.1345e-01, -4.5330e-02,
          4.1206e-01, -3.9273e-01, -1.9450e-01,  1.3716e-02, -2.6335e-01,
          1.4685e-01,  3.2094e-01, -2.6300e-01,  9.1132e-02,  9.6662e-02,
         -2.8584e-01,  4.9270e-01,  5.0694e-01, -6.7856e-01, -1.6952e-02,
          2.0858e-01,  2.7211e-01,  7.7594e-03,  1.1058e-01,  3.5853e-01,
         -3.4715e-02,  1.9556e-01, -1.0988e-01, -2.6661e-01,  8.2309e-02,
         -1.8942e-01,  4.2286e-01,  2.1585e-01,  2.0750e-01, -1.9119e-01,
          3.1705e-01, -3.8454e-01, -2.0743e-01, -3.8114e-02,  6.4414e-02,
         -1.7748e-01,  1.3586e-01,  4.2025e-01,  5.2959e-01, -3.0235e-01,
          6.6244e-02,  5.9458e-02, -3.8626e-01, -3.0927e-01, -2.5877e-01,
          3.9770e-01, -3.5933e-01,  2.1776e-01, -4.3661e-01,  3.3840e-01,
          3.5971e-01, -2.2540e-01, -2.6150e-01, -3.6218e-01,  6.4707e-01,
          8.7594e-01,  5.4092e-01, -8.1894e-02,  5.3965e-01, -1.3166e-01,
         -1.9551e-01, -7.0249e-01, -3.5140e-01,  9.1459e-02,  8.1300e-03,
          2.1649e-01,  9.5686e-02,  4.3850e-01, -5.3493e-01,  1.3832e-01,
         -1.7769e-01, -3.1088e-01,  1.4557e-01,  5.7953e-01, -8.4913e-02,
          1.5262e-01, -4.3042e-02,  3.5596e-01, -2.6371e-01, -1.3432e-01,
          4.5435e-01, -5.2918e-02, -3.9792e-01, -1.0195e-01,  1.0674e-01,
         -8.1712e-02,  7.9050e-01, -7.5311e-02,  3.8989e-02, -5.4863e-01,
          2.3593e-01,  1.7604e-01, -4.1790e-01, -5.9872e-01,  8.6589e-04,
         -2.7348e-02,  6.8003e-01, -2.4577e-01,  2.8322e-01,  2.7373e-04,
          1.9466e-01,  1.7917e-01,  2.8938e-01,  2.7149e-01, -4.1166e-01,
          1.0486e-01, -2.8750e-01, -3.6946e-01,  5.6385e-01, -7.4233e-01,
         -3.6163e-01,  3.5484e-01,  3.3670e-01,  9.1394e-03, -1.0086e-01,
         -1.7736e-01, -3.6094e-01,  8.7540e-01, -2.3598e-01,  3.2910e-01,
         -7.4240e-01,  6.6476e-01, -1.7125e-01,  3.7107e-01, -6.8735e-01,
          7.3219e-01,  5.7308e-01, -7.9865e-02,  2.6137e-03, -1.0492e-01,
          6.2231e-01, -2.2494e-01,  6.8010e-01,  1.1748e-01,  5.2259e-01,
          1.2923e-02,  7.3691e-02,  3.4888e-01,  2.6414e-01,  4.2186e-01,
         -4.1445e-01,  5.7697e-01,  4.0721e-01, -4.0092e-01, -4.1310e-01,
          5.1246e-01,  5.3019e-03,  5.7073e-01, -6.6950e-01, -7.4447e-02,
         -3.0260e-01,  2.1808e-01,  8.2279e-01, -5.1817e-01,  5.0470e-01,
          3.2587e-01,  2.6581e-01,  5.2826e-01, -7.4837e-03, -6.9155e-02,
          2.5341e-01, -3.2784e-01, -2.1990e-02, -4.8601e-01, -1.7147e-01,
         -3.9870e-01, -3.0875e-01, -2.6406e-01, -2.0629e-01,  3.1720e-01,
          3.3498e-01, -1.0637e-01,  1.1432e-01, -2.1800e-01,  6.6413e-01,
         -2.0818e-02, -5.1117e-01, -6.3738e-01,  2.4649e-01,  1.9480e-01,
          1.1880e-02, -4.4444e-01,  9.7113e-02, -1.0584e-01,  6.0753e-01,
          7.0593e-01,  4.3478e-01,  1.8733e-01,  3.2939e-02,  3.8776e-01,
          2.8482e-01, -4.1235e-01, -6.0461e-01,  3.8104e-01,  1.0732e-01,
         -7.0059e-01,  2.6696e-01, -2.9421e-01,  4.3722e-01, -4.5591e-01,
         -8.6827e-02,  5.9254e-02, -4.1622e-01, -3.9528e-01, -4.8446e-01,
         -4.7552e-02, -4.9195e-01,  4.2025e-01, -5.4779e-01, -1.7593e-02,
          7.4183e-01, -7.0238e-01,  4.6337e-01,  4.0638e-01,  2.6151e-01,
          5.7075e-01, -1.9192e-01,  8.6687e-02,  5.0342e-01,  3.5060e-02,
          4.3095e-01,  6.2844e-01, -2.7865e-01, -1.8283e-01,  7.1376e-01,
         -1.0288e-01,  3.3084e-01,  7.6745e-01,  2.1309e-02, -4.1063e-01,
          5.3351e-01, -1.1141e-01, -1.5108e-01,  2.6530e-01,  6.8424e-01,
          1.6492e-01,  4.6153e-01, -2.9771e-01,  1.0697e-01,  1.4702e-01,
          1.2702e-01, -5.0592e-01, -3.6936e-01, -5.2906e-01,  2.2893e-01,
         -2.6245e-01,  4.2968e-02, -1.7851e-01, -5.6460e-02,  5.5637e-01,
         -5.9503e-01, -7.7544e-02, -2.2456e-01, -6.1064e-01,  3.1447e-01,
          1.4890e-01, -2.8982e-02, -1.1260e-04,  4.4912e-01, -3.5829e-01,
         -3.2105e-01,  7.6753e-01, -1.3102e-03,  2.2552e-02,  2.3368e-02,
          1.3975e-01, -6.5992e-01, -3.0786e-01]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.4000% F1: 0.2413
Applying ckpt from fold 1 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.0000% F1: 0.2366
Applying ckpt from fold 2 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2371
Applying ckpt from fold 3 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.0000% F1: 0.2366
Applying ckpt from fold 4 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2371
Applying ckpt from fold 5 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.4000% F1: 0.2413
Applying ckpt from fold 6 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2371
Applying ckpt from fold 7 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.4000% F1: 0.2413
Applying ckpt from fold 8 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2371
Applying ckpt from fold 9 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.0000% F1: 0.2366
Metrics by fold:
Fold 0 - Acc: 0.55 F1: 0.24
Fold 1 - Acc: 0.55 F1: 0.24
Fold 2 - Acc: 0.55 F1: 0.24
Fold 3 - Acc: 0.55 F1: 0.24
Fold 4 - Acc: 0.55 F1: 0.24
Fold 5 - Acc: 0.55 F1: 0.24
Fold 6 - Acc: 0.55 F1: 0.24
Fold 7 - Acc: 0.55 F1: 0.24
Fold 8 - Acc: 0.55 F1: 0.24
Fold 9 - Acc: 0.55 F1: 0.24
agg_acc: 0.5520 agg_f1: 0.2382
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-4.3606e-02, -1.5910e-01, -4.8581e-01, -3.8263e-01, -5.1680e-01,
         -1.8935e-01,  4.8751e-01,  2.9280e-01, -1.0607e-01, -2.6697e-01,
         -4.9493e-01, -1.1257e-01, -1.9788e-01, -1.3184e-01, -2.6747e-01,
         -5.4098e-01,  1.0436e-01, -7.9363e-02,  2.6787e-01, -3.4898e-01,
         -5.5895e-01, -4.0749e-01, -2.7529e-01, -5.5366e-01,  7.3051e-01,
         -4.5888e-01, -7.5373e-02, -1.4036e-01,  4.2218e-02, -9.4052e-02,
         -4.0497e-01,  6.7652e-01, -1.5242e-02,  2.2938e-01,  3.3972e-01,
          2.6711e-01, -5.7348e-03, -3.8172e-01,  3.7646e-01, -4.6330e-01,
          6.0895e-01, -1.1278e-01,  9.5125e-02,  1.5848e-01, -8.8011e-02,
          2.1012e-01,  3.2058e-01, -1.2087e-01,  1.9975e-01, -3.9109e-01,
          1.9737e-01,  1.5232e-01,  7.0129e-01, -9.8670e-02,  6.9456e-01,
         -3.5982e-01,  6.0930e-01,  1.1148e-01,  8.1908e-02,  2.7244e-01,
          1.1667e-01, -5.8989e-01, -2.2864e-01, -5.4887e-01,  4.0342e-01,
          6.6261e-02,  6.1714e-01,  2.9520e-03,  3.1208e-01, -4.7937e-01,
         -6.9867e-01, -2.6097e-01,  3.9696e-01, -2.9471e-01, -5.4417e-01,
          5.6128e-02,  2.0631e-01,  1.4236e-01, -1.7459e-01, -1.3846e-01,
         -1.5302e-01, -2.8679e-01,  7.9617e-02, -5.5280e-01, -5.8188e-02,
         -3.5297e-01,  1.7067e-01,  3.2233e-02, -7.4358e-01,  5.5985e-01,
          1.5651e-01, -7.1408e-01,  2.1729e-01, -6.5467e-01, -3.5687e-01,
          4.0038e-01,  5.3516e-01,  1.2456e-01, -5.9177e-01, -4.7869e-01,
          1.4700e-01, -2.3916e-01, -3.3883e-01, -6.4858e-02,  1.4353e-01,
         -4.7894e-01,  4.1543e-01, -3.2510e-01, -4.1771e-01, -1.3029e-01,
          5.5638e-01, -1.1075e-01, -3.2858e-02,  7.4421e-02, -3.2686e-01,
         -4.8930e-01, -7.5107e-01,  3.2951e-01,  1.4170e-01,  2.4140e-01,
         -6.4900e-02, -3.8840e-01, -2.9613e-02, -2.1750e-02,  1.2730e-01,
         -7.6223e-01, -1.4084e-01,  2.8811e-01, -1.2155e-01,  6.5782e-01,
          1.4252e-01,  2.7522e-01,  5.6607e-01, -3.5640e-01, -1.6254e-01,
         -5.6422e-01, -4.1899e-01,  7.1397e-01, -2.5976e-01,  3.7979e-01,
          6.9408e-01, -9.6555e-02, -5.7445e-01, -8.3463e-02,  6.6205e-02,
          7.3398e-01, -1.4064e-01,  4.6967e-02,  1.7280e-01,  4.3330e-01,
          5.1674e-01,  2.0085e-01, -2.8088e-01, -4.8809e-01, -6.1372e-02,
          1.7789e-01,  8.4561e-02, -2.2256e-01, -8.8882e-02, -2.0205e-01,
          7.9238e-01, -3.7167e-01, -4.3697e-01, -5.5123e-01,  3.4803e-01,
          3.3974e-01, -3.6795e-03, -9.4672e-02,  4.4612e-01,  7.0981e-02,
          1.4914e-01, -1.1917e-01, -1.3173e-01,  5.9845e-02,  4.2897e-01,
          2.7345e-01,  4.5077e-01, -9.3647e-02, -2.5648e-01, -3.4603e-01,
          3.8954e-01,  4.3317e-01, -3.7800e-01,  1.2969e-01,  8.4454e-02,
          1.5298e-01,  3.3882e-01,  1.2758e-01, -2.0599e-01, -2.6551e-01,
          1.8176e-01, -8.8421e-02, -3.2220e-01, -8.8067e-02,  2.1718e-01,
         -3.6291e-01, -4.9237e-01,  2.1455e-01, -1.8674e-02,  3.9949e-01,
         -2.2519e-01, -1.4739e-01, -2.2509e-01,  2.9665e-01, -3.3978e-01,
         -4.4125e-01,  5.8753e-01,  2.4695e-01, -9.5062e-02,  9.9014e-03,
         -1.6486e-01,  2.4021e-01,  3.2167e-02, -2.2061e-01, -4.3971e-01,
          5.9503e-01, -1.8055e-01, -8.3522e-02,  1.0926e-01,  3.9749e-02,
          1.6904e-01,  7.3836e-02,  9.2030e-02,  2.3969e-01,  2.4693e-02,
          3.4840e-01,  3.3886e-02, -2.7562e-01, -4.2305e-01, -1.4418e-01,
          3.3536e-01, -2.7491e-01,  5.2891e-01,  3.0901e-01, -4.6127e-01,
          7.0903e-02, -1.1390e-01,  4.2822e-01, -4.7448e-01, -1.9457e-01,
          1.7779e-01, -3.3084e-01, -4.7311e-01, -4.2679e-01,  7.1815e-02,
          2.4915e-01, -4.4569e-01,  1.6466e-01,  4.1354e-02, -2.4865e-01,
         -4.2151e-01, -2.8002e-01,  8.4000e-02, -1.1305e-01,  3.2736e-01,
          1.0333e-01, -2.9267e-01, -3.9020e-02,  3.9709e-01, -3.1718e-01,
          4.5334e-01,  6.2500e-01, -2.3732e-01,  1.5878e-01, -3.1546e-01,
          1.4519e-01, -3.7691e-01,  4.5056e-01,  3.8429e-01,  1.1904e-01,
          4.6546e-01,  8.9835e-02, -3.4235e-02,  7.0945e-02,  5.7647e-02,
          3.2093e-01, -7.4279e-02,  1.9812e-01,  6.6854e-01,  8.3255e-03,
          5.2060e-01,  1.4760e-01,  4.9135e-02, -5.2057e-01,  8.4303e-02,
          2.5593e-02,  3.9829e-01, -3.1141e-01,  6.5268e-02, -4.9857e-02,
         -4.5633e-02, -6.8734e-01, -2.6750e-03, -2.4190e-01, -2.8735e-01,
         -3.2288e-02,  5.3618e-01,  3.4173e-01, -3.6855e-01, -4.1932e-01,
         -3.2033e-01, -2.7842e-01,  4.4021e-01,  8.6230e-01,  9.1970e-02,
         -1.1976e-01, -3.8733e-01, -9.0361e-02, -5.4882e-02,  1.3525e-01,
          3.8096e-02,  6.2839e-01,  4.1826e-01,  4.6406e-01, -2.4304e-01,
         -4.5163e-01, -2.7172e-01, -1.2460e-01,  2.3671e-01, -3.1206e-01,
         -1.7764e-02,  1.3673e-03, -2.0460e-02, -6.8924e-02, -3.0854e-01,
         -2.8193e-02, -1.2100e-01,  2.0054e-01, -8.8251e-02, -1.1931e-01,
         -1.0426e-01, -6.4048e-01, -3.0713e-01,  2.0817e-01,  6.5585e-02,
         -1.4141e-01,  2.0945e-01, -7.4820e-04, -2.2530e-01, -3.7012e-01,
          1.6271e-01, -4.9095e-01, -2.2408e-01, -3.8781e-01,  2.5892e-01,
         -3.5237e-01,  6.4705e-03, -4.4271e-01,  5.8282e-01,  1.8517e-01,
          3.0051e-02,  5.0570e-02,  2.0626e-01, -1.3862e-01,  1.3162e-01,
          1.2967e-01,  2.0172e-01, -4.2257e-01,  8.3080e-02,  2.6301e-01,
          1.8749e-01, -3.6900e-01,  2.6178e-01,  3.2177e-01, -2.0241e-01,
         -5.9555e-01,  1.7245e-01, -7.6558e-02, -8.9417e-02,  1.7406e-01,
         -3.0616e-01, -5.1685e-02,  1.4586e-01,  5.1845e-01,  3.5010e-01,
         -4.0866e-01, -6.4725e-01,  1.4885e-01,  3.5427e-01, -7.2978e-02,
         -6.2830e-01, -2.0126e-01, -2.4575e-01,  2.5788e-01, -6.6602e-01,
          1.4807e-01,  5.9979e-01,  3.1298e-01, -2.1984e-02, -2.1055e-01,
          4.2543e-01, -4.2785e-01,  2.8597e-01, -4.6195e-02, -4.4302e-01,
         -1.6596e-01,  4.3690e-01,  8.2672e-03,  8.6318e-02,  2.6571e-01,
          3.8568e-01,  7.2709e-02, -5.9491e-01, -3.6851e-01,  3.6038e-01,
          3.4782e-03,  4.1766e-01,  5.5036e-01,  2.9479e-02, -3.7907e-01,
          1.8382e-03, -1.4601e-01,  1.6616e-01,  5.3503e-01,  1.3591e-02,
          1.2013e-01, -8.5887e-02,  3.7715e-01, -3.4969e-01,  4.3805e-01,
          3.1855e-01, -3.6571e-01, -1.7446e-01,  4.0240e-01, -1.6065e-01,
         -3.6733e-01,  1.7065e-01,  9.1335e-02,  3.1418e-01, -1.3760e-01,
         -4.5394e-01, -2.5068e-01,  8.7604e-02, -6.2930e-01,  1.2898e-02,
         -3.7761e-01,  5.9227e-02, -2.4603e-01,  1.9747e-01, -7.6524e-01,
          4.1795e-01, -3.2705e-01, -4.8150e-01, -1.3054e-01, -1.7629e-02,
         -7.9984e-02,  3.5556e-01,  4.0054e-01, -2.2257e-01, -4.4133e-03,
         -2.0015e-01, -1.1900e-01, -2.7484e-01, -5.1239e-01, -6.3264e-01,
         -1.7553e-01, -3.6384e-02,  1.4799e-01,  4.2550e-01,  4.8262e-01,
         -4.1353e-01,  1.6462e-01, -3.8982e-01,  3.9817e-02,  2.0532e-01,
         -1.9002e-01, -1.7682e-01,  8.7832e-01,  1.1802e-01, -4.0827e-01,
          4.1533e-01,  5.2921e-01, -3.8746e-01,  5.6729e-01,  2.9954e-01,
         -4.1602e-01, -1.2003e-01, -1.2318e-01,  6.4842e-02,  7.1454e-01,
         -3.3365e-01, -8.2613e-03, -9.7548e-02,  6.7619e-01, -2.0094e-01,
          6.8275e-02, -1.9088e-01,  2.5895e-01, -1.8892e-02,  8.5494e-02,
          4.3036e-01,  2.0538e-01,  5.8892e-01,  6.2417e-01,  4.8445e-01,
         -2.7654e-01,  3.1131e-01,  3.5275e-01,  3.1345e-01, -4.5330e-02,
          4.1206e-01, -3.9273e-01, -1.9450e-01,  1.3716e-02, -2.6335e-01,
          1.4685e-01,  3.2094e-01, -2.6300e-01,  9.1132e-02,  9.6662e-02,
         -2.8584e-01,  4.9270e-01,  5.0694e-01, -6.7856e-01, -1.6952e-02,
          2.0858e-01,  2.7211e-01,  7.7594e-03,  1.1058e-01,  3.5853e-01,
         -3.4715e-02,  1.9556e-01, -1.0988e-01, -2.6661e-01,  8.2309e-02,
         -1.8942e-01,  4.2286e-01,  2.1585e-01,  2.0750e-01, -1.9119e-01,
          3.1705e-01, -3.8454e-01, -2.0743e-01, -3.8114e-02,  6.4414e-02,
         -1.7748e-01,  1.3586e-01,  4.2025e-01,  5.2959e-01, -3.0235e-01,
          6.6244e-02,  5.9458e-02, -3.8626e-01, -3.0927e-01, -2.5877e-01,
          3.9770e-01, -3.5933e-01,  2.1776e-01, -4.3661e-01,  3.3840e-01,
          3.5971e-01, -2.2540e-01, -2.6150e-01, -3.6218e-01,  6.4707e-01,
          8.7594e-01,  5.4092e-01, -8.1894e-02,  5.3965e-01, -1.3166e-01,
         -1.9551e-01, -7.0249e-01, -3.5140e-01,  9.1459e-02,  8.1300e-03,
          2.1649e-01,  9.5686e-02,  4.3850e-01, -5.3493e-01,  1.3832e-01,
         -1.7769e-01, -3.1088e-01,  1.4557e-01,  5.7953e-01, -8.4913e-02,
          1.5262e-01, -4.3042e-02,  3.5596e-01, -2.6371e-01, -1.3432e-01,
          4.5435e-01, -5.2918e-02, -3.9792e-01, -1.0195e-01,  1.0674e-01,
         -8.1712e-02,  7.9050e-01, -7.5311e-02,  3.8989e-02, -5.4863e-01,
          2.3593e-01,  1.7604e-01, -4.1790e-01, -5.9872e-01,  8.6589e-04,
         -2.7348e-02,  6.8003e-01, -2.4577e-01,  2.8322e-01,  2.7373e-04,
          1.9466e-01,  1.7917e-01,  2.8938e-01,  2.7149e-01, -4.1166e-01,
          1.0486e-01, -2.8750e-01, -3.6946e-01,  5.6385e-01, -7.4233e-01,
         -3.6163e-01,  3.5484e-01,  3.3670e-01,  9.1394e-03, -1.0086e-01,
         -1.7736e-01, -3.6094e-01,  8.7540e-01, -2.3598e-01,  3.2910e-01,
         -7.4240e-01,  6.6476e-01, -1.7125e-01,  3.7107e-01, -6.8735e-01,
          7.3219e-01,  5.7308e-01, -7.9865e-02,  2.6137e-03, -1.0492e-01,
          6.2231e-01, -2.2494e-01,  6.8010e-01,  1.1748e-01,  5.2259e-01,
          1.2923e-02,  7.3691e-02,  3.4888e-01,  2.6414e-01,  4.2186e-01,
         -4.1445e-01,  5.7697e-01,  4.0721e-01, -4.0092e-01, -4.1310e-01,
          5.1246e-01,  5.3019e-03,  5.7073e-01, -6.6950e-01, -7.4447e-02,
         -3.0260e-01,  2.1808e-01,  8.2279e-01, -5.1817e-01,  5.0470e-01,
          3.2587e-01,  2.6581e-01,  5.2826e-01, -7.4837e-03, -6.9155e-02,
          2.5341e-01, -3.2784e-01, -2.1990e-02, -4.8601e-01, -1.7147e-01,
         -3.9870e-01, -3.0875e-01, -2.6406e-01, -2.0629e-01,  3.1720e-01,
          3.3498e-01, -1.0637e-01,  1.1432e-01, -2.1800e-01,  6.6413e-01,
         -2.0818e-02, -5.1117e-01, -6.3738e-01,  2.4649e-01,  1.9480e-01,
          1.1880e-02, -4.4444e-01,  9.7113e-02, -1.0584e-01,  6.0753e-01,
          7.0593e-01,  4.3478e-01,  1.8733e-01,  3.2939e-02,  3.8776e-01,
          2.8482e-01, -4.1235e-01, -6.0461e-01,  3.8104e-01,  1.0732e-01,
         -7.0059e-01,  2.6696e-01, -2.9421e-01,  4.3722e-01, -4.5591e-01,
         -8.6827e-02,  5.9254e-02, -4.1622e-01, -3.9528e-01, -4.8446e-01,
         -4.7552e-02, -4.9195e-01,  4.2025e-01, -5.4779e-01, -1.7593e-02,
          7.4183e-01, -7.0238e-01,  4.6337e-01,  4.0638e-01,  2.6151e-01,
          5.7075e-01, -1.9192e-01,  8.6687e-02,  5.0342e-01,  3.5060e-02,
          4.3095e-01,  6.2844e-01, -2.7865e-01, -1.8283e-01,  7.1376e-01,
         -1.0288e-01,  3.3084e-01,  7.6745e-01,  2.1309e-02, -4.1063e-01,
          5.3351e-01, -1.1141e-01, -1.5108e-01,  2.6530e-01,  6.8424e-01,
          1.6492e-01,  4.6153e-01, -2.9771e-01,  1.0697e-01,  1.4702e-01,
          1.2702e-01, -5.0592e-01, -3.6936e-01, -5.2906e-01,  2.2893e-01,
         -2.6245e-01,  4.2968e-02, -1.7851e-01, -5.6460e-02,  5.5637e-01,
         -5.9503e-01, -7.7544e-02, -2.2456e-01, -6.1064e-01,  3.1447e-01,
          1.4890e-01, -2.8982e-02, -1.1260e-04,  4.4912e-01, -3.5829e-01,
         -3.2105e-01,  7.6753e-01, -1.3102e-03,  2.2552e-02,  2.3368e-02,
          1.3975e-01, -6.5992e-01, -3.0786e-01]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.6000% F1: 0.2628
Applying ckpt from fold 1 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.6000% F1: 0.2842
Applying ckpt from fold 2 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.2000% F1: 0.3166
Applying ckpt from fold 3 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.0000% F1: 0.3345
Applying ckpt from fold 4 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.0000% F1: 0.2737
Applying ckpt from fold 5 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.6000% F1: 0.3197
Applying ckpt from fold 6 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.8000% F1: 0.3208
Applying ckpt from fold 7 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.2000% F1: 0.2804
Applying ckpt from fold 8 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.4000% F1: 0.2926
Applying ckpt from fold 9 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.0000% F1: 0.3277
Metrics by fold:
Fold 0 - Acc: 0.56 F1: 0.26
Fold 1 - Acc: 0.54 F1: 0.28
Fold 2 - Acc: 0.53 F1: 0.32
Fold 3 - Acc: 0.52 F1: 0.33
Fold 4 - Acc: 0.54 F1: 0.27
Fold 5 - Acc: 0.54 F1: 0.32
Fold 6 - Acc: 0.54 F1: 0.32
Fold 7 - Acc: 0.51 F1: 0.28
Fold 8 - Acc: 0.51 F1: 0.29
Fold 9 - Acc: 0.54 F1: 0.33
agg_acc: 0.5324 agg_f1: 0.3013
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-4.3606e-02, -1.5910e-01, -4.8581e-01, -3.8263e-01, -5.1680e-01,
         -1.8935e-01,  4.8751e-01,  2.9280e-01, -1.0607e-01, -2.6697e-01,
         -4.9493e-01, -1.1257e-01, -1.9788e-01, -1.3184e-01, -2.6747e-01,
         -5.4098e-01,  1.0436e-01, -7.9363e-02,  2.6787e-01, -3.4898e-01,
         -5.5895e-01, -4.0749e-01, -2.7529e-01, -5.5366e-01,  7.3051e-01,
         -4.5888e-01, -7.5373e-02, -1.4036e-01,  4.2218e-02, -9.4052e-02,
         -4.0497e-01,  6.7652e-01, -1.5242e-02,  2.2938e-01,  3.3972e-01,
          2.6711e-01, -5.7348e-03, -3.8172e-01,  3.7646e-01, -4.6330e-01,
          6.0895e-01, -1.1278e-01,  9.5125e-02,  1.5848e-01, -8.8011e-02,
          2.1012e-01,  3.2058e-01, -1.2087e-01,  1.9975e-01, -3.9109e-01,
          1.9737e-01,  1.5232e-01,  7.0129e-01, -9.8670e-02,  6.9456e-01,
         -3.5982e-01,  6.0930e-01,  1.1148e-01,  8.1908e-02,  2.7244e-01,
          1.1667e-01, -5.8989e-01, -2.2864e-01, -5.4887e-01,  4.0342e-01,
          6.6261e-02,  6.1714e-01,  2.9520e-03,  3.1208e-01, -4.7937e-01,
         -6.9867e-01, -2.6097e-01,  3.9696e-01, -2.9471e-01, -5.4417e-01,
          5.6128e-02,  2.0631e-01,  1.4236e-01, -1.7459e-01, -1.3846e-01,
         -1.5302e-01, -2.8679e-01,  7.9617e-02, -5.5280e-01, -5.8188e-02,
         -3.5297e-01,  1.7067e-01,  3.2233e-02, -7.4358e-01,  5.5985e-01,
          1.5651e-01, -7.1408e-01,  2.1729e-01, -6.5467e-01, -3.5687e-01,
          4.0038e-01,  5.3516e-01,  1.2456e-01, -5.9177e-01, -4.7869e-01,
          1.4700e-01, -2.3916e-01, -3.3883e-01, -6.4858e-02,  1.4353e-01,
         -4.7894e-01,  4.1543e-01, -3.2510e-01, -4.1771e-01, -1.3029e-01,
          5.5638e-01, -1.1075e-01, -3.2858e-02,  7.4421e-02, -3.2686e-01,
         -4.8930e-01, -7.5107e-01,  3.2951e-01,  1.4170e-01,  2.4140e-01,
         -6.4900e-02, -3.8840e-01, -2.9613e-02, -2.1750e-02,  1.2730e-01,
         -7.6223e-01, -1.4084e-01,  2.8811e-01, -1.2155e-01,  6.5782e-01,
          1.4252e-01,  2.7522e-01,  5.6607e-01, -3.5640e-01, -1.6254e-01,
         -5.6422e-01, -4.1899e-01,  7.1397e-01, -2.5976e-01,  3.7979e-01,
          6.9408e-01, -9.6555e-02, -5.7445e-01, -8.3463e-02,  6.6205e-02,
          7.3398e-01, -1.4064e-01,  4.6967e-02,  1.7280e-01,  4.3330e-01,
          5.1674e-01,  2.0085e-01, -2.8088e-01, -4.8809e-01, -6.1372e-02,
          1.7789e-01,  8.4561e-02, -2.2256e-01, -8.8882e-02, -2.0205e-01,
          7.9238e-01, -3.7167e-01, -4.3697e-01, -5.5123e-01,  3.4803e-01,
          3.3974e-01, -3.6795e-03, -9.4672e-02,  4.4612e-01,  7.0981e-02,
          1.4914e-01, -1.1917e-01, -1.3173e-01,  5.9845e-02,  4.2897e-01,
          2.7345e-01,  4.5077e-01, -9.3647e-02, -2.5648e-01, -3.4603e-01,
          3.8954e-01,  4.3317e-01, -3.7800e-01,  1.2969e-01,  8.4454e-02,
          1.5298e-01,  3.3882e-01,  1.2758e-01, -2.0599e-01, -2.6551e-01,
          1.8176e-01, -8.8421e-02, -3.2220e-01, -8.8067e-02,  2.1718e-01,
         -3.6291e-01, -4.9237e-01,  2.1455e-01, -1.8674e-02,  3.9949e-01,
         -2.2519e-01, -1.4739e-01, -2.2509e-01,  2.9665e-01, -3.3978e-01,
         -4.4125e-01,  5.8753e-01,  2.4695e-01, -9.5062e-02,  9.9014e-03,
         -1.6486e-01,  2.4021e-01,  3.2167e-02, -2.2061e-01, -4.3971e-01,
          5.9503e-01, -1.8055e-01, -8.3522e-02,  1.0926e-01,  3.9749e-02,
          1.6904e-01,  7.3836e-02,  9.2030e-02,  2.3969e-01,  2.4693e-02,
          3.4840e-01,  3.3886e-02, -2.7562e-01, -4.2305e-01, -1.4418e-01,
          3.3536e-01, -2.7491e-01,  5.2891e-01,  3.0901e-01, -4.6127e-01,
          7.0903e-02, -1.1390e-01,  4.2822e-01, -4.7448e-01, -1.9457e-01,
          1.7779e-01, -3.3084e-01, -4.7311e-01, -4.2679e-01,  7.1815e-02,
          2.4915e-01, -4.4569e-01,  1.6466e-01,  4.1354e-02, -2.4865e-01,
         -4.2151e-01, -2.8002e-01,  8.4000e-02, -1.1305e-01,  3.2736e-01,
          1.0333e-01, -2.9267e-01, -3.9020e-02,  3.9709e-01, -3.1718e-01,
          4.5334e-01,  6.2500e-01, -2.3732e-01,  1.5878e-01, -3.1546e-01,
          1.4519e-01, -3.7691e-01,  4.5056e-01,  3.8429e-01,  1.1904e-01,
          4.6546e-01,  8.9835e-02, -3.4235e-02,  7.0945e-02,  5.7647e-02,
          3.2093e-01, -7.4279e-02,  1.9812e-01,  6.6854e-01,  8.3255e-03,
          5.2060e-01,  1.4760e-01,  4.9135e-02, -5.2057e-01,  8.4303e-02,
          2.5593e-02,  3.9829e-01, -3.1141e-01,  6.5268e-02, -4.9857e-02,
         -4.5633e-02, -6.8734e-01, -2.6750e-03, -2.4190e-01, -2.8735e-01,
         -3.2288e-02,  5.3618e-01,  3.4173e-01, -3.6855e-01, -4.1932e-01,
         -3.2033e-01, -2.7842e-01,  4.4021e-01,  8.6230e-01,  9.1970e-02,
         -1.1976e-01, -3.8733e-01, -9.0361e-02, -5.4882e-02,  1.3525e-01,
          3.8096e-02,  6.2839e-01,  4.1826e-01,  4.6406e-01, -2.4304e-01,
         -4.5163e-01, -2.7172e-01, -1.2460e-01,  2.3671e-01, -3.1206e-01,
         -1.7764e-02,  1.3673e-03, -2.0460e-02, -6.8924e-02, -3.0854e-01,
         -2.8193e-02, -1.2100e-01,  2.0054e-01, -8.8251e-02, -1.1931e-01,
         -1.0426e-01, -6.4048e-01, -3.0713e-01,  2.0817e-01,  6.5585e-02,
         -1.4141e-01,  2.0945e-01, -7.4820e-04, -2.2530e-01, -3.7012e-01,
          1.6271e-01, -4.9095e-01, -2.2408e-01, -3.8781e-01,  2.5892e-01,
         -3.5237e-01,  6.4705e-03, -4.4271e-01,  5.8282e-01,  1.8517e-01,
          3.0051e-02,  5.0570e-02,  2.0626e-01, -1.3862e-01,  1.3162e-01,
          1.2967e-01,  2.0172e-01, -4.2257e-01,  8.3080e-02,  2.6301e-01,
          1.8749e-01, -3.6900e-01,  2.6178e-01,  3.2177e-01, -2.0241e-01,
         -5.9555e-01,  1.7245e-01, -7.6558e-02, -8.9417e-02,  1.7406e-01,
         -3.0616e-01, -5.1685e-02,  1.4586e-01,  5.1845e-01,  3.5010e-01,
         -4.0866e-01, -6.4725e-01,  1.4885e-01,  3.5427e-01, -7.2978e-02,
         -6.2830e-01, -2.0126e-01, -2.4575e-01,  2.5788e-01, -6.6602e-01,
          1.4807e-01,  5.9979e-01,  3.1298e-01, -2.1984e-02, -2.1055e-01,
          4.2543e-01, -4.2785e-01,  2.8597e-01, -4.6195e-02, -4.4302e-01,
         -1.6596e-01,  4.3690e-01,  8.2672e-03,  8.6318e-02,  2.6571e-01,
          3.8568e-01,  7.2709e-02, -5.9491e-01, -3.6851e-01,  3.6038e-01,
          3.4782e-03,  4.1766e-01,  5.5036e-01,  2.9479e-02, -3.7907e-01,
          1.8382e-03, -1.4601e-01,  1.6616e-01,  5.3503e-01,  1.3591e-02,
          1.2013e-01, -8.5887e-02,  3.7715e-01, -3.4969e-01,  4.3805e-01,
          3.1855e-01, -3.6571e-01, -1.7446e-01,  4.0240e-01, -1.6065e-01,
         -3.6733e-01,  1.7065e-01,  9.1335e-02,  3.1418e-01, -1.3760e-01,
         -4.5394e-01, -2.5068e-01,  8.7604e-02, -6.2930e-01,  1.2898e-02,
         -3.7761e-01,  5.9227e-02, -2.4603e-01,  1.9747e-01, -7.6524e-01,
          4.1795e-01, -3.2705e-01, -4.8150e-01, -1.3054e-01, -1.7629e-02,
         -7.9984e-02,  3.5556e-01,  4.0054e-01, -2.2257e-01, -4.4133e-03,
         -2.0015e-01, -1.1900e-01, -2.7484e-01, -5.1239e-01, -6.3264e-01,
         -1.7553e-01, -3.6384e-02,  1.4799e-01,  4.2550e-01,  4.8262e-01,
         -4.1353e-01,  1.6462e-01, -3.8982e-01,  3.9817e-02,  2.0532e-01,
         -1.9002e-01, -1.7682e-01,  8.7832e-01,  1.1802e-01, -4.0827e-01,
          4.1533e-01,  5.2921e-01, -3.8746e-01,  5.6729e-01,  2.9954e-01,
         -4.1602e-01, -1.2003e-01, -1.2318e-01,  6.4842e-02,  7.1454e-01,
         -3.3365e-01, -8.2613e-03, -9.7548e-02,  6.7619e-01, -2.0094e-01,
          6.8275e-02, -1.9088e-01,  2.5895e-01, -1.8892e-02,  8.5494e-02,
          4.3036e-01,  2.0538e-01,  5.8892e-01,  6.2417e-01,  4.8445e-01,
         -2.7654e-01,  3.1131e-01,  3.5275e-01,  3.1345e-01, -4.5330e-02,
          4.1206e-01, -3.9273e-01, -1.9450e-01,  1.3716e-02, -2.6335e-01,
          1.4685e-01,  3.2094e-01, -2.6300e-01,  9.1132e-02,  9.6662e-02,
         -2.8584e-01,  4.9270e-01,  5.0694e-01, -6.7856e-01, -1.6952e-02,
          2.0858e-01,  2.7211e-01,  7.7594e-03,  1.1058e-01,  3.5853e-01,
         -3.4715e-02,  1.9556e-01, -1.0988e-01, -2.6661e-01,  8.2309e-02,
         -1.8942e-01,  4.2286e-01,  2.1585e-01,  2.0750e-01, -1.9119e-01,
          3.1705e-01, -3.8454e-01, -2.0743e-01, -3.8114e-02,  6.4414e-02,
         -1.7748e-01,  1.3586e-01,  4.2025e-01,  5.2959e-01, -3.0235e-01,
          6.6244e-02,  5.9458e-02, -3.8626e-01, -3.0927e-01, -2.5877e-01,
          3.9770e-01, -3.5933e-01,  2.1776e-01, -4.3661e-01,  3.3840e-01,
          3.5971e-01, -2.2540e-01, -2.6150e-01, -3.6218e-01,  6.4707e-01,
          8.7594e-01,  5.4092e-01, -8.1894e-02,  5.3965e-01, -1.3166e-01,
         -1.9551e-01, -7.0249e-01, -3.5140e-01,  9.1459e-02,  8.1300e-03,
          2.1649e-01,  9.5686e-02,  4.3850e-01, -5.3493e-01,  1.3832e-01,
         -1.7769e-01, -3.1088e-01,  1.4557e-01,  5.7953e-01, -8.4913e-02,
          1.5262e-01, -4.3042e-02,  3.5596e-01, -2.6371e-01, -1.3432e-01,
          4.5435e-01, -5.2918e-02, -3.9792e-01, -1.0195e-01,  1.0674e-01,
         -8.1712e-02,  7.9050e-01, -7.5311e-02,  3.8989e-02, -5.4863e-01,
          2.3593e-01,  1.7604e-01, -4.1790e-01, -5.9872e-01,  8.6589e-04,
         -2.7348e-02,  6.8003e-01, -2.4577e-01,  2.8322e-01,  2.7373e-04,
          1.9466e-01,  1.7917e-01,  2.8938e-01,  2.7149e-01, -4.1166e-01,
          1.0486e-01, -2.8750e-01, -3.6946e-01,  5.6385e-01, -7.4233e-01,
         -3.6163e-01,  3.5484e-01,  3.3670e-01,  9.1394e-03, -1.0086e-01,
         -1.7736e-01, -3.6094e-01,  8.7540e-01, -2.3598e-01,  3.2910e-01,
         -7.4240e-01,  6.6476e-01, -1.7125e-01,  3.7107e-01, -6.8735e-01,
          7.3219e-01,  5.7308e-01, -7.9865e-02,  2.6137e-03, -1.0492e-01,
          6.2231e-01, -2.2494e-01,  6.8010e-01,  1.1748e-01,  5.2259e-01,
          1.2923e-02,  7.3691e-02,  3.4888e-01,  2.6414e-01,  4.2186e-01,
         -4.1445e-01,  5.7697e-01,  4.0721e-01, -4.0092e-01, -4.1310e-01,
          5.1246e-01,  5.3019e-03,  5.7073e-01, -6.6950e-01, -7.4447e-02,
         -3.0260e-01,  2.1808e-01,  8.2279e-01, -5.1817e-01,  5.0470e-01,
          3.2587e-01,  2.6581e-01,  5.2826e-01, -7.4837e-03, -6.9155e-02,
          2.5341e-01, -3.2784e-01, -2.1990e-02, -4.8601e-01, -1.7147e-01,
         -3.9870e-01, -3.0875e-01, -2.6406e-01, -2.0629e-01,  3.1720e-01,
          3.3498e-01, -1.0637e-01,  1.1432e-01, -2.1800e-01,  6.6413e-01,
         -2.0818e-02, -5.1117e-01, -6.3738e-01,  2.4649e-01,  1.9480e-01,
          1.1880e-02, -4.4444e-01,  9.7113e-02, -1.0584e-01,  6.0753e-01,
          7.0593e-01,  4.3478e-01,  1.8733e-01,  3.2939e-02,  3.8776e-01,
          2.8482e-01, -4.1235e-01, -6.0461e-01,  3.8104e-01,  1.0732e-01,
         -7.0059e-01,  2.6696e-01, -2.9421e-01,  4.3722e-01, -4.5591e-01,
         -8.6827e-02,  5.9254e-02, -4.1622e-01, -3.9528e-01, -4.8446e-01,
         -4.7552e-02, -4.9195e-01,  4.2025e-01, -5.4779e-01, -1.7593e-02,
          7.4183e-01, -7.0238e-01,  4.6337e-01,  4.0638e-01,  2.6151e-01,
          5.7075e-01, -1.9192e-01,  8.6687e-02,  5.0342e-01,  3.5060e-02,
          4.3095e-01,  6.2844e-01, -2.7865e-01, -1.8283e-01,  7.1376e-01,
         -1.0288e-01,  3.3084e-01,  7.6745e-01,  2.1309e-02, -4.1063e-01,
          5.3351e-01, -1.1141e-01, -1.5108e-01,  2.6530e-01,  6.8424e-01,
          1.6492e-01,  4.6153e-01, -2.9771e-01,  1.0697e-01,  1.4702e-01,
          1.2702e-01, -5.0592e-01, -3.6936e-01, -5.2906e-01,  2.2893e-01,
         -2.6245e-01,  4.2968e-02, -1.7851e-01, -5.6460e-02,  5.5637e-01,
         -5.9503e-01, -7.7544e-02, -2.2456e-01, -6.1064e-01,  3.1447e-01,
          1.4890e-01, -2.8982e-02, -1.1260e-04,  4.4912e-01, -3.5829e-01,
         -3.2105e-01,  7.6753e-01, -1.3102e-03,  2.2552e-02,  2.3368e-02,
          1.3975e-01, -6.5992e-01, -3.0786e-01]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.4000% F1: 0.3106
Applying ckpt from fold 1 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.6000% F1: 0.2745
Applying ckpt from fold 2 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.8000% F1: 0.2813
Applying ckpt from fold 3 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.6000% F1: 0.2963
Applying ckpt from fold 4 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.8000% F1: 0.2603
Applying ckpt from fold 5 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.8000% F1: 0.3312
Applying ckpt from fold 6 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.0000% F1: 0.2509
Applying ckpt from fold 7 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.6000% F1: 0.2825
Applying ckpt from fold 8 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.6000% F1: 0.2869
Applying ckpt from fold 9 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.0000% F1: 0.3102
Metrics by fold:
Fold 0 - Acc: 0.51 F1: 0.31
Fold 1 - Acc: 0.53 F1: 0.27
Fold 2 - Acc: 0.56 F1: 0.28
Fold 3 - Acc: 0.55 F1: 0.30
Fold 4 - Acc: 0.56 F1: 0.26
Fold 5 - Acc: 0.55 F1: 0.33
Fold 6 - Acc: 0.54 F1: 0.25
Fold 7 - Acc: 0.52 F1: 0.28
Fold 8 - Acc: 0.54 F1: 0.29
Fold 9 - Acc: 0.53 F1: 0.31
agg_acc: 0.5372 agg_f1: 0.2885
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-4.3606e-02, -1.5910e-01, -4.8581e-01, -3.8263e-01, -5.1680e-01,
         -1.8935e-01,  4.8751e-01,  2.9280e-01, -1.0607e-01, -2.6697e-01,
         -4.9493e-01, -1.1257e-01, -1.9788e-01, -1.3184e-01, -2.6747e-01,
         -5.4098e-01,  1.0436e-01, -7.9363e-02,  2.6787e-01, -3.4898e-01,
         -5.5895e-01, -4.0749e-01, -2.7529e-01, -5.5366e-01,  7.3051e-01,
         -4.5888e-01, -7.5373e-02, -1.4036e-01,  4.2218e-02, -9.4052e-02,
         -4.0497e-01,  6.7652e-01, -1.5242e-02,  2.2938e-01,  3.3972e-01,
          2.6711e-01, -5.7348e-03, -3.8172e-01,  3.7646e-01, -4.6330e-01,
          6.0895e-01, -1.1278e-01,  9.5125e-02,  1.5848e-01, -8.8011e-02,
          2.1012e-01,  3.2058e-01, -1.2087e-01,  1.9975e-01, -3.9109e-01,
          1.9737e-01,  1.5232e-01,  7.0129e-01, -9.8670e-02,  6.9456e-01,
         -3.5982e-01,  6.0930e-01,  1.1148e-01,  8.1908e-02,  2.7244e-01,
          1.1667e-01, -5.8989e-01, -2.2864e-01, -5.4887e-01,  4.0342e-01,
          6.6261e-02,  6.1714e-01,  2.9520e-03,  3.1208e-01, -4.7937e-01,
         -6.9867e-01, -2.6097e-01,  3.9696e-01, -2.9471e-01, -5.4417e-01,
          5.6128e-02,  2.0631e-01,  1.4236e-01, -1.7459e-01, -1.3846e-01,
         -1.5302e-01, -2.8679e-01,  7.9617e-02, -5.5280e-01, -5.8188e-02,
         -3.5297e-01,  1.7067e-01,  3.2233e-02, -7.4358e-01,  5.5985e-01,
          1.5651e-01, -7.1408e-01,  2.1729e-01, -6.5467e-01, -3.5687e-01,
          4.0038e-01,  5.3516e-01,  1.2456e-01, -5.9177e-01, -4.7869e-01,
          1.4700e-01, -2.3916e-01, -3.3883e-01, -6.4858e-02,  1.4353e-01,
         -4.7894e-01,  4.1543e-01, -3.2510e-01, -4.1771e-01, -1.3029e-01,
          5.5638e-01, -1.1075e-01, -3.2858e-02,  7.4421e-02, -3.2686e-01,
         -4.8930e-01, -7.5107e-01,  3.2951e-01,  1.4170e-01,  2.4140e-01,
         -6.4900e-02, -3.8840e-01, -2.9613e-02, -2.1750e-02,  1.2730e-01,
         -7.6223e-01, -1.4084e-01,  2.8811e-01, -1.2155e-01,  6.5782e-01,
          1.4252e-01,  2.7522e-01,  5.6607e-01, -3.5640e-01, -1.6254e-01,
         -5.6422e-01, -4.1899e-01,  7.1397e-01, -2.5976e-01,  3.7979e-01,
          6.9408e-01, -9.6555e-02, -5.7445e-01, -8.3463e-02,  6.6205e-02,
          7.3398e-01, -1.4064e-01,  4.6967e-02,  1.7280e-01,  4.3330e-01,
          5.1674e-01,  2.0085e-01, -2.8088e-01, -4.8809e-01, -6.1372e-02,
          1.7789e-01,  8.4561e-02, -2.2256e-01, -8.8882e-02, -2.0205e-01,
          7.9238e-01, -3.7167e-01, -4.3697e-01, -5.5123e-01,  3.4803e-01,
          3.3974e-01, -3.6795e-03, -9.4672e-02,  4.4612e-01,  7.0981e-02,
          1.4914e-01, -1.1917e-01, -1.3173e-01,  5.9845e-02,  4.2897e-01,
          2.7345e-01,  4.5077e-01, -9.3647e-02, -2.5648e-01, -3.4603e-01,
          3.8954e-01,  4.3317e-01, -3.7800e-01,  1.2969e-01,  8.4454e-02,
          1.5298e-01,  3.3882e-01,  1.2758e-01, -2.0599e-01, -2.6551e-01,
          1.8176e-01, -8.8421e-02, -3.2220e-01, -8.8067e-02,  2.1718e-01,
         -3.6291e-01, -4.9237e-01,  2.1455e-01, -1.8674e-02,  3.9949e-01,
         -2.2519e-01, -1.4739e-01, -2.2509e-01,  2.9665e-01, -3.3978e-01,
         -4.4125e-01,  5.8753e-01,  2.4695e-01, -9.5062e-02,  9.9014e-03,
         -1.6486e-01,  2.4021e-01,  3.2167e-02, -2.2061e-01, -4.3971e-01,
          5.9503e-01, -1.8055e-01, -8.3522e-02,  1.0926e-01,  3.9749e-02,
          1.6904e-01,  7.3836e-02,  9.2030e-02,  2.3969e-01,  2.4693e-02,
          3.4840e-01,  3.3886e-02, -2.7562e-01, -4.2305e-01, -1.4418e-01,
          3.3536e-01, -2.7491e-01,  5.2891e-01,  3.0901e-01, -4.6127e-01,
          7.0903e-02, -1.1390e-01,  4.2822e-01, -4.7448e-01, -1.9457e-01,
          1.7779e-01, -3.3084e-01, -4.7311e-01, -4.2679e-01,  7.1815e-02,
          2.4915e-01, -4.4569e-01,  1.6466e-01,  4.1354e-02, -2.4865e-01,
         -4.2151e-01, -2.8002e-01,  8.4000e-02, -1.1305e-01,  3.2736e-01,
          1.0333e-01, -2.9267e-01, -3.9020e-02,  3.9709e-01, -3.1718e-01,
          4.5334e-01,  6.2500e-01, -2.3732e-01,  1.5878e-01, -3.1546e-01,
          1.4519e-01, -3.7691e-01,  4.5056e-01,  3.8429e-01,  1.1904e-01,
          4.6546e-01,  8.9835e-02, -3.4235e-02,  7.0945e-02,  5.7647e-02,
          3.2093e-01, -7.4279e-02,  1.9812e-01,  6.6854e-01,  8.3255e-03,
          5.2060e-01,  1.4760e-01,  4.9135e-02, -5.2057e-01,  8.4303e-02,
          2.5593e-02,  3.9829e-01, -3.1141e-01,  6.5268e-02, -4.9857e-02,
         -4.5633e-02, -6.8734e-01, -2.6750e-03, -2.4190e-01, -2.8735e-01,
         -3.2288e-02,  5.3618e-01,  3.4173e-01, -3.6855e-01, -4.1932e-01,
         -3.2033e-01, -2.7842e-01,  4.4021e-01,  8.6230e-01,  9.1970e-02,
         -1.1976e-01, -3.8733e-01, -9.0361e-02, -5.4882e-02,  1.3525e-01,
          3.8096e-02,  6.2839e-01,  4.1826e-01,  4.6406e-01, -2.4304e-01,
         -4.5163e-01, -2.7172e-01, -1.2460e-01,  2.3671e-01, -3.1206e-01,
         -1.7764e-02,  1.3673e-03, -2.0460e-02, -6.8924e-02, -3.0854e-01,
         -2.8193e-02, -1.2100e-01,  2.0054e-01, -8.8251e-02, -1.1931e-01,
         -1.0426e-01, -6.4048e-01, -3.0713e-01,  2.0817e-01,  6.5585e-02,
         -1.4141e-01,  2.0945e-01, -7.4820e-04, -2.2530e-01, -3.7012e-01,
          1.6271e-01, -4.9095e-01, -2.2408e-01, -3.8781e-01,  2.5892e-01,
         -3.5237e-01,  6.4705e-03, -4.4271e-01,  5.8282e-01,  1.8517e-01,
          3.0051e-02,  5.0570e-02,  2.0626e-01, -1.3862e-01,  1.3162e-01,
          1.2967e-01,  2.0172e-01, -4.2257e-01,  8.3080e-02,  2.6301e-01,
          1.8749e-01, -3.6900e-01,  2.6178e-01,  3.2177e-01, -2.0241e-01,
         -5.9555e-01,  1.7245e-01, -7.6558e-02, -8.9417e-02,  1.7406e-01,
         -3.0616e-01, -5.1685e-02,  1.4586e-01,  5.1845e-01,  3.5010e-01,
         -4.0866e-01, -6.4725e-01,  1.4885e-01,  3.5427e-01, -7.2978e-02,
         -6.2830e-01, -2.0126e-01, -2.4575e-01,  2.5788e-01, -6.6602e-01,
          1.4807e-01,  5.9979e-01,  3.1298e-01, -2.1984e-02, -2.1055e-01,
          4.2543e-01, -4.2785e-01,  2.8597e-01, -4.6195e-02, -4.4302e-01,
         -1.6596e-01,  4.3690e-01,  8.2672e-03,  8.6318e-02,  2.6571e-01,
          3.8568e-01,  7.2709e-02, -5.9491e-01, -3.6851e-01,  3.6038e-01,
          3.4782e-03,  4.1766e-01,  5.5036e-01,  2.9479e-02, -3.7907e-01,
          1.8382e-03, -1.4601e-01,  1.6616e-01,  5.3503e-01,  1.3591e-02,
          1.2013e-01, -8.5887e-02,  3.7715e-01, -3.4969e-01,  4.3805e-01,
          3.1855e-01, -3.6571e-01, -1.7446e-01,  4.0240e-01, -1.6065e-01,
         -3.6733e-01,  1.7065e-01,  9.1335e-02,  3.1418e-01, -1.3760e-01,
         -4.5394e-01, -2.5068e-01,  8.7604e-02, -6.2930e-01,  1.2898e-02,
         -3.7761e-01,  5.9227e-02, -2.4603e-01,  1.9747e-01, -7.6524e-01,
          4.1795e-01, -3.2705e-01, -4.8150e-01, -1.3054e-01, -1.7629e-02,
         -7.9984e-02,  3.5556e-01,  4.0054e-01, -2.2257e-01, -4.4133e-03,
         -2.0015e-01, -1.1900e-01, -2.7484e-01, -5.1239e-01, -6.3264e-01,
         -1.7553e-01, -3.6384e-02,  1.4799e-01,  4.2550e-01,  4.8262e-01,
         -4.1353e-01,  1.6462e-01, -3.8982e-01,  3.9817e-02,  2.0532e-01,
         -1.9002e-01, -1.7682e-01,  8.7832e-01,  1.1802e-01, -4.0827e-01,
          4.1533e-01,  5.2921e-01, -3.8746e-01,  5.6729e-01,  2.9954e-01,
         -4.1602e-01, -1.2003e-01, -1.2318e-01,  6.4842e-02,  7.1454e-01,
         -3.3365e-01, -8.2613e-03, -9.7548e-02,  6.7619e-01, -2.0094e-01,
          6.8275e-02, -1.9088e-01,  2.5895e-01, -1.8892e-02,  8.5494e-02,
          4.3036e-01,  2.0538e-01,  5.8892e-01,  6.2417e-01,  4.8445e-01,
         -2.7654e-01,  3.1131e-01,  3.5275e-01,  3.1345e-01, -4.5330e-02,
          4.1206e-01, -3.9273e-01, -1.9450e-01,  1.3716e-02, -2.6335e-01,
          1.4685e-01,  3.2094e-01, -2.6300e-01,  9.1132e-02,  9.6662e-02,
         -2.8584e-01,  4.9270e-01,  5.0694e-01, -6.7856e-01, -1.6952e-02,
          2.0858e-01,  2.7211e-01,  7.7594e-03,  1.1058e-01,  3.5853e-01,
         -3.4715e-02,  1.9556e-01, -1.0988e-01, -2.6661e-01,  8.2309e-02,
         -1.8942e-01,  4.2286e-01,  2.1585e-01,  2.0750e-01, -1.9119e-01,
          3.1705e-01, -3.8454e-01, -2.0743e-01, -3.8114e-02,  6.4414e-02,
         -1.7748e-01,  1.3586e-01,  4.2025e-01,  5.2959e-01, -3.0235e-01,
          6.6244e-02,  5.9458e-02, -3.8626e-01, -3.0927e-01, -2.5877e-01,
          3.9770e-01, -3.5933e-01,  2.1776e-01, -4.3661e-01,  3.3840e-01,
          3.5971e-01, -2.2540e-01, -2.6150e-01, -3.6218e-01,  6.4707e-01,
          8.7594e-01,  5.4092e-01, -8.1894e-02,  5.3965e-01, -1.3166e-01,
         -1.9551e-01, -7.0249e-01, -3.5140e-01,  9.1459e-02,  8.1300e-03,
          2.1649e-01,  9.5686e-02,  4.3850e-01, -5.3493e-01,  1.3832e-01,
         -1.7769e-01, -3.1088e-01,  1.4557e-01,  5.7953e-01, -8.4913e-02,
          1.5262e-01, -4.3042e-02,  3.5596e-01, -2.6371e-01, -1.3432e-01,
          4.5435e-01, -5.2918e-02, -3.9792e-01, -1.0195e-01,  1.0674e-01,
         -8.1712e-02,  7.9050e-01, -7.5311e-02,  3.8989e-02, -5.4863e-01,
          2.3593e-01,  1.7604e-01, -4.1790e-01, -5.9872e-01,  8.6589e-04,
         -2.7348e-02,  6.8003e-01, -2.4577e-01,  2.8322e-01,  2.7373e-04,
          1.9466e-01,  1.7917e-01,  2.8938e-01,  2.7149e-01, -4.1166e-01,
          1.0486e-01, -2.8750e-01, -3.6946e-01,  5.6385e-01, -7.4233e-01,
         -3.6163e-01,  3.5484e-01,  3.3670e-01,  9.1394e-03, -1.0086e-01,
         -1.7736e-01, -3.6094e-01,  8.7540e-01, -2.3598e-01,  3.2910e-01,
         -7.4240e-01,  6.6476e-01, -1.7125e-01,  3.7107e-01, -6.8735e-01,
          7.3219e-01,  5.7308e-01, -7.9865e-02,  2.6137e-03, -1.0492e-01,
          6.2231e-01, -2.2494e-01,  6.8010e-01,  1.1748e-01,  5.2259e-01,
          1.2923e-02,  7.3691e-02,  3.4888e-01,  2.6414e-01,  4.2186e-01,
         -4.1445e-01,  5.7697e-01,  4.0721e-01, -4.0092e-01, -4.1310e-01,
          5.1246e-01,  5.3019e-03,  5.7073e-01, -6.6950e-01, -7.4447e-02,
         -3.0260e-01,  2.1808e-01,  8.2279e-01, -5.1817e-01,  5.0470e-01,
          3.2587e-01,  2.6581e-01,  5.2826e-01, -7.4837e-03, -6.9155e-02,
          2.5341e-01, -3.2784e-01, -2.1990e-02, -4.8601e-01, -1.7147e-01,
         -3.9870e-01, -3.0875e-01, -2.6406e-01, -2.0629e-01,  3.1720e-01,
          3.3498e-01, -1.0637e-01,  1.1432e-01, -2.1800e-01,  6.6413e-01,
         -2.0818e-02, -5.1117e-01, -6.3738e-01,  2.4649e-01,  1.9480e-01,
          1.1880e-02, -4.4444e-01,  9.7113e-02, -1.0584e-01,  6.0753e-01,
          7.0593e-01,  4.3478e-01,  1.8733e-01,  3.2939e-02,  3.8776e-01,
          2.8482e-01, -4.1235e-01, -6.0461e-01,  3.8104e-01,  1.0732e-01,
         -7.0059e-01,  2.6696e-01, -2.9421e-01,  4.3722e-01, -4.5591e-01,
         -8.6827e-02,  5.9254e-02, -4.1622e-01, -3.9528e-01, -4.8446e-01,
         -4.7552e-02, -4.9195e-01,  4.2025e-01, -5.4779e-01, -1.7593e-02,
          7.4183e-01, -7.0238e-01,  4.6337e-01,  4.0638e-01,  2.6151e-01,
          5.7075e-01, -1.9192e-01,  8.6687e-02,  5.0342e-01,  3.5060e-02,
          4.3095e-01,  6.2844e-01, -2.7865e-01, -1.8283e-01,  7.1376e-01,
         -1.0288e-01,  3.3084e-01,  7.6745e-01,  2.1309e-02, -4.1063e-01,
          5.3351e-01, -1.1141e-01, -1.5108e-01,  2.6530e-01,  6.8424e-01,
          1.6492e-01,  4.6153e-01, -2.9771e-01,  1.0697e-01,  1.4702e-01,
          1.2702e-01, -5.0592e-01, -3.6936e-01, -5.2906e-01,  2.2893e-01,
         -2.6245e-01,  4.2968e-02, -1.7851e-01, -5.6460e-02,  5.5637e-01,
         -5.9503e-01, -7.7544e-02, -2.2456e-01, -6.1064e-01,  3.1447e-01,
          1.4890e-01, -2.8982e-02, -1.1260e-04,  4.4912e-01, -3.5829e-01,
         -3.2105e-01,  7.6753e-01, -1.3102e-03,  2.2552e-02,  2.3368e-02,
          1.3975e-01, -6.5992e-01, -3.0786e-01]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.0000% F1: 0.3145
Applying ckpt from fold 1 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.0000% F1: 0.3247
Applying ckpt from fold 2 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.4000% F1: 0.3297
Applying ckpt from fold 3 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.0000% F1: 0.3328
Applying ckpt from fold 4 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.0000% F1: 0.3208
Applying ckpt from fold 5 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.8000% F1: 0.3203
Applying ckpt from fold 6 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.2000% F1: 0.3182
Applying ckpt from fold 7 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.2000% F1: 0.3275
Applying ckpt from fold 8 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.0000% F1: 0.3296
Applying ckpt from fold 9 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 44.6000% F1: 0.3135
Metrics by fold:
Fold 0 - Acc: 0.45 F1: 0.31
Fold 1 - Acc: 0.50 F1: 0.32
Fold 2 - Acc: 0.51 F1: 0.33
Fold 3 - Acc: 0.49 F1: 0.33
Fold 4 - Acc: 0.45 F1: 0.32
Fold 5 - Acc: 0.49 F1: 0.32
Fold 6 - Acc: 0.49 F1: 0.32
Fold 7 - Acc: 0.48 F1: 0.33
Fold 8 - Acc: 0.45 F1: 0.33
Fold 9 - Acc: 0.45 F1: 0.31
agg_acc: 0.4762 agg_f1: 0.3232
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-4.3606e-02, -1.5910e-01, -4.8581e-01, -3.8263e-01, -5.1680e-01,
         -1.8935e-01,  4.8751e-01,  2.9280e-01, -1.0607e-01, -2.6697e-01,
         -4.9493e-01, -1.1257e-01, -1.9788e-01, -1.3184e-01, -2.6747e-01,
         -5.4098e-01,  1.0436e-01, -7.9363e-02,  2.6787e-01, -3.4898e-01,
         -5.5895e-01, -4.0749e-01, -2.7529e-01, -5.5366e-01,  7.3051e-01,
         -4.5888e-01, -7.5373e-02, -1.4036e-01,  4.2218e-02, -9.4052e-02,
         -4.0497e-01,  6.7652e-01, -1.5242e-02,  2.2938e-01,  3.3972e-01,
          2.6711e-01, -5.7348e-03, -3.8172e-01,  3.7646e-01, -4.6330e-01,
          6.0895e-01, -1.1278e-01,  9.5125e-02,  1.5848e-01, -8.8011e-02,
          2.1012e-01,  3.2058e-01, -1.2087e-01,  1.9975e-01, -3.9109e-01,
          1.9737e-01,  1.5232e-01,  7.0129e-01, -9.8670e-02,  6.9456e-01,
         -3.5982e-01,  6.0930e-01,  1.1148e-01,  8.1908e-02,  2.7244e-01,
          1.1667e-01, -5.8989e-01, -2.2864e-01, -5.4887e-01,  4.0342e-01,
          6.6261e-02,  6.1714e-01,  2.9520e-03,  3.1208e-01, -4.7937e-01,
         -6.9867e-01, -2.6097e-01,  3.9696e-01, -2.9471e-01, -5.4417e-01,
          5.6128e-02,  2.0631e-01,  1.4236e-01, -1.7459e-01, -1.3846e-01,
         -1.5302e-01, -2.8679e-01,  7.9617e-02, -5.5280e-01, -5.8188e-02,
         -3.5297e-01,  1.7067e-01,  3.2233e-02, -7.4358e-01,  5.5985e-01,
          1.5651e-01, -7.1408e-01,  2.1729e-01, -6.5467e-01, -3.5687e-01,
          4.0038e-01,  5.3516e-01,  1.2456e-01, -5.9177e-01, -4.7869e-01,
          1.4700e-01, -2.3916e-01, -3.3883e-01, -6.4858e-02,  1.4353e-01,
         -4.7894e-01,  4.1543e-01, -3.2510e-01, -4.1771e-01, -1.3029e-01,
          5.5638e-01, -1.1075e-01, -3.2858e-02,  7.4421e-02, -3.2686e-01,
         -4.8930e-01, -7.5107e-01,  3.2951e-01,  1.4170e-01,  2.4140e-01,
         -6.4900e-02, -3.8840e-01, -2.9613e-02, -2.1750e-02,  1.2730e-01,
         -7.6223e-01, -1.4084e-01,  2.8811e-01, -1.2155e-01,  6.5782e-01,
          1.4252e-01,  2.7522e-01,  5.6607e-01, -3.5640e-01, -1.6254e-01,
         -5.6422e-01, -4.1899e-01,  7.1397e-01, -2.5976e-01,  3.7979e-01,
          6.9408e-01, -9.6555e-02, -5.7445e-01, -8.3463e-02,  6.6205e-02,
          7.3398e-01, -1.4064e-01,  4.6967e-02,  1.7280e-01,  4.3330e-01,
          5.1674e-01,  2.0085e-01, -2.8088e-01, -4.8809e-01, -6.1372e-02,
          1.7789e-01,  8.4561e-02, -2.2256e-01, -8.8882e-02, -2.0205e-01,
          7.9238e-01, -3.7167e-01, -4.3697e-01, -5.5123e-01,  3.4803e-01,
          3.3974e-01, -3.6795e-03, -9.4672e-02,  4.4612e-01,  7.0981e-02,
          1.4914e-01, -1.1917e-01, -1.3173e-01,  5.9845e-02,  4.2897e-01,
          2.7345e-01,  4.5077e-01, -9.3647e-02, -2.5648e-01, -3.4603e-01,
          3.8954e-01,  4.3317e-01, -3.7800e-01,  1.2969e-01,  8.4454e-02,
          1.5298e-01,  3.3882e-01,  1.2758e-01, -2.0599e-01, -2.6551e-01,
          1.8176e-01, -8.8421e-02, -3.2220e-01, -8.8067e-02,  2.1718e-01,
         -3.6291e-01, -4.9237e-01,  2.1455e-01, -1.8674e-02,  3.9949e-01,
         -2.2519e-01, -1.4739e-01, -2.2509e-01,  2.9665e-01, -3.3978e-01,
         -4.4125e-01,  5.8753e-01,  2.4695e-01, -9.5062e-02,  9.9014e-03,
         -1.6486e-01,  2.4021e-01,  3.2167e-02, -2.2061e-01, -4.3971e-01,
          5.9503e-01, -1.8055e-01, -8.3522e-02,  1.0926e-01,  3.9749e-02,
          1.6904e-01,  7.3836e-02,  9.2030e-02,  2.3969e-01,  2.4693e-02,
          3.4840e-01,  3.3886e-02, -2.7562e-01, -4.2305e-01, -1.4418e-01,
          3.3536e-01, -2.7491e-01,  5.2891e-01,  3.0901e-01, -4.6127e-01,
          7.0903e-02, -1.1390e-01,  4.2822e-01, -4.7448e-01, -1.9457e-01,
          1.7779e-01, -3.3084e-01, -4.7311e-01, -4.2679e-01,  7.1815e-02,
          2.4915e-01, -4.4569e-01,  1.6466e-01,  4.1354e-02, -2.4865e-01,
         -4.2151e-01, -2.8002e-01,  8.4000e-02, -1.1305e-01,  3.2736e-01,
          1.0333e-01, -2.9267e-01, -3.9020e-02,  3.9709e-01, -3.1718e-01,
          4.5334e-01,  6.2500e-01, -2.3732e-01,  1.5878e-01, -3.1546e-01,
          1.4519e-01, -3.7691e-01,  4.5056e-01,  3.8429e-01,  1.1904e-01,
          4.6546e-01,  8.9835e-02, -3.4235e-02,  7.0945e-02,  5.7647e-02,
          3.2093e-01, -7.4279e-02,  1.9812e-01,  6.6854e-01,  8.3255e-03,
          5.2060e-01,  1.4760e-01,  4.9135e-02, -5.2057e-01,  8.4303e-02,
          2.5593e-02,  3.9829e-01, -3.1141e-01,  6.5268e-02, -4.9857e-02,
         -4.5633e-02, -6.8734e-01, -2.6750e-03, -2.4190e-01, -2.8735e-01,
         -3.2288e-02,  5.3618e-01,  3.4173e-01, -3.6855e-01, -4.1932e-01,
         -3.2033e-01, -2.7842e-01,  4.4021e-01,  8.6230e-01,  9.1970e-02,
         -1.1976e-01, -3.8733e-01, -9.0361e-02, -5.4882e-02,  1.3525e-01,
          3.8096e-02,  6.2839e-01,  4.1826e-01,  4.6406e-01, -2.4304e-01,
         -4.5163e-01, -2.7172e-01, -1.2460e-01,  2.3671e-01, -3.1206e-01,
         -1.7764e-02,  1.3673e-03, -2.0460e-02, -6.8924e-02, -3.0854e-01,
         -2.8193e-02, -1.2100e-01,  2.0054e-01, -8.8251e-02, -1.1931e-01,
         -1.0426e-01, -6.4048e-01, -3.0713e-01,  2.0817e-01,  6.5585e-02,
         -1.4141e-01,  2.0945e-01, -7.4820e-04, -2.2530e-01, -3.7012e-01,
          1.6271e-01, -4.9095e-01, -2.2408e-01, -3.8781e-01,  2.5892e-01,
         -3.5237e-01,  6.4705e-03, -4.4271e-01,  5.8282e-01,  1.8517e-01,
          3.0051e-02,  5.0570e-02,  2.0626e-01, -1.3862e-01,  1.3162e-01,
          1.2967e-01,  2.0172e-01, -4.2257e-01,  8.3080e-02,  2.6301e-01,
          1.8749e-01, -3.6900e-01,  2.6178e-01,  3.2177e-01, -2.0241e-01,
         -5.9555e-01,  1.7245e-01, -7.6558e-02, -8.9417e-02,  1.7406e-01,
         -3.0616e-01, -5.1685e-02,  1.4586e-01,  5.1845e-01,  3.5010e-01,
         -4.0866e-01, -6.4725e-01,  1.4885e-01,  3.5427e-01, -7.2978e-02,
         -6.2830e-01, -2.0126e-01, -2.4575e-01,  2.5788e-01, -6.6602e-01,
          1.4807e-01,  5.9979e-01,  3.1298e-01, -2.1984e-02, -2.1055e-01,
          4.2543e-01, -4.2785e-01,  2.8597e-01, -4.6195e-02, -4.4302e-01,
         -1.6596e-01,  4.3690e-01,  8.2672e-03,  8.6318e-02,  2.6571e-01,
          3.8568e-01,  7.2709e-02, -5.9491e-01, -3.6851e-01,  3.6038e-01,
          3.4782e-03,  4.1766e-01,  5.5036e-01,  2.9479e-02, -3.7907e-01,
          1.8382e-03, -1.4601e-01,  1.6616e-01,  5.3503e-01,  1.3591e-02,
          1.2013e-01, -8.5887e-02,  3.7715e-01, -3.4969e-01,  4.3805e-01,
          3.1855e-01, -3.6571e-01, -1.7446e-01,  4.0240e-01, -1.6065e-01,
         -3.6733e-01,  1.7065e-01,  9.1335e-02,  3.1418e-01, -1.3760e-01,
         -4.5394e-01, -2.5068e-01,  8.7604e-02, -6.2930e-01,  1.2898e-02,
         -3.7761e-01,  5.9227e-02, -2.4603e-01,  1.9747e-01, -7.6524e-01,
          4.1795e-01, -3.2705e-01, -4.8150e-01, -1.3054e-01, -1.7629e-02,
         -7.9984e-02,  3.5556e-01,  4.0054e-01, -2.2257e-01, -4.4133e-03,
         -2.0015e-01, -1.1900e-01, -2.7484e-01, -5.1239e-01, -6.3264e-01,
         -1.7553e-01, -3.6384e-02,  1.4799e-01,  4.2550e-01,  4.8262e-01,
         -4.1353e-01,  1.6462e-01, -3.8982e-01,  3.9817e-02,  2.0532e-01,
         -1.9002e-01, -1.7682e-01,  8.7832e-01,  1.1802e-01, -4.0827e-01,
          4.1533e-01,  5.2921e-01, -3.8746e-01,  5.6729e-01,  2.9954e-01,
         -4.1602e-01, -1.2003e-01, -1.2318e-01,  6.4842e-02,  7.1454e-01,
         -3.3365e-01, -8.2613e-03, -9.7548e-02,  6.7619e-01, -2.0094e-01,
          6.8275e-02, -1.9088e-01,  2.5895e-01, -1.8892e-02,  8.5494e-02,
          4.3036e-01,  2.0538e-01,  5.8892e-01,  6.2417e-01,  4.8445e-01,
         -2.7654e-01,  3.1131e-01,  3.5275e-01,  3.1345e-01, -4.5330e-02,
          4.1206e-01, -3.9273e-01, -1.9450e-01,  1.3716e-02, -2.6335e-01,
          1.4685e-01,  3.2094e-01, -2.6300e-01,  9.1132e-02,  9.6662e-02,
         -2.8584e-01,  4.9270e-01,  5.0694e-01, -6.7856e-01, -1.6952e-02,
          2.0858e-01,  2.7211e-01,  7.7594e-03,  1.1058e-01,  3.5853e-01,
         -3.4715e-02,  1.9556e-01, -1.0988e-01, -2.6661e-01,  8.2309e-02,
         -1.8942e-01,  4.2286e-01,  2.1585e-01,  2.0750e-01, -1.9119e-01,
          3.1705e-01, -3.8454e-01, -2.0743e-01, -3.8114e-02,  6.4414e-02,
         -1.7748e-01,  1.3586e-01,  4.2025e-01,  5.2959e-01, -3.0235e-01,
          6.6244e-02,  5.9458e-02, -3.8626e-01, -3.0927e-01, -2.5877e-01,
          3.9770e-01, -3.5933e-01,  2.1776e-01, -4.3661e-01,  3.3840e-01,
          3.5971e-01, -2.2540e-01, -2.6150e-01, -3.6218e-01,  6.4707e-01,
          8.7594e-01,  5.4092e-01, -8.1894e-02,  5.3965e-01, -1.3166e-01,
         -1.9551e-01, -7.0249e-01, -3.5140e-01,  9.1459e-02,  8.1300e-03,
          2.1649e-01,  9.5686e-02,  4.3850e-01, -5.3493e-01,  1.3832e-01,
         -1.7769e-01, -3.1088e-01,  1.4557e-01,  5.7953e-01, -8.4913e-02,
          1.5262e-01, -4.3042e-02,  3.5596e-01, -2.6371e-01, -1.3432e-01,
          4.5435e-01, -5.2918e-02, -3.9792e-01, -1.0195e-01,  1.0674e-01,
         -8.1712e-02,  7.9050e-01, -7.5311e-02,  3.8989e-02, -5.4863e-01,
          2.3593e-01,  1.7604e-01, -4.1790e-01, -5.9872e-01,  8.6589e-04,
         -2.7348e-02,  6.8003e-01, -2.4577e-01,  2.8322e-01,  2.7373e-04,
          1.9466e-01,  1.7917e-01,  2.8938e-01,  2.7149e-01, -4.1166e-01,
          1.0486e-01, -2.8750e-01, -3.6946e-01,  5.6385e-01, -7.4233e-01,
         -3.6163e-01,  3.5484e-01,  3.3670e-01,  9.1394e-03, -1.0086e-01,
         -1.7736e-01, -3.6094e-01,  8.7540e-01, -2.3598e-01,  3.2910e-01,
         -7.4240e-01,  6.6476e-01, -1.7125e-01,  3.7107e-01, -6.8735e-01,
          7.3219e-01,  5.7308e-01, -7.9865e-02,  2.6137e-03, -1.0492e-01,
          6.2231e-01, -2.2494e-01,  6.8010e-01,  1.1748e-01,  5.2259e-01,
          1.2923e-02,  7.3691e-02,  3.4888e-01,  2.6414e-01,  4.2186e-01,
         -4.1445e-01,  5.7697e-01,  4.0721e-01, -4.0092e-01, -4.1310e-01,
          5.1246e-01,  5.3019e-03,  5.7073e-01, -6.6950e-01, -7.4447e-02,
         -3.0260e-01,  2.1808e-01,  8.2279e-01, -5.1817e-01,  5.0470e-01,
          3.2587e-01,  2.6581e-01,  5.2826e-01, -7.4837e-03, -6.9155e-02,
          2.5341e-01, -3.2784e-01, -2.1990e-02, -4.8601e-01, -1.7147e-01,
         -3.9870e-01, -3.0875e-01, -2.6406e-01, -2.0629e-01,  3.1720e-01,
          3.3498e-01, -1.0637e-01,  1.1432e-01, -2.1800e-01,  6.6413e-01,
         -2.0818e-02, -5.1117e-01, -6.3738e-01,  2.4649e-01,  1.9480e-01,
          1.1880e-02, -4.4444e-01,  9.7113e-02, -1.0584e-01,  6.0753e-01,
          7.0593e-01,  4.3478e-01,  1.8733e-01,  3.2939e-02,  3.8776e-01,
          2.8482e-01, -4.1235e-01, -6.0461e-01,  3.8104e-01,  1.0732e-01,
         -7.0059e-01,  2.6696e-01, -2.9421e-01,  4.3722e-01, -4.5591e-01,
         -8.6827e-02,  5.9254e-02, -4.1622e-01, -3.9528e-01, -4.8446e-01,
         -4.7552e-02, -4.9195e-01,  4.2025e-01, -5.4779e-01, -1.7593e-02,
          7.4183e-01, -7.0238e-01,  4.6337e-01,  4.0638e-01,  2.6151e-01,
          5.7075e-01, -1.9192e-01,  8.6687e-02,  5.0342e-01,  3.5060e-02,
          4.3095e-01,  6.2844e-01, -2.7865e-01, -1.8283e-01,  7.1376e-01,
         -1.0288e-01,  3.3084e-01,  7.6745e-01,  2.1309e-02, -4.1063e-01,
          5.3351e-01, -1.1141e-01, -1.5108e-01,  2.6530e-01,  6.8424e-01,
          1.6492e-01,  4.6153e-01, -2.9771e-01,  1.0697e-01,  1.4702e-01,
          1.2702e-01, -5.0592e-01, -3.6936e-01, -5.2906e-01,  2.2893e-01,
         -2.6245e-01,  4.2968e-02, -1.7851e-01, -5.6460e-02,  5.5637e-01,
         -5.9503e-01, -7.7544e-02, -2.2456e-01, -6.1064e-01,  3.1447e-01,
          1.4890e-01, -2.8982e-02, -1.1260e-04,  4.4912e-01, -3.5829e-01,
         -3.2105e-01,  7.6753e-01, -1.3102e-03,  2.2552e-02,  2.3368e-02,
          1.3975e-01, -6.5992e-01, -3.0786e-01]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.8000% F1: 0.3237
Applying ckpt from fold 1 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.6000% F1: 0.3278
Applying ckpt from fold 2 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.8000% F1: 0.3277
Applying ckpt from fold 3 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.6000% F1: 0.3213
Applying ckpt from fold 4 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 42.0000% F1: 0.3133
Applying ckpt from fold 5 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 42.8000% F1: 0.3262
Applying ckpt from fold 6 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.2000% F1: 0.3435
Applying ckpt from fold 7 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 44.4000% F1: 0.3208
Applying ckpt from fold 8 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 37.4000% F1: 0.3104
Applying ckpt from fold 9 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 46.4000% F1: 0.3358
Metrics by fold:
Fold 0 - Acc: 0.48 F1: 0.32
Fold 1 - Acc: 0.46 F1: 0.33
Fold 2 - Acc: 0.52 F1: 0.33
Fold 3 - Acc: 0.48 F1: 0.32
Fold 4 - Acc: 0.42 F1: 0.31
Fold 5 - Acc: 0.43 F1: 0.33
Fold 6 - Acc: 0.47 F1: 0.34
Fold 7 - Acc: 0.44 F1: 0.32
Fold 8 - Acc: 0.37 F1: 0.31
Fold 9 - Acc: 0.46 F1: 0.34
agg_acc: 0.4530 agg_f1: 0.3250
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-4.3606e-02, -1.5910e-01, -4.8581e-01, -3.8263e-01, -5.1680e-01,
         -1.8935e-01,  4.8751e-01,  2.9280e-01, -1.0607e-01, -2.6697e-01,
         -4.9493e-01, -1.1257e-01, -1.9788e-01, -1.3184e-01, -2.6747e-01,
         -5.4098e-01,  1.0436e-01, -7.9363e-02,  2.6787e-01, -3.4898e-01,
         -5.5895e-01, -4.0749e-01, -2.7529e-01, -5.5366e-01,  7.3051e-01,
         -4.5888e-01, -7.5373e-02, -1.4036e-01,  4.2218e-02, -9.4052e-02,
         -4.0497e-01,  6.7652e-01, -1.5242e-02,  2.2938e-01,  3.3972e-01,
          2.6711e-01, -5.7348e-03, -3.8172e-01,  3.7646e-01, -4.6330e-01,
          6.0895e-01, -1.1278e-01,  9.5125e-02,  1.5848e-01, -8.8011e-02,
          2.1012e-01,  3.2058e-01, -1.2087e-01,  1.9975e-01, -3.9109e-01,
          1.9737e-01,  1.5232e-01,  7.0129e-01, -9.8670e-02,  6.9456e-01,
         -3.5982e-01,  6.0930e-01,  1.1148e-01,  8.1908e-02,  2.7244e-01,
          1.1667e-01, -5.8989e-01, -2.2864e-01, -5.4887e-01,  4.0342e-01,
          6.6261e-02,  6.1714e-01,  2.9520e-03,  3.1208e-01, -4.7937e-01,
         -6.9867e-01, -2.6097e-01,  3.9696e-01, -2.9471e-01, -5.4417e-01,
          5.6128e-02,  2.0631e-01,  1.4236e-01, -1.7459e-01, -1.3846e-01,
         -1.5302e-01, -2.8679e-01,  7.9617e-02, -5.5280e-01, -5.8188e-02,
         -3.5297e-01,  1.7067e-01,  3.2233e-02, -7.4358e-01,  5.5985e-01,
          1.5651e-01, -7.1408e-01,  2.1729e-01, -6.5467e-01, -3.5687e-01,
          4.0038e-01,  5.3516e-01,  1.2456e-01, -5.9177e-01, -4.7869e-01,
          1.4700e-01, -2.3916e-01, -3.3883e-01, -6.4858e-02,  1.4353e-01,
         -4.7894e-01,  4.1543e-01, -3.2510e-01, -4.1771e-01, -1.3029e-01,
          5.5638e-01, -1.1075e-01, -3.2858e-02,  7.4421e-02, -3.2686e-01,
         -4.8930e-01, -7.5107e-01,  3.2951e-01,  1.4170e-01,  2.4140e-01,
         -6.4900e-02, -3.8840e-01, -2.9613e-02, -2.1750e-02,  1.2730e-01,
         -7.6223e-01, -1.4084e-01,  2.8811e-01, -1.2155e-01,  6.5782e-01,
          1.4252e-01,  2.7522e-01,  5.6607e-01, -3.5640e-01, -1.6254e-01,
         -5.6422e-01, -4.1899e-01,  7.1397e-01, -2.5976e-01,  3.7979e-01,
          6.9408e-01, -9.6555e-02, -5.7445e-01, -8.3463e-02,  6.6205e-02,
          7.3398e-01, -1.4064e-01,  4.6967e-02,  1.7280e-01,  4.3330e-01,
          5.1674e-01,  2.0085e-01, -2.8088e-01, -4.8809e-01, -6.1372e-02,
          1.7789e-01,  8.4561e-02, -2.2256e-01, -8.8882e-02, -2.0205e-01,
          7.9238e-01, -3.7167e-01, -4.3697e-01, -5.5123e-01,  3.4803e-01,
          3.3974e-01, -3.6795e-03, -9.4672e-02,  4.4612e-01,  7.0981e-02,
          1.4914e-01, -1.1917e-01, -1.3173e-01,  5.9845e-02,  4.2897e-01,
          2.7345e-01,  4.5077e-01, -9.3647e-02, -2.5648e-01, -3.4603e-01,
          3.8954e-01,  4.3317e-01, -3.7800e-01,  1.2969e-01,  8.4454e-02,
          1.5298e-01,  3.3882e-01,  1.2758e-01, -2.0599e-01, -2.6551e-01,
          1.8176e-01, -8.8421e-02, -3.2220e-01, -8.8067e-02,  2.1718e-01,
         -3.6291e-01, -4.9237e-01,  2.1455e-01, -1.8674e-02,  3.9949e-01,
         -2.2519e-01, -1.4739e-01, -2.2509e-01,  2.9665e-01, -3.3978e-01,
         -4.4125e-01,  5.8753e-01,  2.4695e-01, -9.5062e-02,  9.9014e-03,
         -1.6486e-01,  2.4021e-01,  3.2167e-02, -2.2061e-01, -4.3971e-01,
          5.9503e-01, -1.8055e-01, -8.3522e-02,  1.0926e-01,  3.9749e-02,
          1.6904e-01,  7.3836e-02,  9.2030e-02,  2.3969e-01,  2.4693e-02,
          3.4840e-01,  3.3886e-02, -2.7562e-01, -4.2305e-01, -1.4418e-01,
          3.3536e-01, -2.7491e-01,  5.2891e-01,  3.0901e-01, -4.6127e-01,
          7.0903e-02, -1.1390e-01,  4.2822e-01, -4.7448e-01, -1.9457e-01,
          1.7779e-01, -3.3084e-01, -4.7311e-01, -4.2679e-01,  7.1815e-02,
          2.4915e-01, -4.4569e-01,  1.6466e-01,  4.1354e-02, -2.4865e-01,
         -4.2151e-01, -2.8002e-01,  8.4000e-02, -1.1305e-01,  3.2736e-01,
          1.0333e-01, -2.9267e-01, -3.9020e-02,  3.9709e-01, -3.1718e-01,
          4.5334e-01,  6.2500e-01, -2.3732e-01,  1.5878e-01, -3.1546e-01,
          1.4519e-01, -3.7691e-01,  4.5056e-01,  3.8429e-01,  1.1904e-01,
          4.6546e-01,  8.9835e-02, -3.4235e-02,  7.0945e-02,  5.7647e-02,
          3.2093e-01, -7.4279e-02,  1.9812e-01,  6.6854e-01,  8.3255e-03,
          5.2060e-01,  1.4760e-01,  4.9135e-02, -5.2057e-01,  8.4303e-02,
          2.5593e-02,  3.9829e-01, -3.1141e-01,  6.5268e-02, -4.9857e-02,
         -4.5633e-02, -6.8734e-01, -2.6750e-03, -2.4190e-01, -2.8735e-01,
         -3.2288e-02,  5.3618e-01,  3.4173e-01, -3.6855e-01, -4.1932e-01,
         -3.2033e-01, -2.7842e-01,  4.4021e-01,  8.6230e-01,  9.1970e-02,
         -1.1976e-01, -3.8733e-01, -9.0361e-02, -5.4882e-02,  1.3525e-01,
          3.8096e-02,  6.2839e-01,  4.1826e-01,  4.6406e-01, -2.4304e-01,
         -4.5163e-01, -2.7172e-01, -1.2460e-01,  2.3671e-01, -3.1206e-01,
         -1.7764e-02,  1.3673e-03, -2.0460e-02, -6.8924e-02, -3.0854e-01,
         -2.8193e-02, -1.2100e-01,  2.0054e-01, -8.8251e-02, -1.1931e-01,
         -1.0426e-01, -6.4048e-01, -3.0713e-01,  2.0817e-01,  6.5585e-02,
         -1.4141e-01,  2.0945e-01, -7.4820e-04, -2.2530e-01, -3.7012e-01,
          1.6271e-01, -4.9095e-01, -2.2408e-01, -3.8781e-01,  2.5892e-01,
         -3.5237e-01,  6.4705e-03, -4.4271e-01,  5.8282e-01,  1.8517e-01,
          3.0051e-02,  5.0570e-02,  2.0626e-01, -1.3862e-01,  1.3162e-01,
          1.2967e-01,  2.0172e-01, -4.2257e-01,  8.3080e-02,  2.6301e-01,
          1.8749e-01, -3.6900e-01,  2.6178e-01,  3.2177e-01, -2.0241e-01,
         -5.9555e-01,  1.7245e-01, -7.6558e-02, -8.9417e-02,  1.7406e-01,
         -3.0616e-01, -5.1685e-02,  1.4586e-01,  5.1845e-01,  3.5010e-01,
         -4.0866e-01, -6.4725e-01,  1.4885e-01,  3.5427e-01, -7.2978e-02,
         -6.2830e-01, -2.0126e-01, -2.4575e-01,  2.5788e-01, -6.6602e-01,
          1.4807e-01,  5.9979e-01,  3.1298e-01, -2.1984e-02, -2.1055e-01,
          4.2543e-01, -4.2785e-01,  2.8597e-01, -4.6195e-02, -4.4302e-01,
         -1.6596e-01,  4.3690e-01,  8.2672e-03,  8.6318e-02,  2.6571e-01,
          3.8568e-01,  7.2709e-02, -5.9491e-01, -3.6851e-01,  3.6038e-01,
          3.4782e-03,  4.1766e-01,  5.5036e-01,  2.9479e-02, -3.7907e-01,
          1.8382e-03, -1.4601e-01,  1.6616e-01,  5.3503e-01,  1.3591e-02,
          1.2013e-01, -8.5887e-02,  3.7715e-01, -3.4969e-01,  4.3805e-01,
          3.1855e-01, -3.6571e-01, -1.7446e-01,  4.0240e-01, -1.6065e-01,
         -3.6733e-01,  1.7065e-01,  9.1335e-02,  3.1418e-01, -1.3760e-01,
         -4.5394e-01, -2.5068e-01,  8.7604e-02, -6.2930e-01,  1.2898e-02,
         -3.7761e-01,  5.9227e-02, -2.4603e-01,  1.9747e-01, -7.6524e-01,
          4.1795e-01, -3.2705e-01, -4.8150e-01, -1.3054e-01, -1.7629e-02,
         -7.9984e-02,  3.5556e-01,  4.0054e-01, -2.2257e-01, -4.4133e-03,
         -2.0015e-01, -1.1900e-01, -2.7484e-01, -5.1239e-01, -6.3264e-01,
         -1.7553e-01, -3.6384e-02,  1.4799e-01,  4.2550e-01,  4.8262e-01,
         -4.1353e-01,  1.6462e-01, -3.8982e-01,  3.9817e-02,  2.0532e-01,
         -1.9002e-01, -1.7682e-01,  8.7832e-01,  1.1802e-01, -4.0827e-01,
          4.1533e-01,  5.2921e-01, -3.8746e-01,  5.6729e-01,  2.9954e-01,
         -4.1602e-01, -1.2003e-01, -1.2318e-01,  6.4842e-02,  7.1454e-01,
         -3.3365e-01, -8.2613e-03, -9.7548e-02,  6.7619e-01, -2.0094e-01,
          6.8275e-02, -1.9088e-01,  2.5895e-01, -1.8892e-02,  8.5494e-02,
          4.3036e-01,  2.0538e-01,  5.8892e-01,  6.2417e-01,  4.8445e-01,
         -2.7654e-01,  3.1131e-01,  3.5275e-01,  3.1345e-01, -4.5330e-02,
          4.1206e-01, -3.9273e-01, -1.9450e-01,  1.3716e-02, -2.6335e-01,
          1.4685e-01,  3.2094e-01, -2.6300e-01,  9.1132e-02,  9.6662e-02,
         -2.8584e-01,  4.9270e-01,  5.0694e-01, -6.7856e-01, -1.6952e-02,
          2.0858e-01,  2.7211e-01,  7.7594e-03,  1.1058e-01,  3.5853e-01,
         -3.4715e-02,  1.9556e-01, -1.0988e-01, -2.6661e-01,  8.2309e-02,
         -1.8942e-01,  4.2286e-01,  2.1585e-01,  2.0750e-01, -1.9119e-01,
          3.1705e-01, -3.8454e-01, -2.0743e-01, -3.8114e-02,  6.4414e-02,
         -1.7748e-01,  1.3586e-01,  4.2025e-01,  5.2959e-01, -3.0235e-01,
          6.6244e-02,  5.9458e-02, -3.8626e-01, -3.0927e-01, -2.5877e-01,
          3.9770e-01, -3.5933e-01,  2.1776e-01, -4.3661e-01,  3.3840e-01,
          3.5971e-01, -2.2540e-01, -2.6150e-01, -3.6218e-01,  6.4707e-01,
          8.7594e-01,  5.4092e-01, -8.1894e-02,  5.3965e-01, -1.3166e-01,
         -1.9551e-01, -7.0249e-01, -3.5140e-01,  9.1459e-02,  8.1300e-03,
          2.1649e-01,  9.5686e-02,  4.3850e-01, -5.3493e-01,  1.3832e-01,
         -1.7769e-01, -3.1088e-01,  1.4557e-01,  5.7953e-01, -8.4913e-02,
          1.5262e-01, -4.3042e-02,  3.5596e-01, -2.6371e-01, -1.3432e-01,
          4.5435e-01, -5.2918e-02, -3.9792e-01, -1.0195e-01,  1.0674e-01,
         -8.1712e-02,  7.9050e-01, -7.5311e-02,  3.8989e-02, -5.4863e-01,
          2.3593e-01,  1.7604e-01, -4.1790e-01, -5.9872e-01,  8.6589e-04,
         -2.7348e-02,  6.8003e-01, -2.4577e-01,  2.8322e-01,  2.7373e-04,
          1.9466e-01,  1.7917e-01,  2.8938e-01,  2.7149e-01, -4.1166e-01,
          1.0486e-01, -2.8750e-01, -3.6946e-01,  5.6385e-01, -7.4233e-01,
         -3.6163e-01,  3.5484e-01,  3.3670e-01,  9.1394e-03, -1.0086e-01,
         -1.7736e-01, -3.6094e-01,  8.7540e-01, -2.3598e-01,  3.2910e-01,
         -7.4240e-01,  6.6476e-01, -1.7125e-01,  3.7107e-01, -6.8735e-01,
          7.3219e-01,  5.7308e-01, -7.9865e-02,  2.6137e-03, -1.0492e-01,
          6.2231e-01, -2.2494e-01,  6.8010e-01,  1.1748e-01,  5.2259e-01,
          1.2923e-02,  7.3691e-02,  3.4888e-01,  2.6414e-01,  4.2186e-01,
         -4.1445e-01,  5.7697e-01,  4.0721e-01, -4.0092e-01, -4.1310e-01,
          5.1246e-01,  5.3019e-03,  5.7073e-01, -6.6950e-01, -7.4447e-02,
         -3.0260e-01,  2.1808e-01,  8.2279e-01, -5.1817e-01,  5.0470e-01,
          3.2587e-01,  2.6581e-01,  5.2826e-01, -7.4837e-03, -6.9155e-02,
          2.5341e-01, -3.2784e-01, -2.1990e-02, -4.8601e-01, -1.7147e-01,
         -3.9870e-01, -3.0875e-01, -2.6406e-01, -2.0629e-01,  3.1720e-01,
          3.3498e-01, -1.0637e-01,  1.1432e-01, -2.1800e-01,  6.6413e-01,
         -2.0818e-02, -5.1117e-01, -6.3738e-01,  2.4649e-01,  1.9480e-01,
          1.1880e-02, -4.4444e-01,  9.7113e-02, -1.0584e-01,  6.0753e-01,
          7.0593e-01,  4.3478e-01,  1.8733e-01,  3.2939e-02,  3.8776e-01,
          2.8482e-01, -4.1235e-01, -6.0461e-01,  3.8104e-01,  1.0732e-01,
         -7.0059e-01,  2.6696e-01, -2.9421e-01,  4.3722e-01, -4.5591e-01,
         -8.6827e-02,  5.9254e-02, -4.1622e-01, -3.9528e-01, -4.8446e-01,
         -4.7552e-02, -4.9195e-01,  4.2025e-01, -5.4779e-01, -1.7593e-02,
          7.4183e-01, -7.0238e-01,  4.6337e-01,  4.0638e-01,  2.6151e-01,
          5.7075e-01, -1.9192e-01,  8.6687e-02,  5.0342e-01,  3.5060e-02,
          4.3095e-01,  6.2844e-01, -2.7865e-01, -1.8283e-01,  7.1376e-01,
         -1.0288e-01,  3.3084e-01,  7.6745e-01,  2.1309e-02, -4.1063e-01,
          5.3351e-01, -1.1141e-01, -1.5108e-01,  2.6530e-01,  6.8424e-01,
          1.6492e-01,  4.6153e-01, -2.9771e-01,  1.0697e-01,  1.4702e-01,
          1.2702e-01, -5.0592e-01, -3.6936e-01, -5.2906e-01,  2.2893e-01,
         -2.6245e-01,  4.2968e-02, -1.7851e-01, -5.6460e-02,  5.5637e-01,
         -5.9503e-01, -7.7544e-02, -2.2456e-01, -6.1064e-01,  3.1447e-01,
          1.4890e-01, -2.8982e-02, -1.1260e-04,  4.4912e-01, -3.5829e-01,
         -3.2105e-01,  7.6753e-01, -1.3102e-03,  2.2552e-02,  2.3368e-02,
          1.3975e-01, -6.5992e-01, -3.0786e-01]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.0000% F1: 0.2666
Applying ckpt from fold 1 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.8000% F1: 0.2501
Applying ckpt from fold 2 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.0000% F1: 0.2692
Applying ckpt from fold 3 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.0000% F1: 0.2665
Applying ckpt from fold 4 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.0000% F1: 0.2802
Applying ckpt from fold 5 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.0000% F1: 0.2854
Applying ckpt from fold 6 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.6000% F1: 0.2813
Applying ckpt from fold 7 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2887
Applying ckpt from fold 8 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.0000% F1: 0.2860
Applying ckpt from fold 9 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.8000% F1: 0.2686
Metrics by fold:
Fold 0 - Acc: 0.55 F1: 0.27
Fold 1 - Acc: 0.55 F1: 0.25
Fold 2 - Acc: 0.55 F1: 0.27
Fold 3 - Acc: 0.55 F1: 0.27
Fold 4 - Acc: 0.55 F1: 0.28
Fold 5 - Acc: 0.55 F1: 0.29
Fold 6 - Acc: 0.55 F1: 0.28
Fold 7 - Acc: 0.55 F1: 0.29
Fold 8 - Acc: 0.54 F1: 0.29
Fold 9 - Acc: 0.55 F1: 0.27
agg_acc: 0.5484 agg_f1: 0.2743
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-4.3606e-02, -1.5910e-01, -4.8581e-01, -3.8263e-01, -5.1680e-01,
         -1.8935e-01,  4.8751e-01,  2.9280e-01, -1.0607e-01, -2.6697e-01,
         -4.9493e-01, -1.1257e-01, -1.9788e-01, -1.3184e-01, -2.6747e-01,
         -5.4098e-01,  1.0436e-01, -7.9363e-02,  2.6787e-01, -3.4898e-01,
         -5.5895e-01, -4.0749e-01, -2.7529e-01, -5.5366e-01,  7.3051e-01,
         -4.5888e-01, -7.5373e-02, -1.4036e-01,  4.2218e-02, -9.4052e-02,
         -4.0497e-01,  6.7652e-01, -1.5242e-02,  2.2938e-01,  3.3972e-01,
          2.6711e-01, -5.7348e-03, -3.8172e-01,  3.7646e-01, -4.6330e-01,
          6.0895e-01, -1.1278e-01,  9.5125e-02,  1.5848e-01, -8.8011e-02,
          2.1012e-01,  3.2058e-01, -1.2087e-01,  1.9975e-01, -3.9109e-01,
          1.9737e-01,  1.5232e-01,  7.0129e-01, -9.8670e-02,  6.9456e-01,
         -3.5982e-01,  6.0930e-01,  1.1148e-01,  8.1908e-02,  2.7244e-01,
          1.1667e-01, -5.8989e-01, -2.2864e-01, -5.4887e-01,  4.0342e-01,
          6.6261e-02,  6.1714e-01,  2.9520e-03,  3.1208e-01, -4.7937e-01,
         -6.9867e-01, -2.6097e-01,  3.9696e-01, -2.9471e-01, -5.4417e-01,
          5.6128e-02,  2.0631e-01,  1.4236e-01, -1.7459e-01, -1.3846e-01,
         -1.5302e-01, -2.8679e-01,  7.9617e-02, -5.5280e-01, -5.8188e-02,
         -3.5297e-01,  1.7067e-01,  3.2233e-02, -7.4358e-01,  5.5985e-01,
          1.5651e-01, -7.1408e-01,  2.1729e-01, -6.5467e-01, -3.5687e-01,
          4.0038e-01,  5.3516e-01,  1.2456e-01, -5.9177e-01, -4.7869e-01,
          1.4700e-01, -2.3916e-01, -3.3883e-01, -6.4858e-02,  1.4353e-01,
         -4.7894e-01,  4.1543e-01, -3.2510e-01, -4.1771e-01, -1.3029e-01,
          5.5638e-01, -1.1075e-01, -3.2858e-02,  7.4421e-02, -3.2686e-01,
         -4.8930e-01, -7.5107e-01,  3.2951e-01,  1.4170e-01,  2.4140e-01,
         -6.4900e-02, -3.8840e-01, -2.9613e-02, -2.1750e-02,  1.2730e-01,
         -7.6223e-01, -1.4084e-01,  2.8811e-01, -1.2155e-01,  6.5782e-01,
          1.4252e-01,  2.7522e-01,  5.6607e-01, -3.5640e-01, -1.6254e-01,
         -5.6422e-01, -4.1899e-01,  7.1397e-01, -2.5976e-01,  3.7979e-01,
          6.9408e-01, -9.6555e-02, -5.7445e-01, -8.3463e-02,  6.6205e-02,
          7.3398e-01, -1.4064e-01,  4.6967e-02,  1.7280e-01,  4.3330e-01,
          5.1674e-01,  2.0085e-01, -2.8088e-01, -4.8809e-01, -6.1372e-02,
          1.7789e-01,  8.4561e-02, -2.2256e-01, -8.8882e-02, -2.0205e-01,
          7.9238e-01, -3.7167e-01, -4.3697e-01, -5.5123e-01,  3.4803e-01,
          3.3974e-01, -3.6795e-03, -9.4672e-02,  4.4612e-01,  7.0981e-02,
          1.4914e-01, -1.1917e-01, -1.3173e-01,  5.9845e-02,  4.2897e-01,
          2.7345e-01,  4.5077e-01, -9.3647e-02, -2.5648e-01, -3.4603e-01,
          3.8954e-01,  4.3317e-01, -3.7800e-01,  1.2969e-01,  8.4454e-02,
          1.5298e-01,  3.3882e-01,  1.2758e-01, -2.0599e-01, -2.6551e-01,
          1.8176e-01, -8.8421e-02, -3.2220e-01, -8.8067e-02,  2.1718e-01,
         -3.6291e-01, -4.9237e-01,  2.1455e-01, -1.8674e-02,  3.9949e-01,
         -2.2519e-01, -1.4739e-01, -2.2509e-01,  2.9665e-01, -3.3978e-01,
         -4.4125e-01,  5.8753e-01,  2.4695e-01, -9.5062e-02,  9.9014e-03,
         -1.6486e-01,  2.4021e-01,  3.2167e-02, -2.2061e-01, -4.3971e-01,
          5.9503e-01, -1.8055e-01, -8.3522e-02,  1.0926e-01,  3.9749e-02,
          1.6904e-01,  7.3836e-02,  9.2030e-02,  2.3969e-01,  2.4693e-02,
          3.4840e-01,  3.3886e-02, -2.7562e-01, -4.2305e-01, -1.4418e-01,
          3.3536e-01, -2.7491e-01,  5.2891e-01,  3.0901e-01, -4.6127e-01,
          7.0903e-02, -1.1390e-01,  4.2822e-01, -4.7448e-01, -1.9457e-01,
          1.7779e-01, -3.3084e-01, -4.7311e-01, -4.2679e-01,  7.1815e-02,
          2.4915e-01, -4.4569e-01,  1.6466e-01,  4.1354e-02, -2.4865e-01,
         -4.2151e-01, -2.8002e-01,  8.4000e-02, -1.1305e-01,  3.2736e-01,
          1.0333e-01, -2.9267e-01, -3.9020e-02,  3.9709e-01, -3.1718e-01,
          4.5334e-01,  6.2500e-01, -2.3732e-01,  1.5878e-01, -3.1546e-01,
          1.4519e-01, -3.7691e-01,  4.5056e-01,  3.8429e-01,  1.1904e-01,
          4.6546e-01,  8.9835e-02, -3.4235e-02,  7.0945e-02,  5.7647e-02,
          3.2093e-01, -7.4279e-02,  1.9812e-01,  6.6854e-01,  8.3255e-03,
          5.2060e-01,  1.4760e-01,  4.9135e-02, -5.2057e-01,  8.4303e-02,
          2.5593e-02,  3.9829e-01, -3.1141e-01,  6.5268e-02, -4.9857e-02,
         -4.5633e-02, -6.8734e-01, -2.6750e-03, -2.4190e-01, -2.8735e-01,
         -3.2288e-02,  5.3618e-01,  3.4173e-01, -3.6855e-01, -4.1932e-01,
         -3.2033e-01, -2.7842e-01,  4.4021e-01,  8.6230e-01,  9.1970e-02,
         -1.1976e-01, -3.8733e-01, -9.0361e-02, -5.4882e-02,  1.3525e-01,
          3.8096e-02,  6.2839e-01,  4.1826e-01,  4.6406e-01, -2.4304e-01,
         -4.5163e-01, -2.7172e-01, -1.2460e-01,  2.3671e-01, -3.1206e-01,
         -1.7764e-02,  1.3673e-03, -2.0460e-02, -6.8924e-02, -3.0854e-01,
         -2.8193e-02, -1.2100e-01,  2.0054e-01, -8.8251e-02, -1.1931e-01,
         -1.0426e-01, -6.4048e-01, -3.0713e-01,  2.0817e-01,  6.5585e-02,
         -1.4141e-01,  2.0945e-01, -7.4820e-04, -2.2530e-01, -3.7012e-01,
          1.6271e-01, -4.9095e-01, -2.2408e-01, -3.8781e-01,  2.5892e-01,
         -3.5237e-01,  6.4705e-03, -4.4271e-01,  5.8282e-01,  1.8517e-01,
          3.0051e-02,  5.0570e-02,  2.0626e-01, -1.3862e-01,  1.3162e-01,
          1.2967e-01,  2.0172e-01, -4.2257e-01,  8.3080e-02,  2.6301e-01,
          1.8749e-01, -3.6900e-01,  2.6178e-01,  3.2177e-01, -2.0241e-01,
         -5.9555e-01,  1.7245e-01, -7.6558e-02, -8.9417e-02,  1.7406e-01,
         -3.0616e-01, -5.1685e-02,  1.4586e-01,  5.1845e-01,  3.5010e-01,
         -4.0866e-01, -6.4725e-01,  1.4885e-01,  3.5427e-01, -7.2978e-02,
         -6.2830e-01, -2.0126e-01, -2.4575e-01,  2.5788e-01, -6.6602e-01,
          1.4807e-01,  5.9979e-01,  3.1298e-01, -2.1984e-02, -2.1055e-01,
          4.2543e-01, -4.2785e-01,  2.8597e-01, -4.6195e-02, -4.4302e-01,
         -1.6596e-01,  4.3690e-01,  8.2672e-03,  8.6318e-02,  2.6571e-01,
          3.8568e-01,  7.2709e-02, -5.9491e-01, -3.6851e-01,  3.6038e-01,
          3.4782e-03,  4.1766e-01,  5.5036e-01,  2.9479e-02, -3.7907e-01,
          1.8382e-03, -1.4601e-01,  1.6616e-01,  5.3503e-01,  1.3591e-02,
          1.2013e-01, -8.5887e-02,  3.7715e-01, -3.4969e-01,  4.3805e-01,
          3.1855e-01, -3.6571e-01, -1.7446e-01,  4.0240e-01, -1.6065e-01,
         -3.6733e-01,  1.7065e-01,  9.1335e-02,  3.1418e-01, -1.3760e-01,
         -4.5394e-01, -2.5068e-01,  8.7604e-02, -6.2930e-01,  1.2898e-02,
         -3.7761e-01,  5.9227e-02, -2.4603e-01,  1.9747e-01, -7.6524e-01,
          4.1795e-01, -3.2705e-01, -4.8150e-01, -1.3054e-01, -1.7629e-02,
         -7.9984e-02,  3.5556e-01,  4.0054e-01, -2.2257e-01, -4.4133e-03,
         -2.0015e-01, -1.1900e-01, -2.7484e-01, -5.1239e-01, -6.3264e-01,
         -1.7553e-01, -3.6384e-02,  1.4799e-01,  4.2550e-01,  4.8262e-01,
         -4.1353e-01,  1.6462e-01, -3.8982e-01,  3.9817e-02,  2.0532e-01,
         -1.9002e-01, -1.7682e-01,  8.7832e-01,  1.1802e-01, -4.0827e-01,
          4.1533e-01,  5.2921e-01, -3.8746e-01,  5.6729e-01,  2.9954e-01,
         -4.1602e-01, -1.2003e-01, -1.2318e-01,  6.4842e-02,  7.1454e-01,
         -3.3365e-01, -8.2613e-03, -9.7548e-02,  6.7619e-01, -2.0094e-01,
          6.8275e-02, -1.9088e-01,  2.5895e-01, -1.8892e-02,  8.5494e-02,
          4.3036e-01,  2.0538e-01,  5.8892e-01,  6.2417e-01,  4.8445e-01,
         -2.7654e-01,  3.1131e-01,  3.5275e-01,  3.1345e-01, -4.5330e-02,
          4.1206e-01, -3.9273e-01, -1.9450e-01,  1.3716e-02, -2.6335e-01,
          1.4685e-01,  3.2094e-01, -2.6300e-01,  9.1132e-02,  9.6662e-02,
         -2.8584e-01,  4.9270e-01,  5.0694e-01, -6.7856e-01, -1.6952e-02,
          2.0858e-01,  2.7211e-01,  7.7594e-03,  1.1058e-01,  3.5853e-01,
         -3.4715e-02,  1.9556e-01, -1.0988e-01, -2.6661e-01,  8.2309e-02,
         -1.8942e-01,  4.2286e-01,  2.1585e-01,  2.0750e-01, -1.9119e-01,
          3.1705e-01, -3.8454e-01, -2.0743e-01, -3.8114e-02,  6.4414e-02,
         -1.7748e-01,  1.3586e-01,  4.2025e-01,  5.2959e-01, -3.0235e-01,
          6.6244e-02,  5.9458e-02, -3.8626e-01, -3.0927e-01, -2.5877e-01,
          3.9770e-01, -3.5933e-01,  2.1776e-01, -4.3661e-01,  3.3840e-01,
          3.5971e-01, -2.2540e-01, -2.6150e-01, -3.6218e-01,  6.4707e-01,
          8.7594e-01,  5.4092e-01, -8.1894e-02,  5.3965e-01, -1.3166e-01,
         -1.9551e-01, -7.0249e-01, -3.5140e-01,  9.1459e-02,  8.1300e-03,
          2.1649e-01,  9.5686e-02,  4.3850e-01, -5.3493e-01,  1.3832e-01,
         -1.7769e-01, -3.1088e-01,  1.4557e-01,  5.7953e-01, -8.4913e-02,
          1.5262e-01, -4.3042e-02,  3.5596e-01, -2.6371e-01, -1.3432e-01,
          4.5435e-01, -5.2918e-02, -3.9792e-01, -1.0195e-01,  1.0674e-01,
         -8.1712e-02,  7.9050e-01, -7.5311e-02,  3.8989e-02, -5.4863e-01,
          2.3593e-01,  1.7604e-01, -4.1790e-01, -5.9872e-01,  8.6589e-04,
         -2.7348e-02,  6.8003e-01, -2.4577e-01,  2.8322e-01,  2.7373e-04,
          1.9466e-01,  1.7917e-01,  2.8938e-01,  2.7149e-01, -4.1166e-01,
          1.0486e-01, -2.8750e-01, -3.6946e-01,  5.6385e-01, -7.4233e-01,
         -3.6163e-01,  3.5484e-01,  3.3670e-01,  9.1394e-03, -1.0086e-01,
         -1.7736e-01, -3.6094e-01,  8.7540e-01, -2.3598e-01,  3.2910e-01,
         -7.4240e-01,  6.6476e-01, -1.7125e-01,  3.7107e-01, -6.8735e-01,
          7.3219e-01,  5.7308e-01, -7.9865e-02,  2.6137e-03, -1.0492e-01,
          6.2231e-01, -2.2494e-01,  6.8010e-01,  1.1748e-01,  5.2259e-01,
          1.2923e-02,  7.3691e-02,  3.4888e-01,  2.6414e-01,  4.2186e-01,
         -4.1445e-01,  5.7697e-01,  4.0721e-01, -4.0092e-01, -4.1310e-01,
          5.1246e-01,  5.3019e-03,  5.7073e-01, -6.6950e-01, -7.4447e-02,
         -3.0260e-01,  2.1808e-01,  8.2279e-01, -5.1817e-01,  5.0470e-01,
          3.2587e-01,  2.6581e-01,  5.2826e-01, -7.4837e-03, -6.9155e-02,
          2.5341e-01, -3.2784e-01, -2.1990e-02, -4.8601e-01, -1.7147e-01,
         -3.9870e-01, -3.0875e-01, -2.6406e-01, -2.0629e-01,  3.1720e-01,
          3.3498e-01, -1.0637e-01,  1.1432e-01, -2.1800e-01,  6.6413e-01,
         -2.0818e-02, -5.1117e-01, -6.3738e-01,  2.4649e-01,  1.9480e-01,
          1.1880e-02, -4.4444e-01,  9.7113e-02, -1.0584e-01,  6.0753e-01,
          7.0593e-01,  4.3478e-01,  1.8733e-01,  3.2939e-02,  3.8776e-01,
          2.8482e-01, -4.1235e-01, -6.0461e-01,  3.8104e-01,  1.0732e-01,
         -7.0059e-01,  2.6696e-01, -2.9421e-01,  4.3722e-01, -4.5591e-01,
         -8.6827e-02,  5.9254e-02, -4.1622e-01, -3.9528e-01, -4.8446e-01,
         -4.7552e-02, -4.9195e-01,  4.2025e-01, -5.4779e-01, -1.7593e-02,
          7.4183e-01, -7.0238e-01,  4.6337e-01,  4.0638e-01,  2.6151e-01,
          5.7075e-01, -1.9192e-01,  8.6687e-02,  5.0342e-01,  3.5060e-02,
          4.3095e-01,  6.2844e-01, -2.7865e-01, -1.8283e-01,  7.1376e-01,
         -1.0288e-01,  3.3084e-01,  7.6745e-01,  2.1309e-02, -4.1063e-01,
          5.3351e-01, -1.1141e-01, -1.5108e-01,  2.6530e-01,  6.8424e-01,
          1.6492e-01,  4.6153e-01, -2.9771e-01,  1.0697e-01,  1.4702e-01,
          1.2702e-01, -5.0592e-01, -3.6936e-01, -5.2906e-01,  2.2893e-01,
         -2.6245e-01,  4.2968e-02, -1.7851e-01, -5.6460e-02,  5.5637e-01,
         -5.9503e-01, -7.7544e-02, -2.2456e-01, -6.1064e-01,  3.1447e-01,
          1.4890e-01, -2.8982e-02, -1.1260e-04,  4.4912e-01, -3.5829e-01,
         -3.2105e-01,  7.6753e-01, -1.3102e-03,  2.2552e-02,  2.3368e-02,
          1.3975e-01, -6.5992e-01, -3.0786e-01]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.8000% F1: 0.2650
Applying ckpt from fold 1 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.0000% F1: 0.3197
Applying ckpt from fold 2 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.6000% F1: 0.2998
Applying ckpt from fold 3 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.4000% F1: 0.2934
Applying ckpt from fold 4 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.4000% F1: 0.3104
Applying ckpt from fold 5 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.8000% F1: 0.2980
Applying ckpt from fold 6 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.8000% F1: 0.2909
Applying ckpt from fold 7 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.6000% F1: 0.2827
Applying ckpt from fold 8 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2669
Applying ckpt from fold 9 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.6000% F1: 0.2933
Metrics by fold:
Fold 0 - Acc: 0.54 F1: 0.26
Fold 1 - Acc: 0.52 F1: 0.32
Fold 2 - Acc: 0.56 F1: 0.30
Fold 3 - Acc: 0.50 F1: 0.29
Fold 4 - Acc: 0.54 F1: 0.31
Fold 5 - Acc: 0.54 F1: 0.30
Fold 6 - Acc: 0.52 F1: 0.29
Fold 7 - Acc: 0.56 F1: 0.28
Fold 8 - Acc: 0.55 F1: 0.27
Fold 9 - Acc: 0.54 F1: 0.29
agg_acc: 0.5362 agg_f1: 0.2920
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-4.3606e-02, -1.5910e-01, -4.8581e-01, -3.8263e-01, -5.1680e-01,
         -1.8935e-01,  4.8751e-01,  2.9280e-01, -1.0607e-01, -2.6697e-01,
         -4.9493e-01, -1.1257e-01, -1.9788e-01, -1.3184e-01, -2.6747e-01,
         -5.4098e-01,  1.0436e-01, -7.9363e-02,  2.6787e-01, -3.4898e-01,
         -5.5895e-01, -4.0749e-01, -2.7529e-01, -5.5366e-01,  7.3051e-01,
         -4.5888e-01, -7.5373e-02, -1.4036e-01,  4.2218e-02, -9.4052e-02,
         -4.0497e-01,  6.7652e-01, -1.5242e-02,  2.2938e-01,  3.3972e-01,
          2.6711e-01, -5.7348e-03, -3.8172e-01,  3.7646e-01, -4.6330e-01,
          6.0895e-01, -1.1278e-01,  9.5125e-02,  1.5848e-01, -8.8011e-02,
          2.1012e-01,  3.2058e-01, -1.2087e-01,  1.9975e-01, -3.9109e-01,
          1.9737e-01,  1.5232e-01,  7.0129e-01, -9.8670e-02,  6.9456e-01,
         -3.5982e-01,  6.0930e-01,  1.1148e-01,  8.1908e-02,  2.7244e-01,
          1.1667e-01, -5.8989e-01, -2.2864e-01, -5.4887e-01,  4.0342e-01,
          6.6261e-02,  6.1714e-01,  2.9520e-03,  3.1208e-01, -4.7937e-01,
         -6.9867e-01, -2.6097e-01,  3.9696e-01, -2.9471e-01, -5.4417e-01,
          5.6128e-02,  2.0631e-01,  1.4236e-01, -1.7459e-01, -1.3846e-01,
         -1.5302e-01, -2.8679e-01,  7.9617e-02, -5.5280e-01, -5.8188e-02,
         -3.5297e-01,  1.7067e-01,  3.2233e-02, -7.4358e-01,  5.5985e-01,
          1.5651e-01, -7.1408e-01,  2.1729e-01, -6.5467e-01, -3.5687e-01,
          4.0038e-01,  5.3516e-01,  1.2456e-01, -5.9177e-01, -4.7869e-01,
          1.4700e-01, -2.3916e-01, -3.3883e-01, -6.4858e-02,  1.4353e-01,
         -4.7894e-01,  4.1543e-01, -3.2510e-01, -4.1771e-01, -1.3029e-01,
          5.5638e-01, -1.1075e-01, -3.2858e-02,  7.4421e-02, -3.2686e-01,
         -4.8930e-01, -7.5107e-01,  3.2951e-01,  1.4170e-01,  2.4140e-01,
         -6.4900e-02, -3.8840e-01, -2.9613e-02, -2.1750e-02,  1.2730e-01,
         -7.6223e-01, -1.4084e-01,  2.8811e-01, -1.2155e-01,  6.5782e-01,
          1.4252e-01,  2.7522e-01,  5.6607e-01, -3.5640e-01, -1.6254e-01,
         -5.6422e-01, -4.1899e-01,  7.1397e-01, -2.5976e-01,  3.7979e-01,
          6.9408e-01, -9.6555e-02, -5.7445e-01, -8.3463e-02,  6.6205e-02,
          7.3398e-01, -1.4064e-01,  4.6967e-02,  1.7280e-01,  4.3330e-01,
          5.1674e-01,  2.0085e-01, -2.8088e-01, -4.8809e-01, -6.1372e-02,
          1.7789e-01,  8.4561e-02, -2.2256e-01, -8.8882e-02, -2.0205e-01,
          7.9238e-01, -3.7167e-01, -4.3697e-01, -5.5123e-01,  3.4803e-01,
          3.3974e-01, -3.6795e-03, -9.4672e-02,  4.4612e-01,  7.0981e-02,
          1.4914e-01, -1.1917e-01, -1.3173e-01,  5.9845e-02,  4.2897e-01,
          2.7345e-01,  4.5077e-01, -9.3647e-02, -2.5648e-01, -3.4603e-01,
          3.8954e-01,  4.3317e-01, -3.7800e-01,  1.2969e-01,  8.4454e-02,
          1.5298e-01,  3.3882e-01,  1.2758e-01, -2.0599e-01, -2.6551e-01,
          1.8176e-01, -8.8421e-02, -3.2220e-01, -8.8067e-02,  2.1718e-01,
         -3.6291e-01, -4.9237e-01,  2.1455e-01, -1.8674e-02,  3.9949e-01,
         -2.2519e-01, -1.4739e-01, -2.2509e-01,  2.9665e-01, -3.3978e-01,
         -4.4125e-01,  5.8753e-01,  2.4695e-01, -9.5062e-02,  9.9014e-03,
         -1.6486e-01,  2.4021e-01,  3.2167e-02, -2.2061e-01, -4.3971e-01,
          5.9503e-01, -1.8055e-01, -8.3522e-02,  1.0926e-01,  3.9749e-02,
          1.6904e-01,  7.3836e-02,  9.2030e-02,  2.3969e-01,  2.4693e-02,
          3.4840e-01,  3.3886e-02, -2.7562e-01, -4.2305e-01, -1.4418e-01,
          3.3536e-01, -2.7491e-01,  5.2891e-01,  3.0901e-01, -4.6127e-01,
          7.0903e-02, -1.1390e-01,  4.2822e-01, -4.7448e-01, -1.9457e-01,
          1.7779e-01, -3.3084e-01, -4.7311e-01, -4.2679e-01,  7.1815e-02,
          2.4915e-01, -4.4569e-01,  1.6466e-01,  4.1354e-02, -2.4865e-01,
         -4.2151e-01, -2.8002e-01,  8.4000e-02, -1.1305e-01,  3.2736e-01,
          1.0333e-01, -2.9267e-01, -3.9020e-02,  3.9709e-01, -3.1718e-01,
          4.5334e-01,  6.2500e-01, -2.3732e-01,  1.5878e-01, -3.1546e-01,
          1.4519e-01, -3.7691e-01,  4.5056e-01,  3.8429e-01,  1.1904e-01,
          4.6546e-01,  8.9835e-02, -3.4235e-02,  7.0945e-02,  5.7647e-02,
          3.2093e-01, -7.4279e-02,  1.9812e-01,  6.6854e-01,  8.3255e-03,
          5.2060e-01,  1.4760e-01,  4.9135e-02, -5.2057e-01,  8.4303e-02,
          2.5593e-02,  3.9829e-01, -3.1141e-01,  6.5268e-02, -4.9857e-02,
         -4.5633e-02, -6.8734e-01, -2.6750e-03, -2.4190e-01, -2.8735e-01,
         -3.2288e-02,  5.3618e-01,  3.4173e-01, -3.6855e-01, -4.1932e-01,
         -3.2033e-01, -2.7842e-01,  4.4021e-01,  8.6230e-01,  9.1970e-02,
         -1.1976e-01, -3.8733e-01, -9.0361e-02, -5.4882e-02,  1.3525e-01,
          3.8096e-02,  6.2839e-01,  4.1826e-01,  4.6406e-01, -2.4304e-01,
         -4.5163e-01, -2.7172e-01, -1.2460e-01,  2.3671e-01, -3.1206e-01,
         -1.7764e-02,  1.3673e-03, -2.0460e-02, -6.8924e-02, -3.0854e-01,
         -2.8193e-02, -1.2100e-01,  2.0054e-01, -8.8251e-02, -1.1931e-01,
         -1.0426e-01, -6.4048e-01, -3.0713e-01,  2.0817e-01,  6.5585e-02,
         -1.4141e-01,  2.0945e-01, -7.4820e-04, -2.2530e-01, -3.7012e-01,
          1.6271e-01, -4.9095e-01, -2.2408e-01, -3.8781e-01,  2.5892e-01,
         -3.5237e-01,  6.4705e-03, -4.4271e-01,  5.8282e-01,  1.8517e-01,
          3.0051e-02,  5.0570e-02,  2.0626e-01, -1.3862e-01,  1.3162e-01,
          1.2967e-01,  2.0172e-01, -4.2257e-01,  8.3080e-02,  2.6301e-01,
          1.8749e-01, -3.6900e-01,  2.6178e-01,  3.2177e-01, -2.0241e-01,
         -5.9555e-01,  1.7245e-01, -7.6558e-02, -8.9417e-02,  1.7406e-01,
         -3.0616e-01, -5.1685e-02,  1.4586e-01,  5.1845e-01,  3.5010e-01,
         -4.0866e-01, -6.4725e-01,  1.4885e-01,  3.5427e-01, -7.2978e-02,
         -6.2830e-01, -2.0126e-01, -2.4575e-01,  2.5788e-01, -6.6602e-01,
          1.4807e-01,  5.9979e-01,  3.1298e-01, -2.1984e-02, -2.1055e-01,
          4.2543e-01, -4.2785e-01,  2.8597e-01, -4.6195e-02, -4.4302e-01,
         -1.6596e-01,  4.3690e-01,  8.2672e-03,  8.6318e-02,  2.6571e-01,
          3.8568e-01,  7.2709e-02, -5.9491e-01, -3.6851e-01,  3.6038e-01,
          3.4782e-03,  4.1766e-01,  5.5036e-01,  2.9479e-02, -3.7907e-01,
          1.8382e-03, -1.4601e-01,  1.6616e-01,  5.3503e-01,  1.3591e-02,
          1.2013e-01, -8.5887e-02,  3.7715e-01, -3.4969e-01,  4.3805e-01,
          3.1855e-01, -3.6571e-01, -1.7446e-01,  4.0240e-01, -1.6065e-01,
         -3.6733e-01,  1.7065e-01,  9.1335e-02,  3.1418e-01, -1.3760e-01,
         -4.5394e-01, -2.5068e-01,  8.7604e-02, -6.2930e-01,  1.2898e-02,
         -3.7761e-01,  5.9227e-02, -2.4603e-01,  1.9747e-01, -7.6524e-01,
          4.1795e-01, -3.2705e-01, -4.8150e-01, -1.3054e-01, -1.7629e-02,
         -7.9984e-02,  3.5556e-01,  4.0054e-01, -2.2257e-01, -4.4133e-03,
         -2.0015e-01, -1.1900e-01, -2.7484e-01, -5.1239e-01, -6.3264e-01,
         -1.7553e-01, -3.6384e-02,  1.4799e-01,  4.2550e-01,  4.8262e-01,
         -4.1353e-01,  1.6462e-01, -3.8982e-01,  3.9817e-02,  2.0532e-01,
         -1.9002e-01, -1.7682e-01,  8.7832e-01,  1.1802e-01, -4.0827e-01,
          4.1533e-01,  5.2921e-01, -3.8746e-01,  5.6729e-01,  2.9954e-01,
         -4.1602e-01, -1.2003e-01, -1.2318e-01,  6.4842e-02,  7.1454e-01,
         -3.3365e-01, -8.2613e-03, -9.7548e-02,  6.7619e-01, -2.0094e-01,
          6.8275e-02, -1.9088e-01,  2.5895e-01, -1.8892e-02,  8.5494e-02,
          4.3036e-01,  2.0538e-01,  5.8892e-01,  6.2417e-01,  4.8445e-01,
         -2.7654e-01,  3.1131e-01,  3.5275e-01,  3.1345e-01, -4.5330e-02,
          4.1206e-01, -3.9273e-01, -1.9450e-01,  1.3716e-02, -2.6335e-01,
          1.4685e-01,  3.2094e-01, -2.6300e-01,  9.1132e-02,  9.6662e-02,
         -2.8584e-01,  4.9270e-01,  5.0694e-01, -6.7856e-01, -1.6952e-02,
          2.0858e-01,  2.7211e-01,  7.7594e-03,  1.1058e-01,  3.5853e-01,
         -3.4715e-02,  1.9556e-01, -1.0988e-01, -2.6661e-01,  8.2309e-02,
         -1.8942e-01,  4.2286e-01,  2.1585e-01,  2.0750e-01, -1.9119e-01,
          3.1705e-01, -3.8454e-01, -2.0743e-01, -3.8114e-02,  6.4414e-02,
         -1.7748e-01,  1.3586e-01,  4.2025e-01,  5.2959e-01, -3.0235e-01,
          6.6244e-02,  5.9458e-02, -3.8626e-01, -3.0927e-01, -2.5877e-01,
          3.9770e-01, -3.5933e-01,  2.1776e-01, -4.3661e-01,  3.3840e-01,
          3.5971e-01, -2.2540e-01, -2.6150e-01, -3.6218e-01,  6.4707e-01,
          8.7594e-01,  5.4092e-01, -8.1894e-02,  5.3965e-01, -1.3166e-01,
         -1.9551e-01, -7.0249e-01, -3.5140e-01,  9.1459e-02,  8.1300e-03,
          2.1649e-01,  9.5686e-02,  4.3850e-01, -5.3493e-01,  1.3832e-01,
         -1.7769e-01, -3.1088e-01,  1.4557e-01,  5.7953e-01, -8.4913e-02,
          1.5262e-01, -4.3042e-02,  3.5596e-01, -2.6371e-01, -1.3432e-01,
          4.5435e-01, -5.2918e-02, -3.9792e-01, -1.0195e-01,  1.0674e-01,
         -8.1712e-02,  7.9050e-01, -7.5311e-02,  3.8989e-02, -5.4863e-01,
          2.3593e-01,  1.7604e-01, -4.1790e-01, -5.9872e-01,  8.6589e-04,
         -2.7348e-02,  6.8003e-01, -2.4577e-01,  2.8322e-01,  2.7373e-04,
          1.9466e-01,  1.7917e-01,  2.8938e-01,  2.7149e-01, -4.1166e-01,
          1.0486e-01, -2.8750e-01, -3.6946e-01,  5.6385e-01, -7.4233e-01,
         -3.6163e-01,  3.5484e-01,  3.3670e-01,  9.1394e-03, -1.0086e-01,
         -1.7736e-01, -3.6094e-01,  8.7540e-01, -2.3598e-01,  3.2910e-01,
         -7.4240e-01,  6.6476e-01, -1.7125e-01,  3.7107e-01, -6.8735e-01,
          7.3219e-01,  5.7308e-01, -7.9865e-02,  2.6137e-03, -1.0492e-01,
          6.2231e-01, -2.2494e-01,  6.8010e-01,  1.1748e-01,  5.2259e-01,
          1.2923e-02,  7.3691e-02,  3.4888e-01,  2.6414e-01,  4.2186e-01,
         -4.1445e-01,  5.7697e-01,  4.0721e-01, -4.0092e-01, -4.1310e-01,
          5.1246e-01,  5.3019e-03,  5.7073e-01, -6.6950e-01, -7.4447e-02,
         -3.0260e-01,  2.1808e-01,  8.2279e-01, -5.1817e-01,  5.0470e-01,
          3.2587e-01,  2.6581e-01,  5.2826e-01, -7.4837e-03, -6.9155e-02,
          2.5341e-01, -3.2784e-01, -2.1990e-02, -4.8601e-01, -1.7147e-01,
         -3.9870e-01, -3.0875e-01, -2.6406e-01, -2.0629e-01,  3.1720e-01,
          3.3498e-01, -1.0637e-01,  1.1432e-01, -2.1800e-01,  6.6413e-01,
         -2.0818e-02, -5.1117e-01, -6.3738e-01,  2.4649e-01,  1.9480e-01,
          1.1880e-02, -4.4444e-01,  9.7113e-02, -1.0584e-01,  6.0753e-01,
          7.0593e-01,  4.3478e-01,  1.8733e-01,  3.2939e-02,  3.8776e-01,
          2.8482e-01, -4.1235e-01, -6.0461e-01,  3.8104e-01,  1.0732e-01,
         -7.0059e-01,  2.6696e-01, -2.9421e-01,  4.3722e-01, -4.5591e-01,
         -8.6827e-02,  5.9254e-02, -4.1622e-01, -3.9528e-01, -4.8446e-01,
         -4.7552e-02, -4.9195e-01,  4.2025e-01, -5.4779e-01, -1.7593e-02,
          7.4183e-01, -7.0238e-01,  4.6337e-01,  4.0638e-01,  2.6151e-01,
          5.7075e-01, -1.9192e-01,  8.6687e-02,  5.0342e-01,  3.5060e-02,
          4.3095e-01,  6.2844e-01, -2.7865e-01, -1.8283e-01,  7.1376e-01,
         -1.0288e-01,  3.3084e-01,  7.6745e-01,  2.1309e-02, -4.1063e-01,
          5.3351e-01, -1.1141e-01, -1.5108e-01,  2.6530e-01,  6.8424e-01,
          1.6492e-01,  4.6153e-01, -2.9771e-01,  1.0697e-01,  1.4702e-01,
          1.2702e-01, -5.0592e-01, -3.6936e-01, -5.2906e-01,  2.2893e-01,
         -2.6245e-01,  4.2968e-02, -1.7851e-01, -5.6460e-02,  5.5637e-01,
         -5.9503e-01, -7.7544e-02, -2.2456e-01, -6.1064e-01,  3.1447e-01,
          1.4890e-01, -2.8982e-02, -1.1260e-04,  4.4912e-01, -3.5829e-01,
         -3.2105e-01,  7.6753e-01, -1.3102e-03,  2.2552e-02,  2.3368e-02,
          1.3975e-01, -6.5992e-01, -3.0786e-01]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 46.6000% F1: 0.3417
Applying ckpt from fold 1 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.6000% F1: 0.3320
Applying ckpt from fold 2 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.4000% F1: 0.3325
Applying ckpt from fold 3 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.6000% F1: 0.2848
Applying ckpt from fold 4 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.0000% F1: 0.3111
Applying ckpt from fold 5 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.8000% F1: 0.3274
Applying ckpt from fold 6 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.6000% F1: 0.2912
Applying ckpt from fold 7 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.2000% F1: 0.2992
Applying ckpt from fold 8 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.2000% F1: 0.3076
Applying ckpt from fold 9 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.4000% F1: 0.3470
Metrics by fold:
Fold 0 - Acc: 0.47 F1: 0.34
Fold 1 - Acc: 0.50 F1: 0.33
Fold 2 - Acc: 0.51 F1: 0.33
Fold 3 - Acc: 0.53 F1: 0.28
Fold 4 - Acc: 0.48 F1: 0.31
Fold 5 - Acc: 0.51 F1: 0.33
Fold 6 - Acc: 0.54 F1: 0.29
Fold 7 - Acc: 0.53 F1: 0.30
Fold 8 - Acc: 0.54 F1: 0.31
Fold 9 - Acc: 0.50 F1: 0.35
agg_acc: 0.5104 agg_f1: 0.3175
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-4.3606e-02, -1.5910e-01, -4.8581e-01, -3.8263e-01, -5.1680e-01,
         -1.8935e-01,  4.8751e-01,  2.9280e-01, -1.0607e-01, -2.6697e-01,
         -4.9493e-01, -1.1257e-01, -1.9788e-01, -1.3184e-01, -2.6747e-01,
         -5.4098e-01,  1.0436e-01, -7.9363e-02,  2.6787e-01, -3.4898e-01,
         -5.5895e-01, -4.0749e-01, -2.7529e-01, -5.5366e-01,  7.3051e-01,
         -4.5888e-01, -7.5373e-02, -1.4036e-01,  4.2218e-02, -9.4052e-02,
         -4.0497e-01,  6.7652e-01, -1.5242e-02,  2.2938e-01,  3.3972e-01,
          2.6711e-01, -5.7348e-03, -3.8172e-01,  3.7646e-01, -4.6330e-01,
          6.0895e-01, -1.1278e-01,  9.5125e-02,  1.5848e-01, -8.8011e-02,
          2.1012e-01,  3.2058e-01, -1.2087e-01,  1.9975e-01, -3.9109e-01,
          1.9737e-01,  1.5232e-01,  7.0129e-01, -9.8670e-02,  6.9456e-01,
         -3.5982e-01,  6.0930e-01,  1.1148e-01,  8.1908e-02,  2.7244e-01,
          1.1667e-01, -5.8989e-01, -2.2864e-01, -5.4887e-01,  4.0342e-01,
          6.6261e-02,  6.1714e-01,  2.9520e-03,  3.1208e-01, -4.7937e-01,
         -6.9867e-01, -2.6097e-01,  3.9696e-01, -2.9471e-01, -5.4417e-01,
          5.6128e-02,  2.0631e-01,  1.4236e-01, -1.7459e-01, -1.3846e-01,
         -1.5302e-01, -2.8679e-01,  7.9617e-02, -5.5280e-01, -5.8188e-02,
         -3.5297e-01,  1.7067e-01,  3.2233e-02, -7.4358e-01,  5.5985e-01,
          1.5651e-01, -7.1408e-01,  2.1729e-01, -6.5467e-01, -3.5687e-01,
          4.0038e-01,  5.3516e-01,  1.2456e-01, -5.9177e-01, -4.7869e-01,
          1.4700e-01, -2.3916e-01, -3.3883e-01, -6.4858e-02,  1.4353e-01,
         -4.7894e-01,  4.1543e-01, -3.2510e-01, -4.1771e-01, -1.3029e-01,
          5.5638e-01, -1.1075e-01, -3.2858e-02,  7.4421e-02, -3.2686e-01,
         -4.8930e-01, -7.5107e-01,  3.2951e-01,  1.4170e-01,  2.4140e-01,
         -6.4900e-02, -3.8840e-01, -2.9613e-02, -2.1750e-02,  1.2730e-01,
         -7.6223e-01, -1.4084e-01,  2.8811e-01, -1.2155e-01,  6.5782e-01,
          1.4252e-01,  2.7522e-01,  5.6607e-01, -3.5640e-01, -1.6254e-01,
         -5.6422e-01, -4.1899e-01,  7.1397e-01, -2.5976e-01,  3.7979e-01,
          6.9408e-01, -9.6555e-02, -5.7445e-01, -8.3463e-02,  6.6205e-02,
          7.3398e-01, -1.4064e-01,  4.6967e-02,  1.7280e-01,  4.3330e-01,
          5.1674e-01,  2.0085e-01, -2.8088e-01, -4.8809e-01, -6.1372e-02,
          1.7789e-01,  8.4561e-02, -2.2256e-01, -8.8882e-02, -2.0205e-01,
          7.9238e-01, -3.7167e-01, -4.3697e-01, -5.5123e-01,  3.4803e-01,
          3.3974e-01, -3.6795e-03, -9.4672e-02,  4.4612e-01,  7.0981e-02,
          1.4914e-01, -1.1917e-01, -1.3173e-01,  5.9845e-02,  4.2897e-01,
          2.7345e-01,  4.5077e-01, -9.3647e-02, -2.5648e-01, -3.4603e-01,
          3.8954e-01,  4.3317e-01, -3.7800e-01,  1.2969e-01,  8.4454e-02,
          1.5298e-01,  3.3882e-01,  1.2758e-01, -2.0599e-01, -2.6551e-01,
          1.8176e-01, -8.8421e-02, -3.2220e-01, -8.8067e-02,  2.1718e-01,
         -3.6291e-01, -4.9237e-01,  2.1455e-01, -1.8674e-02,  3.9949e-01,
         -2.2519e-01, -1.4739e-01, -2.2509e-01,  2.9665e-01, -3.3978e-01,
         -4.4125e-01,  5.8753e-01,  2.4695e-01, -9.5062e-02,  9.9014e-03,
         -1.6486e-01,  2.4021e-01,  3.2167e-02, -2.2061e-01, -4.3971e-01,
          5.9503e-01, -1.8055e-01, -8.3522e-02,  1.0926e-01,  3.9749e-02,
          1.6904e-01,  7.3836e-02,  9.2030e-02,  2.3969e-01,  2.4693e-02,
          3.4840e-01,  3.3886e-02, -2.7562e-01, -4.2305e-01, -1.4418e-01,
          3.3536e-01, -2.7491e-01,  5.2891e-01,  3.0901e-01, -4.6127e-01,
          7.0903e-02, -1.1390e-01,  4.2822e-01, -4.7448e-01, -1.9457e-01,
          1.7779e-01, -3.3084e-01, -4.7311e-01, -4.2679e-01,  7.1815e-02,
          2.4915e-01, -4.4569e-01,  1.6466e-01,  4.1354e-02, -2.4865e-01,
         -4.2151e-01, -2.8002e-01,  8.4000e-02, -1.1305e-01,  3.2736e-01,
          1.0333e-01, -2.9267e-01, -3.9020e-02,  3.9709e-01, -3.1718e-01,
          4.5334e-01,  6.2500e-01, -2.3732e-01,  1.5878e-01, -3.1546e-01,
          1.4519e-01, -3.7691e-01,  4.5056e-01,  3.8429e-01,  1.1904e-01,
          4.6546e-01,  8.9835e-02, -3.4235e-02,  7.0945e-02,  5.7647e-02,
          3.2093e-01, -7.4279e-02,  1.9812e-01,  6.6854e-01,  8.3255e-03,
          5.2060e-01,  1.4760e-01,  4.9135e-02, -5.2057e-01,  8.4303e-02,
          2.5593e-02,  3.9829e-01, -3.1141e-01,  6.5268e-02, -4.9857e-02,
         -4.5633e-02, -6.8734e-01, -2.6750e-03, -2.4190e-01, -2.8735e-01,
         -3.2288e-02,  5.3618e-01,  3.4173e-01, -3.6855e-01, -4.1932e-01,
         -3.2033e-01, -2.7842e-01,  4.4021e-01,  8.6230e-01,  9.1970e-02,
         -1.1976e-01, -3.8733e-01, -9.0361e-02, -5.4882e-02,  1.3525e-01,
          3.8096e-02,  6.2839e-01,  4.1826e-01,  4.6406e-01, -2.4304e-01,
         -4.5163e-01, -2.7172e-01, -1.2460e-01,  2.3671e-01, -3.1206e-01,
         -1.7764e-02,  1.3673e-03, -2.0460e-02, -6.8924e-02, -3.0854e-01,
         -2.8193e-02, -1.2100e-01,  2.0054e-01, -8.8251e-02, -1.1931e-01,
         -1.0426e-01, -6.4048e-01, -3.0713e-01,  2.0817e-01,  6.5585e-02,
         -1.4141e-01,  2.0945e-01, -7.4820e-04, -2.2530e-01, -3.7012e-01,
          1.6271e-01, -4.9095e-01, -2.2408e-01, -3.8781e-01,  2.5892e-01,
         -3.5237e-01,  6.4705e-03, -4.4271e-01,  5.8282e-01,  1.8517e-01,
          3.0051e-02,  5.0570e-02,  2.0626e-01, -1.3862e-01,  1.3162e-01,
          1.2967e-01,  2.0172e-01, -4.2257e-01,  8.3080e-02,  2.6301e-01,
          1.8749e-01, -3.6900e-01,  2.6178e-01,  3.2177e-01, -2.0241e-01,
         -5.9555e-01,  1.7245e-01, -7.6558e-02, -8.9417e-02,  1.7406e-01,
         -3.0616e-01, -5.1685e-02,  1.4586e-01,  5.1845e-01,  3.5010e-01,
         -4.0866e-01, -6.4725e-01,  1.4885e-01,  3.5427e-01, -7.2978e-02,
         -6.2830e-01, -2.0126e-01, -2.4575e-01,  2.5788e-01, -6.6602e-01,
          1.4807e-01,  5.9979e-01,  3.1298e-01, -2.1984e-02, -2.1055e-01,
          4.2543e-01, -4.2785e-01,  2.8597e-01, -4.6195e-02, -4.4302e-01,
         -1.6596e-01,  4.3690e-01,  8.2672e-03,  8.6318e-02,  2.6571e-01,
          3.8568e-01,  7.2709e-02, -5.9491e-01, -3.6851e-01,  3.6038e-01,
          3.4782e-03,  4.1766e-01,  5.5036e-01,  2.9479e-02, -3.7907e-01,
          1.8382e-03, -1.4601e-01,  1.6616e-01,  5.3503e-01,  1.3591e-02,
          1.2013e-01, -8.5887e-02,  3.7715e-01, -3.4969e-01,  4.3805e-01,
          3.1855e-01, -3.6571e-01, -1.7446e-01,  4.0240e-01, -1.6065e-01,
         -3.6733e-01,  1.7065e-01,  9.1335e-02,  3.1418e-01, -1.3760e-01,
         -4.5394e-01, -2.5068e-01,  8.7604e-02, -6.2930e-01,  1.2898e-02,
         -3.7761e-01,  5.9227e-02, -2.4603e-01,  1.9747e-01, -7.6524e-01,
          4.1795e-01, -3.2705e-01, -4.8150e-01, -1.3054e-01, -1.7629e-02,
         -7.9984e-02,  3.5556e-01,  4.0054e-01, -2.2257e-01, -4.4133e-03,
         -2.0015e-01, -1.1900e-01, -2.7484e-01, -5.1239e-01, -6.3264e-01,
         -1.7553e-01, -3.6384e-02,  1.4799e-01,  4.2550e-01,  4.8262e-01,
         -4.1353e-01,  1.6462e-01, -3.8982e-01,  3.9817e-02,  2.0532e-01,
         -1.9002e-01, -1.7682e-01,  8.7832e-01,  1.1802e-01, -4.0827e-01,
          4.1533e-01,  5.2921e-01, -3.8746e-01,  5.6729e-01,  2.9954e-01,
         -4.1602e-01, -1.2003e-01, -1.2318e-01,  6.4842e-02,  7.1454e-01,
         -3.3365e-01, -8.2613e-03, -9.7548e-02,  6.7619e-01, -2.0094e-01,
          6.8275e-02, -1.9088e-01,  2.5895e-01, -1.8892e-02,  8.5494e-02,
          4.3036e-01,  2.0538e-01,  5.8892e-01,  6.2417e-01,  4.8445e-01,
         -2.7654e-01,  3.1131e-01,  3.5275e-01,  3.1345e-01, -4.5330e-02,
          4.1206e-01, -3.9273e-01, -1.9450e-01,  1.3716e-02, -2.6335e-01,
          1.4685e-01,  3.2094e-01, -2.6300e-01,  9.1132e-02,  9.6662e-02,
         -2.8584e-01,  4.9270e-01,  5.0694e-01, -6.7856e-01, -1.6952e-02,
          2.0858e-01,  2.7211e-01,  7.7594e-03,  1.1058e-01,  3.5853e-01,
         -3.4715e-02,  1.9556e-01, -1.0988e-01, -2.6661e-01,  8.2309e-02,
         -1.8942e-01,  4.2286e-01,  2.1585e-01,  2.0750e-01, -1.9119e-01,
          3.1705e-01, -3.8454e-01, -2.0743e-01, -3.8114e-02,  6.4414e-02,
         -1.7748e-01,  1.3586e-01,  4.2025e-01,  5.2959e-01, -3.0235e-01,
          6.6244e-02,  5.9458e-02, -3.8626e-01, -3.0927e-01, -2.5877e-01,
          3.9770e-01, -3.5933e-01,  2.1776e-01, -4.3661e-01,  3.3840e-01,
          3.5971e-01, -2.2540e-01, -2.6150e-01, -3.6218e-01,  6.4707e-01,
          8.7594e-01,  5.4092e-01, -8.1894e-02,  5.3965e-01, -1.3166e-01,
         -1.9551e-01, -7.0249e-01, -3.5140e-01,  9.1459e-02,  8.1300e-03,
          2.1649e-01,  9.5686e-02,  4.3850e-01, -5.3493e-01,  1.3832e-01,
         -1.7769e-01, -3.1088e-01,  1.4557e-01,  5.7953e-01, -8.4913e-02,
          1.5262e-01, -4.3042e-02,  3.5596e-01, -2.6371e-01, -1.3432e-01,
          4.5435e-01, -5.2918e-02, -3.9792e-01, -1.0195e-01,  1.0674e-01,
         -8.1712e-02,  7.9050e-01, -7.5311e-02,  3.8989e-02, -5.4863e-01,
          2.3593e-01,  1.7604e-01, -4.1790e-01, -5.9872e-01,  8.6589e-04,
         -2.7348e-02,  6.8003e-01, -2.4577e-01,  2.8322e-01,  2.7373e-04,
          1.9466e-01,  1.7917e-01,  2.8938e-01,  2.7149e-01, -4.1166e-01,
          1.0486e-01, -2.8750e-01, -3.6946e-01,  5.6385e-01, -7.4233e-01,
         -3.6163e-01,  3.5484e-01,  3.3670e-01,  9.1394e-03, -1.0086e-01,
         -1.7736e-01, -3.6094e-01,  8.7540e-01, -2.3598e-01,  3.2910e-01,
         -7.4240e-01,  6.6476e-01, -1.7125e-01,  3.7107e-01, -6.8735e-01,
          7.3219e-01,  5.7308e-01, -7.9865e-02,  2.6137e-03, -1.0492e-01,
          6.2231e-01, -2.2494e-01,  6.8010e-01,  1.1748e-01,  5.2259e-01,
          1.2923e-02,  7.3691e-02,  3.4888e-01,  2.6414e-01,  4.2186e-01,
         -4.1445e-01,  5.7697e-01,  4.0721e-01, -4.0092e-01, -4.1310e-01,
          5.1246e-01,  5.3019e-03,  5.7073e-01, -6.6950e-01, -7.4447e-02,
         -3.0260e-01,  2.1808e-01,  8.2279e-01, -5.1817e-01,  5.0470e-01,
          3.2587e-01,  2.6581e-01,  5.2826e-01, -7.4837e-03, -6.9155e-02,
          2.5341e-01, -3.2784e-01, -2.1990e-02, -4.8601e-01, -1.7147e-01,
         -3.9870e-01, -3.0875e-01, -2.6406e-01, -2.0629e-01,  3.1720e-01,
          3.3498e-01, -1.0637e-01,  1.1432e-01, -2.1800e-01,  6.6413e-01,
         -2.0818e-02, -5.1117e-01, -6.3738e-01,  2.4649e-01,  1.9480e-01,
          1.1880e-02, -4.4444e-01,  9.7113e-02, -1.0584e-01,  6.0753e-01,
          7.0593e-01,  4.3478e-01,  1.8733e-01,  3.2939e-02,  3.8776e-01,
          2.8482e-01, -4.1235e-01, -6.0461e-01,  3.8104e-01,  1.0732e-01,
         -7.0059e-01,  2.6696e-01, -2.9421e-01,  4.3722e-01, -4.5591e-01,
         -8.6827e-02,  5.9254e-02, -4.1622e-01, -3.9528e-01, -4.8446e-01,
         -4.7552e-02, -4.9195e-01,  4.2025e-01, -5.4779e-01, -1.7593e-02,
          7.4183e-01, -7.0238e-01,  4.6337e-01,  4.0638e-01,  2.6151e-01,
          5.7075e-01, -1.9192e-01,  8.6687e-02,  5.0342e-01,  3.5060e-02,
          4.3095e-01,  6.2844e-01, -2.7865e-01, -1.8283e-01,  7.1376e-01,
         -1.0288e-01,  3.3084e-01,  7.6745e-01,  2.1309e-02, -4.1063e-01,
          5.3351e-01, -1.1141e-01, -1.5108e-01,  2.6530e-01,  6.8424e-01,
          1.6492e-01,  4.6153e-01, -2.9771e-01,  1.0697e-01,  1.4702e-01,
          1.2702e-01, -5.0592e-01, -3.6936e-01, -5.2906e-01,  2.2893e-01,
         -2.6245e-01,  4.2968e-02, -1.7851e-01, -5.6460e-02,  5.5637e-01,
         -5.9503e-01, -7.7544e-02, -2.2456e-01, -6.1064e-01,  3.1447e-01,
          1.4890e-01, -2.8982e-02, -1.1260e-04,  4.4912e-01, -3.5829e-01,
         -3.2105e-01,  7.6753e-01, -1.3102e-03,  2.2552e-02,  2.3368e-02,
          1.3975e-01, -6.5992e-01, -3.0786e-01]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 46.0000% F1: 0.3517
Applying ckpt from fold 1 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.4000% F1: 0.3540
Applying ckpt from fold 2 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.0000% F1: 0.3643
Applying ckpt from fold 3 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.2000% F1: 0.3576
Applying ckpt from fold 4 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 41.8000% F1: 0.3413
Applying ckpt from fold 5 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 41.8000% F1: 0.3396
Applying ckpt from fold 6 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.0000% F1: 0.3672
Applying ckpt from fold 7 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 42.6000% F1: 0.3295
Applying ckpt from fold 8 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.6000% F1: 0.3514
Applying ckpt from fold 9 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 42.6000% F1: 0.3378
Metrics by fold:
Fold 0 - Acc: 0.46 F1: 0.35
Fold 1 - Acc: 0.45 F1: 0.35
Fold 2 - Acc: 0.49 F1: 0.36
Fold 3 - Acc: 0.47 F1: 0.36
Fold 4 - Acc: 0.42 F1: 0.34
Fold 5 - Acc: 0.42 F1: 0.34
Fold 6 - Acc: 0.47 F1: 0.37
Fold 7 - Acc: 0.43 F1: 0.33
Fold 8 - Acc: 0.50 F1: 0.35
Fold 9 - Acc: 0.43 F1: 0.34
agg_acc: 0.4530 agg_f1: 0.3494
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-4.3606e-02, -1.5910e-01, -4.8581e-01, -3.8263e-01, -5.1680e-01,
         -1.8935e-01,  4.8751e-01,  2.9280e-01, -1.0607e-01, -2.6697e-01,
         -4.9493e-01, -1.1257e-01, -1.9788e-01, -1.3184e-01, -2.6747e-01,
         -5.4098e-01,  1.0436e-01, -7.9363e-02,  2.6787e-01, -3.4898e-01,
         -5.5895e-01, -4.0749e-01, -2.7529e-01, -5.5366e-01,  7.3051e-01,
         -4.5888e-01, -7.5373e-02, -1.4036e-01,  4.2218e-02, -9.4052e-02,
         -4.0497e-01,  6.7652e-01, -1.5242e-02,  2.2938e-01,  3.3972e-01,
          2.6711e-01, -5.7348e-03, -3.8172e-01,  3.7646e-01, -4.6330e-01,
          6.0895e-01, -1.1278e-01,  9.5125e-02,  1.5848e-01, -8.8011e-02,
          2.1012e-01,  3.2058e-01, -1.2087e-01,  1.9975e-01, -3.9109e-01,
          1.9737e-01,  1.5232e-01,  7.0129e-01, -9.8670e-02,  6.9456e-01,
         -3.5982e-01,  6.0930e-01,  1.1148e-01,  8.1908e-02,  2.7244e-01,
          1.1667e-01, -5.8989e-01, -2.2864e-01, -5.4887e-01,  4.0342e-01,
          6.6261e-02,  6.1714e-01,  2.9520e-03,  3.1208e-01, -4.7937e-01,
         -6.9867e-01, -2.6097e-01,  3.9696e-01, -2.9471e-01, -5.4417e-01,
          5.6128e-02,  2.0631e-01,  1.4236e-01, -1.7459e-01, -1.3846e-01,
         -1.5302e-01, -2.8679e-01,  7.9617e-02, -5.5280e-01, -5.8188e-02,
         -3.5297e-01,  1.7067e-01,  3.2233e-02, -7.4358e-01,  5.5985e-01,
          1.5651e-01, -7.1408e-01,  2.1729e-01, -6.5467e-01, -3.5687e-01,
          4.0038e-01,  5.3516e-01,  1.2456e-01, -5.9177e-01, -4.7869e-01,
          1.4700e-01, -2.3916e-01, -3.3883e-01, -6.4858e-02,  1.4353e-01,
         -4.7894e-01,  4.1543e-01, -3.2510e-01, -4.1771e-01, -1.3029e-01,
          5.5638e-01, -1.1075e-01, -3.2858e-02,  7.4421e-02, -3.2686e-01,
         -4.8930e-01, -7.5107e-01,  3.2951e-01,  1.4170e-01,  2.4140e-01,
         -6.4900e-02, -3.8840e-01, -2.9613e-02, -2.1750e-02,  1.2730e-01,
         -7.6223e-01, -1.4084e-01,  2.8811e-01, -1.2155e-01,  6.5782e-01,
          1.4252e-01,  2.7522e-01,  5.6607e-01, -3.5640e-01, -1.6254e-01,
         -5.6422e-01, -4.1899e-01,  7.1397e-01, -2.5976e-01,  3.7979e-01,
          6.9408e-01, -9.6555e-02, -5.7445e-01, -8.3463e-02,  6.6205e-02,
          7.3398e-01, -1.4064e-01,  4.6967e-02,  1.7280e-01,  4.3330e-01,
          5.1674e-01,  2.0085e-01, -2.8088e-01, -4.8809e-01, -6.1372e-02,
          1.7789e-01,  8.4561e-02, -2.2256e-01, -8.8882e-02, -2.0205e-01,
          7.9238e-01, -3.7167e-01, -4.3697e-01, -5.5123e-01,  3.4803e-01,
          3.3974e-01, -3.6795e-03, -9.4672e-02,  4.4612e-01,  7.0981e-02,
          1.4914e-01, -1.1917e-01, -1.3173e-01,  5.9845e-02,  4.2897e-01,
          2.7345e-01,  4.5077e-01, -9.3647e-02, -2.5648e-01, -3.4603e-01,
          3.8954e-01,  4.3317e-01, -3.7800e-01,  1.2969e-01,  8.4454e-02,
          1.5298e-01,  3.3882e-01,  1.2758e-01, -2.0599e-01, -2.6551e-01,
          1.8176e-01, -8.8421e-02, -3.2220e-01, -8.8067e-02,  2.1718e-01,
         -3.6291e-01, -4.9237e-01,  2.1455e-01, -1.8674e-02,  3.9949e-01,
         -2.2519e-01, -1.4739e-01, -2.2509e-01,  2.9665e-01, -3.3978e-01,
         -4.4125e-01,  5.8753e-01,  2.4695e-01, -9.5062e-02,  9.9014e-03,
         -1.6486e-01,  2.4021e-01,  3.2167e-02, -2.2061e-01, -4.3971e-01,
          5.9503e-01, -1.8055e-01, -8.3522e-02,  1.0926e-01,  3.9749e-02,
          1.6904e-01,  7.3836e-02,  9.2030e-02,  2.3969e-01,  2.4693e-02,
          3.4840e-01,  3.3886e-02, -2.7562e-01, -4.2305e-01, -1.4418e-01,
          3.3536e-01, -2.7491e-01,  5.2891e-01,  3.0901e-01, -4.6127e-01,
          7.0903e-02, -1.1390e-01,  4.2822e-01, -4.7448e-01, -1.9457e-01,
          1.7779e-01, -3.3084e-01, -4.7311e-01, -4.2679e-01,  7.1815e-02,
          2.4915e-01, -4.4569e-01,  1.6466e-01,  4.1354e-02, -2.4865e-01,
         -4.2151e-01, -2.8002e-01,  8.4000e-02, -1.1305e-01,  3.2736e-01,
          1.0333e-01, -2.9267e-01, -3.9020e-02,  3.9709e-01, -3.1718e-01,
          4.5334e-01,  6.2500e-01, -2.3732e-01,  1.5878e-01, -3.1546e-01,
          1.4519e-01, -3.7691e-01,  4.5056e-01,  3.8429e-01,  1.1904e-01,
          4.6546e-01,  8.9835e-02, -3.4235e-02,  7.0945e-02,  5.7647e-02,
          3.2093e-01, -7.4279e-02,  1.9812e-01,  6.6854e-01,  8.3255e-03,
          5.2060e-01,  1.4760e-01,  4.9135e-02, -5.2057e-01,  8.4303e-02,
          2.5593e-02,  3.9829e-01, -3.1141e-01,  6.5268e-02, -4.9857e-02,
         -4.5633e-02, -6.8734e-01, -2.6750e-03, -2.4190e-01, -2.8735e-01,
         -3.2288e-02,  5.3618e-01,  3.4173e-01, -3.6855e-01, -4.1932e-01,
         -3.2033e-01, -2.7842e-01,  4.4021e-01,  8.6230e-01,  9.1970e-02,
         -1.1976e-01, -3.8733e-01, -9.0361e-02, -5.4882e-02,  1.3525e-01,
          3.8096e-02,  6.2839e-01,  4.1826e-01,  4.6406e-01, -2.4304e-01,
         -4.5163e-01, -2.7172e-01, -1.2460e-01,  2.3671e-01, -3.1206e-01,
         -1.7764e-02,  1.3673e-03, -2.0460e-02, -6.8924e-02, -3.0854e-01,
         -2.8193e-02, -1.2100e-01,  2.0054e-01, -8.8251e-02, -1.1931e-01,
         -1.0426e-01, -6.4048e-01, -3.0713e-01,  2.0817e-01,  6.5585e-02,
         -1.4141e-01,  2.0945e-01, -7.4820e-04, -2.2530e-01, -3.7012e-01,
          1.6271e-01, -4.9095e-01, -2.2408e-01, -3.8781e-01,  2.5892e-01,
         -3.5237e-01,  6.4705e-03, -4.4271e-01,  5.8282e-01,  1.8517e-01,
          3.0051e-02,  5.0570e-02,  2.0626e-01, -1.3862e-01,  1.3162e-01,
          1.2967e-01,  2.0172e-01, -4.2257e-01,  8.3080e-02,  2.6301e-01,
          1.8749e-01, -3.6900e-01,  2.6178e-01,  3.2177e-01, -2.0241e-01,
         -5.9555e-01,  1.7245e-01, -7.6558e-02, -8.9417e-02,  1.7406e-01,
         -3.0616e-01, -5.1685e-02,  1.4586e-01,  5.1845e-01,  3.5010e-01,
         -4.0866e-01, -6.4725e-01,  1.4885e-01,  3.5427e-01, -7.2978e-02,
         -6.2830e-01, -2.0126e-01, -2.4575e-01,  2.5788e-01, -6.6602e-01,
          1.4807e-01,  5.9979e-01,  3.1298e-01, -2.1984e-02, -2.1055e-01,
          4.2543e-01, -4.2785e-01,  2.8597e-01, -4.6195e-02, -4.4302e-01,
         -1.6596e-01,  4.3690e-01,  8.2672e-03,  8.6318e-02,  2.6571e-01,
          3.8568e-01,  7.2709e-02, -5.9491e-01, -3.6851e-01,  3.6038e-01,
          3.4782e-03,  4.1766e-01,  5.5036e-01,  2.9479e-02, -3.7907e-01,
          1.8382e-03, -1.4601e-01,  1.6616e-01,  5.3503e-01,  1.3591e-02,
          1.2013e-01, -8.5887e-02,  3.7715e-01, -3.4969e-01,  4.3805e-01,
          3.1855e-01, -3.6571e-01, -1.7446e-01,  4.0240e-01, -1.6065e-01,
         -3.6733e-01,  1.7065e-01,  9.1335e-02,  3.1418e-01, -1.3760e-01,
         -4.5394e-01, -2.5068e-01,  8.7604e-02, -6.2930e-01,  1.2898e-02,
         -3.7761e-01,  5.9227e-02, -2.4603e-01,  1.9747e-01, -7.6524e-01,
          4.1795e-01, -3.2705e-01, -4.8150e-01, -1.3054e-01, -1.7629e-02,
         -7.9984e-02,  3.5556e-01,  4.0054e-01, -2.2257e-01, -4.4133e-03,
         -2.0015e-01, -1.1900e-01, -2.7484e-01, -5.1239e-01, -6.3264e-01,
         -1.7553e-01, -3.6384e-02,  1.4799e-01,  4.2550e-01,  4.8262e-01,
         -4.1353e-01,  1.6462e-01, -3.8982e-01,  3.9817e-02,  2.0532e-01,
         -1.9002e-01, -1.7682e-01,  8.7832e-01,  1.1802e-01, -4.0827e-01,
          4.1533e-01,  5.2921e-01, -3.8746e-01,  5.6729e-01,  2.9954e-01,
         -4.1602e-01, -1.2003e-01, -1.2318e-01,  6.4842e-02,  7.1454e-01,
         -3.3365e-01, -8.2613e-03, -9.7548e-02,  6.7619e-01, -2.0094e-01,
          6.8275e-02, -1.9088e-01,  2.5895e-01, -1.8892e-02,  8.5494e-02,
          4.3036e-01,  2.0538e-01,  5.8892e-01,  6.2417e-01,  4.8445e-01,
         -2.7654e-01,  3.1131e-01,  3.5275e-01,  3.1345e-01, -4.5330e-02,
          4.1206e-01, -3.9273e-01, -1.9450e-01,  1.3716e-02, -2.6335e-01,
          1.4685e-01,  3.2094e-01, -2.6300e-01,  9.1132e-02,  9.6662e-02,
         -2.8584e-01,  4.9270e-01,  5.0694e-01, -6.7856e-01, -1.6952e-02,
          2.0858e-01,  2.7211e-01,  7.7594e-03,  1.1058e-01,  3.5853e-01,
         -3.4715e-02,  1.9556e-01, -1.0988e-01, -2.6661e-01,  8.2309e-02,
         -1.8942e-01,  4.2286e-01,  2.1585e-01,  2.0750e-01, -1.9119e-01,
          3.1705e-01, -3.8454e-01, -2.0743e-01, -3.8114e-02,  6.4414e-02,
         -1.7748e-01,  1.3586e-01,  4.2025e-01,  5.2959e-01, -3.0235e-01,
          6.6244e-02,  5.9458e-02, -3.8626e-01, -3.0927e-01, -2.5877e-01,
          3.9770e-01, -3.5933e-01,  2.1776e-01, -4.3661e-01,  3.3840e-01,
          3.5971e-01, -2.2540e-01, -2.6150e-01, -3.6218e-01,  6.4707e-01,
          8.7594e-01,  5.4092e-01, -8.1894e-02,  5.3965e-01, -1.3166e-01,
         -1.9551e-01, -7.0249e-01, -3.5140e-01,  9.1459e-02,  8.1300e-03,
          2.1649e-01,  9.5686e-02,  4.3850e-01, -5.3493e-01,  1.3832e-01,
         -1.7769e-01, -3.1088e-01,  1.4557e-01,  5.7953e-01, -8.4913e-02,
          1.5262e-01, -4.3042e-02,  3.5596e-01, -2.6371e-01, -1.3432e-01,
          4.5435e-01, -5.2918e-02, -3.9792e-01, -1.0195e-01,  1.0674e-01,
         -8.1712e-02,  7.9050e-01, -7.5311e-02,  3.8989e-02, -5.4863e-01,
          2.3593e-01,  1.7604e-01, -4.1790e-01, -5.9872e-01,  8.6589e-04,
         -2.7348e-02,  6.8003e-01, -2.4577e-01,  2.8322e-01,  2.7373e-04,
          1.9466e-01,  1.7917e-01,  2.8938e-01,  2.7149e-01, -4.1166e-01,
          1.0486e-01, -2.8750e-01, -3.6946e-01,  5.6385e-01, -7.4233e-01,
         -3.6163e-01,  3.5484e-01,  3.3670e-01,  9.1394e-03, -1.0086e-01,
         -1.7736e-01, -3.6094e-01,  8.7540e-01, -2.3598e-01,  3.2910e-01,
         -7.4240e-01,  6.6476e-01, -1.7125e-01,  3.7107e-01, -6.8735e-01,
          7.3219e-01,  5.7308e-01, -7.9865e-02,  2.6137e-03, -1.0492e-01,
          6.2231e-01, -2.2494e-01,  6.8010e-01,  1.1748e-01,  5.2259e-01,
          1.2923e-02,  7.3691e-02,  3.4888e-01,  2.6414e-01,  4.2186e-01,
         -4.1445e-01,  5.7697e-01,  4.0721e-01, -4.0092e-01, -4.1310e-01,
          5.1246e-01,  5.3019e-03,  5.7073e-01, -6.6950e-01, -7.4447e-02,
         -3.0260e-01,  2.1808e-01,  8.2279e-01, -5.1817e-01,  5.0470e-01,
          3.2587e-01,  2.6581e-01,  5.2826e-01, -7.4837e-03, -6.9155e-02,
          2.5341e-01, -3.2784e-01, -2.1990e-02, -4.8601e-01, -1.7147e-01,
         -3.9870e-01, -3.0875e-01, -2.6406e-01, -2.0629e-01,  3.1720e-01,
          3.3498e-01, -1.0637e-01,  1.1432e-01, -2.1800e-01,  6.6413e-01,
         -2.0818e-02, -5.1117e-01, -6.3738e-01,  2.4649e-01,  1.9480e-01,
          1.1880e-02, -4.4444e-01,  9.7113e-02, -1.0584e-01,  6.0753e-01,
          7.0593e-01,  4.3478e-01,  1.8733e-01,  3.2939e-02,  3.8776e-01,
          2.8482e-01, -4.1235e-01, -6.0461e-01,  3.8104e-01,  1.0732e-01,
         -7.0059e-01,  2.6696e-01, -2.9421e-01,  4.3722e-01, -4.5591e-01,
         -8.6827e-02,  5.9254e-02, -4.1622e-01, -3.9528e-01, -4.8446e-01,
         -4.7552e-02, -4.9195e-01,  4.2025e-01, -5.4779e-01, -1.7593e-02,
          7.4183e-01, -7.0238e-01,  4.6337e-01,  4.0638e-01,  2.6151e-01,
          5.7075e-01, -1.9192e-01,  8.6687e-02,  5.0342e-01,  3.5060e-02,
          4.3095e-01,  6.2844e-01, -2.7865e-01, -1.8283e-01,  7.1376e-01,
         -1.0288e-01,  3.3084e-01,  7.6745e-01,  2.1309e-02, -4.1063e-01,
          5.3351e-01, -1.1141e-01, -1.5108e-01,  2.6530e-01,  6.8424e-01,
          1.6492e-01,  4.6153e-01, -2.9771e-01,  1.0697e-01,  1.4702e-01,
          1.2702e-01, -5.0592e-01, -3.6936e-01, -5.2906e-01,  2.2893e-01,
         -2.6245e-01,  4.2968e-02, -1.7851e-01, -5.6460e-02,  5.5637e-01,
         -5.9503e-01, -7.7544e-02, -2.2456e-01, -6.1064e-01,  3.1447e-01,
          1.4890e-01, -2.8982e-02, -1.1260e-04,  4.4912e-01, -3.5829e-01,
         -3.2105e-01,  7.6753e-01, -1.3102e-03,  2.2552e-02,  2.3368e-02,
          1.3975e-01, -6.5992e-01, -3.0786e-01]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 44.2000% F1: 0.3529
Applying ckpt from fold 1 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 42.0000% F1: 0.3420
Applying ckpt from fold 2 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 42.8000% F1: 0.3433
Applying ckpt from fold 3 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.4000% F1: 0.3575
Applying ckpt from fold 4 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 42.0000% F1: 0.3536
Applying ckpt from fold 5 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 40.4000% F1: 0.3483
Applying ckpt from fold 6 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 44.0000% F1: 0.3614
Applying ckpt from fold 7 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.0000% F1: 0.3425
Applying ckpt from fold 8 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.6000% F1: 0.3373
Applying ckpt from fold 9 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 39.6000% F1: 0.3346
Metrics by fold:
Fold 0 - Acc: 0.44 F1: 0.35
Fold 1 - Acc: 0.42 F1: 0.34
Fold 2 - Acc: 0.43 F1: 0.34
Fold 3 - Acc: 0.45 F1: 0.36
Fold 4 - Acc: 0.42 F1: 0.35
Fold 5 - Acc: 0.40 F1: 0.35
Fold 6 - Acc: 0.44 F1: 0.36
Fold 7 - Acc: 0.45 F1: 0.34
Fold 8 - Acc: 0.46 F1: 0.34
Fold 9 - Acc: 0.40 F1: 0.33
agg_acc: 0.4310 agg_f1: 0.3473
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-1.9576e-02,  1.4462e-02,  2.1089e-02, -2.4213e-02, -3.1370e-02,
         -1.4199e-02, -2.5904e-02, -5.0341e-02, -3.6889e-02, -3.2728e-02,
         -6.8087e-04, -3.5233e-02, -3.9792e-02, -2.0962e-02, -7.1844e-03,
         -9.9852e-03, -2.8043e-02, -2.2781e-02, -4.4245e-03, -4.3463e-02,
         -4.1087e-02, -4.5657e-02, -1.9222e-02, -7.8390e-03, -2.0070e-02,
         -3.9880e-02,  1.8200e-02, -2.9268e-02, -1.6676e-02, -2.1610e-02,
         -2.6654e-02, -2.5254e-02,  9.2145e-03, -4.5557e-02, -3.3439e-02,
         -7.2401e-03, -2.6082e-02,  1.0227e-02, -1.4157e-02, -1.4822e-02,
         -4.3798e-02, -4.1658e-02, -1.4709e-02, -2.5902e-02, -8.7081e-03,
         -3.9880e-02, -1.5114e-02, -1.3367e-02, -3.1035e-02, -3.6392e-02,
          1.2227e-02, -8.7005e-03, -1.9950e-02, -1.3439e-02, -3.7631e-02,
         -3.0060e-02, -1.7583e-03, -4.8765e-02,  1.0541e-03, -1.3689e-02,
         -2.3786e-02,  8.0220e-03, -3.0173e-02, -2.5209e-02, -2.2526e-02,
         -1.9942e-02,  8.4238e-03, -1.9661e-02, -1.2119e-02, -3.4659e-03,
         -3.1803e-02, -3.2865e-03, -1.0539e-02, -3.9146e-03, -4.3804e-02,
          2.2994e-02,  1.2197e-02, -4.6647e-02, -3.5887e-02, -1.4468e-02,
         -3.3255e-03, -1.7044e-02,  2.0406e-02,  1.0396e-02, -2.0522e-02,
         -3.4509e-02, -4.8150e-02, -5.4708e-03,  3.8065e-02, -5.5523e-02,
          3.8816e-03, -6.3457e-02, -2.4241e-02, -9.3510e-03, -1.5897e-02,
         -8.8885e-03, -1.4690e-02, -5.4748e-03, -9.9003e-03, -7.0308e-03,
          3.4854e-03, -6.2360e-04,  1.0930e-02,  2.8643e-02, -1.1186e-02,
         -2.6669e-02, -1.9786e-02,  1.7164e-02, -1.3477e-02, -4.4371e-02,
         -1.4301e-02, -1.3759e-02, -4.0720e-02, -2.1774e-02,  1.6330e-02,
         -2.6441e-02, -4.0575e-02, -3.9297e-02, -9.2287e-03, -2.3262e-02,
         -5.1135e-03,  1.7898e-02,  1.0295e-02, -4.4888e-02, -1.1444e-02,
         -6.7636e-05,  3.0896e-02, -2.1793e-02, -2.7886e-02,  7.3077e-04,
         -7.0966e-03, -2.8983e-02, -2.4230e-02, -4.3455e-03, -3.6372e-02,
         -1.4622e-02, -1.9455e-02, -6.2994e-03, -4.8066e-02,  1.2134e-03,
         -2.6100e-02, -2.2397e-02, -4.3888e-02, -4.5778e-03, -4.2798e-02,
         -4.1344e-03, -4.0403e-02, -1.4517e-02, -7.4589e-03, -2.9797e-02,
         -4.2728e-02, -5.6681e-02, -7.0879e-03,  7.4267e-03,  2.2647e-02,
         -2.2768e-02,  7.6049e-04, -3.0197e-02, -5.4283e-03,  9.8245e-03,
         -1.2252e-03, -2.3723e-02,  3.4096e-02, -1.4257e-02, -3.2253e-02,
         -1.8886e-02, -5.4247e-03, -1.1375e-02, -9.0462e-03, -1.1843e-02,
          1.3237e-02, -2.4774e-02, -2.8040e-02, -3.8893e-02, -2.9173e-02,
         -3.3035e-02, -5.6146e-03, -2.8491e-02, -1.4185e-02, -1.6383e-02,
          1.3736e-03, -2.7760e-02, -4.3374e-03,  1.7261e-02, -2.0601e-02,
         -1.9357e-03, -1.5073e-02, -9.6997e-03, -1.1300e-02, -4.2982e-02,
          8.4574e-03, -3.8737e-02, -1.5231e-02, -2.3515e-02, -1.3568e-02,
          3.3063e-03, -3.3534e-02, -8.0107e-03, -3.6351e-02, -3.9080e-02,
         -8.1655e-03, -8.9546e-03,  4.9051e-03, -6.2526e-03, -4.5883e-02,
         -2.0797e-02, -3.6205e-02, -8.1598e-03, -2.8076e-02, -8.8447e-03,
         -1.9260e-02,  1.1396e-02,  1.5052e-02, -1.6075e-02, -1.5518e-02,
         -1.7724e-02,  2.0844e-02, -2.6688e-02, -3.4171e-02, -2.8748e-02,
          7.2581e-03, -1.6509e-02, -2.8037e-02, -2.2494e-02, -6.6422e-03,
         -3.8462e-02, -4.8222e-02, -4.5790e-02, -1.1145e-02,  4.5953e-02,
         -1.1314e-04,  1.1308e-03, -4.2939e-02, -2.3548e-02,  1.3748e-02,
          4.0744e-03,  8.6413e-03, -1.0417e-03, -5.3433e-02, -4.8686e-03,
          2.5878e-02, -1.2791e-02, -1.8810e-02, -1.7619e-02, -9.7876e-03,
         -2.5285e-02, -2.1384e-02,  1.4755e-02, -3.9157e-02,  1.8993e-02,
          5.0377e-03, -2.9328e-02, -1.6048e-02, -3.0006e-02, -2.8478e-02,
         -8.5162e-03, -1.2241e-02, -1.8590e-02, -2.9219e-03, -2.3340e-02,
         -2.1185e-02, -1.4722e-02, -1.4868e-02, -1.5969e-02, -2.2238e-02,
         -2.0746e-02,  9.0726e-03,  1.1734e-02, -3.8070e-02,  9.3740e-04,
         -3.4404e-02, -5.3068e-02,  7.4766e-03, -3.3690e-02, -2.3907e-02,
         -1.1922e-02, -3.2821e-02, -4.6094e-02,  4.7032e-04, -4.1886e-02,
         -5.7862e-03, -2.4299e-02, -2.8858e-02,  1.1723e-02, -3.0093e-02,
         -4.6471e-02, -4.9816e-03, -2.3448e-03, -2.2391e-02, -3.6809e-02,
         -3.7831e-02,  8.4370e-03, -4.2447e-02, -1.9412e-02, -3.9165e-02,
         -2.3906e-02,  7.2951e-03, -4.2961e-02,  8.2211e-03, -2.2970e-02,
         -1.4029e-02,  1.2471e-03,  3.8190e-02, -5.0079e-03, -4.4626e-02,
         -1.3463e-02, -1.6834e-02,  3.9899e-04, -1.4055e-02, -3.9695e-02,
         -3.6972e-02, -1.7081e-02, -3.0984e-02, -1.9453e-02, -1.2163e-05,
         -1.2716e-02, -9.5281e-03, -2.4193e-02, -3.0648e-02,  8.4034e-03,
         -9.2663e-03, -4.4070e-02, -2.4568e-02, -1.5319e-02, -5.6182e-03,
          6.3644e-03, -1.5009e-02,  1.2869e-02, -7.8058e-03,  5.4362e-03,
          2.2388e-03, -2.6862e-02, -1.5712e-03, -1.8940e-02,  1.3159e-02,
         -1.3461e-02, -3.9902e-02, -5.0591e-02, -1.7753e-02, -1.3713e-02,
          8.0693e-03, -3.5620e-02, -3.3676e-02, -1.3030e-02, -1.6888e-02,
         -2.5140e-02, -3.4833e-02, -7.2791e-03, -3.2956e-02, -2.4693e-02,
         -1.1791e-02, -1.2542e-02, -1.6742e-02, -4.3013e-02, -1.3429e-02,
          1.2613e-03, -4.0043e-02, -1.1774e-02, -3.2534e-02, -3.4204e-02,
          8.6550e-03, -8.3946e-03, -3.6755e-02, -3.3793e-02, -2.7884e-02,
         -7.4445e-03, -1.8833e-03,  1.2610e-02,  9.8851e-03,  1.2191e-02,
         -3.6666e-02, -8.5410e-02, -2.8082e-02, -3.0407e-02, -1.9044e-02,
          2.4342e-03, -1.4180e-03, -2.6470e-02, -2.5302e-02, -2.5253e-02,
         -1.1512e-02, -2.8345e-02, -1.5937e-02,  9.6349e-03, -1.0218e-02,
          1.3560e-02,  1.5391e-02, -1.9179e-02,  1.5864e-02, -1.0996e-02,
         -1.0817e-02,  2.6805e-03, -3.1092e-02, -3.8091e-02, -2.3368e-02,
         -5.9125e-02, -1.0858e-02,  4.5047e-03, -1.8238e-02, -2.1426e-02,
         -1.7773e-02, -2.9463e-02, -3.7479e-03, -4.9064e-03, -1.5818e-02,
         -2.5526e-02, -1.4419e-03, -1.1299e-02,  8.5140e-03, -1.0698e-02,
         -1.1708e-02, -2.0608e-02, -1.4593e-02, -7.7355e-03, -7.3931e-03,
         -4.0843e-02, -2.1167e-02, -1.2983e-02, -2.9919e-03,  3.0490e-03,
         -4.7598e-03, -7.2291e-02, -9.2503e-03, -3.9466e-02, -4.7297e-02,
         -2.1130e-02, -3.5272e-02,  2.0385e-02,  5.3947e-03, -2.0301e-02,
         -9.7881e-03, -1.9998e-02, -6.5725e-02, -4.3420e-02, -3.1609e-02,
         -1.8267e-04, -3.4371e-03, -9.8789e-04,  9.6274e-03, -5.9154e-03,
         -3.4675e-02, -6.5226e-02, -2.0677e-02, -4.1714e-02,  2.1622e-02,
          2.0240e-02, -9.2820e-03, -1.7129e-02, -3.2057e-02, -3.1468e-02,
         -3.4941e-02,  2.3813e-02, -1.6644e-02, -5.0642e-02, -1.6989e-02,
         -2.9996e-02, -2.5404e-02, -2.8092e-02, -4.2349e-02, -3.9435e-02,
         -4.4279e-02, -2.2080e-02,  3.3196e-03, -1.1349e-02,  6.9159e-03,
         -3.3969e-02, -5.3818e-02,  4.0196e-02, -3.8763e-02,  1.4048e-02,
          5.9220e-04, -2.6749e-02, -1.3595e-03, -4.5813e-02, -6.8420e-03,
         -3.4372e-02, -1.8214e-02,  4.0495e-03,  3.8787e-06, -1.8598e-02,
          9.7004e-03, -2.1482e-02, -1.9200e-02, -4.7962e-02, -3.4414e-02,
         -3.2698e-02, -2.5277e-02, -3.4527e-02,  1.4325e-02, -3.6852e-02,
          4.9736e-03, -4.6518e-02, -1.2696e-02, -4.6521e-02, -3.6610e-02,
         -2.4398e-02, -3.2662e-02, -2.5911e-03, -5.8092e-02,  2.9025e-02,
         -2.1087e-02, -1.7487e-02, -3.1389e-02, -4.2529e-02, -1.0128e-02,
         -1.7335e-02,  2.8430e-02,  3.9904e-02,  8.0061e-04, -3.1003e-02,
         -7.1200e-02, -2.8507e-03, -5.9049e-02, -1.5139e-02,  5.0690e-03,
         -1.6833e-02, -9.0752e-03, -2.3263e-02, -2.1165e-02, -4.3393e-02,
         -8.7630e-03, -1.3716e-02, -2.7933e-02, -4.8012e-02, -1.4200e-02,
         -5.1839e-02, -6.0081e-03, -1.8939e-02, -1.7114e-02, -4.1764e-02,
         -5.2397e-03, -5.4814e-03, -2.0793e-02, -4.0475e-02, -4.4624e-02,
         -7.9084e-03, -3.5071e-03,  2.0474e-02, -2.6987e-02, -1.4414e-02,
         -1.9035e-02, -4.9324e-02, -2.8345e-02,  1.4301e-02, -3.8973e-02,
         -1.2840e-02, -7.5258e-03, -4.6916e-02, -4.7070e-02, -1.3649e-02,
         -5.4320e-02, -1.8288e-03, -1.8652e-03, -2.7375e-02,  1.1466e-02,
         -4.0584e-02, -1.2032e-02, -3.9389e-02, -2.1145e-02,  2.4070e-03,
          9.3934e-03, -3.9291e-02, -5.9169e-02, -4.5224e-03, -1.4565e-02,
         -2.3315e-02, -3.0413e-02, -1.4424e-02, -1.6966e-02,  1.0072e-02,
          3.6617e-02, -3.9734e-02, -3.2399e-02, -1.3331e-02, -2.1236e-02,
          2.2823e-02, -1.9419e-02, -4.0604e-03, -1.3728e-02, -1.8695e-02,
         -2.6998e-02, -1.7203e-02, -6.4163e-03, -1.3199e-02, -5.5872e-02,
         -3.5325e-02, -3.1695e-02, -4.9119e-02,  4.0982e-02,  1.8657e-02,
         -3.3573e-02, -8.9048e-03,  1.6459e-02, -3.6141e-02, -3.5255e-02,
         -2.0351e-02,  3.6519e-02, -1.1686e-02,  2.1606e-02,  1.8557e-02,
         -4.5092e-03, -9.0398e-03,  2.1982e-02, -3.4125e-02,  1.8775e-02,
         -5.1349e-02, -2.0664e-03, -1.0744e-02, -1.6671e-02,  2.6162e-02,
         -6.4523e-03, -5.7046e-02, -3.6390e-03, -1.9814e-02, -1.6118e-02,
          6.7051e-03, -5.2483e-03,  8.4542e-04, -2.6400e-02, -6.1003e-03,
         -1.2574e-02, -3.9921e-02, -2.9327e-02, -2.4630e-02,  8.4810e-03,
         -7.4100e-04, -1.8916e-02,  5.1565e-03,  2.2242e-02, -9.2054e-03,
         -5.8127e-02, -1.7812e-03, -1.1566e-02, -1.5581e-02, -2.4738e-02,
         -8.5652e-03, -1.4644e-02, -1.7377e-02, -7.8154e-03,  8.7701e-03,
         -1.5758e-02, -2.9299e-02, -5.7990e-02,  5.2301e-03, -1.7015e-03,
         -1.0382e-02, -6.0044e-03, -2.6569e-02, -1.6470e-03,  1.8650e-03,
          1.0926e-02, -2.2354e-02,  1.7114e-02, -7.1626e-03, -4.9205e-02,
         -1.3529e-02,  2.1432e-02, -1.5802e-02, -2.3511e-02, -1.6134e-02,
         -3.9555e-02,  2.8150e-02, -9.2762e-03, -8.4562e-03, -2.7197e-02,
         -7.0721e-03, -4.0385e-03, -4.7109e-02, -5.2178e-03, -4.8849e-02,
          1.6391e-02, -3.0436e-02, -2.0354e-02, -1.7472e-02, -1.0822e-02,
         -3.9952e-02, -3.1226e-02, -5.1212e-02,  1.2849e-02, -4.3737e-02,
         -1.6600e-02, -1.7369e-02, -3.5132e-02, -7.9695e-03, -1.9029e-02,
         -2.9353e-02, -2.5525e-02, -1.2254e-02,  1.0975e-03, -4.0945e-02,
         -1.6960e-02, -4.7521e-03, -1.3975e-02, -1.2778e-02, -2.7528e-02,
         -3.3573e-02, -4.6857e-03, -4.8495e-03, -1.5761e-02, -1.7572e-02,
         -1.5772e-02, -7.3530e-03, -3.1005e-02, -1.7780e-02, -1.4125e-02,
         -2.0564e-02, -1.9258e-02, -1.5787e-02, -2.5870e-02,  8.4195e-03,
          1.2669e-02, -1.9583e-02, -1.6337e-02, -1.2081e-02,  7.1074e-03,
         -4.5319e-02, -2.1659e-02, -1.2411e-02, -2.7327e-02, -1.0128e-02,
         -3.7986e-02, -1.6327e-02, -5.8103e-03, -1.7206e-02, -1.4065e-02,
          2.7339e-02, -2.2147e-02, -3.9057e-02, -8.3084e-03, -2.7950e-02,
         -1.3844e-02, -1.8129e-02, -4.8987e-02,  1.5473e-02, -2.5392e-02,
         -3.8005e-02, -4.3275e-02, -1.0993e-02, -5.9326e-03, -6.6074e-02,
         -4.9379e-03, -2.7258e-02, -2.5302e-02, -3.8126e-02, -3.0043e-02,
         -8.6250e-03, -4.3281e-03, -5.0636e-02, -5.5711e-02, -2.7074e-02,
         -3.6164e-02, -1.2752e-02, -1.9970e-02, -2.1273e-02, -5.8114e-03,
         -6.4127e-02, -2.3056e-02,  2.3241e-03, -3.5551e-02, -1.8637e-02,
         -2.2455e-02, -3.8589e-02,  3.4994e-03, -5.7992e-03,  9.8726e-03,
         -4.2325e-02, -3.3603e-02,  9.3079e-03]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2371
Applying ckpt from fold 1 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2371
Applying ckpt from fold 2 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2371
Applying ckpt from fold 3 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2374
Applying ckpt from fold 4 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2371
Applying ckpt from fold 5 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.4000% F1: 0.2416
Applying ckpt from fold 6 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2408
Applying ckpt from fold 7 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2410
Applying ckpt from fold 8 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2371
Applying ckpt from fold 9 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2371
Metrics by fold:
Fold 0 - Acc: 0.55 F1: 0.24
Fold 1 - Acc: 0.55 F1: 0.24
Fold 2 - Acc: 0.55 F1: 0.24
Fold 3 - Acc: 0.55 F1: 0.24
Fold 4 - Acc: 0.55 F1: 0.24
Fold 5 - Acc: 0.55 F1: 0.24
Fold 6 - Acc: 0.55 F1: 0.24
Fold 7 - Acc: 0.55 F1: 0.24
Fold 8 - Acc: 0.55 F1: 0.24
Fold 9 - Acc: 0.55 F1: 0.24
agg_acc: 0.5522 agg_f1: 0.2384
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-1.9576e-02,  1.4462e-02,  2.1089e-02, -2.4213e-02, -3.1370e-02,
         -1.4199e-02, -2.5904e-02, -5.0341e-02, -3.6889e-02, -3.2728e-02,
         -6.8087e-04, -3.5233e-02, -3.9792e-02, -2.0962e-02, -7.1844e-03,
         -9.9852e-03, -2.8043e-02, -2.2781e-02, -4.4245e-03, -4.3463e-02,
         -4.1087e-02, -4.5657e-02, -1.9222e-02, -7.8390e-03, -2.0070e-02,
         -3.9880e-02,  1.8200e-02, -2.9268e-02, -1.6676e-02, -2.1610e-02,
         -2.6654e-02, -2.5254e-02,  9.2145e-03, -4.5557e-02, -3.3439e-02,
         -7.2401e-03, -2.6082e-02,  1.0227e-02, -1.4157e-02, -1.4822e-02,
         -4.3798e-02, -4.1658e-02, -1.4709e-02, -2.5902e-02, -8.7081e-03,
         -3.9880e-02, -1.5114e-02, -1.3367e-02, -3.1035e-02, -3.6392e-02,
          1.2227e-02, -8.7005e-03, -1.9950e-02, -1.3439e-02, -3.7631e-02,
         -3.0060e-02, -1.7583e-03, -4.8765e-02,  1.0541e-03, -1.3689e-02,
         -2.3786e-02,  8.0220e-03, -3.0173e-02, -2.5209e-02, -2.2526e-02,
         -1.9942e-02,  8.4238e-03, -1.9661e-02, -1.2119e-02, -3.4659e-03,
         -3.1803e-02, -3.2865e-03, -1.0539e-02, -3.9146e-03, -4.3804e-02,
          2.2994e-02,  1.2197e-02, -4.6647e-02, -3.5887e-02, -1.4468e-02,
         -3.3255e-03, -1.7044e-02,  2.0406e-02,  1.0396e-02, -2.0522e-02,
         -3.4509e-02, -4.8150e-02, -5.4708e-03,  3.8065e-02, -5.5523e-02,
          3.8816e-03, -6.3457e-02, -2.4241e-02, -9.3510e-03, -1.5897e-02,
         -8.8885e-03, -1.4690e-02, -5.4748e-03, -9.9003e-03, -7.0308e-03,
          3.4854e-03, -6.2360e-04,  1.0930e-02,  2.8643e-02, -1.1186e-02,
         -2.6669e-02, -1.9786e-02,  1.7164e-02, -1.3477e-02, -4.4371e-02,
         -1.4301e-02, -1.3759e-02, -4.0720e-02, -2.1774e-02,  1.6330e-02,
         -2.6441e-02, -4.0575e-02, -3.9297e-02, -9.2287e-03, -2.3262e-02,
         -5.1135e-03,  1.7898e-02,  1.0295e-02, -4.4888e-02, -1.1444e-02,
         -6.7636e-05,  3.0896e-02, -2.1793e-02, -2.7886e-02,  7.3077e-04,
         -7.0966e-03, -2.8983e-02, -2.4230e-02, -4.3455e-03, -3.6372e-02,
         -1.4622e-02, -1.9455e-02, -6.2994e-03, -4.8066e-02,  1.2134e-03,
         -2.6100e-02, -2.2397e-02, -4.3888e-02, -4.5778e-03, -4.2798e-02,
         -4.1344e-03, -4.0403e-02, -1.4517e-02, -7.4589e-03, -2.9797e-02,
         -4.2728e-02, -5.6681e-02, -7.0879e-03,  7.4267e-03,  2.2647e-02,
         -2.2768e-02,  7.6049e-04, -3.0197e-02, -5.4283e-03,  9.8245e-03,
         -1.2252e-03, -2.3723e-02,  3.4096e-02, -1.4257e-02, -3.2253e-02,
         -1.8886e-02, -5.4247e-03, -1.1375e-02, -9.0462e-03, -1.1843e-02,
          1.3237e-02, -2.4774e-02, -2.8040e-02, -3.8893e-02, -2.9173e-02,
         -3.3035e-02, -5.6146e-03, -2.8491e-02, -1.4185e-02, -1.6383e-02,
          1.3736e-03, -2.7760e-02, -4.3374e-03,  1.7261e-02, -2.0601e-02,
         -1.9357e-03, -1.5073e-02, -9.6997e-03, -1.1300e-02, -4.2982e-02,
          8.4574e-03, -3.8737e-02, -1.5231e-02, -2.3515e-02, -1.3568e-02,
          3.3063e-03, -3.3534e-02, -8.0107e-03, -3.6351e-02, -3.9080e-02,
         -8.1655e-03, -8.9546e-03,  4.9051e-03, -6.2526e-03, -4.5883e-02,
         -2.0797e-02, -3.6205e-02, -8.1598e-03, -2.8076e-02, -8.8447e-03,
         -1.9260e-02,  1.1396e-02,  1.5052e-02, -1.6075e-02, -1.5518e-02,
         -1.7724e-02,  2.0844e-02, -2.6688e-02, -3.4171e-02, -2.8748e-02,
          7.2581e-03, -1.6509e-02, -2.8037e-02, -2.2494e-02, -6.6422e-03,
         -3.8462e-02, -4.8222e-02, -4.5790e-02, -1.1145e-02,  4.5953e-02,
         -1.1314e-04,  1.1308e-03, -4.2939e-02, -2.3548e-02,  1.3748e-02,
          4.0744e-03,  8.6413e-03, -1.0417e-03, -5.3433e-02, -4.8686e-03,
          2.5878e-02, -1.2791e-02, -1.8810e-02, -1.7619e-02, -9.7876e-03,
         -2.5285e-02, -2.1384e-02,  1.4755e-02, -3.9157e-02,  1.8993e-02,
          5.0377e-03, -2.9328e-02, -1.6048e-02, -3.0006e-02, -2.8478e-02,
         -8.5162e-03, -1.2241e-02, -1.8590e-02, -2.9219e-03, -2.3340e-02,
         -2.1185e-02, -1.4722e-02, -1.4868e-02, -1.5969e-02, -2.2238e-02,
         -2.0746e-02,  9.0726e-03,  1.1734e-02, -3.8070e-02,  9.3740e-04,
         -3.4404e-02, -5.3068e-02,  7.4766e-03, -3.3690e-02, -2.3907e-02,
         -1.1922e-02, -3.2821e-02, -4.6094e-02,  4.7032e-04, -4.1886e-02,
         -5.7862e-03, -2.4299e-02, -2.8858e-02,  1.1723e-02, -3.0093e-02,
         -4.6471e-02, -4.9816e-03, -2.3448e-03, -2.2391e-02, -3.6809e-02,
         -3.7831e-02,  8.4370e-03, -4.2447e-02, -1.9412e-02, -3.9165e-02,
         -2.3906e-02,  7.2951e-03, -4.2961e-02,  8.2211e-03, -2.2970e-02,
         -1.4029e-02,  1.2471e-03,  3.8190e-02, -5.0079e-03, -4.4626e-02,
         -1.3463e-02, -1.6834e-02,  3.9899e-04, -1.4055e-02, -3.9695e-02,
         -3.6972e-02, -1.7081e-02, -3.0984e-02, -1.9453e-02, -1.2163e-05,
         -1.2716e-02, -9.5281e-03, -2.4193e-02, -3.0648e-02,  8.4034e-03,
         -9.2663e-03, -4.4070e-02, -2.4568e-02, -1.5319e-02, -5.6182e-03,
          6.3644e-03, -1.5009e-02,  1.2869e-02, -7.8058e-03,  5.4362e-03,
          2.2388e-03, -2.6862e-02, -1.5712e-03, -1.8940e-02,  1.3159e-02,
         -1.3461e-02, -3.9902e-02, -5.0591e-02, -1.7753e-02, -1.3713e-02,
          8.0693e-03, -3.5620e-02, -3.3676e-02, -1.3030e-02, -1.6888e-02,
         -2.5140e-02, -3.4833e-02, -7.2791e-03, -3.2956e-02, -2.4693e-02,
         -1.1791e-02, -1.2542e-02, -1.6742e-02, -4.3013e-02, -1.3429e-02,
          1.2613e-03, -4.0043e-02, -1.1774e-02, -3.2534e-02, -3.4204e-02,
          8.6550e-03, -8.3946e-03, -3.6755e-02, -3.3793e-02, -2.7884e-02,
         -7.4445e-03, -1.8833e-03,  1.2610e-02,  9.8851e-03,  1.2191e-02,
         -3.6666e-02, -8.5410e-02, -2.8082e-02, -3.0407e-02, -1.9044e-02,
          2.4342e-03, -1.4180e-03, -2.6470e-02, -2.5302e-02, -2.5253e-02,
         -1.1512e-02, -2.8345e-02, -1.5937e-02,  9.6349e-03, -1.0218e-02,
          1.3560e-02,  1.5391e-02, -1.9179e-02,  1.5864e-02, -1.0996e-02,
         -1.0817e-02,  2.6805e-03, -3.1092e-02, -3.8091e-02, -2.3368e-02,
         -5.9125e-02, -1.0858e-02,  4.5047e-03, -1.8238e-02, -2.1426e-02,
         -1.7773e-02, -2.9463e-02, -3.7479e-03, -4.9064e-03, -1.5818e-02,
         -2.5526e-02, -1.4419e-03, -1.1299e-02,  8.5140e-03, -1.0698e-02,
         -1.1708e-02, -2.0608e-02, -1.4593e-02, -7.7355e-03, -7.3931e-03,
         -4.0843e-02, -2.1167e-02, -1.2983e-02, -2.9919e-03,  3.0490e-03,
         -4.7598e-03, -7.2291e-02, -9.2503e-03, -3.9466e-02, -4.7297e-02,
         -2.1130e-02, -3.5272e-02,  2.0385e-02,  5.3947e-03, -2.0301e-02,
         -9.7881e-03, -1.9998e-02, -6.5725e-02, -4.3420e-02, -3.1609e-02,
         -1.8267e-04, -3.4371e-03, -9.8789e-04,  9.6274e-03, -5.9154e-03,
         -3.4675e-02, -6.5226e-02, -2.0677e-02, -4.1714e-02,  2.1622e-02,
          2.0240e-02, -9.2820e-03, -1.7129e-02, -3.2057e-02, -3.1468e-02,
         -3.4941e-02,  2.3813e-02, -1.6644e-02, -5.0642e-02, -1.6989e-02,
         -2.9996e-02, -2.5404e-02, -2.8092e-02, -4.2349e-02, -3.9435e-02,
         -4.4279e-02, -2.2080e-02,  3.3196e-03, -1.1349e-02,  6.9159e-03,
         -3.3969e-02, -5.3818e-02,  4.0196e-02, -3.8763e-02,  1.4048e-02,
          5.9220e-04, -2.6749e-02, -1.3595e-03, -4.5813e-02, -6.8420e-03,
         -3.4372e-02, -1.8214e-02,  4.0495e-03,  3.8787e-06, -1.8598e-02,
          9.7004e-03, -2.1482e-02, -1.9200e-02, -4.7962e-02, -3.4414e-02,
         -3.2698e-02, -2.5277e-02, -3.4527e-02,  1.4325e-02, -3.6852e-02,
          4.9736e-03, -4.6518e-02, -1.2696e-02, -4.6521e-02, -3.6610e-02,
         -2.4398e-02, -3.2662e-02, -2.5911e-03, -5.8092e-02,  2.9025e-02,
         -2.1087e-02, -1.7487e-02, -3.1389e-02, -4.2529e-02, -1.0128e-02,
         -1.7335e-02,  2.8430e-02,  3.9904e-02,  8.0061e-04, -3.1003e-02,
         -7.1200e-02, -2.8507e-03, -5.9049e-02, -1.5139e-02,  5.0690e-03,
         -1.6833e-02, -9.0752e-03, -2.3263e-02, -2.1165e-02, -4.3393e-02,
         -8.7630e-03, -1.3716e-02, -2.7933e-02, -4.8012e-02, -1.4200e-02,
         -5.1839e-02, -6.0081e-03, -1.8939e-02, -1.7114e-02, -4.1764e-02,
         -5.2397e-03, -5.4814e-03, -2.0793e-02, -4.0475e-02, -4.4624e-02,
         -7.9084e-03, -3.5071e-03,  2.0474e-02, -2.6987e-02, -1.4414e-02,
         -1.9035e-02, -4.9324e-02, -2.8345e-02,  1.4301e-02, -3.8973e-02,
         -1.2840e-02, -7.5258e-03, -4.6916e-02, -4.7070e-02, -1.3649e-02,
         -5.4320e-02, -1.8288e-03, -1.8652e-03, -2.7375e-02,  1.1466e-02,
         -4.0584e-02, -1.2032e-02, -3.9389e-02, -2.1145e-02,  2.4070e-03,
          9.3934e-03, -3.9291e-02, -5.9169e-02, -4.5224e-03, -1.4565e-02,
         -2.3315e-02, -3.0413e-02, -1.4424e-02, -1.6966e-02,  1.0072e-02,
          3.6617e-02, -3.9734e-02, -3.2399e-02, -1.3331e-02, -2.1236e-02,
          2.2823e-02, -1.9419e-02, -4.0604e-03, -1.3728e-02, -1.8695e-02,
         -2.6998e-02, -1.7203e-02, -6.4163e-03, -1.3199e-02, -5.5872e-02,
         -3.5325e-02, -3.1695e-02, -4.9119e-02,  4.0982e-02,  1.8657e-02,
         -3.3573e-02, -8.9048e-03,  1.6459e-02, -3.6141e-02, -3.5255e-02,
         -2.0351e-02,  3.6519e-02, -1.1686e-02,  2.1606e-02,  1.8557e-02,
         -4.5092e-03, -9.0398e-03,  2.1982e-02, -3.4125e-02,  1.8775e-02,
         -5.1349e-02, -2.0664e-03, -1.0744e-02, -1.6671e-02,  2.6162e-02,
         -6.4523e-03, -5.7046e-02, -3.6390e-03, -1.9814e-02, -1.6118e-02,
          6.7051e-03, -5.2483e-03,  8.4542e-04, -2.6400e-02, -6.1003e-03,
         -1.2574e-02, -3.9921e-02, -2.9327e-02, -2.4630e-02,  8.4810e-03,
         -7.4100e-04, -1.8916e-02,  5.1565e-03,  2.2242e-02, -9.2054e-03,
         -5.8127e-02, -1.7812e-03, -1.1566e-02, -1.5581e-02, -2.4738e-02,
         -8.5652e-03, -1.4644e-02, -1.7377e-02, -7.8154e-03,  8.7701e-03,
         -1.5758e-02, -2.9299e-02, -5.7990e-02,  5.2301e-03, -1.7015e-03,
         -1.0382e-02, -6.0044e-03, -2.6569e-02, -1.6470e-03,  1.8650e-03,
          1.0926e-02, -2.2354e-02,  1.7114e-02, -7.1626e-03, -4.9205e-02,
         -1.3529e-02,  2.1432e-02, -1.5802e-02, -2.3511e-02, -1.6134e-02,
         -3.9555e-02,  2.8150e-02, -9.2762e-03, -8.4562e-03, -2.7197e-02,
         -7.0721e-03, -4.0385e-03, -4.7109e-02, -5.2178e-03, -4.8849e-02,
          1.6391e-02, -3.0436e-02, -2.0354e-02, -1.7472e-02, -1.0822e-02,
         -3.9952e-02, -3.1226e-02, -5.1212e-02,  1.2849e-02, -4.3737e-02,
         -1.6600e-02, -1.7369e-02, -3.5132e-02, -7.9695e-03, -1.9029e-02,
         -2.9353e-02, -2.5525e-02, -1.2254e-02,  1.0975e-03, -4.0945e-02,
         -1.6960e-02, -4.7521e-03, -1.3975e-02, -1.2778e-02, -2.7528e-02,
         -3.3573e-02, -4.6857e-03, -4.8495e-03, -1.5761e-02, -1.7572e-02,
         -1.5772e-02, -7.3530e-03, -3.1005e-02, -1.7780e-02, -1.4125e-02,
         -2.0564e-02, -1.9258e-02, -1.5787e-02, -2.5870e-02,  8.4195e-03,
          1.2669e-02, -1.9583e-02, -1.6337e-02, -1.2081e-02,  7.1074e-03,
         -4.5319e-02, -2.1659e-02, -1.2411e-02, -2.7327e-02, -1.0128e-02,
         -3.7986e-02, -1.6327e-02, -5.8103e-03, -1.7206e-02, -1.4065e-02,
          2.7339e-02, -2.2147e-02, -3.9057e-02, -8.3084e-03, -2.7950e-02,
         -1.3844e-02, -1.8129e-02, -4.8987e-02,  1.5473e-02, -2.5392e-02,
         -3.8005e-02, -4.3275e-02, -1.0993e-02, -5.9326e-03, -6.6074e-02,
         -4.9379e-03, -2.7258e-02, -2.5302e-02, -3.8126e-02, -3.0043e-02,
         -8.6250e-03, -4.3281e-03, -5.0636e-02, -5.5711e-02, -2.7074e-02,
         -3.6164e-02, -1.2752e-02, -1.9970e-02, -2.1273e-02, -5.8114e-03,
         -6.4127e-02, -2.3056e-02,  2.3241e-03, -3.5551e-02, -1.8637e-02,
         -2.2455e-02, -3.8589e-02,  3.4994e-03, -5.7992e-03,  9.8726e-03,
         -4.2325e-02, -3.3603e-02,  9.3079e-03]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.0000% F1: 0.2819
Applying ckpt from fold 1 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.0000% F1: 0.2735
Applying ckpt from fold 2 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.0000% F1: 0.2604
Applying ckpt from fold 3 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.8000% F1: 0.3045
Applying ckpt from fold 4 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.2000% F1: 0.2899
Applying ckpt from fold 5 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.2000% F1: 0.3033
Applying ckpt from fold 6 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.2000% F1: 0.3098
Applying ckpt from fold 7 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.4000% F1: 0.2772
Applying ckpt from fold 8 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.6000% F1: 0.2622
Applying ckpt from fold 9 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.8000% F1: 0.3038
Metrics by fold:
Fold 0 - Acc: 0.53 F1: 0.28
Fold 1 - Acc: 0.52 F1: 0.27
Fold 2 - Acc: 0.54 F1: 0.26
Fold 3 - Acc: 0.53 F1: 0.30
Fold 4 - Acc: 0.51 F1: 0.29
Fold 5 - Acc: 0.52 F1: 0.30
Fold 6 - Acc: 0.53 F1: 0.31
Fold 7 - Acc: 0.52 F1: 0.28
Fold 8 - Acc: 0.55 F1: 0.26
Fold 9 - Acc: 0.54 F1: 0.30
agg_acc: 0.5292 agg_f1: 0.2866
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-1.9576e-02,  1.4462e-02,  2.1089e-02, -2.4213e-02, -3.1370e-02,
         -1.4199e-02, -2.5904e-02, -5.0341e-02, -3.6889e-02, -3.2728e-02,
         -6.8087e-04, -3.5233e-02, -3.9792e-02, -2.0962e-02, -7.1844e-03,
         -9.9852e-03, -2.8043e-02, -2.2781e-02, -4.4245e-03, -4.3463e-02,
         -4.1087e-02, -4.5657e-02, -1.9222e-02, -7.8390e-03, -2.0070e-02,
         -3.9880e-02,  1.8200e-02, -2.9268e-02, -1.6676e-02, -2.1610e-02,
         -2.6654e-02, -2.5254e-02,  9.2145e-03, -4.5557e-02, -3.3439e-02,
         -7.2401e-03, -2.6082e-02,  1.0227e-02, -1.4157e-02, -1.4822e-02,
         -4.3798e-02, -4.1658e-02, -1.4709e-02, -2.5902e-02, -8.7081e-03,
         -3.9880e-02, -1.5114e-02, -1.3367e-02, -3.1035e-02, -3.6392e-02,
          1.2227e-02, -8.7005e-03, -1.9950e-02, -1.3439e-02, -3.7631e-02,
         -3.0060e-02, -1.7583e-03, -4.8765e-02,  1.0541e-03, -1.3689e-02,
         -2.3786e-02,  8.0220e-03, -3.0173e-02, -2.5209e-02, -2.2526e-02,
         -1.9942e-02,  8.4238e-03, -1.9661e-02, -1.2119e-02, -3.4659e-03,
         -3.1803e-02, -3.2865e-03, -1.0539e-02, -3.9146e-03, -4.3804e-02,
          2.2994e-02,  1.2197e-02, -4.6647e-02, -3.5887e-02, -1.4468e-02,
         -3.3255e-03, -1.7044e-02,  2.0406e-02,  1.0396e-02, -2.0522e-02,
         -3.4509e-02, -4.8150e-02, -5.4708e-03,  3.8065e-02, -5.5523e-02,
          3.8816e-03, -6.3457e-02, -2.4241e-02, -9.3510e-03, -1.5897e-02,
         -8.8885e-03, -1.4690e-02, -5.4748e-03, -9.9003e-03, -7.0308e-03,
          3.4854e-03, -6.2360e-04,  1.0930e-02,  2.8643e-02, -1.1186e-02,
         -2.6669e-02, -1.9786e-02,  1.7164e-02, -1.3477e-02, -4.4371e-02,
         -1.4301e-02, -1.3759e-02, -4.0720e-02, -2.1774e-02,  1.6330e-02,
         -2.6441e-02, -4.0575e-02, -3.9297e-02, -9.2287e-03, -2.3262e-02,
         -5.1135e-03,  1.7898e-02,  1.0295e-02, -4.4888e-02, -1.1444e-02,
         -6.7636e-05,  3.0896e-02, -2.1793e-02, -2.7886e-02,  7.3077e-04,
         -7.0966e-03, -2.8983e-02, -2.4230e-02, -4.3455e-03, -3.6372e-02,
         -1.4622e-02, -1.9455e-02, -6.2994e-03, -4.8066e-02,  1.2134e-03,
         -2.6100e-02, -2.2397e-02, -4.3888e-02, -4.5778e-03, -4.2798e-02,
         -4.1344e-03, -4.0403e-02, -1.4517e-02, -7.4589e-03, -2.9797e-02,
         -4.2728e-02, -5.6681e-02, -7.0879e-03,  7.4267e-03,  2.2647e-02,
         -2.2768e-02,  7.6049e-04, -3.0197e-02, -5.4283e-03,  9.8245e-03,
         -1.2252e-03, -2.3723e-02,  3.4096e-02, -1.4257e-02, -3.2253e-02,
         -1.8886e-02, -5.4247e-03, -1.1375e-02, -9.0462e-03, -1.1843e-02,
          1.3237e-02, -2.4774e-02, -2.8040e-02, -3.8893e-02, -2.9173e-02,
         -3.3035e-02, -5.6146e-03, -2.8491e-02, -1.4185e-02, -1.6383e-02,
          1.3736e-03, -2.7760e-02, -4.3374e-03,  1.7261e-02, -2.0601e-02,
         -1.9357e-03, -1.5073e-02, -9.6997e-03, -1.1300e-02, -4.2982e-02,
          8.4574e-03, -3.8737e-02, -1.5231e-02, -2.3515e-02, -1.3568e-02,
          3.3063e-03, -3.3534e-02, -8.0107e-03, -3.6351e-02, -3.9080e-02,
         -8.1655e-03, -8.9546e-03,  4.9051e-03, -6.2526e-03, -4.5883e-02,
         -2.0797e-02, -3.6205e-02, -8.1598e-03, -2.8076e-02, -8.8447e-03,
         -1.9260e-02,  1.1396e-02,  1.5052e-02, -1.6075e-02, -1.5518e-02,
         -1.7724e-02,  2.0844e-02, -2.6688e-02, -3.4171e-02, -2.8748e-02,
          7.2581e-03, -1.6509e-02, -2.8037e-02, -2.2494e-02, -6.6422e-03,
         -3.8462e-02, -4.8222e-02, -4.5790e-02, -1.1145e-02,  4.5953e-02,
         -1.1314e-04,  1.1308e-03, -4.2939e-02, -2.3548e-02,  1.3748e-02,
          4.0744e-03,  8.6413e-03, -1.0417e-03, -5.3433e-02, -4.8686e-03,
          2.5878e-02, -1.2791e-02, -1.8810e-02, -1.7619e-02, -9.7876e-03,
         -2.5285e-02, -2.1384e-02,  1.4755e-02, -3.9157e-02,  1.8993e-02,
          5.0377e-03, -2.9328e-02, -1.6048e-02, -3.0006e-02, -2.8478e-02,
         -8.5162e-03, -1.2241e-02, -1.8590e-02, -2.9219e-03, -2.3340e-02,
         -2.1185e-02, -1.4722e-02, -1.4868e-02, -1.5969e-02, -2.2238e-02,
         -2.0746e-02,  9.0726e-03,  1.1734e-02, -3.8070e-02,  9.3740e-04,
         -3.4404e-02, -5.3068e-02,  7.4766e-03, -3.3690e-02, -2.3907e-02,
         -1.1922e-02, -3.2821e-02, -4.6094e-02,  4.7032e-04, -4.1886e-02,
         -5.7862e-03, -2.4299e-02, -2.8858e-02,  1.1723e-02, -3.0093e-02,
         -4.6471e-02, -4.9816e-03, -2.3448e-03, -2.2391e-02, -3.6809e-02,
         -3.7831e-02,  8.4370e-03, -4.2447e-02, -1.9412e-02, -3.9165e-02,
         -2.3906e-02,  7.2951e-03, -4.2961e-02,  8.2211e-03, -2.2970e-02,
         -1.4029e-02,  1.2471e-03,  3.8190e-02, -5.0079e-03, -4.4626e-02,
         -1.3463e-02, -1.6834e-02,  3.9899e-04, -1.4055e-02, -3.9695e-02,
         -3.6972e-02, -1.7081e-02, -3.0984e-02, -1.9453e-02, -1.2163e-05,
         -1.2716e-02, -9.5281e-03, -2.4193e-02, -3.0648e-02,  8.4034e-03,
         -9.2663e-03, -4.4070e-02, -2.4568e-02, -1.5319e-02, -5.6182e-03,
          6.3644e-03, -1.5009e-02,  1.2869e-02, -7.8058e-03,  5.4362e-03,
          2.2388e-03, -2.6862e-02, -1.5712e-03, -1.8940e-02,  1.3159e-02,
         -1.3461e-02, -3.9902e-02, -5.0591e-02, -1.7753e-02, -1.3713e-02,
          8.0693e-03, -3.5620e-02, -3.3676e-02, -1.3030e-02, -1.6888e-02,
         -2.5140e-02, -3.4833e-02, -7.2791e-03, -3.2956e-02, -2.4693e-02,
         -1.1791e-02, -1.2542e-02, -1.6742e-02, -4.3013e-02, -1.3429e-02,
          1.2613e-03, -4.0043e-02, -1.1774e-02, -3.2534e-02, -3.4204e-02,
          8.6550e-03, -8.3946e-03, -3.6755e-02, -3.3793e-02, -2.7884e-02,
         -7.4445e-03, -1.8833e-03,  1.2610e-02,  9.8851e-03,  1.2191e-02,
         -3.6666e-02, -8.5410e-02, -2.8082e-02, -3.0407e-02, -1.9044e-02,
          2.4342e-03, -1.4180e-03, -2.6470e-02, -2.5302e-02, -2.5253e-02,
         -1.1512e-02, -2.8345e-02, -1.5937e-02,  9.6349e-03, -1.0218e-02,
          1.3560e-02,  1.5391e-02, -1.9179e-02,  1.5864e-02, -1.0996e-02,
         -1.0817e-02,  2.6805e-03, -3.1092e-02, -3.8091e-02, -2.3368e-02,
         -5.9125e-02, -1.0858e-02,  4.5047e-03, -1.8238e-02, -2.1426e-02,
         -1.7773e-02, -2.9463e-02, -3.7479e-03, -4.9064e-03, -1.5818e-02,
         -2.5526e-02, -1.4419e-03, -1.1299e-02,  8.5140e-03, -1.0698e-02,
         -1.1708e-02, -2.0608e-02, -1.4593e-02, -7.7355e-03, -7.3931e-03,
         -4.0843e-02, -2.1167e-02, -1.2983e-02, -2.9919e-03,  3.0490e-03,
         -4.7598e-03, -7.2291e-02, -9.2503e-03, -3.9466e-02, -4.7297e-02,
         -2.1130e-02, -3.5272e-02,  2.0385e-02,  5.3947e-03, -2.0301e-02,
         -9.7881e-03, -1.9998e-02, -6.5725e-02, -4.3420e-02, -3.1609e-02,
         -1.8267e-04, -3.4371e-03, -9.8789e-04,  9.6274e-03, -5.9154e-03,
         -3.4675e-02, -6.5226e-02, -2.0677e-02, -4.1714e-02,  2.1622e-02,
          2.0240e-02, -9.2820e-03, -1.7129e-02, -3.2057e-02, -3.1468e-02,
         -3.4941e-02,  2.3813e-02, -1.6644e-02, -5.0642e-02, -1.6989e-02,
         -2.9996e-02, -2.5404e-02, -2.8092e-02, -4.2349e-02, -3.9435e-02,
         -4.4279e-02, -2.2080e-02,  3.3196e-03, -1.1349e-02,  6.9159e-03,
         -3.3969e-02, -5.3818e-02,  4.0196e-02, -3.8763e-02,  1.4048e-02,
          5.9220e-04, -2.6749e-02, -1.3595e-03, -4.5813e-02, -6.8420e-03,
         -3.4372e-02, -1.8214e-02,  4.0495e-03,  3.8787e-06, -1.8598e-02,
          9.7004e-03, -2.1482e-02, -1.9200e-02, -4.7962e-02, -3.4414e-02,
         -3.2698e-02, -2.5277e-02, -3.4527e-02,  1.4325e-02, -3.6852e-02,
          4.9736e-03, -4.6518e-02, -1.2696e-02, -4.6521e-02, -3.6610e-02,
         -2.4398e-02, -3.2662e-02, -2.5911e-03, -5.8092e-02,  2.9025e-02,
         -2.1087e-02, -1.7487e-02, -3.1389e-02, -4.2529e-02, -1.0128e-02,
         -1.7335e-02,  2.8430e-02,  3.9904e-02,  8.0061e-04, -3.1003e-02,
         -7.1200e-02, -2.8507e-03, -5.9049e-02, -1.5139e-02,  5.0690e-03,
         -1.6833e-02, -9.0752e-03, -2.3263e-02, -2.1165e-02, -4.3393e-02,
         -8.7630e-03, -1.3716e-02, -2.7933e-02, -4.8012e-02, -1.4200e-02,
         -5.1839e-02, -6.0081e-03, -1.8939e-02, -1.7114e-02, -4.1764e-02,
         -5.2397e-03, -5.4814e-03, -2.0793e-02, -4.0475e-02, -4.4624e-02,
         -7.9084e-03, -3.5071e-03,  2.0474e-02, -2.6987e-02, -1.4414e-02,
         -1.9035e-02, -4.9324e-02, -2.8345e-02,  1.4301e-02, -3.8973e-02,
         -1.2840e-02, -7.5258e-03, -4.6916e-02, -4.7070e-02, -1.3649e-02,
         -5.4320e-02, -1.8288e-03, -1.8652e-03, -2.7375e-02,  1.1466e-02,
         -4.0584e-02, -1.2032e-02, -3.9389e-02, -2.1145e-02,  2.4070e-03,
          9.3934e-03, -3.9291e-02, -5.9169e-02, -4.5224e-03, -1.4565e-02,
         -2.3315e-02, -3.0413e-02, -1.4424e-02, -1.6966e-02,  1.0072e-02,
          3.6617e-02, -3.9734e-02, -3.2399e-02, -1.3331e-02, -2.1236e-02,
          2.2823e-02, -1.9419e-02, -4.0604e-03, -1.3728e-02, -1.8695e-02,
         -2.6998e-02, -1.7203e-02, -6.4163e-03, -1.3199e-02, -5.5872e-02,
         -3.5325e-02, -3.1695e-02, -4.9119e-02,  4.0982e-02,  1.8657e-02,
         -3.3573e-02, -8.9048e-03,  1.6459e-02, -3.6141e-02, -3.5255e-02,
         -2.0351e-02,  3.6519e-02, -1.1686e-02,  2.1606e-02,  1.8557e-02,
         -4.5092e-03, -9.0398e-03,  2.1982e-02, -3.4125e-02,  1.8775e-02,
         -5.1349e-02, -2.0664e-03, -1.0744e-02, -1.6671e-02,  2.6162e-02,
         -6.4523e-03, -5.7046e-02, -3.6390e-03, -1.9814e-02, -1.6118e-02,
          6.7051e-03, -5.2483e-03,  8.4542e-04, -2.6400e-02, -6.1003e-03,
         -1.2574e-02, -3.9921e-02, -2.9327e-02, -2.4630e-02,  8.4810e-03,
         -7.4100e-04, -1.8916e-02,  5.1565e-03,  2.2242e-02, -9.2054e-03,
         -5.8127e-02, -1.7812e-03, -1.1566e-02, -1.5581e-02, -2.4738e-02,
         -8.5652e-03, -1.4644e-02, -1.7377e-02, -7.8154e-03,  8.7701e-03,
         -1.5758e-02, -2.9299e-02, -5.7990e-02,  5.2301e-03, -1.7015e-03,
         -1.0382e-02, -6.0044e-03, -2.6569e-02, -1.6470e-03,  1.8650e-03,
          1.0926e-02, -2.2354e-02,  1.7114e-02, -7.1626e-03, -4.9205e-02,
         -1.3529e-02,  2.1432e-02, -1.5802e-02, -2.3511e-02, -1.6134e-02,
         -3.9555e-02,  2.8150e-02, -9.2762e-03, -8.4562e-03, -2.7197e-02,
         -7.0721e-03, -4.0385e-03, -4.7109e-02, -5.2178e-03, -4.8849e-02,
          1.6391e-02, -3.0436e-02, -2.0354e-02, -1.7472e-02, -1.0822e-02,
         -3.9952e-02, -3.1226e-02, -5.1212e-02,  1.2849e-02, -4.3737e-02,
         -1.6600e-02, -1.7369e-02, -3.5132e-02, -7.9695e-03, -1.9029e-02,
         -2.9353e-02, -2.5525e-02, -1.2254e-02,  1.0975e-03, -4.0945e-02,
         -1.6960e-02, -4.7521e-03, -1.3975e-02, -1.2778e-02, -2.7528e-02,
         -3.3573e-02, -4.6857e-03, -4.8495e-03, -1.5761e-02, -1.7572e-02,
         -1.5772e-02, -7.3530e-03, -3.1005e-02, -1.7780e-02, -1.4125e-02,
         -2.0564e-02, -1.9258e-02, -1.5787e-02, -2.5870e-02,  8.4195e-03,
          1.2669e-02, -1.9583e-02, -1.6337e-02, -1.2081e-02,  7.1074e-03,
         -4.5319e-02, -2.1659e-02, -1.2411e-02, -2.7327e-02, -1.0128e-02,
         -3.7986e-02, -1.6327e-02, -5.8103e-03, -1.7206e-02, -1.4065e-02,
          2.7339e-02, -2.2147e-02, -3.9057e-02, -8.3084e-03, -2.7950e-02,
         -1.3844e-02, -1.8129e-02, -4.8987e-02,  1.5473e-02, -2.5392e-02,
         -3.8005e-02, -4.3275e-02, -1.0993e-02, -5.9326e-03, -6.6074e-02,
         -4.9379e-03, -2.7258e-02, -2.5302e-02, -3.8126e-02, -3.0043e-02,
         -8.6250e-03, -4.3281e-03, -5.0636e-02, -5.5711e-02, -2.7074e-02,
         -3.6164e-02, -1.2752e-02, -1.9970e-02, -2.1273e-02, -5.8114e-03,
         -6.4127e-02, -2.3056e-02,  2.3241e-03, -3.5551e-02, -1.8637e-02,
         -2.2455e-02, -3.8589e-02,  3.4994e-03, -5.7992e-03,  9.8726e-03,
         -4.2325e-02, -3.3603e-02,  9.3079e-03]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.4000% F1: 0.3026
Applying ckpt from fold 1 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.8000% F1: 0.2766
Applying ckpt from fold 2 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.4000% F1: 0.2698
Applying ckpt from fold 3 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.6000% F1: 0.2908
Applying ckpt from fold 4 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.8000% F1: 0.2908
Applying ckpt from fold 5 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.0000% F1: 0.3172
Applying ckpt from fold 6 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.0000% F1: 0.3151
Applying ckpt from fold 7 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.8000% F1: 0.2808
Applying ckpt from fold 8 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.2000% F1: 0.2482
Applying ckpt from fold 9 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.6000% F1: 0.2743
Metrics by fold:
Fold 0 - Acc: 0.52 F1: 0.30
Fold 1 - Acc: 0.53 F1: 0.28
Fold 2 - Acc: 0.54 F1: 0.27
Fold 3 - Acc: 0.55 F1: 0.29
Fold 4 - Acc: 0.48 F1: 0.29
Fold 5 - Acc: 0.52 F1: 0.32
Fold 6 - Acc: 0.50 F1: 0.32
Fold 7 - Acc: 0.53 F1: 0.28
Fold 8 - Acc: 0.54 F1: 0.25
Fold 9 - Acc: 0.53 F1: 0.27
agg_acc: 0.5236 agg_f1: 0.2866
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-1.9576e-02,  1.4462e-02,  2.1089e-02, -2.4213e-02, -3.1370e-02,
         -1.4199e-02, -2.5904e-02, -5.0341e-02, -3.6889e-02, -3.2728e-02,
         -6.8087e-04, -3.5233e-02, -3.9792e-02, -2.0962e-02, -7.1844e-03,
         -9.9852e-03, -2.8043e-02, -2.2781e-02, -4.4245e-03, -4.3463e-02,
         -4.1087e-02, -4.5657e-02, -1.9222e-02, -7.8390e-03, -2.0070e-02,
         -3.9880e-02,  1.8200e-02, -2.9268e-02, -1.6676e-02, -2.1610e-02,
         -2.6654e-02, -2.5254e-02,  9.2145e-03, -4.5557e-02, -3.3439e-02,
         -7.2401e-03, -2.6082e-02,  1.0227e-02, -1.4157e-02, -1.4822e-02,
         -4.3798e-02, -4.1658e-02, -1.4709e-02, -2.5902e-02, -8.7081e-03,
         -3.9880e-02, -1.5114e-02, -1.3367e-02, -3.1035e-02, -3.6392e-02,
          1.2227e-02, -8.7005e-03, -1.9950e-02, -1.3439e-02, -3.7631e-02,
         -3.0060e-02, -1.7583e-03, -4.8765e-02,  1.0541e-03, -1.3689e-02,
         -2.3786e-02,  8.0220e-03, -3.0173e-02, -2.5209e-02, -2.2526e-02,
         -1.9942e-02,  8.4238e-03, -1.9661e-02, -1.2119e-02, -3.4659e-03,
         -3.1803e-02, -3.2865e-03, -1.0539e-02, -3.9146e-03, -4.3804e-02,
          2.2994e-02,  1.2197e-02, -4.6647e-02, -3.5887e-02, -1.4468e-02,
         -3.3255e-03, -1.7044e-02,  2.0406e-02,  1.0396e-02, -2.0522e-02,
         -3.4509e-02, -4.8150e-02, -5.4708e-03,  3.8065e-02, -5.5523e-02,
          3.8816e-03, -6.3457e-02, -2.4241e-02, -9.3510e-03, -1.5897e-02,
         -8.8885e-03, -1.4690e-02, -5.4748e-03, -9.9003e-03, -7.0308e-03,
          3.4854e-03, -6.2360e-04,  1.0930e-02,  2.8643e-02, -1.1186e-02,
         -2.6669e-02, -1.9786e-02,  1.7164e-02, -1.3477e-02, -4.4371e-02,
         -1.4301e-02, -1.3759e-02, -4.0720e-02, -2.1774e-02,  1.6330e-02,
         -2.6441e-02, -4.0575e-02, -3.9297e-02, -9.2287e-03, -2.3262e-02,
         -5.1135e-03,  1.7898e-02,  1.0295e-02, -4.4888e-02, -1.1444e-02,
         -6.7636e-05,  3.0896e-02, -2.1793e-02, -2.7886e-02,  7.3077e-04,
         -7.0966e-03, -2.8983e-02, -2.4230e-02, -4.3455e-03, -3.6372e-02,
         -1.4622e-02, -1.9455e-02, -6.2994e-03, -4.8066e-02,  1.2134e-03,
         -2.6100e-02, -2.2397e-02, -4.3888e-02, -4.5778e-03, -4.2798e-02,
         -4.1344e-03, -4.0403e-02, -1.4517e-02, -7.4589e-03, -2.9797e-02,
         -4.2728e-02, -5.6681e-02, -7.0879e-03,  7.4267e-03,  2.2647e-02,
         -2.2768e-02,  7.6049e-04, -3.0197e-02, -5.4283e-03,  9.8245e-03,
         -1.2252e-03, -2.3723e-02,  3.4096e-02, -1.4257e-02, -3.2253e-02,
         -1.8886e-02, -5.4247e-03, -1.1375e-02, -9.0462e-03, -1.1843e-02,
          1.3237e-02, -2.4774e-02, -2.8040e-02, -3.8893e-02, -2.9173e-02,
         -3.3035e-02, -5.6146e-03, -2.8491e-02, -1.4185e-02, -1.6383e-02,
          1.3736e-03, -2.7760e-02, -4.3374e-03,  1.7261e-02, -2.0601e-02,
         -1.9357e-03, -1.5073e-02, -9.6997e-03, -1.1300e-02, -4.2982e-02,
          8.4574e-03, -3.8737e-02, -1.5231e-02, -2.3515e-02, -1.3568e-02,
          3.3063e-03, -3.3534e-02, -8.0107e-03, -3.6351e-02, -3.9080e-02,
         -8.1655e-03, -8.9546e-03,  4.9051e-03, -6.2526e-03, -4.5883e-02,
         -2.0797e-02, -3.6205e-02, -8.1598e-03, -2.8076e-02, -8.8447e-03,
         -1.9260e-02,  1.1396e-02,  1.5052e-02, -1.6075e-02, -1.5518e-02,
         -1.7724e-02,  2.0844e-02, -2.6688e-02, -3.4171e-02, -2.8748e-02,
          7.2581e-03, -1.6509e-02, -2.8037e-02, -2.2494e-02, -6.6422e-03,
         -3.8462e-02, -4.8222e-02, -4.5790e-02, -1.1145e-02,  4.5953e-02,
         -1.1314e-04,  1.1308e-03, -4.2939e-02, -2.3548e-02,  1.3748e-02,
          4.0744e-03,  8.6413e-03, -1.0417e-03, -5.3433e-02, -4.8686e-03,
          2.5878e-02, -1.2791e-02, -1.8810e-02, -1.7619e-02, -9.7876e-03,
         -2.5285e-02, -2.1384e-02,  1.4755e-02, -3.9157e-02,  1.8993e-02,
          5.0377e-03, -2.9328e-02, -1.6048e-02, -3.0006e-02, -2.8478e-02,
         -8.5162e-03, -1.2241e-02, -1.8590e-02, -2.9219e-03, -2.3340e-02,
         -2.1185e-02, -1.4722e-02, -1.4868e-02, -1.5969e-02, -2.2238e-02,
         -2.0746e-02,  9.0726e-03,  1.1734e-02, -3.8070e-02,  9.3740e-04,
         -3.4404e-02, -5.3068e-02,  7.4766e-03, -3.3690e-02, -2.3907e-02,
         -1.1922e-02, -3.2821e-02, -4.6094e-02,  4.7032e-04, -4.1886e-02,
         -5.7862e-03, -2.4299e-02, -2.8858e-02,  1.1723e-02, -3.0093e-02,
         -4.6471e-02, -4.9816e-03, -2.3448e-03, -2.2391e-02, -3.6809e-02,
         -3.7831e-02,  8.4370e-03, -4.2447e-02, -1.9412e-02, -3.9165e-02,
         -2.3906e-02,  7.2951e-03, -4.2961e-02,  8.2211e-03, -2.2970e-02,
         -1.4029e-02,  1.2471e-03,  3.8190e-02, -5.0079e-03, -4.4626e-02,
         -1.3463e-02, -1.6834e-02,  3.9899e-04, -1.4055e-02, -3.9695e-02,
         -3.6972e-02, -1.7081e-02, -3.0984e-02, -1.9453e-02, -1.2163e-05,
         -1.2716e-02, -9.5281e-03, -2.4193e-02, -3.0648e-02,  8.4034e-03,
         -9.2663e-03, -4.4070e-02, -2.4568e-02, -1.5319e-02, -5.6182e-03,
          6.3644e-03, -1.5009e-02,  1.2869e-02, -7.8058e-03,  5.4362e-03,
          2.2388e-03, -2.6862e-02, -1.5712e-03, -1.8940e-02,  1.3159e-02,
         -1.3461e-02, -3.9902e-02, -5.0591e-02, -1.7753e-02, -1.3713e-02,
          8.0693e-03, -3.5620e-02, -3.3676e-02, -1.3030e-02, -1.6888e-02,
         -2.5140e-02, -3.4833e-02, -7.2791e-03, -3.2956e-02, -2.4693e-02,
         -1.1791e-02, -1.2542e-02, -1.6742e-02, -4.3013e-02, -1.3429e-02,
          1.2613e-03, -4.0043e-02, -1.1774e-02, -3.2534e-02, -3.4204e-02,
          8.6550e-03, -8.3946e-03, -3.6755e-02, -3.3793e-02, -2.7884e-02,
         -7.4445e-03, -1.8833e-03,  1.2610e-02,  9.8851e-03,  1.2191e-02,
         -3.6666e-02, -8.5410e-02, -2.8082e-02, -3.0407e-02, -1.9044e-02,
          2.4342e-03, -1.4180e-03, -2.6470e-02, -2.5302e-02, -2.5253e-02,
         -1.1512e-02, -2.8345e-02, -1.5937e-02,  9.6349e-03, -1.0218e-02,
          1.3560e-02,  1.5391e-02, -1.9179e-02,  1.5864e-02, -1.0996e-02,
         -1.0817e-02,  2.6805e-03, -3.1092e-02, -3.8091e-02, -2.3368e-02,
         -5.9125e-02, -1.0858e-02,  4.5047e-03, -1.8238e-02, -2.1426e-02,
         -1.7773e-02, -2.9463e-02, -3.7479e-03, -4.9064e-03, -1.5818e-02,
         -2.5526e-02, -1.4419e-03, -1.1299e-02,  8.5140e-03, -1.0698e-02,
         -1.1708e-02, -2.0608e-02, -1.4593e-02, -7.7355e-03, -7.3931e-03,
         -4.0843e-02, -2.1167e-02, -1.2983e-02, -2.9919e-03,  3.0490e-03,
         -4.7598e-03, -7.2291e-02, -9.2503e-03, -3.9466e-02, -4.7297e-02,
         -2.1130e-02, -3.5272e-02,  2.0385e-02,  5.3947e-03, -2.0301e-02,
         -9.7881e-03, -1.9998e-02, -6.5725e-02, -4.3420e-02, -3.1609e-02,
         -1.8267e-04, -3.4371e-03, -9.8789e-04,  9.6274e-03, -5.9154e-03,
         -3.4675e-02, -6.5226e-02, -2.0677e-02, -4.1714e-02,  2.1622e-02,
          2.0240e-02, -9.2820e-03, -1.7129e-02, -3.2057e-02, -3.1468e-02,
         -3.4941e-02,  2.3813e-02, -1.6644e-02, -5.0642e-02, -1.6989e-02,
         -2.9996e-02, -2.5404e-02, -2.8092e-02, -4.2349e-02, -3.9435e-02,
         -4.4279e-02, -2.2080e-02,  3.3196e-03, -1.1349e-02,  6.9159e-03,
         -3.3969e-02, -5.3818e-02,  4.0196e-02, -3.8763e-02,  1.4048e-02,
          5.9220e-04, -2.6749e-02, -1.3595e-03, -4.5813e-02, -6.8420e-03,
         -3.4372e-02, -1.8214e-02,  4.0495e-03,  3.8787e-06, -1.8598e-02,
          9.7004e-03, -2.1482e-02, -1.9200e-02, -4.7962e-02, -3.4414e-02,
         -3.2698e-02, -2.5277e-02, -3.4527e-02,  1.4325e-02, -3.6852e-02,
          4.9736e-03, -4.6518e-02, -1.2696e-02, -4.6521e-02, -3.6610e-02,
         -2.4398e-02, -3.2662e-02, -2.5911e-03, -5.8092e-02,  2.9025e-02,
         -2.1087e-02, -1.7487e-02, -3.1389e-02, -4.2529e-02, -1.0128e-02,
         -1.7335e-02,  2.8430e-02,  3.9904e-02,  8.0061e-04, -3.1003e-02,
         -7.1200e-02, -2.8507e-03, -5.9049e-02, -1.5139e-02,  5.0690e-03,
         -1.6833e-02, -9.0752e-03, -2.3263e-02, -2.1165e-02, -4.3393e-02,
         -8.7630e-03, -1.3716e-02, -2.7933e-02, -4.8012e-02, -1.4200e-02,
         -5.1839e-02, -6.0081e-03, -1.8939e-02, -1.7114e-02, -4.1764e-02,
         -5.2397e-03, -5.4814e-03, -2.0793e-02, -4.0475e-02, -4.4624e-02,
         -7.9084e-03, -3.5071e-03,  2.0474e-02, -2.6987e-02, -1.4414e-02,
         -1.9035e-02, -4.9324e-02, -2.8345e-02,  1.4301e-02, -3.8973e-02,
         -1.2840e-02, -7.5258e-03, -4.6916e-02, -4.7070e-02, -1.3649e-02,
         -5.4320e-02, -1.8288e-03, -1.8652e-03, -2.7375e-02,  1.1466e-02,
         -4.0584e-02, -1.2032e-02, -3.9389e-02, -2.1145e-02,  2.4070e-03,
          9.3934e-03, -3.9291e-02, -5.9169e-02, -4.5224e-03, -1.4565e-02,
         -2.3315e-02, -3.0413e-02, -1.4424e-02, -1.6966e-02,  1.0072e-02,
          3.6617e-02, -3.9734e-02, -3.2399e-02, -1.3331e-02, -2.1236e-02,
          2.2823e-02, -1.9419e-02, -4.0604e-03, -1.3728e-02, -1.8695e-02,
         -2.6998e-02, -1.7203e-02, -6.4163e-03, -1.3199e-02, -5.5872e-02,
         -3.5325e-02, -3.1695e-02, -4.9119e-02,  4.0982e-02,  1.8657e-02,
         -3.3573e-02, -8.9048e-03,  1.6459e-02, -3.6141e-02, -3.5255e-02,
         -2.0351e-02,  3.6519e-02, -1.1686e-02,  2.1606e-02,  1.8557e-02,
         -4.5092e-03, -9.0398e-03,  2.1982e-02, -3.4125e-02,  1.8775e-02,
         -5.1349e-02, -2.0664e-03, -1.0744e-02, -1.6671e-02,  2.6162e-02,
         -6.4523e-03, -5.7046e-02, -3.6390e-03, -1.9814e-02, -1.6118e-02,
          6.7051e-03, -5.2483e-03,  8.4542e-04, -2.6400e-02, -6.1003e-03,
         -1.2574e-02, -3.9921e-02, -2.9327e-02, -2.4630e-02,  8.4810e-03,
         -7.4100e-04, -1.8916e-02,  5.1565e-03,  2.2242e-02, -9.2054e-03,
         -5.8127e-02, -1.7812e-03, -1.1566e-02, -1.5581e-02, -2.4738e-02,
         -8.5652e-03, -1.4644e-02, -1.7377e-02, -7.8154e-03,  8.7701e-03,
         -1.5758e-02, -2.9299e-02, -5.7990e-02,  5.2301e-03, -1.7015e-03,
         -1.0382e-02, -6.0044e-03, -2.6569e-02, -1.6470e-03,  1.8650e-03,
          1.0926e-02, -2.2354e-02,  1.7114e-02, -7.1626e-03, -4.9205e-02,
         -1.3529e-02,  2.1432e-02, -1.5802e-02, -2.3511e-02, -1.6134e-02,
         -3.9555e-02,  2.8150e-02, -9.2762e-03, -8.4562e-03, -2.7197e-02,
         -7.0721e-03, -4.0385e-03, -4.7109e-02, -5.2178e-03, -4.8849e-02,
          1.6391e-02, -3.0436e-02, -2.0354e-02, -1.7472e-02, -1.0822e-02,
         -3.9952e-02, -3.1226e-02, -5.1212e-02,  1.2849e-02, -4.3737e-02,
         -1.6600e-02, -1.7369e-02, -3.5132e-02, -7.9695e-03, -1.9029e-02,
         -2.9353e-02, -2.5525e-02, -1.2254e-02,  1.0975e-03, -4.0945e-02,
         -1.6960e-02, -4.7521e-03, -1.3975e-02, -1.2778e-02, -2.7528e-02,
         -3.3573e-02, -4.6857e-03, -4.8495e-03, -1.5761e-02, -1.7572e-02,
         -1.5772e-02, -7.3530e-03, -3.1005e-02, -1.7780e-02, -1.4125e-02,
         -2.0564e-02, -1.9258e-02, -1.5787e-02, -2.5870e-02,  8.4195e-03,
          1.2669e-02, -1.9583e-02, -1.6337e-02, -1.2081e-02,  7.1074e-03,
         -4.5319e-02, -2.1659e-02, -1.2411e-02, -2.7327e-02, -1.0128e-02,
         -3.7986e-02, -1.6327e-02, -5.8103e-03, -1.7206e-02, -1.4065e-02,
          2.7339e-02, -2.2147e-02, -3.9057e-02, -8.3084e-03, -2.7950e-02,
         -1.3844e-02, -1.8129e-02, -4.8987e-02,  1.5473e-02, -2.5392e-02,
         -3.8005e-02, -4.3275e-02, -1.0993e-02, -5.9326e-03, -6.6074e-02,
         -4.9379e-03, -2.7258e-02, -2.5302e-02, -3.8126e-02, -3.0043e-02,
         -8.6250e-03, -4.3281e-03, -5.0636e-02, -5.5711e-02, -2.7074e-02,
         -3.6164e-02, -1.2752e-02, -1.9970e-02, -2.1273e-02, -5.8114e-03,
         -6.4127e-02, -2.3056e-02,  2.3241e-03, -3.5551e-02, -1.8637e-02,
         -2.2455e-02, -3.8589e-02,  3.4994e-03, -5.7992e-03,  9.8726e-03,
         -4.2325e-02, -3.3603e-02,  9.3079e-03]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 39.6000% F1: 0.3146
Applying ckpt from fold 1 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.8000% F1: 0.3232
Applying ckpt from fold 2 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.8000% F1: 0.3208
Applying ckpt from fold 3 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.4000% F1: 0.3344
Applying ckpt from fold 4 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 43.8000% F1: 0.3050
Applying ckpt from fold 5 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.4000% F1: 0.3434
Applying ckpt from fold 6 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 41.4000% F1: 0.3218
Applying ckpt from fold 7 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.2000% F1: 0.3357
Applying ckpt from fold 8 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.4000% F1: 0.3428
Applying ckpt from fold 9 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.4000% F1: 0.3222
Metrics by fold:
Fold 0 - Acc: 0.40 F1: 0.31
Fold 1 - Acc: 0.51 F1: 0.32
Fold 2 - Acc: 0.51 F1: 0.32
Fold 3 - Acc: 0.49 F1: 0.33
Fold 4 - Acc: 0.44 F1: 0.31
Fold 5 - Acc: 0.47 F1: 0.34
Fold 6 - Acc: 0.41 F1: 0.32
Fold 7 - Acc: 0.49 F1: 0.34
Fold 8 - Acc: 0.52 F1: 0.34
Fold 9 - Acc: 0.47 F1: 0.32
agg_acc: 0.4722 agg_f1: 0.3264
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-1.9576e-02,  1.4462e-02,  2.1089e-02, -2.4213e-02, -3.1370e-02,
         -1.4199e-02, -2.5904e-02, -5.0341e-02, -3.6889e-02, -3.2728e-02,
         -6.8087e-04, -3.5233e-02, -3.9792e-02, -2.0962e-02, -7.1844e-03,
         -9.9852e-03, -2.8043e-02, -2.2781e-02, -4.4245e-03, -4.3463e-02,
         -4.1087e-02, -4.5657e-02, -1.9222e-02, -7.8390e-03, -2.0070e-02,
         -3.9880e-02,  1.8200e-02, -2.9268e-02, -1.6676e-02, -2.1610e-02,
         -2.6654e-02, -2.5254e-02,  9.2145e-03, -4.5557e-02, -3.3439e-02,
         -7.2401e-03, -2.6082e-02,  1.0227e-02, -1.4157e-02, -1.4822e-02,
         -4.3798e-02, -4.1658e-02, -1.4709e-02, -2.5902e-02, -8.7081e-03,
         -3.9880e-02, -1.5114e-02, -1.3367e-02, -3.1035e-02, -3.6392e-02,
          1.2227e-02, -8.7005e-03, -1.9950e-02, -1.3439e-02, -3.7631e-02,
         -3.0060e-02, -1.7583e-03, -4.8765e-02,  1.0541e-03, -1.3689e-02,
         -2.3786e-02,  8.0220e-03, -3.0173e-02, -2.5209e-02, -2.2526e-02,
         -1.9942e-02,  8.4238e-03, -1.9661e-02, -1.2119e-02, -3.4659e-03,
         -3.1803e-02, -3.2865e-03, -1.0539e-02, -3.9146e-03, -4.3804e-02,
          2.2994e-02,  1.2197e-02, -4.6647e-02, -3.5887e-02, -1.4468e-02,
         -3.3255e-03, -1.7044e-02,  2.0406e-02,  1.0396e-02, -2.0522e-02,
         -3.4509e-02, -4.8150e-02, -5.4708e-03,  3.8065e-02, -5.5523e-02,
          3.8816e-03, -6.3457e-02, -2.4241e-02, -9.3510e-03, -1.5897e-02,
         -8.8885e-03, -1.4690e-02, -5.4748e-03, -9.9003e-03, -7.0308e-03,
          3.4854e-03, -6.2360e-04,  1.0930e-02,  2.8643e-02, -1.1186e-02,
         -2.6669e-02, -1.9786e-02,  1.7164e-02, -1.3477e-02, -4.4371e-02,
         -1.4301e-02, -1.3759e-02, -4.0720e-02, -2.1774e-02,  1.6330e-02,
         -2.6441e-02, -4.0575e-02, -3.9297e-02, -9.2287e-03, -2.3262e-02,
         -5.1135e-03,  1.7898e-02,  1.0295e-02, -4.4888e-02, -1.1444e-02,
         -6.7636e-05,  3.0896e-02, -2.1793e-02, -2.7886e-02,  7.3077e-04,
         -7.0966e-03, -2.8983e-02, -2.4230e-02, -4.3455e-03, -3.6372e-02,
         -1.4622e-02, -1.9455e-02, -6.2994e-03, -4.8066e-02,  1.2134e-03,
         -2.6100e-02, -2.2397e-02, -4.3888e-02, -4.5778e-03, -4.2798e-02,
         -4.1344e-03, -4.0403e-02, -1.4517e-02, -7.4589e-03, -2.9797e-02,
         -4.2728e-02, -5.6681e-02, -7.0879e-03,  7.4267e-03,  2.2647e-02,
         -2.2768e-02,  7.6049e-04, -3.0197e-02, -5.4283e-03,  9.8245e-03,
         -1.2252e-03, -2.3723e-02,  3.4096e-02, -1.4257e-02, -3.2253e-02,
         -1.8886e-02, -5.4247e-03, -1.1375e-02, -9.0462e-03, -1.1843e-02,
          1.3237e-02, -2.4774e-02, -2.8040e-02, -3.8893e-02, -2.9173e-02,
         -3.3035e-02, -5.6146e-03, -2.8491e-02, -1.4185e-02, -1.6383e-02,
          1.3736e-03, -2.7760e-02, -4.3374e-03,  1.7261e-02, -2.0601e-02,
         -1.9357e-03, -1.5073e-02, -9.6997e-03, -1.1300e-02, -4.2982e-02,
          8.4574e-03, -3.8737e-02, -1.5231e-02, -2.3515e-02, -1.3568e-02,
          3.3063e-03, -3.3534e-02, -8.0107e-03, -3.6351e-02, -3.9080e-02,
         -8.1655e-03, -8.9546e-03,  4.9051e-03, -6.2526e-03, -4.5883e-02,
         -2.0797e-02, -3.6205e-02, -8.1598e-03, -2.8076e-02, -8.8447e-03,
         -1.9260e-02,  1.1396e-02,  1.5052e-02, -1.6075e-02, -1.5518e-02,
         -1.7724e-02,  2.0844e-02, -2.6688e-02, -3.4171e-02, -2.8748e-02,
          7.2581e-03, -1.6509e-02, -2.8037e-02, -2.2494e-02, -6.6422e-03,
         -3.8462e-02, -4.8222e-02, -4.5790e-02, -1.1145e-02,  4.5953e-02,
         -1.1314e-04,  1.1308e-03, -4.2939e-02, -2.3548e-02,  1.3748e-02,
          4.0744e-03,  8.6413e-03, -1.0417e-03, -5.3433e-02, -4.8686e-03,
          2.5878e-02, -1.2791e-02, -1.8810e-02, -1.7619e-02, -9.7876e-03,
         -2.5285e-02, -2.1384e-02,  1.4755e-02, -3.9157e-02,  1.8993e-02,
          5.0377e-03, -2.9328e-02, -1.6048e-02, -3.0006e-02, -2.8478e-02,
         -8.5162e-03, -1.2241e-02, -1.8590e-02, -2.9219e-03, -2.3340e-02,
         -2.1185e-02, -1.4722e-02, -1.4868e-02, -1.5969e-02, -2.2238e-02,
         -2.0746e-02,  9.0726e-03,  1.1734e-02, -3.8070e-02,  9.3740e-04,
         -3.4404e-02, -5.3068e-02,  7.4766e-03, -3.3690e-02, -2.3907e-02,
         -1.1922e-02, -3.2821e-02, -4.6094e-02,  4.7032e-04, -4.1886e-02,
         -5.7862e-03, -2.4299e-02, -2.8858e-02,  1.1723e-02, -3.0093e-02,
         -4.6471e-02, -4.9816e-03, -2.3448e-03, -2.2391e-02, -3.6809e-02,
         -3.7831e-02,  8.4370e-03, -4.2447e-02, -1.9412e-02, -3.9165e-02,
         -2.3906e-02,  7.2951e-03, -4.2961e-02,  8.2211e-03, -2.2970e-02,
         -1.4029e-02,  1.2471e-03,  3.8190e-02, -5.0079e-03, -4.4626e-02,
         -1.3463e-02, -1.6834e-02,  3.9899e-04, -1.4055e-02, -3.9695e-02,
         -3.6972e-02, -1.7081e-02, -3.0984e-02, -1.9453e-02, -1.2163e-05,
         -1.2716e-02, -9.5281e-03, -2.4193e-02, -3.0648e-02,  8.4034e-03,
         -9.2663e-03, -4.4070e-02, -2.4568e-02, -1.5319e-02, -5.6182e-03,
          6.3644e-03, -1.5009e-02,  1.2869e-02, -7.8058e-03,  5.4362e-03,
          2.2388e-03, -2.6862e-02, -1.5712e-03, -1.8940e-02,  1.3159e-02,
         -1.3461e-02, -3.9902e-02, -5.0591e-02, -1.7753e-02, -1.3713e-02,
          8.0693e-03, -3.5620e-02, -3.3676e-02, -1.3030e-02, -1.6888e-02,
         -2.5140e-02, -3.4833e-02, -7.2791e-03, -3.2956e-02, -2.4693e-02,
         -1.1791e-02, -1.2542e-02, -1.6742e-02, -4.3013e-02, -1.3429e-02,
          1.2613e-03, -4.0043e-02, -1.1774e-02, -3.2534e-02, -3.4204e-02,
          8.6550e-03, -8.3946e-03, -3.6755e-02, -3.3793e-02, -2.7884e-02,
         -7.4445e-03, -1.8833e-03,  1.2610e-02,  9.8851e-03,  1.2191e-02,
         -3.6666e-02, -8.5410e-02, -2.8082e-02, -3.0407e-02, -1.9044e-02,
          2.4342e-03, -1.4180e-03, -2.6470e-02, -2.5302e-02, -2.5253e-02,
         -1.1512e-02, -2.8345e-02, -1.5937e-02,  9.6349e-03, -1.0218e-02,
          1.3560e-02,  1.5391e-02, -1.9179e-02,  1.5864e-02, -1.0996e-02,
         -1.0817e-02,  2.6805e-03, -3.1092e-02, -3.8091e-02, -2.3368e-02,
         -5.9125e-02, -1.0858e-02,  4.5047e-03, -1.8238e-02, -2.1426e-02,
         -1.7773e-02, -2.9463e-02, -3.7479e-03, -4.9064e-03, -1.5818e-02,
         -2.5526e-02, -1.4419e-03, -1.1299e-02,  8.5140e-03, -1.0698e-02,
         -1.1708e-02, -2.0608e-02, -1.4593e-02, -7.7355e-03, -7.3931e-03,
         -4.0843e-02, -2.1167e-02, -1.2983e-02, -2.9919e-03,  3.0490e-03,
         -4.7598e-03, -7.2291e-02, -9.2503e-03, -3.9466e-02, -4.7297e-02,
         -2.1130e-02, -3.5272e-02,  2.0385e-02,  5.3947e-03, -2.0301e-02,
         -9.7881e-03, -1.9998e-02, -6.5725e-02, -4.3420e-02, -3.1609e-02,
         -1.8267e-04, -3.4371e-03, -9.8789e-04,  9.6274e-03, -5.9154e-03,
         -3.4675e-02, -6.5226e-02, -2.0677e-02, -4.1714e-02,  2.1622e-02,
          2.0240e-02, -9.2820e-03, -1.7129e-02, -3.2057e-02, -3.1468e-02,
         -3.4941e-02,  2.3813e-02, -1.6644e-02, -5.0642e-02, -1.6989e-02,
         -2.9996e-02, -2.5404e-02, -2.8092e-02, -4.2349e-02, -3.9435e-02,
         -4.4279e-02, -2.2080e-02,  3.3196e-03, -1.1349e-02,  6.9159e-03,
         -3.3969e-02, -5.3818e-02,  4.0196e-02, -3.8763e-02,  1.4048e-02,
          5.9220e-04, -2.6749e-02, -1.3595e-03, -4.5813e-02, -6.8420e-03,
         -3.4372e-02, -1.8214e-02,  4.0495e-03,  3.8787e-06, -1.8598e-02,
          9.7004e-03, -2.1482e-02, -1.9200e-02, -4.7962e-02, -3.4414e-02,
         -3.2698e-02, -2.5277e-02, -3.4527e-02,  1.4325e-02, -3.6852e-02,
          4.9736e-03, -4.6518e-02, -1.2696e-02, -4.6521e-02, -3.6610e-02,
         -2.4398e-02, -3.2662e-02, -2.5911e-03, -5.8092e-02,  2.9025e-02,
         -2.1087e-02, -1.7487e-02, -3.1389e-02, -4.2529e-02, -1.0128e-02,
         -1.7335e-02,  2.8430e-02,  3.9904e-02,  8.0061e-04, -3.1003e-02,
         -7.1200e-02, -2.8507e-03, -5.9049e-02, -1.5139e-02,  5.0690e-03,
         -1.6833e-02, -9.0752e-03, -2.3263e-02, -2.1165e-02, -4.3393e-02,
         -8.7630e-03, -1.3716e-02, -2.7933e-02, -4.8012e-02, -1.4200e-02,
         -5.1839e-02, -6.0081e-03, -1.8939e-02, -1.7114e-02, -4.1764e-02,
         -5.2397e-03, -5.4814e-03, -2.0793e-02, -4.0475e-02, -4.4624e-02,
         -7.9084e-03, -3.5071e-03,  2.0474e-02, -2.6987e-02, -1.4414e-02,
         -1.9035e-02, -4.9324e-02, -2.8345e-02,  1.4301e-02, -3.8973e-02,
         -1.2840e-02, -7.5258e-03, -4.6916e-02, -4.7070e-02, -1.3649e-02,
         -5.4320e-02, -1.8288e-03, -1.8652e-03, -2.7375e-02,  1.1466e-02,
         -4.0584e-02, -1.2032e-02, -3.9389e-02, -2.1145e-02,  2.4070e-03,
          9.3934e-03, -3.9291e-02, -5.9169e-02, -4.5224e-03, -1.4565e-02,
         -2.3315e-02, -3.0413e-02, -1.4424e-02, -1.6966e-02,  1.0072e-02,
          3.6617e-02, -3.9734e-02, -3.2399e-02, -1.3331e-02, -2.1236e-02,
          2.2823e-02, -1.9419e-02, -4.0604e-03, -1.3728e-02, -1.8695e-02,
         -2.6998e-02, -1.7203e-02, -6.4163e-03, -1.3199e-02, -5.5872e-02,
         -3.5325e-02, -3.1695e-02, -4.9119e-02,  4.0982e-02,  1.8657e-02,
         -3.3573e-02, -8.9048e-03,  1.6459e-02, -3.6141e-02, -3.5255e-02,
         -2.0351e-02,  3.6519e-02, -1.1686e-02,  2.1606e-02,  1.8557e-02,
         -4.5092e-03, -9.0398e-03,  2.1982e-02, -3.4125e-02,  1.8775e-02,
         -5.1349e-02, -2.0664e-03, -1.0744e-02, -1.6671e-02,  2.6162e-02,
         -6.4523e-03, -5.7046e-02, -3.6390e-03, -1.9814e-02, -1.6118e-02,
          6.7051e-03, -5.2483e-03,  8.4542e-04, -2.6400e-02, -6.1003e-03,
         -1.2574e-02, -3.9921e-02, -2.9327e-02, -2.4630e-02,  8.4810e-03,
         -7.4100e-04, -1.8916e-02,  5.1565e-03,  2.2242e-02, -9.2054e-03,
         -5.8127e-02, -1.7812e-03, -1.1566e-02, -1.5581e-02, -2.4738e-02,
         -8.5652e-03, -1.4644e-02, -1.7377e-02, -7.8154e-03,  8.7701e-03,
         -1.5758e-02, -2.9299e-02, -5.7990e-02,  5.2301e-03, -1.7015e-03,
         -1.0382e-02, -6.0044e-03, -2.6569e-02, -1.6470e-03,  1.8650e-03,
          1.0926e-02, -2.2354e-02,  1.7114e-02, -7.1626e-03, -4.9205e-02,
         -1.3529e-02,  2.1432e-02, -1.5802e-02, -2.3511e-02, -1.6134e-02,
         -3.9555e-02,  2.8150e-02, -9.2762e-03, -8.4562e-03, -2.7197e-02,
         -7.0721e-03, -4.0385e-03, -4.7109e-02, -5.2178e-03, -4.8849e-02,
          1.6391e-02, -3.0436e-02, -2.0354e-02, -1.7472e-02, -1.0822e-02,
         -3.9952e-02, -3.1226e-02, -5.1212e-02,  1.2849e-02, -4.3737e-02,
         -1.6600e-02, -1.7369e-02, -3.5132e-02, -7.9695e-03, -1.9029e-02,
         -2.9353e-02, -2.5525e-02, -1.2254e-02,  1.0975e-03, -4.0945e-02,
         -1.6960e-02, -4.7521e-03, -1.3975e-02, -1.2778e-02, -2.7528e-02,
         -3.3573e-02, -4.6857e-03, -4.8495e-03, -1.5761e-02, -1.7572e-02,
         -1.5772e-02, -7.3530e-03, -3.1005e-02, -1.7780e-02, -1.4125e-02,
         -2.0564e-02, -1.9258e-02, -1.5787e-02, -2.5870e-02,  8.4195e-03,
          1.2669e-02, -1.9583e-02, -1.6337e-02, -1.2081e-02,  7.1074e-03,
         -4.5319e-02, -2.1659e-02, -1.2411e-02, -2.7327e-02, -1.0128e-02,
         -3.7986e-02, -1.6327e-02, -5.8103e-03, -1.7206e-02, -1.4065e-02,
          2.7339e-02, -2.2147e-02, -3.9057e-02, -8.3084e-03, -2.7950e-02,
         -1.3844e-02, -1.8129e-02, -4.8987e-02,  1.5473e-02, -2.5392e-02,
         -3.8005e-02, -4.3275e-02, -1.0993e-02, -5.9326e-03, -6.6074e-02,
         -4.9379e-03, -2.7258e-02, -2.5302e-02, -3.8126e-02, -3.0043e-02,
         -8.6250e-03, -4.3281e-03, -5.0636e-02, -5.5711e-02, -2.7074e-02,
         -3.6164e-02, -1.2752e-02, -1.9970e-02, -2.1273e-02, -5.8114e-03,
         -6.4127e-02, -2.3056e-02,  2.3241e-03, -3.5551e-02, -1.8637e-02,
         -2.2455e-02, -3.8589e-02,  3.4994e-03, -5.7992e-03,  9.8726e-03,
         -4.2325e-02, -3.3603e-02,  9.3079e-03]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 44.8000% F1: 0.3263
Applying ckpt from fold 1 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.6000% F1: 0.3351
Applying ckpt from fold 2 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.0000% F1: 0.3327
Applying ckpt from fold 3 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 46.2000% F1: 0.3453
Applying ckpt from fold 4 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 41.0000% F1: 0.3125
Applying ckpt from fold 5 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.2000% F1: 0.3455
Applying ckpt from fold 6 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 39.8000% F1: 0.3191
Applying ckpt from fold 7 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.6000% F1: 0.2896
Applying ckpt from fold 8 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.4000% F1: 0.3345
Applying ckpt from fold 9 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 43.8000% F1: 0.3298
Metrics by fold:
Fold 0 - Acc: 0.45 F1: 0.33
Fold 1 - Acc: 0.48 F1: 0.34
Fold 2 - Acc: 0.48 F1: 0.33
Fold 3 - Acc: 0.46 F1: 0.35
Fold 4 - Acc: 0.41 F1: 0.31
Fold 5 - Acc: 0.48 F1: 0.35
Fold 6 - Acc: 0.40 F1: 0.32
Fold 7 - Acc: 0.49 F1: 0.29
Fold 8 - Acc: 0.52 F1: 0.33
Fold 9 - Acc: 0.44 F1: 0.33
agg_acc: 0.4604 agg_f1: 0.3271
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-1.9576e-02,  1.4462e-02,  2.1089e-02, -2.4213e-02, -3.1370e-02,
         -1.4199e-02, -2.5904e-02, -5.0341e-02, -3.6889e-02, -3.2728e-02,
         -6.8087e-04, -3.5233e-02, -3.9792e-02, -2.0962e-02, -7.1844e-03,
         -9.9852e-03, -2.8043e-02, -2.2781e-02, -4.4245e-03, -4.3463e-02,
         -4.1087e-02, -4.5657e-02, -1.9222e-02, -7.8390e-03, -2.0070e-02,
         -3.9880e-02,  1.8200e-02, -2.9268e-02, -1.6676e-02, -2.1610e-02,
         -2.6654e-02, -2.5254e-02,  9.2145e-03, -4.5557e-02, -3.3439e-02,
         -7.2401e-03, -2.6082e-02,  1.0227e-02, -1.4157e-02, -1.4822e-02,
         -4.3798e-02, -4.1658e-02, -1.4709e-02, -2.5902e-02, -8.7081e-03,
         -3.9880e-02, -1.5114e-02, -1.3367e-02, -3.1035e-02, -3.6392e-02,
          1.2227e-02, -8.7005e-03, -1.9950e-02, -1.3439e-02, -3.7631e-02,
         -3.0060e-02, -1.7583e-03, -4.8765e-02,  1.0541e-03, -1.3689e-02,
         -2.3786e-02,  8.0220e-03, -3.0173e-02, -2.5209e-02, -2.2526e-02,
         -1.9942e-02,  8.4238e-03, -1.9661e-02, -1.2119e-02, -3.4659e-03,
         -3.1803e-02, -3.2865e-03, -1.0539e-02, -3.9146e-03, -4.3804e-02,
          2.2994e-02,  1.2197e-02, -4.6647e-02, -3.5887e-02, -1.4468e-02,
         -3.3255e-03, -1.7044e-02,  2.0406e-02,  1.0396e-02, -2.0522e-02,
         -3.4509e-02, -4.8150e-02, -5.4708e-03,  3.8065e-02, -5.5523e-02,
          3.8816e-03, -6.3457e-02, -2.4241e-02, -9.3510e-03, -1.5897e-02,
         -8.8885e-03, -1.4690e-02, -5.4748e-03, -9.9003e-03, -7.0308e-03,
          3.4854e-03, -6.2360e-04,  1.0930e-02,  2.8643e-02, -1.1186e-02,
         -2.6669e-02, -1.9786e-02,  1.7164e-02, -1.3477e-02, -4.4371e-02,
         -1.4301e-02, -1.3759e-02, -4.0720e-02, -2.1774e-02,  1.6330e-02,
         -2.6441e-02, -4.0575e-02, -3.9297e-02, -9.2287e-03, -2.3262e-02,
         -5.1135e-03,  1.7898e-02,  1.0295e-02, -4.4888e-02, -1.1444e-02,
         -6.7636e-05,  3.0896e-02, -2.1793e-02, -2.7886e-02,  7.3077e-04,
         -7.0966e-03, -2.8983e-02, -2.4230e-02, -4.3455e-03, -3.6372e-02,
         -1.4622e-02, -1.9455e-02, -6.2994e-03, -4.8066e-02,  1.2134e-03,
         -2.6100e-02, -2.2397e-02, -4.3888e-02, -4.5778e-03, -4.2798e-02,
         -4.1344e-03, -4.0403e-02, -1.4517e-02, -7.4589e-03, -2.9797e-02,
         -4.2728e-02, -5.6681e-02, -7.0879e-03,  7.4267e-03,  2.2647e-02,
         -2.2768e-02,  7.6049e-04, -3.0197e-02, -5.4283e-03,  9.8245e-03,
         -1.2252e-03, -2.3723e-02,  3.4096e-02, -1.4257e-02, -3.2253e-02,
         -1.8886e-02, -5.4247e-03, -1.1375e-02, -9.0462e-03, -1.1843e-02,
          1.3237e-02, -2.4774e-02, -2.8040e-02, -3.8893e-02, -2.9173e-02,
         -3.3035e-02, -5.6146e-03, -2.8491e-02, -1.4185e-02, -1.6383e-02,
          1.3736e-03, -2.7760e-02, -4.3374e-03,  1.7261e-02, -2.0601e-02,
         -1.9357e-03, -1.5073e-02, -9.6997e-03, -1.1300e-02, -4.2982e-02,
          8.4574e-03, -3.8737e-02, -1.5231e-02, -2.3515e-02, -1.3568e-02,
          3.3063e-03, -3.3534e-02, -8.0107e-03, -3.6351e-02, -3.9080e-02,
         -8.1655e-03, -8.9546e-03,  4.9051e-03, -6.2526e-03, -4.5883e-02,
         -2.0797e-02, -3.6205e-02, -8.1598e-03, -2.8076e-02, -8.8447e-03,
         -1.9260e-02,  1.1396e-02,  1.5052e-02, -1.6075e-02, -1.5518e-02,
         -1.7724e-02,  2.0844e-02, -2.6688e-02, -3.4171e-02, -2.8748e-02,
          7.2581e-03, -1.6509e-02, -2.8037e-02, -2.2494e-02, -6.6422e-03,
         -3.8462e-02, -4.8222e-02, -4.5790e-02, -1.1145e-02,  4.5953e-02,
         -1.1314e-04,  1.1308e-03, -4.2939e-02, -2.3548e-02,  1.3748e-02,
          4.0744e-03,  8.6413e-03, -1.0417e-03, -5.3433e-02, -4.8686e-03,
          2.5878e-02, -1.2791e-02, -1.8810e-02, -1.7619e-02, -9.7876e-03,
         -2.5285e-02, -2.1384e-02,  1.4755e-02, -3.9157e-02,  1.8993e-02,
          5.0377e-03, -2.9328e-02, -1.6048e-02, -3.0006e-02, -2.8478e-02,
         -8.5162e-03, -1.2241e-02, -1.8590e-02, -2.9219e-03, -2.3340e-02,
         -2.1185e-02, -1.4722e-02, -1.4868e-02, -1.5969e-02, -2.2238e-02,
         -2.0746e-02,  9.0726e-03,  1.1734e-02, -3.8070e-02,  9.3740e-04,
         -3.4404e-02, -5.3068e-02,  7.4766e-03, -3.3690e-02, -2.3907e-02,
         -1.1922e-02, -3.2821e-02, -4.6094e-02,  4.7032e-04, -4.1886e-02,
         -5.7862e-03, -2.4299e-02, -2.8858e-02,  1.1723e-02, -3.0093e-02,
         -4.6471e-02, -4.9816e-03, -2.3448e-03, -2.2391e-02, -3.6809e-02,
         -3.7831e-02,  8.4370e-03, -4.2447e-02, -1.9412e-02, -3.9165e-02,
         -2.3906e-02,  7.2951e-03, -4.2961e-02,  8.2211e-03, -2.2970e-02,
         -1.4029e-02,  1.2471e-03,  3.8190e-02, -5.0079e-03, -4.4626e-02,
         -1.3463e-02, -1.6834e-02,  3.9899e-04, -1.4055e-02, -3.9695e-02,
         -3.6972e-02, -1.7081e-02, -3.0984e-02, -1.9453e-02, -1.2163e-05,
         -1.2716e-02, -9.5281e-03, -2.4193e-02, -3.0648e-02,  8.4034e-03,
         -9.2663e-03, -4.4070e-02, -2.4568e-02, -1.5319e-02, -5.6182e-03,
          6.3644e-03, -1.5009e-02,  1.2869e-02, -7.8058e-03,  5.4362e-03,
          2.2388e-03, -2.6862e-02, -1.5712e-03, -1.8940e-02,  1.3159e-02,
         -1.3461e-02, -3.9902e-02, -5.0591e-02, -1.7753e-02, -1.3713e-02,
          8.0693e-03, -3.5620e-02, -3.3676e-02, -1.3030e-02, -1.6888e-02,
         -2.5140e-02, -3.4833e-02, -7.2791e-03, -3.2956e-02, -2.4693e-02,
         -1.1791e-02, -1.2542e-02, -1.6742e-02, -4.3013e-02, -1.3429e-02,
          1.2613e-03, -4.0043e-02, -1.1774e-02, -3.2534e-02, -3.4204e-02,
          8.6550e-03, -8.3946e-03, -3.6755e-02, -3.3793e-02, -2.7884e-02,
         -7.4445e-03, -1.8833e-03,  1.2610e-02,  9.8851e-03,  1.2191e-02,
         -3.6666e-02, -8.5410e-02, -2.8082e-02, -3.0407e-02, -1.9044e-02,
          2.4342e-03, -1.4180e-03, -2.6470e-02, -2.5302e-02, -2.5253e-02,
         -1.1512e-02, -2.8345e-02, -1.5937e-02,  9.6349e-03, -1.0218e-02,
          1.3560e-02,  1.5391e-02, -1.9179e-02,  1.5864e-02, -1.0996e-02,
         -1.0817e-02,  2.6805e-03, -3.1092e-02, -3.8091e-02, -2.3368e-02,
         -5.9125e-02, -1.0858e-02,  4.5047e-03, -1.8238e-02, -2.1426e-02,
         -1.7773e-02, -2.9463e-02, -3.7479e-03, -4.9064e-03, -1.5818e-02,
         -2.5526e-02, -1.4419e-03, -1.1299e-02,  8.5140e-03, -1.0698e-02,
         -1.1708e-02, -2.0608e-02, -1.4593e-02, -7.7355e-03, -7.3931e-03,
         -4.0843e-02, -2.1167e-02, -1.2983e-02, -2.9919e-03,  3.0490e-03,
         -4.7598e-03, -7.2291e-02, -9.2503e-03, -3.9466e-02, -4.7297e-02,
         -2.1130e-02, -3.5272e-02,  2.0385e-02,  5.3947e-03, -2.0301e-02,
         -9.7881e-03, -1.9998e-02, -6.5725e-02, -4.3420e-02, -3.1609e-02,
         -1.8267e-04, -3.4371e-03, -9.8789e-04,  9.6274e-03, -5.9154e-03,
         -3.4675e-02, -6.5226e-02, -2.0677e-02, -4.1714e-02,  2.1622e-02,
          2.0240e-02, -9.2820e-03, -1.7129e-02, -3.2057e-02, -3.1468e-02,
         -3.4941e-02,  2.3813e-02, -1.6644e-02, -5.0642e-02, -1.6989e-02,
         -2.9996e-02, -2.5404e-02, -2.8092e-02, -4.2349e-02, -3.9435e-02,
         -4.4279e-02, -2.2080e-02,  3.3196e-03, -1.1349e-02,  6.9159e-03,
         -3.3969e-02, -5.3818e-02,  4.0196e-02, -3.8763e-02,  1.4048e-02,
          5.9220e-04, -2.6749e-02, -1.3595e-03, -4.5813e-02, -6.8420e-03,
         -3.4372e-02, -1.8214e-02,  4.0495e-03,  3.8787e-06, -1.8598e-02,
          9.7004e-03, -2.1482e-02, -1.9200e-02, -4.7962e-02, -3.4414e-02,
         -3.2698e-02, -2.5277e-02, -3.4527e-02,  1.4325e-02, -3.6852e-02,
          4.9736e-03, -4.6518e-02, -1.2696e-02, -4.6521e-02, -3.6610e-02,
         -2.4398e-02, -3.2662e-02, -2.5911e-03, -5.8092e-02,  2.9025e-02,
         -2.1087e-02, -1.7487e-02, -3.1389e-02, -4.2529e-02, -1.0128e-02,
         -1.7335e-02,  2.8430e-02,  3.9904e-02,  8.0061e-04, -3.1003e-02,
         -7.1200e-02, -2.8507e-03, -5.9049e-02, -1.5139e-02,  5.0690e-03,
         -1.6833e-02, -9.0752e-03, -2.3263e-02, -2.1165e-02, -4.3393e-02,
         -8.7630e-03, -1.3716e-02, -2.7933e-02, -4.8012e-02, -1.4200e-02,
         -5.1839e-02, -6.0081e-03, -1.8939e-02, -1.7114e-02, -4.1764e-02,
         -5.2397e-03, -5.4814e-03, -2.0793e-02, -4.0475e-02, -4.4624e-02,
         -7.9084e-03, -3.5071e-03,  2.0474e-02, -2.6987e-02, -1.4414e-02,
         -1.9035e-02, -4.9324e-02, -2.8345e-02,  1.4301e-02, -3.8973e-02,
         -1.2840e-02, -7.5258e-03, -4.6916e-02, -4.7070e-02, -1.3649e-02,
         -5.4320e-02, -1.8288e-03, -1.8652e-03, -2.7375e-02,  1.1466e-02,
         -4.0584e-02, -1.2032e-02, -3.9389e-02, -2.1145e-02,  2.4070e-03,
          9.3934e-03, -3.9291e-02, -5.9169e-02, -4.5224e-03, -1.4565e-02,
         -2.3315e-02, -3.0413e-02, -1.4424e-02, -1.6966e-02,  1.0072e-02,
          3.6617e-02, -3.9734e-02, -3.2399e-02, -1.3331e-02, -2.1236e-02,
          2.2823e-02, -1.9419e-02, -4.0604e-03, -1.3728e-02, -1.8695e-02,
         -2.6998e-02, -1.7203e-02, -6.4163e-03, -1.3199e-02, -5.5872e-02,
         -3.5325e-02, -3.1695e-02, -4.9119e-02,  4.0982e-02,  1.8657e-02,
         -3.3573e-02, -8.9048e-03,  1.6459e-02, -3.6141e-02, -3.5255e-02,
         -2.0351e-02,  3.6519e-02, -1.1686e-02,  2.1606e-02,  1.8557e-02,
         -4.5092e-03, -9.0398e-03,  2.1982e-02, -3.4125e-02,  1.8775e-02,
         -5.1349e-02, -2.0664e-03, -1.0744e-02, -1.6671e-02,  2.6162e-02,
         -6.4523e-03, -5.7046e-02, -3.6390e-03, -1.9814e-02, -1.6118e-02,
          6.7051e-03, -5.2483e-03,  8.4542e-04, -2.6400e-02, -6.1003e-03,
         -1.2574e-02, -3.9921e-02, -2.9327e-02, -2.4630e-02,  8.4810e-03,
         -7.4100e-04, -1.8916e-02,  5.1565e-03,  2.2242e-02, -9.2054e-03,
         -5.8127e-02, -1.7812e-03, -1.1566e-02, -1.5581e-02, -2.4738e-02,
         -8.5652e-03, -1.4644e-02, -1.7377e-02, -7.8154e-03,  8.7701e-03,
         -1.5758e-02, -2.9299e-02, -5.7990e-02,  5.2301e-03, -1.7015e-03,
         -1.0382e-02, -6.0044e-03, -2.6569e-02, -1.6470e-03,  1.8650e-03,
          1.0926e-02, -2.2354e-02,  1.7114e-02, -7.1626e-03, -4.9205e-02,
         -1.3529e-02,  2.1432e-02, -1.5802e-02, -2.3511e-02, -1.6134e-02,
         -3.9555e-02,  2.8150e-02, -9.2762e-03, -8.4562e-03, -2.7197e-02,
         -7.0721e-03, -4.0385e-03, -4.7109e-02, -5.2178e-03, -4.8849e-02,
          1.6391e-02, -3.0436e-02, -2.0354e-02, -1.7472e-02, -1.0822e-02,
         -3.9952e-02, -3.1226e-02, -5.1212e-02,  1.2849e-02, -4.3737e-02,
         -1.6600e-02, -1.7369e-02, -3.5132e-02, -7.9695e-03, -1.9029e-02,
         -2.9353e-02, -2.5525e-02, -1.2254e-02,  1.0975e-03, -4.0945e-02,
         -1.6960e-02, -4.7521e-03, -1.3975e-02, -1.2778e-02, -2.7528e-02,
         -3.3573e-02, -4.6857e-03, -4.8495e-03, -1.5761e-02, -1.7572e-02,
         -1.5772e-02, -7.3530e-03, -3.1005e-02, -1.7780e-02, -1.4125e-02,
         -2.0564e-02, -1.9258e-02, -1.5787e-02, -2.5870e-02,  8.4195e-03,
          1.2669e-02, -1.9583e-02, -1.6337e-02, -1.2081e-02,  7.1074e-03,
         -4.5319e-02, -2.1659e-02, -1.2411e-02, -2.7327e-02, -1.0128e-02,
         -3.7986e-02, -1.6327e-02, -5.8103e-03, -1.7206e-02, -1.4065e-02,
          2.7339e-02, -2.2147e-02, -3.9057e-02, -8.3084e-03, -2.7950e-02,
         -1.3844e-02, -1.8129e-02, -4.8987e-02,  1.5473e-02, -2.5392e-02,
         -3.8005e-02, -4.3275e-02, -1.0993e-02, -5.9326e-03, -6.6074e-02,
         -4.9379e-03, -2.7258e-02, -2.5302e-02, -3.8126e-02, -3.0043e-02,
         -8.6250e-03, -4.3281e-03, -5.0636e-02, -5.5711e-02, -2.7074e-02,
         -3.6164e-02, -1.2752e-02, -1.9970e-02, -2.1273e-02, -5.8114e-03,
         -6.4127e-02, -2.3056e-02,  2.3241e-03, -3.5551e-02, -1.8637e-02,
         -2.2455e-02, -3.8589e-02,  3.4994e-03, -5.7992e-03,  9.8726e-03,
         -4.2325e-02, -3.3603e-02,  9.3079e-03]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.0000% F1: 0.2440
Applying ckpt from fold 1 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.8000% F1: 0.2436
Applying ckpt from fold 2 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.0000% F1: 0.2440
Applying ckpt from fold 3 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.4000% F1: 0.2520
Applying ckpt from fold 4 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.8000% F1: 0.2468
Applying ckpt from fold 5 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.8000% F1: 0.2534
Applying ckpt from fold 6 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.8000% F1: 0.2501
Applying ckpt from fold 7 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.4000% F1: 0.2455
Applying ckpt from fold 8 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2478
Applying ckpt from fold 9 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.6000% F1: 0.2430
Metrics by fold:
Fold 0 - Acc: 0.55 F1: 0.24
Fold 1 - Acc: 0.55 F1: 0.24
Fold 2 - Acc: 0.55 F1: 0.24
Fold 3 - Acc: 0.54 F1: 0.25
Fold 4 - Acc: 0.55 F1: 0.25
Fold 5 - Acc: 0.55 F1: 0.25
Fold 6 - Acc: 0.55 F1: 0.25
Fold 7 - Acc: 0.54 F1: 0.25
Fold 8 - Acc: 0.55 F1: 0.25
Fold 9 - Acc: 0.55 F1: 0.24
agg_acc: 0.5478 agg_f1: 0.2470
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-1.9576e-02,  1.4462e-02,  2.1089e-02, -2.4213e-02, -3.1370e-02,
         -1.4199e-02, -2.5904e-02, -5.0341e-02, -3.6889e-02, -3.2728e-02,
         -6.8087e-04, -3.5233e-02, -3.9792e-02, -2.0962e-02, -7.1844e-03,
         -9.9852e-03, -2.8043e-02, -2.2781e-02, -4.4245e-03, -4.3463e-02,
         -4.1087e-02, -4.5657e-02, -1.9222e-02, -7.8390e-03, -2.0070e-02,
         -3.9880e-02,  1.8200e-02, -2.9268e-02, -1.6676e-02, -2.1610e-02,
         -2.6654e-02, -2.5254e-02,  9.2145e-03, -4.5557e-02, -3.3439e-02,
         -7.2401e-03, -2.6082e-02,  1.0227e-02, -1.4157e-02, -1.4822e-02,
         -4.3798e-02, -4.1658e-02, -1.4709e-02, -2.5902e-02, -8.7081e-03,
         -3.9880e-02, -1.5114e-02, -1.3367e-02, -3.1035e-02, -3.6392e-02,
          1.2227e-02, -8.7005e-03, -1.9950e-02, -1.3439e-02, -3.7631e-02,
         -3.0060e-02, -1.7583e-03, -4.8765e-02,  1.0541e-03, -1.3689e-02,
         -2.3786e-02,  8.0220e-03, -3.0173e-02, -2.5209e-02, -2.2526e-02,
         -1.9942e-02,  8.4238e-03, -1.9661e-02, -1.2119e-02, -3.4659e-03,
         -3.1803e-02, -3.2865e-03, -1.0539e-02, -3.9146e-03, -4.3804e-02,
          2.2994e-02,  1.2197e-02, -4.6647e-02, -3.5887e-02, -1.4468e-02,
         -3.3255e-03, -1.7044e-02,  2.0406e-02,  1.0396e-02, -2.0522e-02,
         -3.4509e-02, -4.8150e-02, -5.4708e-03,  3.8065e-02, -5.5523e-02,
          3.8816e-03, -6.3457e-02, -2.4241e-02, -9.3510e-03, -1.5897e-02,
         -8.8885e-03, -1.4690e-02, -5.4748e-03, -9.9003e-03, -7.0308e-03,
          3.4854e-03, -6.2360e-04,  1.0930e-02,  2.8643e-02, -1.1186e-02,
         -2.6669e-02, -1.9786e-02,  1.7164e-02, -1.3477e-02, -4.4371e-02,
         -1.4301e-02, -1.3759e-02, -4.0720e-02, -2.1774e-02,  1.6330e-02,
         -2.6441e-02, -4.0575e-02, -3.9297e-02, -9.2287e-03, -2.3262e-02,
         -5.1135e-03,  1.7898e-02,  1.0295e-02, -4.4888e-02, -1.1444e-02,
         -6.7636e-05,  3.0896e-02, -2.1793e-02, -2.7886e-02,  7.3077e-04,
         -7.0966e-03, -2.8983e-02, -2.4230e-02, -4.3455e-03, -3.6372e-02,
         -1.4622e-02, -1.9455e-02, -6.2994e-03, -4.8066e-02,  1.2134e-03,
         -2.6100e-02, -2.2397e-02, -4.3888e-02, -4.5778e-03, -4.2798e-02,
         -4.1344e-03, -4.0403e-02, -1.4517e-02, -7.4589e-03, -2.9797e-02,
         -4.2728e-02, -5.6681e-02, -7.0879e-03,  7.4267e-03,  2.2647e-02,
         -2.2768e-02,  7.6049e-04, -3.0197e-02, -5.4283e-03,  9.8245e-03,
         -1.2252e-03, -2.3723e-02,  3.4096e-02, -1.4257e-02, -3.2253e-02,
         -1.8886e-02, -5.4247e-03, -1.1375e-02, -9.0462e-03, -1.1843e-02,
          1.3237e-02, -2.4774e-02, -2.8040e-02, -3.8893e-02, -2.9173e-02,
         -3.3035e-02, -5.6146e-03, -2.8491e-02, -1.4185e-02, -1.6383e-02,
          1.3736e-03, -2.7760e-02, -4.3374e-03,  1.7261e-02, -2.0601e-02,
         -1.9357e-03, -1.5073e-02, -9.6997e-03, -1.1300e-02, -4.2982e-02,
          8.4574e-03, -3.8737e-02, -1.5231e-02, -2.3515e-02, -1.3568e-02,
          3.3063e-03, -3.3534e-02, -8.0107e-03, -3.6351e-02, -3.9080e-02,
         -8.1655e-03, -8.9546e-03,  4.9051e-03, -6.2526e-03, -4.5883e-02,
         -2.0797e-02, -3.6205e-02, -8.1598e-03, -2.8076e-02, -8.8447e-03,
         -1.9260e-02,  1.1396e-02,  1.5052e-02, -1.6075e-02, -1.5518e-02,
         -1.7724e-02,  2.0844e-02, -2.6688e-02, -3.4171e-02, -2.8748e-02,
          7.2581e-03, -1.6509e-02, -2.8037e-02, -2.2494e-02, -6.6422e-03,
         -3.8462e-02, -4.8222e-02, -4.5790e-02, -1.1145e-02,  4.5953e-02,
         -1.1314e-04,  1.1308e-03, -4.2939e-02, -2.3548e-02,  1.3748e-02,
          4.0744e-03,  8.6413e-03, -1.0417e-03, -5.3433e-02, -4.8686e-03,
          2.5878e-02, -1.2791e-02, -1.8810e-02, -1.7619e-02, -9.7876e-03,
         -2.5285e-02, -2.1384e-02,  1.4755e-02, -3.9157e-02,  1.8993e-02,
          5.0377e-03, -2.9328e-02, -1.6048e-02, -3.0006e-02, -2.8478e-02,
         -8.5162e-03, -1.2241e-02, -1.8590e-02, -2.9219e-03, -2.3340e-02,
         -2.1185e-02, -1.4722e-02, -1.4868e-02, -1.5969e-02, -2.2238e-02,
         -2.0746e-02,  9.0726e-03,  1.1734e-02, -3.8070e-02,  9.3740e-04,
         -3.4404e-02, -5.3068e-02,  7.4766e-03, -3.3690e-02, -2.3907e-02,
         -1.1922e-02, -3.2821e-02, -4.6094e-02,  4.7032e-04, -4.1886e-02,
         -5.7862e-03, -2.4299e-02, -2.8858e-02,  1.1723e-02, -3.0093e-02,
         -4.6471e-02, -4.9816e-03, -2.3448e-03, -2.2391e-02, -3.6809e-02,
         -3.7831e-02,  8.4370e-03, -4.2447e-02, -1.9412e-02, -3.9165e-02,
         -2.3906e-02,  7.2951e-03, -4.2961e-02,  8.2211e-03, -2.2970e-02,
         -1.4029e-02,  1.2471e-03,  3.8190e-02, -5.0079e-03, -4.4626e-02,
         -1.3463e-02, -1.6834e-02,  3.9899e-04, -1.4055e-02, -3.9695e-02,
         -3.6972e-02, -1.7081e-02, -3.0984e-02, -1.9453e-02, -1.2163e-05,
         -1.2716e-02, -9.5281e-03, -2.4193e-02, -3.0648e-02,  8.4034e-03,
         -9.2663e-03, -4.4070e-02, -2.4568e-02, -1.5319e-02, -5.6182e-03,
          6.3644e-03, -1.5009e-02,  1.2869e-02, -7.8058e-03,  5.4362e-03,
          2.2388e-03, -2.6862e-02, -1.5712e-03, -1.8940e-02,  1.3159e-02,
         -1.3461e-02, -3.9902e-02, -5.0591e-02, -1.7753e-02, -1.3713e-02,
          8.0693e-03, -3.5620e-02, -3.3676e-02, -1.3030e-02, -1.6888e-02,
         -2.5140e-02, -3.4833e-02, -7.2791e-03, -3.2956e-02, -2.4693e-02,
         -1.1791e-02, -1.2542e-02, -1.6742e-02, -4.3013e-02, -1.3429e-02,
          1.2613e-03, -4.0043e-02, -1.1774e-02, -3.2534e-02, -3.4204e-02,
          8.6550e-03, -8.3946e-03, -3.6755e-02, -3.3793e-02, -2.7884e-02,
         -7.4445e-03, -1.8833e-03,  1.2610e-02,  9.8851e-03,  1.2191e-02,
         -3.6666e-02, -8.5410e-02, -2.8082e-02, -3.0407e-02, -1.9044e-02,
          2.4342e-03, -1.4180e-03, -2.6470e-02, -2.5302e-02, -2.5253e-02,
         -1.1512e-02, -2.8345e-02, -1.5937e-02,  9.6349e-03, -1.0218e-02,
          1.3560e-02,  1.5391e-02, -1.9179e-02,  1.5864e-02, -1.0996e-02,
         -1.0817e-02,  2.6805e-03, -3.1092e-02, -3.8091e-02, -2.3368e-02,
         -5.9125e-02, -1.0858e-02,  4.5047e-03, -1.8238e-02, -2.1426e-02,
         -1.7773e-02, -2.9463e-02, -3.7479e-03, -4.9064e-03, -1.5818e-02,
         -2.5526e-02, -1.4419e-03, -1.1299e-02,  8.5140e-03, -1.0698e-02,
         -1.1708e-02, -2.0608e-02, -1.4593e-02, -7.7355e-03, -7.3931e-03,
         -4.0843e-02, -2.1167e-02, -1.2983e-02, -2.9919e-03,  3.0490e-03,
         -4.7598e-03, -7.2291e-02, -9.2503e-03, -3.9466e-02, -4.7297e-02,
         -2.1130e-02, -3.5272e-02,  2.0385e-02,  5.3947e-03, -2.0301e-02,
         -9.7881e-03, -1.9998e-02, -6.5725e-02, -4.3420e-02, -3.1609e-02,
         -1.8267e-04, -3.4371e-03, -9.8789e-04,  9.6274e-03, -5.9154e-03,
         -3.4675e-02, -6.5226e-02, -2.0677e-02, -4.1714e-02,  2.1622e-02,
          2.0240e-02, -9.2820e-03, -1.7129e-02, -3.2057e-02, -3.1468e-02,
         -3.4941e-02,  2.3813e-02, -1.6644e-02, -5.0642e-02, -1.6989e-02,
         -2.9996e-02, -2.5404e-02, -2.8092e-02, -4.2349e-02, -3.9435e-02,
         -4.4279e-02, -2.2080e-02,  3.3196e-03, -1.1349e-02,  6.9159e-03,
         -3.3969e-02, -5.3818e-02,  4.0196e-02, -3.8763e-02,  1.4048e-02,
          5.9220e-04, -2.6749e-02, -1.3595e-03, -4.5813e-02, -6.8420e-03,
         -3.4372e-02, -1.8214e-02,  4.0495e-03,  3.8787e-06, -1.8598e-02,
          9.7004e-03, -2.1482e-02, -1.9200e-02, -4.7962e-02, -3.4414e-02,
         -3.2698e-02, -2.5277e-02, -3.4527e-02,  1.4325e-02, -3.6852e-02,
          4.9736e-03, -4.6518e-02, -1.2696e-02, -4.6521e-02, -3.6610e-02,
         -2.4398e-02, -3.2662e-02, -2.5911e-03, -5.8092e-02,  2.9025e-02,
         -2.1087e-02, -1.7487e-02, -3.1389e-02, -4.2529e-02, -1.0128e-02,
         -1.7335e-02,  2.8430e-02,  3.9904e-02,  8.0061e-04, -3.1003e-02,
         -7.1200e-02, -2.8507e-03, -5.9049e-02, -1.5139e-02,  5.0690e-03,
         -1.6833e-02, -9.0752e-03, -2.3263e-02, -2.1165e-02, -4.3393e-02,
         -8.7630e-03, -1.3716e-02, -2.7933e-02, -4.8012e-02, -1.4200e-02,
         -5.1839e-02, -6.0081e-03, -1.8939e-02, -1.7114e-02, -4.1764e-02,
         -5.2397e-03, -5.4814e-03, -2.0793e-02, -4.0475e-02, -4.4624e-02,
         -7.9084e-03, -3.5071e-03,  2.0474e-02, -2.6987e-02, -1.4414e-02,
         -1.9035e-02, -4.9324e-02, -2.8345e-02,  1.4301e-02, -3.8973e-02,
         -1.2840e-02, -7.5258e-03, -4.6916e-02, -4.7070e-02, -1.3649e-02,
         -5.4320e-02, -1.8288e-03, -1.8652e-03, -2.7375e-02,  1.1466e-02,
         -4.0584e-02, -1.2032e-02, -3.9389e-02, -2.1145e-02,  2.4070e-03,
          9.3934e-03, -3.9291e-02, -5.9169e-02, -4.5224e-03, -1.4565e-02,
         -2.3315e-02, -3.0413e-02, -1.4424e-02, -1.6966e-02,  1.0072e-02,
          3.6617e-02, -3.9734e-02, -3.2399e-02, -1.3331e-02, -2.1236e-02,
          2.2823e-02, -1.9419e-02, -4.0604e-03, -1.3728e-02, -1.8695e-02,
         -2.6998e-02, -1.7203e-02, -6.4163e-03, -1.3199e-02, -5.5872e-02,
         -3.5325e-02, -3.1695e-02, -4.9119e-02,  4.0982e-02,  1.8657e-02,
         -3.3573e-02, -8.9048e-03,  1.6459e-02, -3.6141e-02, -3.5255e-02,
         -2.0351e-02,  3.6519e-02, -1.1686e-02,  2.1606e-02,  1.8557e-02,
         -4.5092e-03, -9.0398e-03,  2.1982e-02, -3.4125e-02,  1.8775e-02,
         -5.1349e-02, -2.0664e-03, -1.0744e-02, -1.6671e-02,  2.6162e-02,
         -6.4523e-03, -5.7046e-02, -3.6390e-03, -1.9814e-02, -1.6118e-02,
          6.7051e-03, -5.2483e-03,  8.4542e-04, -2.6400e-02, -6.1003e-03,
         -1.2574e-02, -3.9921e-02, -2.9327e-02, -2.4630e-02,  8.4810e-03,
         -7.4100e-04, -1.8916e-02,  5.1565e-03,  2.2242e-02, -9.2054e-03,
         -5.8127e-02, -1.7812e-03, -1.1566e-02, -1.5581e-02, -2.4738e-02,
         -8.5652e-03, -1.4644e-02, -1.7377e-02, -7.8154e-03,  8.7701e-03,
         -1.5758e-02, -2.9299e-02, -5.7990e-02,  5.2301e-03, -1.7015e-03,
         -1.0382e-02, -6.0044e-03, -2.6569e-02, -1.6470e-03,  1.8650e-03,
          1.0926e-02, -2.2354e-02,  1.7114e-02, -7.1626e-03, -4.9205e-02,
         -1.3529e-02,  2.1432e-02, -1.5802e-02, -2.3511e-02, -1.6134e-02,
         -3.9555e-02,  2.8150e-02, -9.2762e-03, -8.4562e-03, -2.7197e-02,
         -7.0721e-03, -4.0385e-03, -4.7109e-02, -5.2178e-03, -4.8849e-02,
          1.6391e-02, -3.0436e-02, -2.0354e-02, -1.7472e-02, -1.0822e-02,
         -3.9952e-02, -3.1226e-02, -5.1212e-02,  1.2849e-02, -4.3737e-02,
         -1.6600e-02, -1.7369e-02, -3.5132e-02, -7.9695e-03, -1.9029e-02,
         -2.9353e-02, -2.5525e-02, -1.2254e-02,  1.0975e-03, -4.0945e-02,
         -1.6960e-02, -4.7521e-03, -1.3975e-02, -1.2778e-02, -2.7528e-02,
         -3.3573e-02, -4.6857e-03, -4.8495e-03, -1.5761e-02, -1.7572e-02,
         -1.5772e-02, -7.3530e-03, -3.1005e-02, -1.7780e-02, -1.4125e-02,
         -2.0564e-02, -1.9258e-02, -1.5787e-02, -2.5870e-02,  8.4195e-03,
          1.2669e-02, -1.9583e-02, -1.6337e-02, -1.2081e-02,  7.1074e-03,
         -4.5319e-02, -2.1659e-02, -1.2411e-02, -2.7327e-02, -1.0128e-02,
         -3.7986e-02, -1.6327e-02, -5.8103e-03, -1.7206e-02, -1.4065e-02,
          2.7339e-02, -2.2147e-02, -3.9057e-02, -8.3084e-03, -2.7950e-02,
         -1.3844e-02, -1.8129e-02, -4.8987e-02,  1.5473e-02, -2.5392e-02,
         -3.8005e-02, -4.3275e-02, -1.0993e-02, -5.9326e-03, -6.6074e-02,
         -4.9379e-03, -2.7258e-02, -2.5302e-02, -3.8126e-02, -3.0043e-02,
         -8.6250e-03, -4.3281e-03, -5.0636e-02, -5.5711e-02, -2.7074e-02,
         -3.6164e-02, -1.2752e-02, -1.9970e-02, -2.1273e-02, -5.8114e-03,
         -6.4127e-02, -2.3056e-02,  2.3241e-03, -3.5551e-02, -1.8637e-02,
         -2.2455e-02, -3.8589e-02,  3.4994e-03, -5.7992e-03,  9.8726e-03,
         -4.2325e-02, -3.3603e-02,  9.3079e-03]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.6000% F1: 0.3390
Applying ckpt from fold 1 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.4000% F1: 0.3121
Applying ckpt from fold 2 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.3044
Applying ckpt from fold 3 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.4000% F1: 0.2966
Applying ckpt from fold 4 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.8000% F1: 0.3157
Applying ckpt from fold 5 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.8000% F1: 0.3136
Applying ckpt from fold 6 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.8000% F1: 0.3075
Applying ckpt from fold 7 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.6000% F1: 0.2952
Applying ckpt from fold 8 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 56.4000% F1: 0.3011
Applying ckpt from fold 9 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.4000% F1: 0.2992
Metrics by fold:
Fold 0 - Acc: 0.54 F1: 0.34
Fold 1 - Acc: 0.52 F1: 0.31
Fold 2 - Acc: 0.55 F1: 0.30
Fold 3 - Acc: 0.54 F1: 0.30
Fold 4 - Acc: 0.50 F1: 0.32
Fold 5 - Acc: 0.51 F1: 0.31
Fold 6 - Acc: 0.54 F1: 0.31
Fold 7 - Acc: 0.56 F1: 0.30
Fold 8 - Acc: 0.56 F1: 0.30
Fold 9 - Acc: 0.55 F1: 0.30
agg_acc: 0.5374 agg_f1: 0.3084
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-1.9576e-02,  1.4462e-02,  2.1089e-02, -2.4213e-02, -3.1370e-02,
         -1.4199e-02, -2.5904e-02, -5.0341e-02, -3.6889e-02, -3.2728e-02,
         -6.8087e-04, -3.5233e-02, -3.9792e-02, -2.0962e-02, -7.1844e-03,
         -9.9852e-03, -2.8043e-02, -2.2781e-02, -4.4245e-03, -4.3463e-02,
         -4.1087e-02, -4.5657e-02, -1.9222e-02, -7.8390e-03, -2.0070e-02,
         -3.9880e-02,  1.8200e-02, -2.9268e-02, -1.6676e-02, -2.1610e-02,
         -2.6654e-02, -2.5254e-02,  9.2145e-03, -4.5557e-02, -3.3439e-02,
         -7.2401e-03, -2.6082e-02,  1.0227e-02, -1.4157e-02, -1.4822e-02,
         -4.3798e-02, -4.1658e-02, -1.4709e-02, -2.5902e-02, -8.7081e-03,
         -3.9880e-02, -1.5114e-02, -1.3367e-02, -3.1035e-02, -3.6392e-02,
          1.2227e-02, -8.7005e-03, -1.9950e-02, -1.3439e-02, -3.7631e-02,
         -3.0060e-02, -1.7583e-03, -4.8765e-02,  1.0541e-03, -1.3689e-02,
         -2.3786e-02,  8.0220e-03, -3.0173e-02, -2.5209e-02, -2.2526e-02,
         -1.9942e-02,  8.4238e-03, -1.9661e-02, -1.2119e-02, -3.4659e-03,
         -3.1803e-02, -3.2865e-03, -1.0539e-02, -3.9146e-03, -4.3804e-02,
          2.2994e-02,  1.2197e-02, -4.6647e-02, -3.5887e-02, -1.4468e-02,
         -3.3255e-03, -1.7044e-02,  2.0406e-02,  1.0396e-02, -2.0522e-02,
         -3.4509e-02, -4.8150e-02, -5.4708e-03,  3.8065e-02, -5.5523e-02,
          3.8816e-03, -6.3457e-02, -2.4241e-02, -9.3510e-03, -1.5897e-02,
         -8.8885e-03, -1.4690e-02, -5.4748e-03, -9.9003e-03, -7.0308e-03,
          3.4854e-03, -6.2360e-04,  1.0930e-02,  2.8643e-02, -1.1186e-02,
         -2.6669e-02, -1.9786e-02,  1.7164e-02, -1.3477e-02, -4.4371e-02,
         -1.4301e-02, -1.3759e-02, -4.0720e-02, -2.1774e-02,  1.6330e-02,
         -2.6441e-02, -4.0575e-02, -3.9297e-02, -9.2287e-03, -2.3262e-02,
         -5.1135e-03,  1.7898e-02,  1.0295e-02, -4.4888e-02, -1.1444e-02,
         -6.7636e-05,  3.0896e-02, -2.1793e-02, -2.7886e-02,  7.3077e-04,
         -7.0966e-03, -2.8983e-02, -2.4230e-02, -4.3455e-03, -3.6372e-02,
         -1.4622e-02, -1.9455e-02, -6.2994e-03, -4.8066e-02,  1.2134e-03,
         -2.6100e-02, -2.2397e-02, -4.3888e-02, -4.5778e-03, -4.2798e-02,
         -4.1344e-03, -4.0403e-02, -1.4517e-02, -7.4589e-03, -2.9797e-02,
         -4.2728e-02, -5.6681e-02, -7.0879e-03,  7.4267e-03,  2.2647e-02,
         -2.2768e-02,  7.6049e-04, -3.0197e-02, -5.4283e-03,  9.8245e-03,
         -1.2252e-03, -2.3723e-02,  3.4096e-02, -1.4257e-02, -3.2253e-02,
         -1.8886e-02, -5.4247e-03, -1.1375e-02, -9.0462e-03, -1.1843e-02,
          1.3237e-02, -2.4774e-02, -2.8040e-02, -3.8893e-02, -2.9173e-02,
         -3.3035e-02, -5.6146e-03, -2.8491e-02, -1.4185e-02, -1.6383e-02,
          1.3736e-03, -2.7760e-02, -4.3374e-03,  1.7261e-02, -2.0601e-02,
         -1.9357e-03, -1.5073e-02, -9.6997e-03, -1.1300e-02, -4.2982e-02,
          8.4574e-03, -3.8737e-02, -1.5231e-02, -2.3515e-02, -1.3568e-02,
          3.3063e-03, -3.3534e-02, -8.0107e-03, -3.6351e-02, -3.9080e-02,
         -8.1655e-03, -8.9546e-03,  4.9051e-03, -6.2526e-03, -4.5883e-02,
         -2.0797e-02, -3.6205e-02, -8.1598e-03, -2.8076e-02, -8.8447e-03,
         -1.9260e-02,  1.1396e-02,  1.5052e-02, -1.6075e-02, -1.5518e-02,
         -1.7724e-02,  2.0844e-02, -2.6688e-02, -3.4171e-02, -2.8748e-02,
          7.2581e-03, -1.6509e-02, -2.8037e-02, -2.2494e-02, -6.6422e-03,
         -3.8462e-02, -4.8222e-02, -4.5790e-02, -1.1145e-02,  4.5953e-02,
         -1.1314e-04,  1.1308e-03, -4.2939e-02, -2.3548e-02,  1.3748e-02,
          4.0744e-03,  8.6413e-03, -1.0417e-03, -5.3433e-02, -4.8686e-03,
          2.5878e-02, -1.2791e-02, -1.8810e-02, -1.7619e-02, -9.7876e-03,
         -2.5285e-02, -2.1384e-02,  1.4755e-02, -3.9157e-02,  1.8993e-02,
          5.0377e-03, -2.9328e-02, -1.6048e-02, -3.0006e-02, -2.8478e-02,
         -8.5162e-03, -1.2241e-02, -1.8590e-02, -2.9219e-03, -2.3340e-02,
         -2.1185e-02, -1.4722e-02, -1.4868e-02, -1.5969e-02, -2.2238e-02,
         -2.0746e-02,  9.0726e-03,  1.1734e-02, -3.8070e-02,  9.3740e-04,
         -3.4404e-02, -5.3068e-02,  7.4766e-03, -3.3690e-02, -2.3907e-02,
         -1.1922e-02, -3.2821e-02, -4.6094e-02,  4.7032e-04, -4.1886e-02,
         -5.7862e-03, -2.4299e-02, -2.8858e-02,  1.1723e-02, -3.0093e-02,
         -4.6471e-02, -4.9816e-03, -2.3448e-03, -2.2391e-02, -3.6809e-02,
         -3.7831e-02,  8.4370e-03, -4.2447e-02, -1.9412e-02, -3.9165e-02,
         -2.3906e-02,  7.2951e-03, -4.2961e-02,  8.2211e-03, -2.2970e-02,
         -1.4029e-02,  1.2471e-03,  3.8190e-02, -5.0079e-03, -4.4626e-02,
         -1.3463e-02, -1.6834e-02,  3.9899e-04, -1.4055e-02, -3.9695e-02,
         -3.6972e-02, -1.7081e-02, -3.0984e-02, -1.9453e-02, -1.2163e-05,
         -1.2716e-02, -9.5281e-03, -2.4193e-02, -3.0648e-02,  8.4034e-03,
         -9.2663e-03, -4.4070e-02, -2.4568e-02, -1.5319e-02, -5.6182e-03,
          6.3644e-03, -1.5009e-02,  1.2869e-02, -7.8058e-03,  5.4362e-03,
          2.2388e-03, -2.6862e-02, -1.5712e-03, -1.8940e-02,  1.3159e-02,
         -1.3461e-02, -3.9902e-02, -5.0591e-02, -1.7753e-02, -1.3713e-02,
          8.0693e-03, -3.5620e-02, -3.3676e-02, -1.3030e-02, -1.6888e-02,
         -2.5140e-02, -3.4833e-02, -7.2791e-03, -3.2956e-02, -2.4693e-02,
         -1.1791e-02, -1.2542e-02, -1.6742e-02, -4.3013e-02, -1.3429e-02,
          1.2613e-03, -4.0043e-02, -1.1774e-02, -3.2534e-02, -3.4204e-02,
          8.6550e-03, -8.3946e-03, -3.6755e-02, -3.3793e-02, -2.7884e-02,
         -7.4445e-03, -1.8833e-03,  1.2610e-02,  9.8851e-03,  1.2191e-02,
         -3.6666e-02, -8.5410e-02, -2.8082e-02, -3.0407e-02, -1.9044e-02,
          2.4342e-03, -1.4180e-03, -2.6470e-02, -2.5302e-02, -2.5253e-02,
         -1.1512e-02, -2.8345e-02, -1.5937e-02,  9.6349e-03, -1.0218e-02,
          1.3560e-02,  1.5391e-02, -1.9179e-02,  1.5864e-02, -1.0996e-02,
         -1.0817e-02,  2.6805e-03, -3.1092e-02, -3.8091e-02, -2.3368e-02,
         -5.9125e-02, -1.0858e-02,  4.5047e-03, -1.8238e-02, -2.1426e-02,
         -1.7773e-02, -2.9463e-02, -3.7479e-03, -4.9064e-03, -1.5818e-02,
         -2.5526e-02, -1.4419e-03, -1.1299e-02,  8.5140e-03, -1.0698e-02,
         -1.1708e-02, -2.0608e-02, -1.4593e-02, -7.7355e-03, -7.3931e-03,
         -4.0843e-02, -2.1167e-02, -1.2983e-02, -2.9919e-03,  3.0490e-03,
         -4.7598e-03, -7.2291e-02, -9.2503e-03, -3.9466e-02, -4.7297e-02,
         -2.1130e-02, -3.5272e-02,  2.0385e-02,  5.3947e-03, -2.0301e-02,
         -9.7881e-03, -1.9998e-02, -6.5725e-02, -4.3420e-02, -3.1609e-02,
         -1.8267e-04, -3.4371e-03, -9.8789e-04,  9.6274e-03, -5.9154e-03,
         -3.4675e-02, -6.5226e-02, -2.0677e-02, -4.1714e-02,  2.1622e-02,
          2.0240e-02, -9.2820e-03, -1.7129e-02, -3.2057e-02, -3.1468e-02,
         -3.4941e-02,  2.3813e-02, -1.6644e-02, -5.0642e-02, -1.6989e-02,
         -2.9996e-02, -2.5404e-02, -2.8092e-02, -4.2349e-02, -3.9435e-02,
         -4.4279e-02, -2.2080e-02,  3.3196e-03, -1.1349e-02,  6.9159e-03,
         -3.3969e-02, -5.3818e-02,  4.0196e-02, -3.8763e-02,  1.4048e-02,
          5.9220e-04, -2.6749e-02, -1.3595e-03, -4.5813e-02, -6.8420e-03,
         -3.4372e-02, -1.8214e-02,  4.0495e-03,  3.8787e-06, -1.8598e-02,
          9.7004e-03, -2.1482e-02, -1.9200e-02, -4.7962e-02, -3.4414e-02,
         -3.2698e-02, -2.5277e-02, -3.4527e-02,  1.4325e-02, -3.6852e-02,
          4.9736e-03, -4.6518e-02, -1.2696e-02, -4.6521e-02, -3.6610e-02,
         -2.4398e-02, -3.2662e-02, -2.5911e-03, -5.8092e-02,  2.9025e-02,
         -2.1087e-02, -1.7487e-02, -3.1389e-02, -4.2529e-02, -1.0128e-02,
         -1.7335e-02,  2.8430e-02,  3.9904e-02,  8.0061e-04, -3.1003e-02,
         -7.1200e-02, -2.8507e-03, -5.9049e-02, -1.5139e-02,  5.0690e-03,
         -1.6833e-02, -9.0752e-03, -2.3263e-02, -2.1165e-02, -4.3393e-02,
         -8.7630e-03, -1.3716e-02, -2.7933e-02, -4.8012e-02, -1.4200e-02,
         -5.1839e-02, -6.0081e-03, -1.8939e-02, -1.7114e-02, -4.1764e-02,
         -5.2397e-03, -5.4814e-03, -2.0793e-02, -4.0475e-02, -4.4624e-02,
         -7.9084e-03, -3.5071e-03,  2.0474e-02, -2.6987e-02, -1.4414e-02,
         -1.9035e-02, -4.9324e-02, -2.8345e-02,  1.4301e-02, -3.8973e-02,
         -1.2840e-02, -7.5258e-03, -4.6916e-02, -4.7070e-02, -1.3649e-02,
         -5.4320e-02, -1.8288e-03, -1.8652e-03, -2.7375e-02,  1.1466e-02,
         -4.0584e-02, -1.2032e-02, -3.9389e-02, -2.1145e-02,  2.4070e-03,
          9.3934e-03, -3.9291e-02, -5.9169e-02, -4.5224e-03, -1.4565e-02,
         -2.3315e-02, -3.0413e-02, -1.4424e-02, -1.6966e-02,  1.0072e-02,
          3.6617e-02, -3.9734e-02, -3.2399e-02, -1.3331e-02, -2.1236e-02,
          2.2823e-02, -1.9419e-02, -4.0604e-03, -1.3728e-02, -1.8695e-02,
         -2.6998e-02, -1.7203e-02, -6.4163e-03, -1.3199e-02, -5.5872e-02,
         -3.5325e-02, -3.1695e-02, -4.9119e-02,  4.0982e-02,  1.8657e-02,
         -3.3573e-02, -8.9048e-03,  1.6459e-02, -3.6141e-02, -3.5255e-02,
         -2.0351e-02,  3.6519e-02, -1.1686e-02,  2.1606e-02,  1.8557e-02,
         -4.5092e-03, -9.0398e-03,  2.1982e-02, -3.4125e-02,  1.8775e-02,
         -5.1349e-02, -2.0664e-03, -1.0744e-02, -1.6671e-02,  2.6162e-02,
         -6.4523e-03, -5.7046e-02, -3.6390e-03, -1.9814e-02, -1.6118e-02,
          6.7051e-03, -5.2483e-03,  8.4542e-04, -2.6400e-02, -6.1003e-03,
         -1.2574e-02, -3.9921e-02, -2.9327e-02, -2.4630e-02,  8.4810e-03,
         -7.4100e-04, -1.8916e-02,  5.1565e-03,  2.2242e-02, -9.2054e-03,
         -5.8127e-02, -1.7812e-03, -1.1566e-02, -1.5581e-02, -2.4738e-02,
         -8.5652e-03, -1.4644e-02, -1.7377e-02, -7.8154e-03,  8.7701e-03,
         -1.5758e-02, -2.9299e-02, -5.7990e-02,  5.2301e-03, -1.7015e-03,
         -1.0382e-02, -6.0044e-03, -2.6569e-02, -1.6470e-03,  1.8650e-03,
          1.0926e-02, -2.2354e-02,  1.7114e-02, -7.1626e-03, -4.9205e-02,
         -1.3529e-02,  2.1432e-02, -1.5802e-02, -2.3511e-02, -1.6134e-02,
         -3.9555e-02,  2.8150e-02, -9.2762e-03, -8.4562e-03, -2.7197e-02,
         -7.0721e-03, -4.0385e-03, -4.7109e-02, -5.2178e-03, -4.8849e-02,
          1.6391e-02, -3.0436e-02, -2.0354e-02, -1.7472e-02, -1.0822e-02,
         -3.9952e-02, -3.1226e-02, -5.1212e-02,  1.2849e-02, -4.3737e-02,
         -1.6600e-02, -1.7369e-02, -3.5132e-02, -7.9695e-03, -1.9029e-02,
         -2.9353e-02, -2.5525e-02, -1.2254e-02,  1.0975e-03, -4.0945e-02,
         -1.6960e-02, -4.7521e-03, -1.3975e-02, -1.2778e-02, -2.7528e-02,
         -3.3573e-02, -4.6857e-03, -4.8495e-03, -1.5761e-02, -1.7572e-02,
         -1.5772e-02, -7.3530e-03, -3.1005e-02, -1.7780e-02, -1.4125e-02,
         -2.0564e-02, -1.9258e-02, -1.5787e-02, -2.5870e-02,  8.4195e-03,
          1.2669e-02, -1.9583e-02, -1.6337e-02, -1.2081e-02,  7.1074e-03,
         -4.5319e-02, -2.1659e-02, -1.2411e-02, -2.7327e-02, -1.0128e-02,
         -3.7986e-02, -1.6327e-02, -5.8103e-03, -1.7206e-02, -1.4065e-02,
          2.7339e-02, -2.2147e-02, -3.9057e-02, -8.3084e-03, -2.7950e-02,
         -1.3844e-02, -1.8129e-02, -4.8987e-02,  1.5473e-02, -2.5392e-02,
         -3.8005e-02, -4.3275e-02, -1.0993e-02, -5.9326e-03, -6.6074e-02,
         -4.9379e-03, -2.7258e-02, -2.5302e-02, -3.8126e-02, -3.0043e-02,
         -8.6250e-03, -4.3281e-03, -5.0636e-02, -5.5711e-02, -2.7074e-02,
         -3.6164e-02, -1.2752e-02, -1.9970e-02, -2.1273e-02, -5.8114e-03,
         -6.4127e-02, -2.3056e-02,  2.3241e-03, -3.5551e-02, -1.8637e-02,
         -2.2455e-02, -3.8589e-02,  3.4994e-03, -5.7992e-03,  9.8726e-03,
         -4.2325e-02, -3.3603e-02,  9.3079e-03]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.8000% F1: 0.3440
Applying ckpt from fold 1 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.4000% F1: 0.3504
Applying ckpt from fold 2 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.6000% F1: 0.3003
Applying ckpt from fold 3 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.8000% F1: 0.3168
Applying ckpt from fold 4 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.2000% F1: 0.3403
Applying ckpt from fold 5 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.8000% F1: 0.3310
Applying ckpt from fold 6 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.6000% F1: 0.2978
Applying ckpt from fold 7 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.2000% F1: 0.3178
Applying ckpt from fold 8 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.6000% F1: 0.3559
Applying ckpt from fold 9 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.0000% F1: 0.3506
Metrics by fold:
Fold 0 - Acc: 0.46 F1: 0.34
Fold 1 - Acc: 0.48 F1: 0.35
Fold 2 - Acc: 0.54 F1: 0.30
Fold 3 - Acc: 0.49 F1: 0.32
Fold 4 - Acc: 0.45 F1: 0.34
Fold 5 - Acc: 0.51 F1: 0.33
Fold 6 - Acc: 0.54 F1: 0.30
Fold 7 - Acc: 0.50 F1: 0.32
Fold 8 - Acc: 0.49 F1: 0.36
Fold 9 - Acc: 0.48 F1: 0.35
agg_acc: 0.4930 agg_f1: 0.3305
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-1.9576e-02,  1.4462e-02,  2.1089e-02, -2.4213e-02, -3.1370e-02,
         -1.4199e-02, -2.5904e-02, -5.0341e-02, -3.6889e-02, -3.2728e-02,
         -6.8087e-04, -3.5233e-02, -3.9792e-02, -2.0962e-02, -7.1844e-03,
         -9.9852e-03, -2.8043e-02, -2.2781e-02, -4.4245e-03, -4.3463e-02,
         -4.1087e-02, -4.5657e-02, -1.9222e-02, -7.8390e-03, -2.0070e-02,
         -3.9880e-02,  1.8200e-02, -2.9268e-02, -1.6676e-02, -2.1610e-02,
         -2.6654e-02, -2.5254e-02,  9.2145e-03, -4.5557e-02, -3.3439e-02,
         -7.2401e-03, -2.6082e-02,  1.0227e-02, -1.4157e-02, -1.4822e-02,
         -4.3798e-02, -4.1658e-02, -1.4709e-02, -2.5902e-02, -8.7081e-03,
         -3.9880e-02, -1.5114e-02, -1.3367e-02, -3.1035e-02, -3.6392e-02,
          1.2227e-02, -8.7005e-03, -1.9950e-02, -1.3439e-02, -3.7631e-02,
         -3.0060e-02, -1.7583e-03, -4.8765e-02,  1.0541e-03, -1.3689e-02,
         -2.3786e-02,  8.0220e-03, -3.0173e-02, -2.5209e-02, -2.2526e-02,
         -1.9942e-02,  8.4238e-03, -1.9661e-02, -1.2119e-02, -3.4659e-03,
         -3.1803e-02, -3.2865e-03, -1.0539e-02, -3.9146e-03, -4.3804e-02,
          2.2994e-02,  1.2197e-02, -4.6647e-02, -3.5887e-02, -1.4468e-02,
         -3.3255e-03, -1.7044e-02,  2.0406e-02,  1.0396e-02, -2.0522e-02,
         -3.4509e-02, -4.8150e-02, -5.4708e-03,  3.8065e-02, -5.5523e-02,
          3.8816e-03, -6.3457e-02, -2.4241e-02, -9.3510e-03, -1.5897e-02,
         -8.8885e-03, -1.4690e-02, -5.4748e-03, -9.9003e-03, -7.0308e-03,
          3.4854e-03, -6.2360e-04,  1.0930e-02,  2.8643e-02, -1.1186e-02,
         -2.6669e-02, -1.9786e-02,  1.7164e-02, -1.3477e-02, -4.4371e-02,
         -1.4301e-02, -1.3759e-02, -4.0720e-02, -2.1774e-02,  1.6330e-02,
         -2.6441e-02, -4.0575e-02, -3.9297e-02, -9.2287e-03, -2.3262e-02,
         -5.1135e-03,  1.7898e-02,  1.0295e-02, -4.4888e-02, -1.1444e-02,
         -6.7636e-05,  3.0896e-02, -2.1793e-02, -2.7886e-02,  7.3077e-04,
         -7.0966e-03, -2.8983e-02, -2.4230e-02, -4.3455e-03, -3.6372e-02,
         -1.4622e-02, -1.9455e-02, -6.2994e-03, -4.8066e-02,  1.2134e-03,
         -2.6100e-02, -2.2397e-02, -4.3888e-02, -4.5778e-03, -4.2798e-02,
         -4.1344e-03, -4.0403e-02, -1.4517e-02, -7.4589e-03, -2.9797e-02,
         -4.2728e-02, -5.6681e-02, -7.0879e-03,  7.4267e-03,  2.2647e-02,
         -2.2768e-02,  7.6049e-04, -3.0197e-02, -5.4283e-03,  9.8245e-03,
         -1.2252e-03, -2.3723e-02,  3.4096e-02, -1.4257e-02, -3.2253e-02,
         -1.8886e-02, -5.4247e-03, -1.1375e-02, -9.0462e-03, -1.1843e-02,
          1.3237e-02, -2.4774e-02, -2.8040e-02, -3.8893e-02, -2.9173e-02,
         -3.3035e-02, -5.6146e-03, -2.8491e-02, -1.4185e-02, -1.6383e-02,
          1.3736e-03, -2.7760e-02, -4.3374e-03,  1.7261e-02, -2.0601e-02,
         -1.9357e-03, -1.5073e-02, -9.6997e-03, -1.1300e-02, -4.2982e-02,
          8.4574e-03, -3.8737e-02, -1.5231e-02, -2.3515e-02, -1.3568e-02,
          3.3063e-03, -3.3534e-02, -8.0107e-03, -3.6351e-02, -3.9080e-02,
         -8.1655e-03, -8.9546e-03,  4.9051e-03, -6.2526e-03, -4.5883e-02,
         -2.0797e-02, -3.6205e-02, -8.1598e-03, -2.8076e-02, -8.8447e-03,
         -1.9260e-02,  1.1396e-02,  1.5052e-02, -1.6075e-02, -1.5518e-02,
         -1.7724e-02,  2.0844e-02, -2.6688e-02, -3.4171e-02, -2.8748e-02,
          7.2581e-03, -1.6509e-02, -2.8037e-02, -2.2494e-02, -6.6422e-03,
         -3.8462e-02, -4.8222e-02, -4.5790e-02, -1.1145e-02,  4.5953e-02,
         -1.1314e-04,  1.1308e-03, -4.2939e-02, -2.3548e-02,  1.3748e-02,
          4.0744e-03,  8.6413e-03, -1.0417e-03, -5.3433e-02, -4.8686e-03,
          2.5878e-02, -1.2791e-02, -1.8810e-02, -1.7619e-02, -9.7876e-03,
         -2.5285e-02, -2.1384e-02,  1.4755e-02, -3.9157e-02,  1.8993e-02,
          5.0377e-03, -2.9328e-02, -1.6048e-02, -3.0006e-02, -2.8478e-02,
         -8.5162e-03, -1.2241e-02, -1.8590e-02, -2.9219e-03, -2.3340e-02,
         -2.1185e-02, -1.4722e-02, -1.4868e-02, -1.5969e-02, -2.2238e-02,
         -2.0746e-02,  9.0726e-03,  1.1734e-02, -3.8070e-02,  9.3740e-04,
         -3.4404e-02, -5.3068e-02,  7.4766e-03, -3.3690e-02, -2.3907e-02,
         -1.1922e-02, -3.2821e-02, -4.6094e-02,  4.7032e-04, -4.1886e-02,
         -5.7862e-03, -2.4299e-02, -2.8858e-02,  1.1723e-02, -3.0093e-02,
         -4.6471e-02, -4.9816e-03, -2.3448e-03, -2.2391e-02, -3.6809e-02,
         -3.7831e-02,  8.4370e-03, -4.2447e-02, -1.9412e-02, -3.9165e-02,
         -2.3906e-02,  7.2951e-03, -4.2961e-02,  8.2211e-03, -2.2970e-02,
         -1.4029e-02,  1.2471e-03,  3.8190e-02, -5.0079e-03, -4.4626e-02,
         -1.3463e-02, -1.6834e-02,  3.9899e-04, -1.4055e-02, -3.9695e-02,
         -3.6972e-02, -1.7081e-02, -3.0984e-02, -1.9453e-02, -1.2163e-05,
         -1.2716e-02, -9.5281e-03, -2.4193e-02, -3.0648e-02,  8.4034e-03,
         -9.2663e-03, -4.4070e-02, -2.4568e-02, -1.5319e-02, -5.6182e-03,
          6.3644e-03, -1.5009e-02,  1.2869e-02, -7.8058e-03,  5.4362e-03,
          2.2388e-03, -2.6862e-02, -1.5712e-03, -1.8940e-02,  1.3159e-02,
         -1.3461e-02, -3.9902e-02, -5.0591e-02, -1.7753e-02, -1.3713e-02,
          8.0693e-03, -3.5620e-02, -3.3676e-02, -1.3030e-02, -1.6888e-02,
         -2.5140e-02, -3.4833e-02, -7.2791e-03, -3.2956e-02, -2.4693e-02,
         -1.1791e-02, -1.2542e-02, -1.6742e-02, -4.3013e-02, -1.3429e-02,
          1.2613e-03, -4.0043e-02, -1.1774e-02, -3.2534e-02, -3.4204e-02,
          8.6550e-03, -8.3946e-03, -3.6755e-02, -3.3793e-02, -2.7884e-02,
         -7.4445e-03, -1.8833e-03,  1.2610e-02,  9.8851e-03,  1.2191e-02,
         -3.6666e-02, -8.5410e-02, -2.8082e-02, -3.0407e-02, -1.9044e-02,
          2.4342e-03, -1.4180e-03, -2.6470e-02, -2.5302e-02, -2.5253e-02,
         -1.1512e-02, -2.8345e-02, -1.5937e-02,  9.6349e-03, -1.0218e-02,
          1.3560e-02,  1.5391e-02, -1.9179e-02,  1.5864e-02, -1.0996e-02,
         -1.0817e-02,  2.6805e-03, -3.1092e-02, -3.8091e-02, -2.3368e-02,
         -5.9125e-02, -1.0858e-02,  4.5047e-03, -1.8238e-02, -2.1426e-02,
         -1.7773e-02, -2.9463e-02, -3.7479e-03, -4.9064e-03, -1.5818e-02,
         -2.5526e-02, -1.4419e-03, -1.1299e-02,  8.5140e-03, -1.0698e-02,
         -1.1708e-02, -2.0608e-02, -1.4593e-02, -7.7355e-03, -7.3931e-03,
         -4.0843e-02, -2.1167e-02, -1.2983e-02, -2.9919e-03,  3.0490e-03,
         -4.7598e-03, -7.2291e-02, -9.2503e-03, -3.9466e-02, -4.7297e-02,
         -2.1130e-02, -3.5272e-02,  2.0385e-02,  5.3947e-03, -2.0301e-02,
         -9.7881e-03, -1.9998e-02, -6.5725e-02, -4.3420e-02, -3.1609e-02,
         -1.8267e-04, -3.4371e-03, -9.8789e-04,  9.6274e-03, -5.9154e-03,
         -3.4675e-02, -6.5226e-02, -2.0677e-02, -4.1714e-02,  2.1622e-02,
          2.0240e-02, -9.2820e-03, -1.7129e-02, -3.2057e-02, -3.1468e-02,
         -3.4941e-02,  2.3813e-02, -1.6644e-02, -5.0642e-02, -1.6989e-02,
         -2.9996e-02, -2.5404e-02, -2.8092e-02, -4.2349e-02, -3.9435e-02,
         -4.4279e-02, -2.2080e-02,  3.3196e-03, -1.1349e-02,  6.9159e-03,
         -3.3969e-02, -5.3818e-02,  4.0196e-02, -3.8763e-02,  1.4048e-02,
          5.9220e-04, -2.6749e-02, -1.3595e-03, -4.5813e-02, -6.8420e-03,
         -3.4372e-02, -1.8214e-02,  4.0495e-03,  3.8787e-06, -1.8598e-02,
          9.7004e-03, -2.1482e-02, -1.9200e-02, -4.7962e-02, -3.4414e-02,
         -3.2698e-02, -2.5277e-02, -3.4527e-02,  1.4325e-02, -3.6852e-02,
          4.9736e-03, -4.6518e-02, -1.2696e-02, -4.6521e-02, -3.6610e-02,
         -2.4398e-02, -3.2662e-02, -2.5911e-03, -5.8092e-02,  2.9025e-02,
         -2.1087e-02, -1.7487e-02, -3.1389e-02, -4.2529e-02, -1.0128e-02,
         -1.7335e-02,  2.8430e-02,  3.9904e-02,  8.0061e-04, -3.1003e-02,
         -7.1200e-02, -2.8507e-03, -5.9049e-02, -1.5139e-02,  5.0690e-03,
         -1.6833e-02, -9.0752e-03, -2.3263e-02, -2.1165e-02, -4.3393e-02,
         -8.7630e-03, -1.3716e-02, -2.7933e-02, -4.8012e-02, -1.4200e-02,
         -5.1839e-02, -6.0081e-03, -1.8939e-02, -1.7114e-02, -4.1764e-02,
         -5.2397e-03, -5.4814e-03, -2.0793e-02, -4.0475e-02, -4.4624e-02,
         -7.9084e-03, -3.5071e-03,  2.0474e-02, -2.6987e-02, -1.4414e-02,
         -1.9035e-02, -4.9324e-02, -2.8345e-02,  1.4301e-02, -3.8973e-02,
         -1.2840e-02, -7.5258e-03, -4.6916e-02, -4.7070e-02, -1.3649e-02,
         -5.4320e-02, -1.8288e-03, -1.8652e-03, -2.7375e-02,  1.1466e-02,
         -4.0584e-02, -1.2032e-02, -3.9389e-02, -2.1145e-02,  2.4070e-03,
          9.3934e-03, -3.9291e-02, -5.9169e-02, -4.5224e-03, -1.4565e-02,
         -2.3315e-02, -3.0413e-02, -1.4424e-02, -1.6966e-02,  1.0072e-02,
          3.6617e-02, -3.9734e-02, -3.2399e-02, -1.3331e-02, -2.1236e-02,
          2.2823e-02, -1.9419e-02, -4.0604e-03, -1.3728e-02, -1.8695e-02,
         -2.6998e-02, -1.7203e-02, -6.4163e-03, -1.3199e-02, -5.5872e-02,
         -3.5325e-02, -3.1695e-02, -4.9119e-02,  4.0982e-02,  1.8657e-02,
         -3.3573e-02, -8.9048e-03,  1.6459e-02, -3.6141e-02, -3.5255e-02,
         -2.0351e-02,  3.6519e-02, -1.1686e-02,  2.1606e-02,  1.8557e-02,
         -4.5092e-03, -9.0398e-03,  2.1982e-02, -3.4125e-02,  1.8775e-02,
         -5.1349e-02, -2.0664e-03, -1.0744e-02, -1.6671e-02,  2.6162e-02,
         -6.4523e-03, -5.7046e-02, -3.6390e-03, -1.9814e-02, -1.6118e-02,
          6.7051e-03, -5.2483e-03,  8.4542e-04, -2.6400e-02, -6.1003e-03,
         -1.2574e-02, -3.9921e-02, -2.9327e-02, -2.4630e-02,  8.4810e-03,
         -7.4100e-04, -1.8916e-02,  5.1565e-03,  2.2242e-02, -9.2054e-03,
         -5.8127e-02, -1.7812e-03, -1.1566e-02, -1.5581e-02, -2.4738e-02,
         -8.5652e-03, -1.4644e-02, -1.7377e-02, -7.8154e-03,  8.7701e-03,
         -1.5758e-02, -2.9299e-02, -5.7990e-02,  5.2301e-03, -1.7015e-03,
         -1.0382e-02, -6.0044e-03, -2.6569e-02, -1.6470e-03,  1.8650e-03,
          1.0926e-02, -2.2354e-02,  1.7114e-02, -7.1626e-03, -4.9205e-02,
         -1.3529e-02,  2.1432e-02, -1.5802e-02, -2.3511e-02, -1.6134e-02,
         -3.9555e-02,  2.8150e-02, -9.2762e-03, -8.4562e-03, -2.7197e-02,
         -7.0721e-03, -4.0385e-03, -4.7109e-02, -5.2178e-03, -4.8849e-02,
          1.6391e-02, -3.0436e-02, -2.0354e-02, -1.7472e-02, -1.0822e-02,
         -3.9952e-02, -3.1226e-02, -5.1212e-02,  1.2849e-02, -4.3737e-02,
         -1.6600e-02, -1.7369e-02, -3.5132e-02, -7.9695e-03, -1.9029e-02,
         -2.9353e-02, -2.5525e-02, -1.2254e-02,  1.0975e-03, -4.0945e-02,
         -1.6960e-02, -4.7521e-03, -1.3975e-02, -1.2778e-02, -2.7528e-02,
         -3.3573e-02, -4.6857e-03, -4.8495e-03, -1.5761e-02, -1.7572e-02,
         -1.5772e-02, -7.3530e-03, -3.1005e-02, -1.7780e-02, -1.4125e-02,
         -2.0564e-02, -1.9258e-02, -1.5787e-02, -2.5870e-02,  8.4195e-03,
          1.2669e-02, -1.9583e-02, -1.6337e-02, -1.2081e-02,  7.1074e-03,
         -4.5319e-02, -2.1659e-02, -1.2411e-02, -2.7327e-02, -1.0128e-02,
         -3.7986e-02, -1.6327e-02, -5.8103e-03, -1.7206e-02, -1.4065e-02,
          2.7339e-02, -2.2147e-02, -3.9057e-02, -8.3084e-03, -2.7950e-02,
         -1.3844e-02, -1.8129e-02, -4.8987e-02,  1.5473e-02, -2.5392e-02,
         -3.8005e-02, -4.3275e-02, -1.0993e-02, -5.9326e-03, -6.6074e-02,
         -4.9379e-03, -2.7258e-02, -2.5302e-02, -3.8126e-02, -3.0043e-02,
         -8.6250e-03, -4.3281e-03, -5.0636e-02, -5.5711e-02, -2.7074e-02,
         -3.6164e-02, -1.2752e-02, -1.9970e-02, -2.1273e-02, -5.8114e-03,
         -6.4127e-02, -2.3056e-02,  2.3241e-03, -3.5551e-02, -1.8637e-02,
         -2.2455e-02, -3.8589e-02,  3.4994e-03, -5.7992e-03,  9.8726e-03,
         -4.2325e-02, -3.3603e-02,  9.3079e-03]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 46.6000% F1: 0.3489
Applying ckpt from fold 1 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 46.2000% F1: 0.3568
Applying ckpt from fold 2 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.2000% F1: 0.3512
Applying ckpt from fold 3 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 41.4000% F1: 0.3193
Applying ckpt from fold 4 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 36.8000% F1: 0.3035
Applying ckpt from fold 5 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 40.8000% F1: 0.3246
Applying ckpt from fold 6 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.4000% F1: 0.3579
Applying ckpt from fold 7 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 39.0000% F1: 0.3179
Applying ckpt from fold 8 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.0000% F1: 0.3458
Applying ckpt from fold 9 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 43.4000% F1: 0.3450
Metrics by fold:
Fold 0 - Acc: 0.47 F1: 0.35
Fold 1 - Acc: 0.46 F1: 0.36
Fold 2 - Acc: 0.53 F1: 0.35
Fold 3 - Acc: 0.41 F1: 0.32
Fold 4 - Acc: 0.37 F1: 0.30
Fold 5 - Acc: 0.41 F1: 0.32
Fold 6 - Acc: 0.53 F1: 0.36
Fold 7 - Acc: 0.39 F1: 0.32
Fold 8 - Acc: 0.45 F1: 0.35
Fold 9 - Acc: 0.43 F1: 0.35
agg_acc: 0.4458 agg_f1: 0.3371
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-1.9576e-02,  1.4462e-02,  2.1089e-02, -2.4213e-02, -3.1370e-02,
         -1.4199e-02, -2.5904e-02, -5.0341e-02, -3.6889e-02, -3.2728e-02,
         -6.8087e-04, -3.5233e-02, -3.9792e-02, -2.0962e-02, -7.1844e-03,
         -9.9852e-03, -2.8043e-02, -2.2781e-02, -4.4245e-03, -4.3463e-02,
         -4.1087e-02, -4.5657e-02, -1.9222e-02, -7.8390e-03, -2.0070e-02,
         -3.9880e-02,  1.8200e-02, -2.9268e-02, -1.6676e-02, -2.1610e-02,
         -2.6654e-02, -2.5254e-02,  9.2145e-03, -4.5557e-02, -3.3439e-02,
         -7.2401e-03, -2.6082e-02,  1.0227e-02, -1.4157e-02, -1.4822e-02,
         -4.3798e-02, -4.1658e-02, -1.4709e-02, -2.5902e-02, -8.7081e-03,
         -3.9880e-02, -1.5114e-02, -1.3367e-02, -3.1035e-02, -3.6392e-02,
          1.2227e-02, -8.7005e-03, -1.9950e-02, -1.3439e-02, -3.7631e-02,
         -3.0060e-02, -1.7583e-03, -4.8765e-02,  1.0541e-03, -1.3689e-02,
         -2.3786e-02,  8.0220e-03, -3.0173e-02, -2.5209e-02, -2.2526e-02,
         -1.9942e-02,  8.4238e-03, -1.9661e-02, -1.2119e-02, -3.4659e-03,
         -3.1803e-02, -3.2865e-03, -1.0539e-02, -3.9146e-03, -4.3804e-02,
          2.2994e-02,  1.2197e-02, -4.6647e-02, -3.5887e-02, -1.4468e-02,
         -3.3255e-03, -1.7044e-02,  2.0406e-02,  1.0396e-02, -2.0522e-02,
         -3.4509e-02, -4.8150e-02, -5.4708e-03,  3.8065e-02, -5.5523e-02,
          3.8816e-03, -6.3457e-02, -2.4241e-02, -9.3510e-03, -1.5897e-02,
         -8.8885e-03, -1.4690e-02, -5.4748e-03, -9.9003e-03, -7.0308e-03,
          3.4854e-03, -6.2360e-04,  1.0930e-02,  2.8643e-02, -1.1186e-02,
         -2.6669e-02, -1.9786e-02,  1.7164e-02, -1.3477e-02, -4.4371e-02,
         -1.4301e-02, -1.3759e-02, -4.0720e-02, -2.1774e-02,  1.6330e-02,
         -2.6441e-02, -4.0575e-02, -3.9297e-02, -9.2287e-03, -2.3262e-02,
         -5.1135e-03,  1.7898e-02,  1.0295e-02, -4.4888e-02, -1.1444e-02,
         -6.7636e-05,  3.0896e-02, -2.1793e-02, -2.7886e-02,  7.3077e-04,
         -7.0966e-03, -2.8983e-02, -2.4230e-02, -4.3455e-03, -3.6372e-02,
         -1.4622e-02, -1.9455e-02, -6.2994e-03, -4.8066e-02,  1.2134e-03,
         -2.6100e-02, -2.2397e-02, -4.3888e-02, -4.5778e-03, -4.2798e-02,
         -4.1344e-03, -4.0403e-02, -1.4517e-02, -7.4589e-03, -2.9797e-02,
         -4.2728e-02, -5.6681e-02, -7.0879e-03,  7.4267e-03,  2.2647e-02,
         -2.2768e-02,  7.6049e-04, -3.0197e-02, -5.4283e-03,  9.8245e-03,
         -1.2252e-03, -2.3723e-02,  3.4096e-02, -1.4257e-02, -3.2253e-02,
         -1.8886e-02, -5.4247e-03, -1.1375e-02, -9.0462e-03, -1.1843e-02,
          1.3237e-02, -2.4774e-02, -2.8040e-02, -3.8893e-02, -2.9173e-02,
         -3.3035e-02, -5.6146e-03, -2.8491e-02, -1.4185e-02, -1.6383e-02,
          1.3736e-03, -2.7760e-02, -4.3374e-03,  1.7261e-02, -2.0601e-02,
         -1.9357e-03, -1.5073e-02, -9.6997e-03, -1.1300e-02, -4.2982e-02,
          8.4574e-03, -3.8737e-02, -1.5231e-02, -2.3515e-02, -1.3568e-02,
          3.3063e-03, -3.3534e-02, -8.0107e-03, -3.6351e-02, -3.9080e-02,
         -8.1655e-03, -8.9546e-03,  4.9051e-03, -6.2526e-03, -4.5883e-02,
         -2.0797e-02, -3.6205e-02, -8.1598e-03, -2.8076e-02, -8.8447e-03,
         -1.9260e-02,  1.1396e-02,  1.5052e-02, -1.6075e-02, -1.5518e-02,
         -1.7724e-02,  2.0844e-02, -2.6688e-02, -3.4171e-02, -2.8748e-02,
          7.2581e-03, -1.6509e-02, -2.8037e-02, -2.2494e-02, -6.6422e-03,
         -3.8462e-02, -4.8222e-02, -4.5790e-02, -1.1145e-02,  4.5953e-02,
         -1.1314e-04,  1.1308e-03, -4.2939e-02, -2.3548e-02,  1.3748e-02,
          4.0744e-03,  8.6413e-03, -1.0417e-03, -5.3433e-02, -4.8686e-03,
          2.5878e-02, -1.2791e-02, -1.8810e-02, -1.7619e-02, -9.7876e-03,
         -2.5285e-02, -2.1384e-02,  1.4755e-02, -3.9157e-02,  1.8993e-02,
          5.0377e-03, -2.9328e-02, -1.6048e-02, -3.0006e-02, -2.8478e-02,
         -8.5162e-03, -1.2241e-02, -1.8590e-02, -2.9219e-03, -2.3340e-02,
         -2.1185e-02, -1.4722e-02, -1.4868e-02, -1.5969e-02, -2.2238e-02,
         -2.0746e-02,  9.0726e-03,  1.1734e-02, -3.8070e-02,  9.3740e-04,
         -3.4404e-02, -5.3068e-02,  7.4766e-03, -3.3690e-02, -2.3907e-02,
         -1.1922e-02, -3.2821e-02, -4.6094e-02,  4.7032e-04, -4.1886e-02,
         -5.7862e-03, -2.4299e-02, -2.8858e-02,  1.1723e-02, -3.0093e-02,
         -4.6471e-02, -4.9816e-03, -2.3448e-03, -2.2391e-02, -3.6809e-02,
         -3.7831e-02,  8.4370e-03, -4.2447e-02, -1.9412e-02, -3.9165e-02,
         -2.3906e-02,  7.2951e-03, -4.2961e-02,  8.2211e-03, -2.2970e-02,
         -1.4029e-02,  1.2471e-03,  3.8190e-02, -5.0079e-03, -4.4626e-02,
         -1.3463e-02, -1.6834e-02,  3.9899e-04, -1.4055e-02, -3.9695e-02,
         -3.6972e-02, -1.7081e-02, -3.0984e-02, -1.9453e-02, -1.2163e-05,
         -1.2716e-02, -9.5281e-03, -2.4193e-02, -3.0648e-02,  8.4034e-03,
         -9.2663e-03, -4.4070e-02, -2.4568e-02, -1.5319e-02, -5.6182e-03,
          6.3644e-03, -1.5009e-02,  1.2869e-02, -7.8058e-03,  5.4362e-03,
          2.2388e-03, -2.6862e-02, -1.5712e-03, -1.8940e-02,  1.3159e-02,
         -1.3461e-02, -3.9902e-02, -5.0591e-02, -1.7753e-02, -1.3713e-02,
          8.0693e-03, -3.5620e-02, -3.3676e-02, -1.3030e-02, -1.6888e-02,
         -2.5140e-02, -3.4833e-02, -7.2791e-03, -3.2956e-02, -2.4693e-02,
         -1.1791e-02, -1.2542e-02, -1.6742e-02, -4.3013e-02, -1.3429e-02,
          1.2613e-03, -4.0043e-02, -1.1774e-02, -3.2534e-02, -3.4204e-02,
          8.6550e-03, -8.3946e-03, -3.6755e-02, -3.3793e-02, -2.7884e-02,
         -7.4445e-03, -1.8833e-03,  1.2610e-02,  9.8851e-03,  1.2191e-02,
         -3.6666e-02, -8.5410e-02, -2.8082e-02, -3.0407e-02, -1.9044e-02,
          2.4342e-03, -1.4180e-03, -2.6470e-02, -2.5302e-02, -2.5253e-02,
         -1.1512e-02, -2.8345e-02, -1.5937e-02,  9.6349e-03, -1.0218e-02,
          1.3560e-02,  1.5391e-02, -1.9179e-02,  1.5864e-02, -1.0996e-02,
         -1.0817e-02,  2.6805e-03, -3.1092e-02, -3.8091e-02, -2.3368e-02,
         -5.9125e-02, -1.0858e-02,  4.5047e-03, -1.8238e-02, -2.1426e-02,
         -1.7773e-02, -2.9463e-02, -3.7479e-03, -4.9064e-03, -1.5818e-02,
         -2.5526e-02, -1.4419e-03, -1.1299e-02,  8.5140e-03, -1.0698e-02,
         -1.1708e-02, -2.0608e-02, -1.4593e-02, -7.7355e-03, -7.3931e-03,
         -4.0843e-02, -2.1167e-02, -1.2983e-02, -2.9919e-03,  3.0490e-03,
         -4.7598e-03, -7.2291e-02, -9.2503e-03, -3.9466e-02, -4.7297e-02,
         -2.1130e-02, -3.5272e-02,  2.0385e-02,  5.3947e-03, -2.0301e-02,
         -9.7881e-03, -1.9998e-02, -6.5725e-02, -4.3420e-02, -3.1609e-02,
         -1.8267e-04, -3.4371e-03, -9.8789e-04,  9.6274e-03, -5.9154e-03,
         -3.4675e-02, -6.5226e-02, -2.0677e-02, -4.1714e-02,  2.1622e-02,
          2.0240e-02, -9.2820e-03, -1.7129e-02, -3.2057e-02, -3.1468e-02,
         -3.4941e-02,  2.3813e-02, -1.6644e-02, -5.0642e-02, -1.6989e-02,
         -2.9996e-02, -2.5404e-02, -2.8092e-02, -4.2349e-02, -3.9435e-02,
         -4.4279e-02, -2.2080e-02,  3.3196e-03, -1.1349e-02,  6.9159e-03,
         -3.3969e-02, -5.3818e-02,  4.0196e-02, -3.8763e-02,  1.4048e-02,
          5.9220e-04, -2.6749e-02, -1.3595e-03, -4.5813e-02, -6.8420e-03,
         -3.4372e-02, -1.8214e-02,  4.0495e-03,  3.8787e-06, -1.8598e-02,
          9.7004e-03, -2.1482e-02, -1.9200e-02, -4.7962e-02, -3.4414e-02,
         -3.2698e-02, -2.5277e-02, -3.4527e-02,  1.4325e-02, -3.6852e-02,
          4.9736e-03, -4.6518e-02, -1.2696e-02, -4.6521e-02, -3.6610e-02,
         -2.4398e-02, -3.2662e-02, -2.5911e-03, -5.8092e-02,  2.9025e-02,
         -2.1087e-02, -1.7487e-02, -3.1389e-02, -4.2529e-02, -1.0128e-02,
         -1.7335e-02,  2.8430e-02,  3.9904e-02,  8.0061e-04, -3.1003e-02,
         -7.1200e-02, -2.8507e-03, -5.9049e-02, -1.5139e-02,  5.0690e-03,
         -1.6833e-02, -9.0752e-03, -2.3263e-02, -2.1165e-02, -4.3393e-02,
         -8.7630e-03, -1.3716e-02, -2.7933e-02, -4.8012e-02, -1.4200e-02,
         -5.1839e-02, -6.0081e-03, -1.8939e-02, -1.7114e-02, -4.1764e-02,
         -5.2397e-03, -5.4814e-03, -2.0793e-02, -4.0475e-02, -4.4624e-02,
         -7.9084e-03, -3.5071e-03,  2.0474e-02, -2.6987e-02, -1.4414e-02,
         -1.9035e-02, -4.9324e-02, -2.8345e-02,  1.4301e-02, -3.8973e-02,
         -1.2840e-02, -7.5258e-03, -4.6916e-02, -4.7070e-02, -1.3649e-02,
         -5.4320e-02, -1.8288e-03, -1.8652e-03, -2.7375e-02,  1.1466e-02,
         -4.0584e-02, -1.2032e-02, -3.9389e-02, -2.1145e-02,  2.4070e-03,
          9.3934e-03, -3.9291e-02, -5.9169e-02, -4.5224e-03, -1.4565e-02,
         -2.3315e-02, -3.0413e-02, -1.4424e-02, -1.6966e-02,  1.0072e-02,
          3.6617e-02, -3.9734e-02, -3.2399e-02, -1.3331e-02, -2.1236e-02,
          2.2823e-02, -1.9419e-02, -4.0604e-03, -1.3728e-02, -1.8695e-02,
         -2.6998e-02, -1.7203e-02, -6.4163e-03, -1.3199e-02, -5.5872e-02,
         -3.5325e-02, -3.1695e-02, -4.9119e-02,  4.0982e-02,  1.8657e-02,
         -3.3573e-02, -8.9048e-03,  1.6459e-02, -3.6141e-02, -3.5255e-02,
         -2.0351e-02,  3.6519e-02, -1.1686e-02,  2.1606e-02,  1.8557e-02,
         -4.5092e-03, -9.0398e-03,  2.1982e-02, -3.4125e-02,  1.8775e-02,
         -5.1349e-02, -2.0664e-03, -1.0744e-02, -1.6671e-02,  2.6162e-02,
         -6.4523e-03, -5.7046e-02, -3.6390e-03, -1.9814e-02, -1.6118e-02,
          6.7051e-03, -5.2483e-03,  8.4542e-04, -2.6400e-02, -6.1003e-03,
         -1.2574e-02, -3.9921e-02, -2.9327e-02, -2.4630e-02,  8.4810e-03,
         -7.4100e-04, -1.8916e-02,  5.1565e-03,  2.2242e-02, -9.2054e-03,
         -5.8127e-02, -1.7812e-03, -1.1566e-02, -1.5581e-02, -2.4738e-02,
         -8.5652e-03, -1.4644e-02, -1.7377e-02, -7.8154e-03,  8.7701e-03,
         -1.5758e-02, -2.9299e-02, -5.7990e-02,  5.2301e-03, -1.7015e-03,
         -1.0382e-02, -6.0044e-03, -2.6569e-02, -1.6470e-03,  1.8650e-03,
          1.0926e-02, -2.2354e-02,  1.7114e-02, -7.1626e-03, -4.9205e-02,
         -1.3529e-02,  2.1432e-02, -1.5802e-02, -2.3511e-02, -1.6134e-02,
         -3.9555e-02,  2.8150e-02, -9.2762e-03, -8.4562e-03, -2.7197e-02,
         -7.0721e-03, -4.0385e-03, -4.7109e-02, -5.2178e-03, -4.8849e-02,
          1.6391e-02, -3.0436e-02, -2.0354e-02, -1.7472e-02, -1.0822e-02,
         -3.9952e-02, -3.1226e-02, -5.1212e-02,  1.2849e-02, -4.3737e-02,
         -1.6600e-02, -1.7369e-02, -3.5132e-02, -7.9695e-03, -1.9029e-02,
         -2.9353e-02, -2.5525e-02, -1.2254e-02,  1.0975e-03, -4.0945e-02,
         -1.6960e-02, -4.7521e-03, -1.3975e-02, -1.2778e-02, -2.7528e-02,
         -3.3573e-02, -4.6857e-03, -4.8495e-03, -1.5761e-02, -1.7572e-02,
         -1.5772e-02, -7.3530e-03, -3.1005e-02, -1.7780e-02, -1.4125e-02,
         -2.0564e-02, -1.9258e-02, -1.5787e-02, -2.5870e-02,  8.4195e-03,
          1.2669e-02, -1.9583e-02, -1.6337e-02, -1.2081e-02,  7.1074e-03,
         -4.5319e-02, -2.1659e-02, -1.2411e-02, -2.7327e-02, -1.0128e-02,
         -3.7986e-02, -1.6327e-02, -5.8103e-03, -1.7206e-02, -1.4065e-02,
          2.7339e-02, -2.2147e-02, -3.9057e-02, -8.3084e-03, -2.7950e-02,
         -1.3844e-02, -1.8129e-02, -4.8987e-02,  1.5473e-02, -2.5392e-02,
         -3.8005e-02, -4.3275e-02, -1.0993e-02, -5.9326e-03, -6.6074e-02,
         -4.9379e-03, -2.7258e-02, -2.5302e-02, -3.8126e-02, -3.0043e-02,
         -8.6250e-03, -4.3281e-03, -5.0636e-02, -5.5711e-02, -2.7074e-02,
         -3.6164e-02, -1.2752e-02, -1.9970e-02, -2.1273e-02, -5.8114e-03,
         -6.4127e-02, -2.3056e-02,  2.3241e-03, -3.5551e-02, -1.8637e-02,
         -2.2455e-02, -3.8589e-02,  3.4994e-03, -5.7992e-03,  9.8726e-03,
         -4.2325e-02, -3.3603e-02,  9.3079e-03]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 41.8000% F1: 0.3278
Applying ckpt from fold 1 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 43.8000% F1: 0.3436
Applying ckpt from fold 2 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.2000% F1: 0.3385
Applying ckpt from fold 3 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 43.6000% F1: 0.3368
Applying ckpt from fold 4 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 36.6000% F1: 0.3141
Applying ckpt from fold 5 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 40.4000% F1: 0.3278
Applying ckpt from fold 6 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.4000% F1: 0.3343
Applying ckpt from fold 7 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.0000% F1: 0.3536
Applying ckpt from fold 8 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.2000% F1: 0.3510
Applying ckpt from fold 9 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 44.4000% F1: 0.3375
Metrics by fold:
Fold 0 - Acc: 0.42 F1: 0.33
Fold 1 - Acc: 0.44 F1: 0.34
Fold 2 - Acc: 0.45 F1: 0.34
Fold 3 - Acc: 0.44 F1: 0.34
Fold 4 - Acc: 0.37 F1: 0.31
Fold 5 - Acc: 0.40 F1: 0.33
Fold 6 - Acc: 0.45 F1: 0.33
Fold 7 - Acc: 0.48 F1: 0.35
Fold 8 - Acc: 0.47 F1: 0.35
Fold 9 - Acc: 0.44 F1: 0.34
agg_acc: 0.4364 agg_f1: 0.3365
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-2.0626e-02, -4.4060e-02, -2.6161e-02, -5.2382e-02, -1.1801e-02,
         -2.1239e-02, -1.8071e-02, -3.0182e-02, -3.2382e-02, -2.0418e-02,
         -2.6720e-02, -4.3357e-02, -2.5472e-02,  5.5979e-03,  1.2318e-02,
         -3.4176e-02, -4.4977e-02, -2.8053e-02, -2.1231e-02, -6.0782e-02,
         -4.0279e-02, -3.8476e-02, -1.6334e-02, -3.2569e-02, -2.5926e-02,
         -2.7391e-02, -2.3964e-02, -3.0589e-02, -2.9190e-02, -3.3341e-02,
         -1.8691e-02, -3.5133e-02, -6.1570e-02, -1.4964e-02, -2.1376e-02,
         -3.1147e-02, -3.0501e-02,  1.4628e-03, -1.8252e-02, -1.9517e-02,
         -1.1622e-02, -3.5739e-02, -3.6812e-02, -1.9371e-02, -1.1859e-02,
         -8.8161e-03, -3.1636e-02, -2.0528e-02, -1.1131e-02, -3.5867e-02,
         -3.8365e-02, -2.5705e-02, -2.1792e-02, -4.4399e-02, -4.0270e-02,
         -5.4638e-02, -2.8454e-02, -2.5333e-02, -2.5547e-02, -1.5287e-02,
         -2.4182e-02, -3.0630e-02,  1.5069e-02, -3.6271e-02, -2.8401e-02,
         -1.5753e-02, -3.0542e-02, -4.4240e-02, -2.0518e-02,  1.3146e-02,
         -2.6623e-02, -5.8353e-03, -6.2991e-02, -2.9645e-02, -5.2723e-02,
         -6.1875e-03, -4.6658e-02, -1.1706e-02, -2.0831e-02, -2.1911e-02,
         -3.0621e-02, -3.0604e-02, -3.1597e-02, -1.4894e-02, -3.7422e-02,
         -1.8669e-02, -3.9261e-02, -2.2540e-02, -3.5005e-02, -1.8804e-02,
         -3.9859e-02, -2.3636e-02, -4.4098e-02, -2.2001e-02, -4.0159e-02,
         -4.1603e-02, -6.0479e-02, -3.4732e-02, -3.5348e-02, -1.1855e-02,
         -1.1457e-02, -1.8017e-02, -2.5695e-02, -3.2170e-02, -1.8815e-02,
          6.0778e-04, -2.9451e-02, -1.5095e-02, -3.4335e-02, -1.8684e-02,
         -5.2852e-02, -2.8976e-02, -4.0829e-02, -1.9680e-02, -1.9389e-02,
         -2.6357e-02, -1.0519e-02, -3.3680e-02, -3.3897e-02, -1.6169e-02,
         -2.5509e-02,  6.1193e-03, -2.6227e-02, -4.9142e-02, -5.1203e-02,
         -2.7614e-02, -2.7042e-02, -8.2370e-02, -3.2448e-02, -6.2488e-02,
         -2.4354e-02, -5.3159e-02,  2.3348e-02, -3.0051e-02, -2.0879e-02,
         -1.0396e-02, -1.9578e-02, -2.8474e-02, -2.0294e-02, -6.0514e-03,
         -3.1489e-02, -2.7566e-02, -8.3959e-03, -8.8849e-03, -3.2843e-02,
         -3.9592e-02, -2.8364e-02, -3.0351e-02, -3.9907e-02, -2.9026e-02,
         -4.1853e-02, -1.4049e-02, -5.6452e-02, -2.7035e-02, -3.0331e-02,
         -2.6986e-02, -1.8532e-02, -1.1369e-02, -4.2319e-02, -1.0535e-01,
         -2.5081e-02, -2.4970e-02, -1.3560e-02, -3.2619e-02, -2.3543e-02,
         -3.1439e-02, -1.0665e-02, -2.8571e-02, -2.4338e-02, -2.9927e-02,
         -2.2083e-02, -1.0367e-02, -3.6159e-02, -3.5902e-02, -3.8141e-02,
          2.2199e-02, -3.4954e-02, -4.2879e-02, -2.6929e-02, -6.4845e-03,
         -2.5604e-02, -2.3864e-02, -6.5536e-02, -1.1395e-02, -2.0720e-02,
         -1.9895e-02, -3.2456e-02, -4.2429e-02, -2.7246e-02, -7.3045e-03,
         -7.3728e-03, -4.4053e-02, -4.0074e-02, -3.2210e-02, -5.1612e-02,
         -3.5234e-02, -4.5111e-02, -1.9451e-02, -3.2387e-02, -4.2629e-02,
         -2.9188e-02, -9.1431e-03, -5.6937e-03, -3.6857e-02, -3.5655e-02,
         -1.4412e-02, -1.6586e-02, -4.8305e-02, -2.0054e-02, -2.2196e-03,
         -2.6737e-02, -2.1182e-02, -3.0844e-02, -2.2878e-02, -2.6762e-02,
         -2.2593e-02, -1.2894e-01, -2.6952e-03, -4.7206e-02, -1.9133e-02,
         -1.6194e-02, -3.4907e-02, -3.0068e-02, -8.7365e-03, -2.4353e-02,
         -1.0010e-01, -3.6861e-02, -4.0455e-02, -3.1136e-02, -5.0729e-02,
         -2.6141e-02, -2.6761e-02, -4.6217e-02, -3.6219e-02, -2.3151e-02,
         -1.7108e-02, -3.9074e-02, -1.9915e-02, -1.2001e-02, -3.7315e-02,
         -3.3087e-02, -2.6547e-02, -4.3930e-02, -4.6760e-02, -2.4470e-02,
          5.5595e-05, -4.3790e-02, -2.8079e-02, -3.8258e-02, -4.1491e-02,
         -3.3981e-02, -2.7939e-02, -2.7030e-02, -1.2909e-02, -4.0956e-02,
         -2.1886e-02, -2.3271e-02, -2.3112e-02, -2.3970e-02, -1.5977e-02,
         -1.6904e-02, -3.9638e-02, -1.4792e-02, -4.5347e-02, -3.1461e-02,
         -2.8825e-02, -1.2313e-02, -3.7781e-02,  2.4980e-03, -2.8167e-02,
         -3.1846e-02, -3.3554e-02, -2.1765e-02, -2.0045e-02, -4.7427e-02,
         -1.8519e-02, -2.8280e-02, -4.4778e-02, -1.3524e-02, -3.2319e-03,
         -2.9903e-02, -3.1917e-02, -2.2511e-02, -5.9006e-02,  1.5946e-03,
         -2.4006e-02, -1.7079e-02, -2.9951e-02, -2.5281e-02, -5.0775e-02,
         -4.3378e-02,  8.9525e-04, -1.6057e-02, -1.3209e-03, -1.9282e-02,
         -3.7466e-02, -7.5034e-02, -3.4903e-02, -2.6046e-02, -6.0244e-02,
         -2.3133e-02, -3.6307e-02, -1.1735e-02, -1.5822e-02, -5.8465e-02,
         -9.4279e-03, -2.4606e-02, -1.6206e-02,  6.8120e-03, -3.1115e-02,
         -2.9297e-02, -3.0197e-02, -2.0291e-02, -1.5730e-02, -2.9399e-02,
         -5.8700e-02, -4.9440e-02, -1.4964e-02, -1.4682e-02, -4.7326e-02,
          1.9171e-03, -2.7425e-02, -3.2663e-02, -4.0381e-02, -2.2076e-02,
         -7.2282e-03, -1.7059e-02, -1.3517e-02, -2.6359e-02, -4.3907e-03,
         -3.9467e-02, -6.9909e-02, -3.6269e-02, -3.8785e-02, -2.7625e-02,
         -3.0422e-02, -3.4326e-02, -4.1373e-03, -2.0417e-02, -2.2334e-02,
         -1.4535e-02, -1.3532e-02, -3.6567e-02, -2.2748e-02, -1.6989e-02,
          1.4371e-03, -4.1189e-02, -4.5399e-02, -3.9660e-02, -2.7661e-02,
         -2.3461e-02, -2.6766e-02, -3.6177e-02, -5.6810e-02, -2.0876e-02,
         -3.5100e-02, -4.1278e-02, -2.1627e-02, -3.7129e-03, -1.9762e-02,
         -1.7184e-02, -2.7223e-02, -2.7576e-02, -9.1357e-04, -1.6475e-02,
         -4.0762e-02, -2.2704e-02, -3.2532e-02, -2.5827e-02, -3.1545e-02,
         -1.7120e-02, -3.9241e-02, -2.4638e-02, -2.9520e-02, -3.0369e-02,
         -2.5346e-02, -2.1294e-02, -4.9278e-02, -2.7448e-02, -3.7034e-02,
         -6.7724e-03, -5.7087e-02, -2.8008e-02,  6.8865e-03, -4.9772e-02,
         -4.4891e-02, -3.4240e-02, -5.1939e-02, -2.3135e-02, -1.4994e-02,
         -3.6481e-02, -1.6013e-02, -4.1644e-02, -3.7349e-02, -1.8343e-02,
         -2.8021e-02, -2.3944e-02, -3.5851e-02, -4.4354e-02, -1.8169e-02,
         -2.3095e-02, -9.4431e-02, -3.8140e-02, -3.4660e-02, -3.6032e-02,
         -2.0042e-02, -2.4378e-02, -1.2028e-02, -2.0953e-02, -2.1721e-02,
         -3.2877e-02, -3.8856e-02, -4.7931e-02, -3.5312e-02, -2.8105e-02,
         -4.7969e-02, -1.0577e-02, -5.4178e-02, -1.9335e-02,  1.4594e-02,
         -5.6146e-03, -2.8620e-02, -3.7851e-02, -1.9913e-02, -4.2189e-02,
         -1.0320e-02, -2.1976e-02, -5.2133e-02, -4.3729e-02, -5.4553e-02,
         -3.5142e-02, -3.7726e-02, -2.6058e-02, -1.1231e-02, -3.2618e-02,
         -4.3355e-02, -1.7774e-02, -3.1622e-02, -2.8229e-02, -2.1421e-02,
         -2.9999e-02, -3.1010e-02, -2.5497e-02, -4.5435e-03, -4.1343e-02,
         -3.2268e-02, -2.0374e-02, -1.9872e-02, -4.6008e-02, -2.8307e-02,
         -1.1835e-02, -2.2528e-02, -2.8635e-02, -2.5755e-02, -2.2962e-02,
         -1.1313e-02, -3.7581e-02, -1.8534e-02, -1.6939e-02, -2.5694e-02,
         -4.5719e-02,  2.1832e-02, -1.5461e-02, -1.8565e-02, -2.3459e-02,
         -6.4967e-02, -2.7417e-02, -2.3490e-02, -2.3226e-02, -4.4696e-02,
         -6.2122e-03, -6.0652e-02, -5.4693e-02, -2.0045e-02, -3.9188e-02,
         -1.6182e-02, -1.6512e-02, -8.1976e-03, -3.2709e-02, -2.5799e-02,
         -2.4841e-03, -2.1700e-02,  4.9436e-03, -2.0033e-02, -1.6611e-02,
         -2.2917e-02, -3.5269e-02, -2.3938e-02, -2.5108e-02, -2.5692e-02,
         -1.4544e-02, -1.7141e-02, -1.6639e-02, -3.4002e-02, -2.0499e-02,
         -3.2127e-02, -6.7373e-02, -1.1025e-02, -3.1973e-02, -2.3749e-02,
         -9.4430e-03, -4.9020e-02, -4.0693e-02, -3.4095e-02, -3.2654e-02,
         -4.3039e-02, -3.7553e-02, -3.2732e-02, -2.8386e-02, -2.5889e-02,
         -4.1052e-02, -4.8210e-02, -3.5973e-02, -3.5697e-02, -3.5337e-02,
         -3.0920e-02, -8.5859e-03,  1.3807e-02, -2.3515e-02, -3.5362e-02,
         -2.4852e-02, -2.1957e-02, -1.4952e-02, -2.1925e-02, -3.4758e-02,
         -2.8220e-02, -3.7455e-02, -4.0865e-02, -3.8104e-02,  1.3347e-03,
         -5.2198e-02, -2.5467e-02, -5.1656e-02, -1.5240e-02, -1.6143e-02,
         -1.1116e-02, -2.9076e-02, -1.5411e-02, -3.7430e-02, -2.3534e-02,
         -3.0279e-02, -1.0146e-01, -2.3272e-02, -4.5229e-02, -3.8890e-02,
          1.7913e-03, -6.2969e-03, -4.1688e-02, -3.0044e-02, -9.7487e-03,
         -2.1045e-02, -1.4235e-02, -2.4313e-02, -1.7216e-02, -3.1402e-02,
         -3.4427e-02, -2.1556e-02, -2.8665e-02, -3.3832e-02, -3.4066e-02,
         -2.2086e-02, -2.8477e-02, -5.0919e-02, -3.4791e-02, -1.7713e-02,
         -1.8561e-02, -3.6231e-02, -3.8923e-02, -3.6720e-02, -1.8680e-02,
         -1.9310e-02, -5.3375e-02, -2.2816e-02, -2.2705e-02, -3.0119e-02,
         -1.6189e-02, -3.3022e-02, -3.1215e-02, -3.2107e-02, -3.4758e-02,
         -2.5874e-02, -5.6180e-02, -4.0951e-02, -2.7341e-02, -2.5415e-02,
         -3.5619e-02, -3.5732e-02, -2.5828e-02, -3.6025e-02, -4.4503e-02,
         -7.0487e-03, -8.6296e-03, -4.8478e-02, -3.6195e-02, -3.2900e-02,
         -3.9823e-02, -1.5362e-02, -5.5768e-03, -2.8645e-02, -2.9967e-02,
         -4.2924e-02, -3.2294e-02, -2.9039e-02, -3.4810e-02, -1.9517e-02,
         -2.9691e-02, -2.8602e-02, -4.0939e-02, -5.1788e-02, -2.9741e-02,
         -3.6167e-02, -2.9228e-02, -2.2982e-02, -5.7735e-02, -1.8834e-02,
         -1.7366e-02, -3.5482e-02, -2.1608e-02, -4.6328e-02, -1.2155e-02,
         -3.7046e-02, -4.9812e-02, -1.5587e-02, -4.5353e-02, -1.4188e-02,
         -4.2994e-02, -3.1072e-02, -4.7449e-02, -3.5341e-02, -2.4476e-02,
         -2.2945e-02, -1.8691e-02, -2.2915e-02, -3.1375e-02, -2.5264e-02,
         -2.0859e-02, -2.5641e-02, -3.1363e-02, -2.8384e-02, -4.3555e-02,
         -3.4732e-02, -3.9482e-02, -1.7701e-02, -2.6898e-02, -1.4156e-02,
         -1.7624e-02, -1.3957e-02, -2.4311e-02, -2.0646e-02, -2.5072e-02,
         -2.4137e-02, -1.8694e-02, -1.8910e-02, -1.0031e-02, -1.3634e-02,
          5.8649e-04, -2.2889e-02, -3.8469e-02, -2.8486e-02, -4.6490e-02,
         -1.9475e-02, -1.1686e-02, -3.8871e-02, -2.8555e-02, -3.2153e-02,
         -2.2332e-02, -1.1427e-02, -3.9309e-02, -2.2623e-02, -1.3303e-02,
         -5.9567e-03, -4.0263e-02, -2.7895e-02, -3.2989e-02, -2.7573e-02,
         -2.0798e-02, -4.4355e-02, -3.5247e-02, -4.0966e-02, -7.5861e-04,
         -2.7611e-02, -5.1424e-02, -4.2651e-02, -3.6131e-02, -1.9154e-02,
         -1.5637e-02, -2.3545e-02, -1.4531e-02, -3.4187e-02, -3.3429e-02,
         -2.7579e-02, -3.3237e-02, -1.5961e-02, -2.8258e-02, -2.0247e-02,
         -2.2522e-02, -3.1527e-02, -2.9972e-02, -2.4582e-02, -8.2861e-02,
         -2.8782e-02, -1.5376e-02, -3.8141e-02, -3.1824e-02, -3.6612e-02,
         -3.9245e-02, -1.9609e-02, -3.0501e-02, -7.7609e-03, -8.0570e-03,
         -2.3806e-02, -2.6526e-02, -2.4266e-02, -2.4878e-02, -3.3844e-02,
         -2.9566e-02, -3.6479e-02, -1.4832e-02, -2.4131e-02,  1.2522e-02,
         -3.0995e-02, -1.1293e-02, -2.4523e-02, -3.9244e-02, -3.0727e-02,
         -4.0406e-02, -2.8647e-02, -9.1868e-03, -4.6082e-02, -4.8844e-02,
         -4.1209e-02, -1.3117e-02, -2.7125e-02, -3.0641e-02, -6.2721e-02,
         -1.6724e-02, -1.2205e-02, -7.4066e-03, -2.2215e-02, -2.2350e-02,
         -1.5625e-02, -2.4046e-02, -1.9222e-02, -4.8427e-02, -2.3804e-02,
         -1.7038e-02, -8.9022e-03, -9.0834e-03, -9.2919e-03, -5.0812e-03,
         -2.9265e-02, -1.5873e-02, -1.5446e-02, -3.2083e-02, -5.7845e-02,
         -1.7572e-02, -5.2507e-02,  4.4114e-04, -4.0418e-02, -4.0858e-02,
         -2.4568e-02, -4.6892e-02, -2.0101e-02, -4.1925e-02, -1.5755e-02,
         -2.7231e-02, -2.4822e-02, -2.8439e-02]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.4000% F1: 0.2413
Applying ckpt from fold 1 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2371
Applying ckpt from fold 2 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.4000% F1: 0.2413
Applying ckpt from fold 3 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.4000% F1: 0.2413
Applying ckpt from fold 4 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2413
Applying ckpt from fold 5 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.6000% F1: 0.2455
Applying ckpt from fold 6 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2513
Applying ckpt from fold 7 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.6000% F1: 0.2455
Applying ckpt from fold 8 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2446
Applying ckpt from fold 9 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2512
Metrics by fold:
Fold 0 - Acc: 0.55 F1: 0.24
Fold 1 - Acc: 0.55 F1: 0.24
Fold 2 - Acc: 0.55 F1: 0.24
Fold 3 - Acc: 0.55 F1: 0.24
Fold 4 - Acc: 0.55 F1: 0.24
Fold 5 - Acc: 0.56 F1: 0.25
Fold 6 - Acc: 0.55 F1: 0.25
Fold 7 - Acc: 0.56 F1: 0.25
Fold 8 - Acc: 0.55 F1: 0.24
Fold 9 - Acc: 0.55 F1: 0.25
agg_acc: 0.5534 agg_f1: 0.2441
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-2.0626e-02, -4.4060e-02, -2.6161e-02, -5.2382e-02, -1.1801e-02,
         -2.1239e-02, -1.8071e-02, -3.0182e-02, -3.2382e-02, -2.0418e-02,
         -2.6720e-02, -4.3357e-02, -2.5472e-02,  5.5979e-03,  1.2318e-02,
         -3.4176e-02, -4.4977e-02, -2.8053e-02, -2.1231e-02, -6.0782e-02,
         -4.0279e-02, -3.8476e-02, -1.6334e-02, -3.2569e-02, -2.5926e-02,
         -2.7391e-02, -2.3964e-02, -3.0589e-02, -2.9190e-02, -3.3341e-02,
         -1.8691e-02, -3.5133e-02, -6.1570e-02, -1.4964e-02, -2.1376e-02,
         -3.1147e-02, -3.0501e-02,  1.4628e-03, -1.8252e-02, -1.9517e-02,
         -1.1622e-02, -3.5739e-02, -3.6812e-02, -1.9371e-02, -1.1859e-02,
         -8.8161e-03, -3.1636e-02, -2.0528e-02, -1.1131e-02, -3.5867e-02,
         -3.8365e-02, -2.5705e-02, -2.1792e-02, -4.4399e-02, -4.0270e-02,
         -5.4638e-02, -2.8454e-02, -2.5333e-02, -2.5547e-02, -1.5287e-02,
         -2.4182e-02, -3.0630e-02,  1.5069e-02, -3.6271e-02, -2.8401e-02,
         -1.5753e-02, -3.0542e-02, -4.4240e-02, -2.0518e-02,  1.3146e-02,
         -2.6623e-02, -5.8353e-03, -6.2991e-02, -2.9645e-02, -5.2723e-02,
         -6.1875e-03, -4.6658e-02, -1.1706e-02, -2.0831e-02, -2.1911e-02,
         -3.0621e-02, -3.0604e-02, -3.1597e-02, -1.4894e-02, -3.7422e-02,
         -1.8669e-02, -3.9261e-02, -2.2540e-02, -3.5005e-02, -1.8804e-02,
         -3.9859e-02, -2.3636e-02, -4.4098e-02, -2.2001e-02, -4.0159e-02,
         -4.1603e-02, -6.0479e-02, -3.4732e-02, -3.5348e-02, -1.1855e-02,
         -1.1457e-02, -1.8017e-02, -2.5695e-02, -3.2170e-02, -1.8815e-02,
          6.0778e-04, -2.9451e-02, -1.5095e-02, -3.4335e-02, -1.8684e-02,
         -5.2852e-02, -2.8976e-02, -4.0829e-02, -1.9680e-02, -1.9389e-02,
         -2.6357e-02, -1.0519e-02, -3.3680e-02, -3.3897e-02, -1.6169e-02,
         -2.5509e-02,  6.1193e-03, -2.6227e-02, -4.9142e-02, -5.1203e-02,
         -2.7614e-02, -2.7042e-02, -8.2370e-02, -3.2448e-02, -6.2488e-02,
         -2.4354e-02, -5.3159e-02,  2.3348e-02, -3.0051e-02, -2.0879e-02,
         -1.0396e-02, -1.9578e-02, -2.8474e-02, -2.0294e-02, -6.0514e-03,
         -3.1489e-02, -2.7566e-02, -8.3959e-03, -8.8849e-03, -3.2843e-02,
         -3.9592e-02, -2.8364e-02, -3.0351e-02, -3.9907e-02, -2.9026e-02,
         -4.1853e-02, -1.4049e-02, -5.6452e-02, -2.7035e-02, -3.0331e-02,
         -2.6986e-02, -1.8532e-02, -1.1369e-02, -4.2319e-02, -1.0535e-01,
         -2.5081e-02, -2.4970e-02, -1.3560e-02, -3.2619e-02, -2.3543e-02,
         -3.1439e-02, -1.0665e-02, -2.8571e-02, -2.4338e-02, -2.9927e-02,
         -2.2083e-02, -1.0367e-02, -3.6159e-02, -3.5902e-02, -3.8141e-02,
          2.2199e-02, -3.4954e-02, -4.2879e-02, -2.6929e-02, -6.4845e-03,
         -2.5604e-02, -2.3864e-02, -6.5536e-02, -1.1395e-02, -2.0720e-02,
         -1.9895e-02, -3.2456e-02, -4.2429e-02, -2.7246e-02, -7.3045e-03,
         -7.3728e-03, -4.4053e-02, -4.0074e-02, -3.2210e-02, -5.1612e-02,
         -3.5234e-02, -4.5111e-02, -1.9451e-02, -3.2387e-02, -4.2629e-02,
         -2.9188e-02, -9.1431e-03, -5.6937e-03, -3.6857e-02, -3.5655e-02,
         -1.4412e-02, -1.6586e-02, -4.8305e-02, -2.0054e-02, -2.2196e-03,
         -2.6737e-02, -2.1182e-02, -3.0844e-02, -2.2878e-02, -2.6762e-02,
         -2.2593e-02, -1.2894e-01, -2.6952e-03, -4.7206e-02, -1.9133e-02,
         -1.6194e-02, -3.4907e-02, -3.0068e-02, -8.7365e-03, -2.4353e-02,
         -1.0010e-01, -3.6861e-02, -4.0455e-02, -3.1136e-02, -5.0729e-02,
         -2.6141e-02, -2.6761e-02, -4.6217e-02, -3.6219e-02, -2.3151e-02,
         -1.7108e-02, -3.9074e-02, -1.9915e-02, -1.2001e-02, -3.7315e-02,
         -3.3087e-02, -2.6547e-02, -4.3930e-02, -4.6760e-02, -2.4470e-02,
          5.5595e-05, -4.3790e-02, -2.8079e-02, -3.8258e-02, -4.1491e-02,
         -3.3981e-02, -2.7939e-02, -2.7030e-02, -1.2909e-02, -4.0956e-02,
         -2.1886e-02, -2.3271e-02, -2.3112e-02, -2.3970e-02, -1.5977e-02,
         -1.6904e-02, -3.9638e-02, -1.4792e-02, -4.5347e-02, -3.1461e-02,
         -2.8825e-02, -1.2313e-02, -3.7781e-02,  2.4980e-03, -2.8167e-02,
         -3.1846e-02, -3.3554e-02, -2.1765e-02, -2.0045e-02, -4.7427e-02,
         -1.8519e-02, -2.8280e-02, -4.4778e-02, -1.3524e-02, -3.2319e-03,
         -2.9903e-02, -3.1917e-02, -2.2511e-02, -5.9006e-02,  1.5946e-03,
         -2.4006e-02, -1.7079e-02, -2.9951e-02, -2.5281e-02, -5.0775e-02,
         -4.3378e-02,  8.9525e-04, -1.6057e-02, -1.3209e-03, -1.9282e-02,
         -3.7466e-02, -7.5034e-02, -3.4903e-02, -2.6046e-02, -6.0244e-02,
         -2.3133e-02, -3.6307e-02, -1.1735e-02, -1.5822e-02, -5.8465e-02,
         -9.4279e-03, -2.4606e-02, -1.6206e-02,  6.8120e-03, -3.1115e-02,
         -2.9297e-02, -3.0197e-02, -2.0291e-02, -1.5730e-02, -2.9399e-02,
         -5.8700e-02, -4.9440e-02, -1.4964e-02, -1.4682e-02, -4.7326e-02,
          1.9171e-03, -2.7425e-02, -3.2663e-02, -4.0381e-02, -2.2076e-02,
         -7.2282e-03, -1.7059e-02, -1.3517e-02, -2.6359e-02, -4.3907e-03,
         -3.9467e-02, -6.9909e-02, -3.6269e-02, -3.8785e-02, -2.7625e-02,
         -3.0422e-02, -3.4326e-02, -4.1373e-03, -2.0417e-02, -2.2334e-02,
         -1.4535e-02, -1.3532e-02, -3.6567e-02, -2.2748e-02, -1.6989e-02,
          1.4371e-03, -4.1189e-02, -4.5399e-02, -3.9660e-02, -2.7661e-02,
         -2.3461e-02, -2.6766e-02, -3.6177e-02, -5.6810e-02, -2.0876e-02,
         -3.5100e-02, -4.1278e-02, -2.1627e-02, -3.7129e-03, -1.9762e-02,
         -1.7184e-02, -2.7223e-02, -2.7576e-02, -9.1357e-04, -1.6475e-02,
         -4.0762e-02, -2.2704e-02, -3.2532e-02, -2.5827e-02, -3.1545e-02,
         -1.7120e-02, -3.9241e-02, -2.4638e-02, -2.9520e-02, -3.0369e-02,
         -2.5346e-02, -2.1294e-02, -4.9278e-02, -2.7448e-02, -3.7034e-02,
         -6.7724e-03, -5.7087e-02, -2.8008e-02,  6.8865e-03, -4.9772e-02,
         -4.4891e-02, -3.4240e-02, -5.1939e-02, -2.3135e-02, -1.4994e-02,
         -3.6481e-02, -1.6013e-02, -4.1644e-02, -3.7349e-02, -1.8343e-02,
         -2.8021e-02, -2.3944e-02, -3.5851e-02, -4.4354e-02, -1.8169e-02,
         -2.3095e-02, -9.4431e-02, -3.8140e-02, -3.4660e-02, -3.6032e-02,
         -2.0042e-02, -2.4378e-02, -1.2028e-02, -2.0953e-02, -2.1721e-02,
         -3.2877e-02, -3.8856e-02, -4.7931e-02, -3.5312e-02, -2.8105e-02,
         -4.7969e-02, -1.0577e-02, -5.4178e-02, -1.9335e-02,  1.4594e-02,
         -5.6146e-03, -2.8620e-02, -3.7851e-02, -1.9913e-02, -4.2189e-02,
         -1.0320e-02, -2.1976e-02, -5.2133e-02, -4.3729e-02, -5.4553e-02,
         -3.5142e-02, -3.7726e-02, -2.6058e-02, -1.1231e-02, -3.2618e-02,
         -4.3355e-02, -1.7774e-02, -3.1622e-02, -2.8229e-02, -2.1421e-02,
         -2.9999e-02, -3.1010e-02, -2.5497e-02, -4.5435e-03, -4.1343e-02,
         -3.2268e-02, -2.0374e-02, -1.9872e-02, -4.6008e-02, -2.8307e-02,
         -1.1835e-02, -2.2528e-02, -2.8635e-02, -2.5755e-02, -2.2962e-02,
         -1.1313e-02, -3.7581e-02, -1.8534e-02, -1.6939e-02, -2.5694e-02,
         -4.5719e-02,  2.1832e-02, -1.5461e-02, -1.8565e-02, -2.3459e-02,
         -6.4967e-02, -2.7417e-02, -2.3490e-02, -2.3226e-02, -4.4696e-02,
         -6.2122e-03, -6.0652e-02, -5.4693e-02, -2.0045e-02, -3.9188e-02,
         -1.6182e-02, -1.6512e-02, -8.1976e-03, -3.2709e-02, -2.5799e-02,
         -2.4841e-03, -2.1700e-02,  4.9436e-03, -2.0033e-02, -1.6611e-02,
         -2.2917e-02, -3.5269e-02, -2.3938e-02, -2.5108e-02, -2.5692e-02,
         -1.4544e-02, -1.7141e-02, -1.6639e-02, -3.4002e-02, -2.0499e-02,
         -3.2127e-02, -6.7373e-02, -1.1025e-02, -3.1973e-02, -2.3749e-02,
         -9.4430e-03, -4.9020e-02, -4.0693e-02, -3.4095e-02, -3.2654e-02,
         -4.3039e-02, -3.7553e-02, -3.2732e-02, -2.8386e-02, -2.5889e-02,
         -4.1052e-02, -4.8210e-02, -3.5973e-02, -3.5697e-02, -3.5337e-02,
         -3.0920e-02, -8.5859e-03,  1.3807e-02, -2.3515e-02, -3.5362e-02,
         -2.4852e-02, -2.1957e-02, -1.4952e-02, -2.1925e-02, -3.4758e-02,
         -2.8220e-02, -3.7455e-02, -4.0865e-02, -3.8104e-02,  1.3347e-03,
         -5.2198e-02, -2.5467e-02, -5.1656e-02, -1.5240e-02, -1.6143e-02,
         -1.1116e-02, -2.9076e-02, -1.5411e-02, -3.7430e-02, -2.3534e-02,
         -3.0279e-02, -1.0146e-01, -2.3272e-02, -4.5229e-02, -3.8890e-02,
          1.7913e-03, -6.2969e-03, -4.1688e-02, -3.0044e-02, -9.7487e-03,
         -2.1045e-02, -1.4235e-02, -2.4313e-02, -1.7216e-02, -3.1402e-02,
         -3.4427e-02, -2.1556e-02, -2.8665e-02, -3.3832e-02, -3.4066e-02,
         -2.2086e-02, -2.8477e-02, -5.0919e-02, -3.4791e-02, -1.7713e-02,
         -1.8561e-02, -3.6231e-02, -3.8923e-02, -3.6720e-02, -1.8680e-02,
         -1.9310e-02, -5.3375e-02, -2.2816e-02, -2.2705e-02, -3.0119e-02,
         -1.6189e-02, -3.3022e-02, -3.1215e-02, -3.2107e-02, -3.4758e-02,
         -2.5874e-02, -5.6180e-02, -4.0951e-02, -2.7341e-02, -2.5415e-02,
         -3.5619e-02, -3.5732e-02, -2.5828e-02, -3.6025e-02, -4.4503e-02,
         -7.0487e-03, -8.6296e-03, -4.8478e-02, -3.6195e-02, -3.2900e-02,
         -3.9823e-02, -1.5362e-02, -5.5768e-03, -2.8645e-02, -2.9967e-02,
         -4.2924e-02, -3.2294e-02, -2.9039e-02, -3.4810e-02, -1.9517e-02,
         -2.9691e-02, -2.8602e-02, -4.0939e-02, -5.1788e-02, -2.9741e-02,
         -3.6167e-02, -2.9228e-02, -2.2982e-02, -5.7735e-02, -1.8834e-02,
         -1.7366e-02, -3.5482e-02, -2.1608e-02, -4.6328e-02, -1.2155e-02,
         -3.7046e-02, -4.9812e-02, -1.5587e-02, -4.5353e-02, -1.4188e-02,
         -4.2994e-02, -3.1072e-02, -4.7449e-02, -3.5341e-02, -2.4476e-02,
         -2.2945e-02, -1.8691e-02, -2.2915e-02, -3.1375e-02, -2.5264e-02,
         -2.0859e-02, -2.5641e-02, -3.1363e-02, -2.8384e-02, -4.3555e-02,
         -3.4732e-02, -3.9482e-02, -1.7701e-02, -2.6898e-02, -1.4156e-02,
         -1.7624e-02, -1.3957e-02, -2.4311e-02, -2.0646e-02, -2.5072e-02,
         -2.4137e-02, -1.8694e-02, -1.8910e-02, -1.0031e-02, -1.3634e-02,
          5.8649e-04, -2.2889e-02, -3.8469e-02, -2.8486e-02, -4.6490e-02,
         -1.9475e-02, -1.1686e-02, -3.8871e-02, -2.8555e-02, -3.2153e-02,
         -2.2332e-02, -1.1427e-02, -3.9309e-02, -2.2623e-02, -1.3303e-02,
         -5.9567e-03, -4.0263e-02, -2.7895e-02, -3.2989e-02, -2.7573e-02,
         -2.0798e-02, -4.4355e-02, -3.5247e-02, -4.0966e-02, -7.5861e-04,
         -2.7611e-02, -5.1424e-02, -4.2651e-02, -3.6131e-02, -1.9154e-02,
         -1.5637e-02, -2.3545e-02, -1.4531e-02, -3.4187e-02, -3.3429e-02,
         -2.7579e-02, -3.3237e-02, -1.5961e-02, -2.8258e-02, -2.0247e-02,
         -2.2522e-02, -3.1527e-02, -2.9972e-02, -2.4582e-02, -8.2861e-02,
         -2.8782e-02, -1.5376e-02, -3.8141e-02, -3.1824e-02, -3.6612e-02,
         -3.9245e-02, -1.9609e-02, -3.0501e-02, -7.7609e-03, -8.0570e-03,
         -2.3806e-02, -2.6526e-02, -2.4266e-02, -2.4878e-02, -3.3844e-02,
         -2.9566e-02, -3.6479e-02, -1.4832e-02, -2.4131e-02,  1.2522e-02,
         -3.0995e-02, -1.1293e-02, -2.4523e-02, -3.9244e-02, -3.0727e-02,
         -4.0406e-02, -2.8647e-02, -9.1868e-03, -4.6082e-02, -4.8844e-02,
         -4.1209e-02, -1.3117e-02, -2.7125e-02, -3.0641e-02, -6.2721e-02,
         -1.6724e-02, -1.2205e-02, -7.4066e-03, -2.2215e-02, -2.2350e-02,
         -1.5625e-02, -2.4046e-02, -1.9222e-02, -4.8427e-02, -2.3804e-02,
         -1.7038e-02, -8.9022e-03, -9.0834e-03, -9.2919e-03, -5.0812e-03,
         -2.9265e-02, -1.5873e-02, -1.5446e-02, -3.2083e-02, -5.7845e-02,
         -1.7572e-02, -5.2507e-02,  4.4114e-04, -4.0418e-02, -4.0858e-02,
         -2.4568e-02, -4.6892e-02, -2.0101e-02, -4.1925e-02, -1.5755e-02,
         -2.7231e-02, -2.4822e-02, -2.8439e-02]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.6000% F1: 0.2797
Applying ckpt from fold 1 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.2000% F1: 0.3154
Applying ckpt from fold 2 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.6000% F1: 0.3149
Applying ckpt from fold 3 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.4000% F1: 0.2788
Applying ckpt from fold 4 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.4000% F1: 0.2773
Applying ckpt from fold 5 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.0000% F1: 0.3043
Applying ckpt from fold 6 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.0000% F1: 0.2763
Applying ckpt from fold 7 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.2000% F1: 0.2623
Applying ckpt from fold 8 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.8000% F1: 0.2995
Applying ckpt from fold 9 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.6000% F1: 0.3023
Metrics by fold:
Fold 0 - Acc: 0.54 F1: 0.28
Fold 1 - Acc: 0.52 F1: 0.32
Fold 2 - Acc: 0.54 F1: 0.31
Fold 3 - Acc: 0.53 F1: 0.28
Fold 4 - Acc: 0.52 F1: 0.28
Fold 5 - Acc: 0.53 F1: 0.30
Fold 6 - Acc: 0.54 F1: 0.28
Fold 7 - Acc: 0.52 F1: 0.26
Fold 8 - Acc: 0.53 F1: 0.30
Fold 9 - Acc: 0.55 F1: 0.30
agg_acc: 0.5318 agg_f1: 0.2911
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-2.0626e-02, -4.4060e-02, -2.6161e-02, -5.2382e-02, -1.1801e-02,
         -2.1239e-02, -1.8071e-02, -3.0182e-02, -3.2382e-02, -2.0418e-02,
         -2.6720e-02, -4.3357e-02, -2.5472e-02,  5.5979e-03,  1.2318e-02,
         -3.4176e-02, -4.4977e-02, -2.8053e-02, -2.1231e-02, -6.0782e-02,
         -4.0279e-02, -3.8476e-02, -1.6334e-02, -3.2569e-02, -2.5926e-02,
         -2.7391e-02, -2.3964e-02, -3.0589e-02, -2.9190e-02, -3.3341e-02,
         -1.8691e-02, -3.5133e-02, -6.1570e-02, -1.4964e-02, -2.1376e-02,
         -3.1147e-02, -3.0501e-02,  1.4628e-03, -1.8252e-02, -1.9517e-02,
         -1.1622e-02, -3.5739e-02, -3.6812e-02, -1.9371e-02, -1.1859e-02,
         -8.8161e-03, -3.1636e-02, -2.0528e-02, -1.1131e-02, -3.5867e-02,
         -3.8365e-02, -2.5705e-02, -2.1792e-02, -4.4399e-02, -4.0270e-02,
         -5.4638e-02, -2.8454e-02, -2.5333e-02, -2.5547e-02, -1.5287e-02,
         -2.4182e-02, -3.0630e-02,  1.5069e-02, -3.6271e-02, -2.8401e-02,
         -1.5753e-02, -3.0542e-02, -4.4240e-02, -2.0518e-02,  1.3146e-02,
         -2.6623e-02, -5.8353e-03, -6.2991e-02, -2.9645e-02, -5.2723e-02,
         -6.1875e-03, -4.6658e-02, -1.1706e-02, -2.0831e-02, -2.1911e-02,
         -3.0621e-02, -3.0604e-02, -3.1597e-02, -1.4894e-02, -3.7422e-02,
         -1.8669e-02, -3.9261e-02, -2.2540e-02, -3.5005e-02, -1.8804e-02,
         -3.9859e-02, -2.3636e-02, -4.4098e-02, -2.2001e-02, -4.0159e-02,
         -4.1603e-02, -6.0479e-02, -3.4732e-02, -3.5348e-02, -1.1855e-02,
         -1.1457e-02, -1.8017e-02, -2.5695e-02, -3.2170e-02, -1.8815e-02,
          6.0778e-04, -2.9451e-02, -1.5095e-02, -3.4335e-02, -1.8684e-02,
         -5.2852e-02, -2.8976e-02, -4.0829e-02, -1.9680e-02, -1.9389e-02,
         -2.6357e-02, -1.0519e-02, -3.3680e-02, -3.3897e-02, -1.6169e-02,
         -2.5509e-02,  6.1193e-03, -2.6227e-02, -4.9142e-02, -5.1203e-02,
         -2.7614e-02, -2.7042e-02, -8.2370e-02, -3.2448e-02, -6.2488e-02,
         -2.4354e-02, -5.3159e-02,  2.3348e-02, -3.0051e-02, -2.0879e-02,
         -1.0396e-02, -1.9578e-02, -2.8474e-02, -2.0294e-02, -6.0514e-03,
         -3.1489e-02, -2.7566e-02, -8.3959e-03, -8.8849e-03, -3.2843e-02,
         -3.9592e-02, -2.8364e-02, -3.0351e-02, -3.9907e-02, -2.9026e-02,
         -4.1853e-02, -1.4049e-02, -5.6452e-02, -2.7035e-02, -3.0331e-02,
         -2.6986e-02, -1.8532e-02, -1.1369e-02, -4.2319e-02, -1.0535e-01,
         -2.5081e-02, -2.4970e-02, -1.3560e-02, -3.2619e-02, -2.3543e-02,
         -3.1439e-02, -1.0665e-02, -2.8571e-02, -2.4338e-02, -2.9927e-02,
         -2.2083e-02, -1.0367e-02, -3.6159e-02, -3.5902e-02, -3.8141e-02,
          2.2199e-02, -3.4954e-02, -4.2879e-02, -2.6929e-02, -6.4845e-03,
         -2.5604e-02, -2.3864e-02, -6.5536e-02, -1.1395e-02, -2.0720e-02,
         -1.9895e-02, -3.2456e-02, -4.2429e-02, -2.7246e-02, -7.3045e-03,
         -7.3728e-03, -4.4053e-02, -4.0074e-02, -3.2210e-02, -5.1612e-02,
         -3.5234e-02, -4.5111e-02, -1.9451e-02, -3.2387e-02, -4.2629e-02,
         -2.9188e-02, -9.1431e-03, -5.6937e-03, -3.6857e-02, -3.5655e-02,
         -1.4412e-02, -1.6586e-02, -4.8305e-02, -2.0054e-02, -2.2196e-03,
         -2.6737e-02, -2.1182e-02, -3.0844e-02, -2.2878e-02, -2.6762e-02,
         -2.2593e-02, -1.2894e-01, -2.6952e-03, -4.7206e-02, -1.9133e-02,
         -1.6194e-02, -3.4907e-02, -3.0068e-02, -8.7365e-03, -2.4353e-02,
         -1.0010e-01, -3.6861e-02, -4.0455e-02, -3.1136e-02, -5.0729e-02,
         -2.6141e-02, -2.6761e-02, -4.6217e-02, -3.6219e-02, -2.3151e-02,
         -1.7108e-02, -3.9074e-02, -1.9915e-02, -1.2001e-02, -3.7315e-02,
         -3.3087e-02, -2.6547e-02, -4.3930e-02, -4.6760e-02, -2.4470e-02,
          5.5595e-05, -4.3790e-02, -2.8079e-02, -3.8258e-02, -4.1491e-02,
         -3.3981e-02, -2.7939e-02, -2.7030e-02, -1.2909e-02, -4.0956e-02,
         -2.1886e-02, -2.3271e-02, -2.3112e-02, -2.3970e-02, -1.5977e-02,
         -1.6904e-02, -3.9638e-02, -1.4792e-02, -4.5347e-02, -3.1461e-02,
         -2.8825e-02, -1.2313e-02, -3.7781e-02,  2.4980e-03, -2.8167e-02,
         -3.1846e-02, -3.3554e-02, -2.1765e-02, -2.0045e-02, -4.7427e-02,
         -1.8519e-02, -2.8280e-02, -4.4778e-02, -1.3524e-02, -3.2319e-03,
         -2.9903e-02, -3.1917e-02, -2.2511e-02, -5.9006e-02,  1.5946e-03,
         -2.4006e-02, -1.7079e-02, -2.9951e-02, -2.5281e-02, -5.0775e-02,
         -4.3378e-02,  8.9525e-04, -1.6057e-02, -1.3209e-03, -1.9282e-02,
         -3.7466e-02, -7.5034e-02, -3.4903e-02, -2.6046e-02, -6.0244e-02,
         -2.3133e-02, -3.6307e-02, -1.1735e-02, -1.5822e-02, -5.8465e-02,
         -9.4279e-03, -2.4606e-02, -1.6206e-02,  6.8120e-03, -3.1115e-02,
         -2.9297e-02, -3.0197e-02, -2.0291e-02, -1.5730e-02, -2.9399e-02,
         -5.8700e-02, -4.9440e-02, -1.4964e-02, -1.4682e-02, -4.7326e-02,
          1.9171e-03, -2.7425e-02, -3.2663e-02, -4.0381e-02, -2.2076e-02,
         -7.2282e-03, -1.7059e-02, -1.3517e-02, -2.6359e-02, -4.3907e-03,
         -3.9467e-02, -6.9909e-02, -3.6269e-02, -3.8785e-02, -2.7625e-02,
         -3.0422e-02, -3.4326e-02, -4.1373e-03, -2.0417e-02, -2.2334e-02,
         -1.4535e-02, -1.3532e-02, -3.6567e-02, -2.2748e-02, -1.6989e-02,
          1.4371e-03, -4.1189e-02, -4.5399e-02, -3.9660e-02, -2.7661e-02,
         -2.3461e-02, -2.6766e-02, -3.6177e-02, -5.6810e-02, -2.0876e-02,
         -3.5100e-02, -4.1278e-02, -2.1627e-02, -3.7129e-03, -1.9762e-02,
         -1.7184e-02, -2.7223e-02, -2.7576e-02, -9.1357e-04, -1.6475e-02,
         -4.0762e-02, -2.2704e-02, -3.2532e-02, -2.5827e-02, -3.1545e-02,
         -1.7120e-02, -3.9241e-02, -2.4638e-02, -2.9520e-02, -3.0369e-02,
         -2.5346e-02, -2.1294e-02, -4.9278e-02, -2.7448e-02, -3.7034e-02,
         -6.7724e-03, -5.7087e-02, -2.8008e-02,  6.8865e-03, -4.9772e-02,
         -4.4891e-02, -3.4240e-02, -5.1939e-02, -2.3135e-02, -1.4994e-02,
         -3.6481e-02, -1.6013e-02, -4.1644e-02, -3.7349e-02, -1.8343e-02,
         -2.8021e-02, -2.3944e-02, -3.5851e-02, -4.4354e-02, -1.8169e-02,
         -2.3095e-02, -9.4431e-02, -3.8140e-02, -3.4660e-02, -3.6032e-02,
         -2.0042e-02, -2.4378e-02, -1.2028e-02, -2.0953e-02, -2.1721e-02,
         -3.2877e-02, -3.8856e-02, -4.7931e-02, -3.5312e-02, -2.8105e-02,
         -4.7969e-02, -1.0577e-02, -5.4178e-02, -1.9335e-02,  1.4594e-02,
         -5.6146e-03, -2.8620e-02, -3.7851e-02, -1.9913e-02, -4.2189e-02,
         -1.0320e-02, -2.1976e-02, -5.2133e-02, -4.3729e-02, -5.4553e-02,
         -3.5142e-02, -3.7726e-02, -2.6058e-02, -1.1231e-02, -3.2618e-02,
         -4.3355e-02, -1.7774e-02, -3.1622e-02, -2.8229e-02, -2.1421e-02,
         -2.9999e-02, -3.1010e-02, -2.5497e-02, -4.5435e-03, -4.1343e-02,
         -3.2268e-02, -2.0374e-02, -1.9872e-02, -4.6008e-02, -2.8307e-02,
         -1.1835e-02, -2.2528e-02, -2.8635e-02, -2.5755e-02, -2.2962e-02,
         -1.1313e-02, -3.7581e-02, -1.8534e-02, -1.6939e-02, -2.5694e-02,
         -4.5719e-02,  2.1832e-02, -1.5461e-02, -1.8565e-02, -2.3459e-02,
         -6.4967e-02, -2.7417e-02, -2.3490e-02, -2.3226e-02, -4.4696e-02,
         -6.2122e-03, -6.0652e-02, -5.4693e-02, -2.0045e-02, -3.9188e-02,
         -1.6182e-02, -1.6512e-02, -8.1976e-03, -3.2709e-02, -2.5799e-02,
         -2.4841e-03, -2.1700e-02,  4.9436e-03, -2.0033e-02, -1.6611e-02,
         -2.2917e-02, -3.5269e-02, -2.3938e-02, -2.5108e-02, -2.5692e-02,
         -1.4544e-02, -1.7141e-02, -1.6639e-02, -3.4002e-02, -2.0499e-02,
         -3.2127e-02, -6.7373e-02, -1.1025e-02, -3.1973e-02, -2.3749e-02,
         -9.4430e-03, -4.9020e-02, -4.0693e-02, -3.4095e-02, -3.2654e-02,
         -4.3039e-02, -3.7553e-02, -3.2732e-02, -2.8386e-02, -2.5889e-02,
         -4.1052e-02, -4.8210e-02, -3.5973e-02, -3.5697e-02, -3.5337e-02,
         -3.0920e-02, -8.5859e-03,  1.3807e-02, -2.3515e-02, -3.5362e-02,
         -2.4852e-02, -2.1957e-02, -1.4952e-02, -2.1925e-02, -3.4758e-02,
         -2.8220e-02, -3.7455e-02, -4.0865e-02, -3.8104e-02,  1.3347e-03,
         -5.2198e-02, -2.5467e-02, -5.1656e-02, -1.5240e-02, -1.6143e-02,
         -1.1116e-02, -2.9076e-02, -1.5411e-02, -3.7430e-02, -2.3534e-02,
         -3.0279e-02, -1.0146e-01, -2.3272e-02, -4.5229e-02, -3.8890e-02,
          1.7913e-03, -6.2969e-03, -4.1688e-02, -3.0044e-02, -9.7487e-03,
         -2.1045e-02, -1.4235e-02, -2.4313e-02, -1.7216e-02, -3.1402e-02,
         -3.4427e-02, -2.1556e-02, -2.8665e-02, -3.3832e-02, -3.4066e-02,
         -2.2086e-02, -2.8477e-02, -5.0919e-02, -3.4791e-02, -1.7713e-02,
         -1.8561e-02, -3.6231e-02, -3.8923e-02, -3.6720e-02, -1.8680e-02,
         -1.9310e-02, -5.3375e-02, -2.2816e-02, -2.2705e-02, -3.0119e-02,
         -1.6189e-02, -3.3022e-02, -3.1215e-02, -3.2107e-02, -3.4758e-02,
         -2.5874e-02, -5.6180e-02, -4.0951e-02, -2.7341e-02, -2.5415e-02,
         -3.5619e-02, -3.5732e-02, -2.5828e-02, -3.6025e-02, -4.4503e-02,
         -7.0487e-03, -8.6296e-03, -4.8478e-02, -3.6195e-02, -3.2900e-02,
         -3.9823e-02, -1.5362e-02, -5.5768e-03, -2.8645e-02, -2.9967e-02,
         -4.2924e-02, -3.2294e-02, -2.9039e-02, -3.4810e-02, -1.9517e-02,
         -2.9691e-02, -2.8602e-02, -4.0939e-02, -5.1788e-02, -2.9741e-02,
         -3.6167e-02, -2.9228e-02, -2.2982e-02, -5.7735e-02, -1.8834e-02,
         -1.7366e-02, -3.5482e-02, -2.1608e-02, -4.6328e-02, -1.2155e-02,
         -3.7046e-02, -4.9812e-02, -1.5587e-02, -4.5353e-02, -1.4188e-02,
         -4.2994e-02, -3.1072e-02, -4.7449e-02, -3.5341e-02, -2.4476e-02,
         -2.2945e-02, -1.8691e-02, -2.2915e-02, -3.1375e-02, -2.5264e-02,
         -2.0859e-02, -2.5641e-02, -3.1363e-02, -2.8384e-02, -4.3555e-02,
         -3.4732e-02, -3.9482e-02, -1.7701e-02, -2.6898e-02, -1.4156e-02,
         -1.7624e-02, -1.3957e-02, -2.4311e-02, -2.0646e-02, -2.5072e-02,
         -2.4137e-02, -1.8694e-02, -1.8910e-02, -1.0031e-02, -1.3634e-02,
          5.8649e-04, -2.2889e-02, -3.8469e-02, -2.8486e-02, -4.6490e-02,
         -1.9475e-02, -1.1686e-02, -3.8871e-02, -2.8555e-02, -3.2153e-02,
         -2.2332e-02, -1.1427e-02, -3.9309e-02, -2.2623e-02, -1.3303e-02,
         -5.9567e-03, -4.0263e-02, -2.7895e-02, -3.2989e-02, -2.7573e-02,
         -2.0798e-02, -4.4355e-02, -3.5247e-02, -4.0966e-02, -7.5861e-04,
         -2.7611e-02, -5.1424e-02, -4.2651e-02, -3.6131e-02, -1.9154e-02,
         -1.5637e-02, -2.3545e-02, -1.4531e-02, -3.4187e-02, -3.3429e-02,
         -2.7579e-02, -3.3237e-02, -1.5961e-02, -2.8258e-02, -2.0247e-02,
         -2.2522e-02, -3.1527e-02, -2.9972e-02, -2.4582e-02, -8.2861e-02,
         -2.8782e-02, -1.5376e-02, -3.8141e-02, -3.1824e-02, -3.6612e-02,
         -3.9245e-02, -1.9609e-02, -3.0501e-02, -7.7609e-03, -8.0570e-03,
         -2.3806e-02, -2.6526e-02, -2.4266e-02, -2.4878e-02, -3.3844e-02,
         -2.9566e-02, -3.6479e-02, -1.4832e-02, -2.4131e-02,  1.2522e-02,
         -3.0995e-02, -1.1293e-02, -2.4523e-02, -3.9244e-02, -3.0727e-02,
         -4.0406e-02, -2.8647e-02, -9.1868e-03, -4.6082e-02, -4.8844e-02,
         -4.1209e-02, -1.3117e-02, -2.7125e-02, -3.0641e-02, -6.2721e-02,
         -1.6724e-02, -1.2205e-02, -7.4066e-03, -2.2215e-02, -2.2350e-02,
         -1.5625e-02, -2.4046e-02, -1.9222e-02, -4.8427e-02, -2.3804e-02,
         -1.7038e-02, -8.9022e-03, -9.0834e-03, -9.2919e-03, -5.0812e-03,
         -2.9265e-02, -1.5873e-02, -1.5446e-02, -3.2083e-02, -5.7845e-02,
         -1.7572e-02, -5.2507e-02,  4.4114e-04, -4.0418e-02, -4.0858e-02,
         -2.4568e-02, -4.6892e-02, -2.0101e-02, -4.1925e-02, -1.5755e-02,
         -2.7231e-02, -2.4822e-02, -2.8439e-02]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.4000% F1: 0.2930
Applying ckpt from fold 1 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.2000% F1: 0.3088
Applying ckpt from fold 2 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.8000% F1: 0.3288
Applying ckpt from fold 3 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.8000% F1: 0.2896
Applying ckpt from fold 4 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.6000% F1: 0.3100
Applying ckpt from fold 5 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.8000% F1: 0.3186
Applying ckpt from fold 6 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.0000% F1: 0.3095
Applying ckpt from fold 7 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.6000% F1: 0.3367
Applying ckpt from fold 8 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.8000% F1: 0.2964
Applying ckpt from fold 9 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.2000% F1: 0.3623
Metrics by fold:
Fold 0 - Acc: 0.49 F1: 0.29
Fold 1 - Acc: 0.51 F1: 0.31
Fold 2 - Acc: 0.52 F1: 0.33
Fold 3 - Acc: 0.53 F1: 0.29
Fold 4 - Acc: 0.51 F1: 0.31
Fold 5 - Acc: 0.50 F1: 0.32
Fold 6 - Acc: 0.52 F1: 0.31
Fold 7 - Acc: 0.52 F1: 0.34
Fold 8 - Acc: 0.50 F1: 0.30
Fold 9 - Acc: 0.52 F1: 0.36
agg_acc: 0.5112 agg_f1: 0.3154
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-2.0626e-02, -4.4060e-02, -2.6161e-02, -5.2382e-02, -1.1801e-02,
         -2.1239e-02, -1.8071e-02, -3.0182e-02, -3.2382e-02, -2.0418e-02,
         -2.6720e-02, -4.3357e-02, -2.5472e-02,  5.5979e-03,  1.2318e-02,
         -3.4176e-02, -4.4977e-02, -2.8053e-02, -2.1231e-02, -6.0782e-02,
         -4.0279e-02, -3.8476e-02, -1.6334e-02, -3.2569e-02, -2.5926e-02,
         -2.7391e-02, -2.3964e-02, -3.0589e-02, -2.9190e-02, -3.3341e-02,
         -1.8691e-02, -3.5133e-02, -6.1570e-02, -1.4964e-02, -2.1376e-02,
         -3.1147e-02, -3.0501e-02,  1.4628e-03, -1.8252e-02, -1.9517e-02,
         -1.1622e-02, -3.5739e-02, -3.6812e-02, -1.9371e-02, -1.1859e-02,
         -8.8161e-03, -3.1636e-02, -2.0528e-02, -1.1131e-02, -3.5867e-02,
         -3.8365e-02, -2.5705e-02, -2.1792e-02, -4.4399e-02, -4.0270e-02,
         -5.4638e-02, -2.8454e-02, -2.5333e-02, -2.5547e-02, -1.5287e-02,
         -2.4182e-02, -3.0630e-02,  1.5069e-02, -3.6271e-02, -2.8401e-02,
         -1.5753e-02, -3.0542e-02, -4.4240e-02, -2.0518e-02,  1.3146e-02,
         -2.6623e-02, -5.8353e-03, -6.2991e-02, -2.9645e-02, -5.2723e-02,
         -6.1875e-03, -4.6658e-02, -1.1706e-02, -2.0831e-02, -2.1911e-02,
         -3.0621e-02, -3.0604e-02, -3.1597e-02, -1.4894e-02, -3.7422e-02,
         -1.8669e-02, -3.9261e-02, -2.2540e-02, -3.5005e-02, -1.8804e-02,
         -3.9859e-02, -2.3636e-02, -4.4098e-02, -2.2001e-02, -4.0159e-02,
         -4.1603e-02, -6.0479e-02, -3.4732e-02, -3.5348e-02, -1.1855e-02,
         -1.1457e-02, -1.8017e-02, -2.5695e-02, -3.2170e-02, -1.8815e-02,
          6.0778e-04, -2.9451e-02, -1.5095e-02, -3.4335e-02, -1.8684e-02,
         -5.2852e-02, -2.8976e-02, -4.0829e-02, -1.9680e-02, -1.9389e-02,
         -2.6357e-02, -1.0519e-02, -3.3680e-02, -3.3897e-02, -1.6169e-02,
         -2.5509e-02,  6.1193e-03, -2.6227e-02, -4.9142e-02, -5.1203e-02,
         -2.7614e-02, -2.7042e-02, -8.2370e-02, -3.2448e-02, -6.2488e-02,
         -2.4354e-02, -5.3159e-02,  2.3348e-02, -3.0051e-02, -2.0879e-02,
         -1.0396e-02, -1.9578e-02, -2.8474e-02, -2.0294e-02, -6.0514e-03,
         -3.1489e-02, -2.7566e-02, -8.3959e-03, -8.8849e-03, -3.2843e-02,
         -3.9592e-02, -2.8364e-02, -3.0351e-02, -3.9907e-02, -2.9026e-02,
         -4.1853e-02, -1.4049e-02, -5.6452e-02, -2.7035e-02, -3.0331e-02,
         -2.6986e-02, -1.8532e-02, -1.1369e-02, -4.2319e-02, -1.0535e-01,
         -2.5081e-02, -2.4970e-02, -1.3560e-02, -3.2619e-02, -2.3543e-02,
         -3.1439e-02, -1.0665e-02, -2.8571e-02, -2.4338e-02, -2.9927e-02,
         -2.2083e-02, -1.0367e-02, -3.6159e-02, -3.5902e-02, -3.8141e-02,
          2.2199e-02, -3.4954e-02, -4.2879e-02, -2.6929e-02, -6.4845e-03,
         -2.5604e-02, -2.3864e-02, -6.5536e-02, -1.1395e-02, -2.0720e-02,
         -1.9895e-02, -3.2456e-02, -4.2429e-02, -2.7246e-02, -7.3045e-03,
         -7.3728e-03, -4.4053e-02, -4.0074e-02, -3.2210e-02, -5.1612e-02,
         -3.5234e-02, -4.5111e-02, -1.9451e-02, -3.2387e-02, -4.2629e-02,
         -2.9188e-02, -9.1431e-03, -5.6937e-03, -3.6857e-02, -3.5655e-02,
         -1.4412e-02, -1.6586e-02, -4.8305e-02, -2.0054e-02, -2.2196e-03,
         -2.6737e-02, -2.1182e-02, -3.0844e-02, -2.2878e-02, -2.6762e-02,
         -2.2593e-02, -1.2894e-01, -2.6952e-03, -4.7206e-02, -1.9133e-02,
         -1.6194e-02, -3.4907e-02, -3.0068e-02, -8.7365e-03, -2.4353e-02,
         -1.0010e-01, -3.6861e-02, -4.0455e-02, -3.1136e-02, -5.0729e-02,
         -2.6141e-02, -2.6761e-02, -4.6217e-02, -3.6219e-02, -2.3151e-02,
         -1.7108e-02, -3.9074e-02, -1.9915e-02, -1.2001e-02, -3.7315e-02,
         -3.3087e-02, -2.6547e-02, -4.3930e-02, -4.6760e-02, -2.4470e-02,
          5.5595e-05, -4.3790e-02, -2.8079e-02, -3.8258e-02, -4.1491e-02,
         -3.3981e-02, -2.7939e-02, -2.7030e-02, -1.2909e-02, -4.0956e-02,
         -2.1886e-02, -2.3271e-02, -2.3112e-02, -2.3970e-02, -1.5977e-02,
         -1.6904e-02, -3.9638e-02, -1.4792e-02, -4.5347e-02, -3.1461e-02,
         -2.8825e-02, -1.2313e-02, -3.7781e-02,  2.4980e-03, -2.8167e-02,
         -3.1846e-02, -3.3554e-02, -2.1765e-02, -2.0045e-02, -4.7427e-02,
         -1.8519e-02, -2.8280e-02, -4.4778e-02, -1.3524e-02, -3.2319e-03,
         -2.9903e-02, -3.1917e-02, -2.2511e-02, -5.9006e-02,  1.5946e-03,
         -2.4006e-02, -1.7079e-02, -2.9951e-02, -2.5281e-02, -5.0775e-02,
         -4.3378e-02,  8.9525e-04, -1.6057e-02, -1.3209e-03, -1.9282e-02,
         -3.7466e-02, -7.5034e-02, -3.4903e-02, -2.6046e-02, -6.0244e-02,
         -2.3133e-02, -3.6307e-02, -1.1735e-02, -1.5822e-02, -5.8465e-02,
         -9.4279e-03, -2.4606e-02, -1.6206e-02,  6.8120e-03, -3.1115e-02,
         -2.9297e-02, -3.0197e-02, -2.0291e-02, -1.5730e-02, -2.9399e-02,
         -5.8700e-02, -4.9440e-02, -1.4964e-02, -1.4682e-02, -4.7326e-02,
          1.9171e-03, -2.7425e-02, -3.2663e-02, -4.0381e-02, -2.2076e-02,
         -7.2282e-03, -1.7059e-02, -1.3517e-02, -2.6359e-02, -4.3907e-03,
         -3.9467e-02, -6.9909e-02, -3.6269e-02, -3.8785e-02, -2.7625e-02,
         -3.0422e-02, -3.4326e-02, -4.1373e-03, -2.0417e-02, -2.2334e-02,
         -1.4535e-02, -1.3532e-02, -3.6567e-02, -2.2748e-02, -1.6989e-02,
          1.4371e-03, -4.1189e-02, -4.5399e-02, -3.9660e-02, -2.7661e-02,
         -2.3461e-02, -2.6766e-02, -3.6177e-02, -5.6810e-02, -2.0876e-02,
         -3.5100e-02, -4.1278e-02, -2.1627e-02, -3.7129e-03, -1.9762e-02,
         -1.7184e-02, -2.7223e-02, -2.7576e-02, -9.1357e-04, -1.6475e-02,
         -4.0762e-02, -2.2704e-02, -3.2532e-02, -2.5827e-02, -3.1545e-02,
         -1.7120e-02, -3.9241e-02, -2.4638e-02, -2.9520e-02, -3.0369e-02,
         -2.5346e-02, -2.1294e-02, -4.9278e-02, -2.7448e-02, -3.7034e-02,
         -6.7724e-03, -5.7087e-02, -2.8008e-02,  6.8865e-03, -4.9772e-02,
         -4.4891e-02, -3.4240e-02, -5.1939e-02, -2.3135e-02, -1.4994e-02,
         -3.6481e-02, -1.6013e-02, -4.1644e-02, -3.7349e-02, -1.8343e-02,
         -2.8021e-02, -2.3944e-02, -3.5851e-02, -4.4354e-02, -1.8169e-02,
         -2.3095e-02, -9.4431e-02, -3.8140e-02, -3.4660e-02, -3.6032e-02,
         -2.0042e-02, -2.4378e-02, -1.2028e-02, -2.0953e-02, -2.1721e-02,
         -3.2877e-02, -3.8856e-02, -4.7931e-02, -3.5312e-02, -2.8105e-02,
         -4.7969e-02, -1.0577e-02, -5.4178e-02, -1.9335e-02,  1.4594e-02,
         -5.6146e-03, -2.8620e-02, -3.7851e-02, -1.9913e-02, -4.2189e-02,
         -1.0320e-02, -2.1976e-02, -5.2133e-02, -4.3729e-02, -5.4553e-02,
         -3.5142e-02, -3.7726e-02, -2.6058e-02, -1.1231e-02, -3.2618e-02,
         -4.3355e-02, -1.7774e-02, -3.1622e-02, -2.8229e-02, -2.1421e-02,
         -2.9999e-02, -3.1010e-02, -2.5497e-02, -4.5435e-03, -4.1343e-02,
         -3.2268e-02, -2.0374e-02, -1.9872e-02, -4.6008e-02, -2.8307e-02,
         -1.1835e-02, -2.2528e-02, -2.8635e-02, -2.5755e-02, -2.2962e-02,
         -1.1313e-02, -3.7581e-02, -1.8534e-02, -1.6939e-02, -2.5694e-02,
         -4.5719e-02,  2.1832e-02, -1.5461e-02, -1.8565e-02, -2.3459e-02,
         -6.4967e-02, -2.7417e-02, -2.3490e-02, -2.3226e-02, -4.4696e-02,
         -6.2122e-03, -6.0652e-02, -5.4693e-02, -2.0045e-02, -3.9188e-02,
         -1.6182e-02, -1.6512e-02, -8.1976e-03, -3.2709e-02, -2.5799e-02,
         -2.4841e-03, -2.1700e-02,  4.9436e-03, -2.0033e-02, -1.6611e-02,
         -2.2917e-02, -3.5269e-02, -2.3938e-02, -2.5108e-02, -2.5692e-02,
         -1.4544e-02, -1.7141e-02, -1.6639e-02, -3.4002e-02, -2.0499e-02,
         -3.2127e-02, -6.7373e-02, -1.1025e-02, -3.1973e-02, -2.3749e-02,
         -9.4430e-03, -4.9020e-02, -4.0693e-02, -3.4095e-02, -3.2654e-02,
         -4.3039e-02, -3.7553e-02, -3.2732e-02, -2.8386e-02, -2.5889e-02,
         -4.1052e-02, -4.8210e-02, -3.5973e-02, -3.5697e-02, -3.5337e-02,
         -3.0920e-02, -8.5859e-03,  1.3807e-02, -2.3515e-02, -3.5362e-02,
         -2.4852e-02, -2.1957e-02, -1.4952e-02, -2.1925e-02, -3.4758e-02,
         -2.8220e-02, -3.7455e-02, -4.0865e-02, -3.8104e-02,  1.3347e-03,
         -5.2198e-02, -2.5467e-02, -5.1656e-02, -1.5240e-02, -1.6143e-02,
         -1.1116e-02, -2.9076e-02, -1.5411e-02, -3.7430e-02, -2.3534e-02,
         -3.0279e-02, -1.0146e-01, -2.3272e-02, -4.5229e-02, -3.8890e-02,
          1.7913e-03, -6.2969e-03, -4.1688e-02, -3.0044e-02, -9.7487e-03,
         -2.1045e-02, -1.4235e-02, -2.4313e-02, -1.7216e-02, -3.1402e-02,
         -3.4427e-02, -2.1556e-02, -2.8665e-02, -3.3832e-02, -3.4066e-02,
         -2.2086e-02, -2.8477e-02, -5.0919e-02, -3.4791e-02, -1.7713e-02,
         -1.8561e-02, -3.6231e-02, -3.8923e-02, -3.6720e-02, -1.8680e-02,
         -1.9310e-02, -5.3375e-02, -2.2816e-02, -2.2705e-02, -3.0119e-02,
         -1.6189e-02, -3.3022e-02, -3.1215e-02, -3.2107e-02, -3.4758e-02,
         -2.5874e-02, -5.6180e-02, -4.0951e-02, -2.7341e-02, -2.5415e-02,
         -3.5619e-02, -3.5732e-02, -2.5828e-02, -3.6025e-02, -4.4503e-02,
         -7.0487e-03, -8.6296e-03, -4.8478e-02, -3.6195e-02, -3.2900e-02,
         -3.9823e-02, -1.5362e-02, -5.5768e-03, -2.8645e-02, -2.9967e-02,
         -4.2924e-02, -3.2294e-02, -2.9039e-02, -3.4810e-02, -1.9517e-02,
         -2.9691e-02, -2.8602e-02, -4.0939e-02, -5.1788e-02, -2.9741e-02,
         -3.6167e-02, -2.9228e-02, -2.2982e-02, -5.7735e-02, -1.8834e-02,
         -1.7366e-02, -3.5482e-02, -2.1608e-02, -4.6328e-02, -1.2155e-02,
         -3.7046e-02, -4.9812e-02, -1.5587e-02, -4.5353e-02, -1.4188e-02,
         -4.2994e-02, -3.1072e-02, -4.7449e-02, -3.5341e-02, -2.4476e-02,
         -2.2945e-02, -1.8691e-02, -2.2915e-02, -3.1375e-02, -2.5264e-02,
         -2.0859e-02, -2.5641e-02, -3.1363e-02, -2.8384e-02, -4.3555e-02,
         -3.4732e-02, -3.9482e-02, -1.7701e-02, -2.6898e-02, -1.4156e-02,
         -1.7624e-02, -1.3957e-02, -2.4311e-02, -2.0646e-02, -2.5072e-02,
         -2.4137e-02, -1.8694e-02, -1.8910e-02, -1.0031e-02, -1.3634e-02,
          5.8649e-04, -2.2889e-02, -3.8469e-02, -2.8486e-02, -4.6490e-02,
         -1.9475e-02, -1.1686e-02, -3.8871e-02, -2.8555e-02, -3.2153e-02,
         -2.2332e-02, -1.1427e-02, -3.9309e-02, -2.2623e-02, -1.3303e-02,
         -5.9567e-03, -4.0263e-02, -2.7895e-02, -3.2989e-02, -2.7573e-02,
         -2.0798e-02, -4.4355e-02, -3.5247e-02, -4.0966e-02, -7.5861e-04,
         -2.7611e-02, -5.1424e-02, -4.2651e-02, -3.6131e-02, -1.9154e-02,
         -1.5637e-02, -2.3545e-02, -1.4531e-02, -3.4187e-02, -3.3429e-02,
         -2.7579e-02, -3.3237e-02, -1.5961e-02, -2.8258e-02, -2.0247e-02,
         -2.2522e-02, -3.1527e-02, -2.9972e-02, -2.4582e-02, -8.2861e-02,
         -2.8782e-02, -1.5376e-02, -3.8141e-02, -3.1824e-02, -3.6612e-02,
         -3.9245e-02, -1.9609e-02, -3.0501e-02, -7.7609e-03, -8.0570e-03,
         -2.3806e-02, -2.6526e-02, -2.4266e-02, -2.4878e-02, -3.3844e-02,
         -2.9566e-02, -3.6479e-02, -1.4832e-02, -2.4131e-02,  1.2522e-02,
         -3.0995e-02, -1.1293e-02, -2.4523e-02, -3.9244e-02, -3.0727e-02,
         -4.0406e-02, -2.8647e-02, -9.1868e-03, -4.6082e-02, -4.8844e-02,
         -4.1209e-02, -1.3117e-02, -2.7125e-02, -3.0641e-02, -6.2721e-02,
         -1.6724e-02, -1.2205e-02, -7.4066e-03, -2.2215e-02, -2.2350e-02,
         -1.5625e-02, -2.4046e-02, -1.9222e-02, -4.8427e-02, -2.3804e-02,
         -1.7038e-02, -8.9022e-03, -9.0834e-03, -9.2919e-03, -5.0812e-03,
         -2.9265e-02, -1.5873e-02, -1.5446e-02, -3.2083e-02, -5.7845e-02,
         -1.7572e-02, -5.2507e-02,  4.4114e-04, -4.0418e-02, -4.0858e-02,
         -2.4568e-02, -4.6892e-02, -2.0101e-02, -4.1925e-02, -1.5755e-02,
         -2.7231e-02, -2.4822e-02, -2.8439e-02]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.0000% F1: 0.3084
Applying ckpt from fold 1 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.0000% F1: 0.3152
Applying ckpt from fold 2 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.0000% F1: 0.3144
Applying ckpt from fold 3 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.4000% F1: 0.3098
Applying ckpt from fold 4 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.6000% F1: 0.3097
Applying ckpt from fold 5 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.0000% F1: 0.3591
Applying ckpt from fold 6 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.6000% F1: 0.2923
Applying ckpt from fold 7 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.4000% F1: 0.3131
Applying ckpt from fold 8 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.2000% F1: 0.2890
Applying ckpt from fold 9 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.8000% F1: 0.3441
Metrics by fold:
Fold 0 - Acc: 0.50 F1: 0.31
Fold 1 - Acc: 0.48 F1: 0.32
Fold 2 - Acc: 0.52 F1: 0.31
Fold 3 - Acc: 0.50 F1: 0.31
Fold 4 - Acc: 0.51 F1: 0.31
Fold 5 - Acc: 0.50 F1: 0.36
Fold 6 - Acc: 0.51 F1: 0.29
Fold 7 - Acc: 0.47 F1: 0.31
Fold 8 - Acc: 0.51 F1: 0.29
Fold 9 - Acc: 0.49 F1: 0.34
agg_acc: 0.4990 agg_f1: 0.3155
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-2.0626e-02, -4.4060e-02, -2.6161e-02, -5.2382e-02, -1.1801e-02,
         -2.1239e-02, -1.8071e-02, -3.0182e-02, -3.2382e-02, -2.0418e-02,
         -2.6720e-02, -4.3357e-02, -2.5472e-02,  5.5979e-03,  1.2318e-02,
         -3.4176e-02, -4.4977e-02, -2.8053e-02, -2.1231e-02, -6.0782e-02,
         -4.0279e-02, -3.8476e-02, -1.6334e-02, -3.2569e-02, -2.5926e-02,
         -2.7391e-02, -2.3964e-02, -3.0589e-02, -2.9190e-02, -3.3341e-02,
         -1.8691e-02, -3.5133e-02, -6.1570e-02, -1.4964e-02, -2.1376e-02,
         -3.1147e-02, -3.0501e-02,  1.4628e-03, -1.8252e-02, -1.9517e-02,
         -1.1622e-02, -3.5739e-02, -3.6812e-02, -1.9371e-02, -1.1859e-02,
         -8.8161e-03, -3.1636e-02, -2.0528e-02, -1.1131e-02, -3.5867e-02,
         -3.8365e-02, -2.5705e-02, -2.1792e-02, -4.4399e-02, -4.0270e-02,
         -5.4638e-02, -2.8454e-02, -2.5333e-02, -2.5547e-02, -1.5287e-02,
         -2.4182e-02, -3.0630e-02,  1.5069e-02, -3.6271e-02, -2.8401e-02,
         -1.5753e-02, -3.0542e-02, -4.4240e-02, -2.0518e-02,  1.3146e-02,
         -2.6623e-02, -5.8353e-03, -6.2991e-02, -2.9645e-02, -5.2723e-02,
         -6.1875e-03, -4.6658e-02, -1.1706e-02, -2.0831e-02, -2.1911e-02,
         -3.0621e-02, -3.0604e-02, -3.1597e-02, -1.4894e-02, -3.7422e-02,
         -1.8669e-02, -3.9261e-02, -2.2540e-02, -3.5005e-02, -1.8804e-02,
         -3.9859e-02, -2.3636e-02, -4.4098e-02, -2.2001e-02, -4.0159e-02,
         -4.1603e-02, -6.0479e-02, -3.4732e-02, -3.5348e-02, -1.1855e-02,
         -1.1457e-02, -1.8017e-02, -2.5695e-02, -3.2170e-02, -1.8815e-02,
          6.0778e-04, -2.9451e-02, -1.5095e-02, -3.4335e-02, -1.8684e-02,
         -5.2852e-02, -2.8976e-02, -4.0829e-02, -1.9680e-02, -1.9389e-02,
         -2.6357e-02, -1.0519e-02, -3.3680e-02, -3.3897e-02, -1.6169e-02,
         -2.5509e-02,  6.1193e-03, -2.6227e-02, -4.9142e-02, -5.1203e-02,
         -2.7614e-02, -2.7042e-02, -8.2370e-02, -3.2448e-02, -6.2488e-02,
         -2.4354e-02, -5.3159e-02,  2.3348e-02, -3.0051e-02, -2.0879e-02,
         -1.0396e-02, -1.9578e-02, -2.8474e-02, -2.0294e-02, -6.0514e-03,
         -3.1489e-02, -2.7566e-02, -8.3959e-03, -8.8849e-03, -3.2843e-02,
         -3.9592e-02, -2.8364e-02, -3.0351e-02, -3.9907e-02, -2.9026e-02,
         -4.1853e-02, -1.4049e-02, -5.6452e-02, -2.7035e-02, -3.0331e-02,
         -2.6986e-02, -1.8532e-02, -1.1369e-02, -4.2319e-02, -1.0535e-01,
         -2.5081e-02, -2.4970e-02, -1.3560e-02, -3.2619e-02, -2.3543e-02,
         -3.1439e-02, -1.0665e-02, -2.8571e-02, -2.4338e-02, -2.9927e-02,
         -2.2083e-02, -1.0367e-02, -3.6159e-02, -3.5902e-02, -3.8141e-02,
          2.2199e-02, -3.4954e-02, -4.2879e-02, -2.6929e-02, -6.4845e-03,
         -2.5604e-02, -2.3864e-02, -6.5536e-02, -1.1395e-02, -2.0720e-02,
         -1.9895e-02, -3.2456e-02, -4.2429e-02, -2.7246e-02, -7.3045e-03,
         -7.3728e-03, -4.4053e-02, -4.0074e-02, -3.2210e-02, -5.1612e-02,
         -3.5234e-02, -4.5111e-02, -1.9451e-02, -3.2387e-02, -4.2629e-02,
         -2.9188e-02, -9.1431e-03, -5.6937e-03, -3.6857e-02, -3.5655e-02,
         -1.4412e-02, -1.6586e-02, -4.8305e-02, -2.0054e-02, -2.2196e-03,
         -2.6737e-02, -2.1182e-02, -3.0844e-02, -2.2878e-02, -2.6762e-02,
         -2.2593e-02, -1.2894e-01, -2.6952e-03, -4.7206e-02, -1.9133e-02,
         -1.6194e-02, -3.4907e-02, -3.0068e-02, -8.7365e-03, -2.4353e-02,
         -1.0010e-01, -3.6861e-02, -4.0455e-02, -3.1136e-02, -5.0729e-02,
         -2.6141e-02, -2.6761e-02, -4.6217e-02, -3.6219e-02, -2.3151e-02,
         -1.7108e-02, -3.9074e-02, -1.9915e-02, -1.2001e-02, -3.7315e-02,
         -3.3087e-02, -2.6547e-02, -4.3930e-02, -4.6760e-02, -2.4470e-02,
          5.5595e-05, -4.3790e-02, -2.8079e-02, -3.8258e-02, -4.1491e-02,
         -3.3981e-02, -2.7939e-02, -2.7030e-02, -1.2909e-02, -4.0956e-02,
         -2.1886e-02, -2.3271e-02, -2.3112e-02, -2.3970e-02, -1.5977e-02,
         -1.6904e-02, -3.9638e-02, -1.4792e-02, -4.5347e-02, -3.1461e-02,
         -2.8825e-02, -1.2313e-02, -3.7781e-02,  2.4980e-03, -2.8167e-02,
         -3.1846e-02, -3.3554e-02, -2.1765e-02, -2.0045e-02, -4.7427e-02,
         -1.8519e-02, -2.8280e-02, -4.4778e-02, -1.3524e-02, -3.2319e-03,
         -2.9903e-02, -3.1917e-02, -2.2511e-02, -5.9006e-02,  1.5946e-03,
         -2.4006e-02, -1.7079e-02, -2.9951e-02, -2.5281e-02, -5.0775e-02,
         -4.3378e-02,  8.9525e-04, -1.6057e-02, -1.3209e-03, -1.9282e-02,
         -3.7466e-02, -7.5034e-02, -3.4903e-02, -2.6046e-02, -6.0244e-02,
         -2.3133e-02, -3.6307e-02, -1.1735e-02, -1.5822e-02, -5.8465e-02,
         -9.4279e-03, -2.4606e-02, -1.6206e-02,  6.8120e-03, -3.1115e-02,
         -2.9297e-02, -3.0197e-02, -2.0291e-02, -1.5730e-02, -2.9399e-02,
         -5.8700e-02, -4.9440e-02, -1.4964e-02, -1.4682e-02, -4.7326e-02,
          1.9171e-03, -2.7425e-02, -3.2663e-02, -4.0381e-02, -2.2076e-02,
         -7.2282e-03, -1.7059e-02, -1.3517e-02, -2.6359e-02, -4.3907e-03,
         -3.9467e-02, -6.9909e-02, -3.6269e-02, -3.8785e-02, -2.7625e-02,
         -3.0422e-02, -3.4326e-02, -4.1373e-03, -2.0417e-02, -2.2334e-02,
         -1.4535e-02, -1.3532e-02, -3.6567e-02, -2.2748e-02, -1.6989e-02,
          1.4371e-03, -4.1189e-02, -4.5399e-02, -3.9660e-02, -2.7661e-02,
         -2.3461e-02, -2.6766e-02, -3.6177e-02, -5.6810e-02, -2.0876e-02,
         -3.5100e-02, -4.1278e-02, -2.1627e-02, -3.7129e-03, -1.9762e-02,
         -1.7184e-02, -2.7223e-02, -2.7576e-02, -9.1357e-04, -1.6475e-02,
         -4.0762e-02, -2.2704e-02, -3.2532e-02, -2.5827e-02, -3.1545e-02,
         -1.7120e-02, -3.9241e-02, -2.4638e-02, -2.9520e-02, -3.0369e-02,
         -2.5346e-02, -2.1294e-02, -4.9278e-02, -2.7448e-02, -3.7034e-02,
         -6.7724e-03, -5.7087e-02, -2.8008e-02,  6.8865e-03, -4.9772e-02,
         -4.4891e-02, -3.4240e-02, -5.1939e-02, -2.3135e-02, -1.4994e-02,
         -3.6481e-02, -1.6013e-02, -4.1644e-02, -3.7349e-02, -1.8343e-02,
         -2.8021e-02, -2.3944e-02, -3.5851e-02, -4.4354e-02, -1.8169e-02,
         -2.3095e-02, -9.4431e-02, -3.8140e-02, -3.4660e-02, -3.6032e-02,
         -2.0042e-02, -2.4378e-02, -1.2028e-02, -2.0953e-02, -2.1721e-02,
         -3.2877e-02, -3.8856e-02, -4.7931e-02, -3.5312e-02, -2.8105e-02,
         -4.7969e-02, -1.0577e-02, -5.4178e-02, -1.9335e-02,  1.4594e-02,
         -5.6146e-03, -2.8620e-02, -3.7851e-02, -1.9913e-02, -4.2189e-02,
         -1.0320e-02, -2.1976e-02, -5.2133e-02, -4.3729e-02, -5.4553e-02,
         -3.5142e-02, -3.7726e-02, -2.6058e-02, -1.1231e-02, -3.2618e-02,
         -4.3355e-02, -1.7774e-02, -3.1622e-02, -2.8229e-02, -2.1421e-02,
         -2.9999e-02, -3.1010e-02, -2.5497e-02, -4.5435e-03, -4.1343e-02,
         -3.2268e-02, -2.0374e-02, -1.9872e-02, -4.6008e-02, -2.8307e-02,
         -1.1835e-02, -2.2528e-02, -2.8635e-02, -2.5755e-02, -2.2962e-02,
         -1.1313e-02, -3.7581e-02, -1.8534e-02, -1.6939e-02, -2.5694e-02,
         -4.5719e-02,  2.1832e-02, -1.5461e-02, -1.8565e-02, -2.3459e-02,
         -6.4967e-02, -2.7417e-02, -2.3490e-02, -2.3226e-02, -4.4696e-02,
         -6.2122e-03, -6.0652e-02, -5.4693e-02, -2.0045e-02, -3.9188e-02,
         -1.6182e-02, -1.6512e-02, -8.1976e-03, -3.2709e-02, -2.5799e-02,
         -2.4841e-03, -2.1700e-02,  4.9436e-03, -2.0033e-02, -1.6611e-02,
         -2.2917e-02, -3.5269e-02, -2.3938e-02, -2.5108e-02, -2.5692e-02,
         -1.4544e-02, -1.7141e-02, -1.6639e-02, -3.4002e-02, -2.0499e-02,
         -3.2127e-02, -6.7373e-02, -1.1025e-02, -3.1973e-02, -2.3749e-02,
         -9.4430e-03, -4.9020e-02, -4.0693e-02, -3.4095e-02, -3.2654e-02,
         -4.3039e-02, -3.7553e-02, -3.2732e-02, -2.8386e-02, -2.5889e-02,
         -4.1052e-02, -4.8210e-02, -3.5973e-02, -3.5697e-02, -3.5337e-02,
         -3.0920e-02, -8.5859e-03,  1.3807e-02, -2.3515e-02, -3.5362e-02,
         -2.4852e-02, -2.1957e-02, -1.4952e-02, -2.1925e-02, -3.4758e-02,
         -2.8220e-02, -3.7455e-02, -4.0865e-02, -3.8104e-02,  1.3347e-03,
         -5.2198e-02, -2.5467e-02, -5.1656e-02, -1.5240e-02, -1.6143e-02,
         -1.1116e-02, -2.9076e-02, -1.5411e-02, -3.7430e-02, -2.3534e-02,
         -3.0279e-02, -1.0146e-01, -2.3272e-02, -4.5229e-02, -3.8890e-02,
          1.7913e-03, -6.2969e-03, -4.1688e-02, -3.0044e-02, -9.7487e-03,
         -2.1045e-02, -1.4235e-02, -2.4313e-02, -1.7216e-02, -3.1402e-02,
         -3.4427e-02, -2.1556e-02, -2.8665e-02, -3.3832e-02, -3.4066e-02,
         -2.2086e-02, -2.8477e-02, -5.0919e-02, -3.4791e-02, -1.7713e-02,
         -1.8561e-02, -3.6231e-02, -3.8923e-02, -3.6720e-02, -1.8680e-02,
         -1.9310e-02, -5.3375e-02, -2.2816e-02, -2.2705e-02, -3.0119e-02,
         -1.6189e-02, -3.3022e-02, -3.1215e-02, -3.2107e-02, -3.4758e-02,
         -2.5874e-02, -5.6180e-02, -4.0951e-02, -2.7341e-02, -2.5415e-02,
         -3.5619e-02, -3.5732e-02, -2.5828e-02, -3.6025e-02, -4.4503e-02,
         -7.0487e-03, -8.6296e-03, -4.8478e-02, -3.6195e-02, -3.2900e-02,
         -3.9823e-02, -1.5362e-02, -5.5768e-03, -2.8645e-02, -2.9967e-02,
         -4.2924e-02, -3.2294e-02, -2.9039e-02, -3.4810e-02, -1.9517e-02,
         -2.9691e-02, -2.8602e-02, -4.0939e-02, -5.1788e-02, -2.9741e-02,
         -3.6167e-02, -2.9228e-02, -2.2982e-02, -5.7735e-02, -1.8834e-02,
         -1.7366e-02, -3.5482e-02, -2.1608e-02, -4.6328e-02, -1.2155e-02,
         -3.7046e-02, -4.9812e-02, -1.5587e-02, -4.5353e-02, -1.4188e-02,
         -4.2994e-02, -3.1072e-02, -4.7449e-02, -3.5341e-02, -2.4476e-02,
         -2.2945e-02, -1.8691e-02, -2.2915e-02, -3.1375e-02, -2.5264e-02,
         -2.0859e-02, -2.5641e-02, -3.1363e-02, -2.8384e-02, -4.3555e-02,
         -3.4732e-02, -3.9482e-02, -1.7701e-02, -2.6898e-02, -1.4156e-02,
         -1.7624e-02, -1.3957e-02, -2.4311e-02, -2.0646e-02, -2.5072e-02,
         -2.4137e-02, -1.8694e-02, -1.8910e-02, -1.0031e-02, -1.3634e-02,
          5.8649e-04, -2.2889e-02, -3.8469e-02, -2.8486e-02, -4.6490e-02,
         -1.9475e-02, -1.1686e-02, -3.8871e-02, -2.8555e-02, -3.2153e-02,
         -2.2332e-02, -1.1427e-02, -3.9309e-02, -2.2623e-02, -1.3303e-02,
         -5.9567e-03, -4.0263e-02, -2.7895e-02, -3.2989e-02, -2.7573e-02,
         -2.0798e-02, -4.4355e-02, -3.5247e-02, -4.0966e-02, -7.5861e-04,
         -2.7611e-02, -5.1424e-02, -4.2651e-02, -3.6131e-02, -1.9154e-02,
         -1.5637e-02, -2.3545e-02, -1.4531e-02, -3.4187e-02, -3.3429e-02,
         -2.7579e-02, -3.3237e-02, -1.5961e-02, -2.8258e-02, -2.0247e-02,
         -2.2522e-02, -3.1527e-02, -2.9972e-02, -2.4582e-02, -8.2861e-02,
         -2.8782e-02, -1.5376e-02, -3.8141e-02, -3.1824e-02, -3.6612e-02,
         -3.9245e-02, -1.9609e-02, -3.0501e-02, -7.7609e-03, -8.0570e-03,
         -2.3806e-02, -2.6526e-02, -2.4266e-02, -2.4878e-02, -3.3844e-02,
         -2.9566e-02, -3.6479e-02, -1.4832e-02, -2.4131e-02,  1.2522e-02,
         -3.0995e-02, -1.1293e-02, -2.4523e-02, -3.9244e-02, -3.0727e-02,
         -4.0406e-02, -2.8647e-02, -9.1868e-03, -4.6082e-02, -4.8844e-02,
         -4.1209e-02, -1.3117e-02, -2.7125e-02, -3.0641e-02, -6.2721e-02,
         -1.6724e-02, -1.2205e-02, -7.4066e-03, -2.2215e-02, -2.2350e-02,
         -1.5625e-02, -2.4046e-02, -1.9222e-02, -4.8427e-02, -2.3804e-02,
         -1.7038e-02, -8.9022e-03, -9.0834e-03, -9.2919e-03, -5.0812e-03,
         -2.9265e-02, -1.5873e-02, -1.5446e-02, -3.2083e-02, -5.7845e-02,
         -1.7572e-02, -5.2507e-02,  4.4114e-04, -4.0418e-02, -4.0858e-02,
         -2.4568e-02, -4.6892e-02, -2.0101e-02, -4.1925e-02, -1.5755e-02,
         -2.7231e-02, -2.4822e-02, -2.8439e-02]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 40.0000% F1: 0.3416
Applying ckpt from fold 1 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.6000% F1: 0.2990
Applying ckpt from fold 2 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 43.0000% F1: 0.3353
Applying ckpt from fold 3 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.0000% F1: 0.2966
Applying ckpt from fold 4 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.8000% F1: 0.3328
Applying ckpt from fold 5 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.2000% F1: 0.3842
Applying ckpt from fold 6 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 43.4000% F1: 0.3462
Applying ckpt from fold 7 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.4000% F1: 0.3229
Applying ckpt from fold 8 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.2000% F1: 0.3480
Applying ckpt from fold 9 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 43.6000% F1: 0.3228
Metrics by fold:
Fold 0 - Acc: 0.40 F1: 0.34
Fold 1 - Acc: 0.46 F1: 0.30
Fold 2 - Acc: 0.43 F1: 0.34
Fold 3 - Acc: 0.49 F1: 0.30
Fold 4 - Acc: 0.46 F1: 0.33
Fold 5 - Acc: 0.50 F1: 0.38
Fold 6 - Acc: 0.43 F1: 0.35
Fold 7 - Acc: 0.47 F1: 0.32
Fold 8 - Acc: 0.49 F1: 0.35
Fold 9 - Acc: 0.44 F1: 0.32
agg_acc: 0.4572 agg_f1: 0.3329
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-2.0626e-02, -4.4060e-02, -2.6161e-02, -5.2382e-02, -1.1801e-02,
         -2.1239e-02, -1.8071e-02, -3.0182e-02, -3.2382e-02, -2.0418e-02,
         -2.6720e-02, -4.3357e-02, -2.5472e-02,  5.5979e-03,  1.2318e-02,
         -3.4176e-02, -4.4977e-02, -2.8053e-02, -2.1231e-02, -6.0782e-02,
         -4.0279e-02, -3.8476e-02, -1.6334e-02, -3.2569e-02, -2.5926e-02,
         -2.7391e-02, -2.3964e-02, -3.0589e-02, -2.9190e-02, -3.3341e-02,
         -1.8691e-02, -3.5133e-02, -6.1570e-02, -1.4964e-02, -2.1376e-02,
         -3.1147e-02, -3.0501e-02,  1.4628e-03, -1.8252e-02, -1.9517e-02,
         -1.1622e-02, -3.5739e-02, -3.6812e-02, -1.9371e-02, -1.1859e-02,
         -8.8161e-03, -3.1636e-02, -2.0528e-02, -1.1131e-02, -3.5867e-02,
         -3.8365e-02, -2.5705e-02, -2.1792e-02, -4.4399e-02, -4.0270e-02,
         -5.4638e-02, -2.8454e-02, -2.5333e-02, -2.5547e-02, -1.5287e-02,
         -2.4182e-02, -3.0630e-02,  1.5069e-02, -3.6271e-02, -2.8401e-02,
         -1.5753e-02, -3.0542e-02, -4.4240e-02, -2.0518e-02,  1.3146e-02,
         -2.6623e-02, -5.8353e-03, -6.2991e-02, -2.9645e-02, -5.2723e-02,
         -6.1875e-03, -4.6658e-02, -1.1706e-02, -2.0831e-02, -2.1911e-02,
         -3.0621e-02, -3.0604e-02, -3.1597e-02, -1.4894e-02, -3.7422e-02,
         -1.8669e-02, -3.9261e-02, -2.2540e-02, -3.5005e-02, -1.8804e-02,
         -3.9859e-02, -2.3636e-02, -4.4098e-02, -2.2001e-02, -4.0159e-02,
         -4.1603e-02, -6.0479e-02, -3.4732e-02, -3.5348e-02, -1.1855e-02,
         -1.1457e-02, -1.8017e-02, -2.5695e-02, -3.2170e-02, -1.8815e-02,
          6.0778e-04, -2.9451e-02, -1.5095e-02, -3.4335e-02, -1.8684e-02,
         -5.2852e-02, -2.8976e-02, -4.0829e-02, -1.9680e-02, -1.9389e-02,
         -2.6357e-02, -1.0519e-02, -3.3680e-02, -3.3897e-02, -1.6169e-02,
         -2.5509e-02,  6.1193e-03, -2.6227e-02, -4.9142e-02, -5.1203e-02,
         -2.7614e-02, -2.7042e-02, -8.2370e-02, -3.2448e-02, -6.2488e-02,
         -2.4354e-02, -5.3159e-02,  2.3348e-02, -3.0051e-02, -2.0879e-02,
         -1.0396e-02, -1.9578e-02, -2.8474e-02, -2.0294e-02, -6.0514e-03,
         -3.1489e-02, -2.7566e-02, -8.3959e-03, -8.8849e-03, -3.2843e-02,
         -3.9592e-02, -2.8364e-02, -3.0351e-02, -3.9907e-02, -2.9026e-02,
         -4.1853e-02, -1.4049e-02, -5.6452e-02, -2.7035e-02, -3.0331e-02,
         -2.6986e-02, -1.8532e-02, -1.1369e-02, -4.2319e-02, -1.0535e-01,
         -2.5081e-02, -2.4970e-02, -1.3560e-02, -3.2619e-02, -2.3543e-02,
         -3.1439e-02, -1.0665e-02, -2.8571e-02, -2.4338e-02, -2.9927e-02,
         -2.2083e-02, -1.0367e-02, -3.6159e-02, -3.5902e-02, -3.8141e-02,
          2.2199e-02, -3.4954e-02, -4.2879e-02, -2.6929e-02, -6.4845e-03,
         -2.5604e-02, -2.3864e-02, -6.5536e-02, -1.1395e-02, -2.0720e-02,
         -1.9895e-02, -3.2456e-02, -4.2429e-02, -2.7246e-02, -7.3045e-03,
         -7.3728e-03, -4.4053e-02, -4.0074e-02, -3.2210e-02, -5.1612e-02,
         -3.5234e-02, -4.5111e-02, -1.9451e-02, -3.2387e-02, -4.2629e-02,
         -2.9188e-02, -9.1431e-03, -5.6937e-03, -3.6857e-02, -3.5655e-02,
         -1.4412e-02, -1.6586e-02, -4.8305e-02, -2.0054e-02, -2.2196e-03,
         -2.6737e-02, -2.1182e-02, -3.0844e-02, -2.2878e-02, -2.6762e-02,
         -2.2593e-02, -1.2894e-01, -2.6952e-03, -4.7206e-02, -1.9133e-02,
         -1.6194e-02, -3.4907e-02, -3.0068e-02, -8.7365e-03, -2.4353e-02,
         -1.0010e-01, -3.6861e-02, -4.0455e-02, -3.1136e-02, -5.0729e-02,
         -2.6141e-02, -2.6761e-02, -4.6217e-02, -3.6219e-02, -2.3151e-02,
         -1.7108e-02, -3.9074e-02, -1.9915e-02, -1.2001e-02, -3.7315e-02,
         -3.3087e-02, -2.6547e-02, -4.3930e-02, -4.6760e-02, -2.4470e-02,
          5.5595e-05, -4.3790e-02, -2.8079e-02, -3.8258e-02, -4.1491e-02,
         -3.3981e-02, -2.7939e-02, -2.7030e-02, -1.2909e-02, -4.0956e-02,
         -2.1886e-02, -2.3271e-02, -2.3112e-02, -2.3970e-02, -1.5977e-02,
         -1.6904e-02, -3.9638e-02, -1.4792e-02, -4.5347e-02, -3.1461e-02,
         -2.8825e-02, -1.2313e-02, -3.7781e-02,  2.4980e-03, -2.8167e-02,
         -3.1846e-02, -3.3554e-02, -2.1765e-02, -2.0045e-02, -4.7427e-02,
         -1.8519e-02, -2.8280e-02, -4.4778e-02, -1.3524e-02, -3.2319e-03,
         -2.9903e-02, -3.1917e-02, -2.2511e-02, -5.9006e-02,  1.5946e-03,
         -2.4006e-02, -1.7079e-02, -2.9951e-02, -2.5281e-02, -5.0775e-02,
         -4.3378e-02,  8.9525e-04, -1.6057e-02, -1.3209e-03, -1.9282e-02,
         -3.7466e-02, -7.5034e-02, -3.4903e-02, -2.6046e-02, -6.0244e-02,
         -2.3133e-02, -3.6307e-02, -1.1735e-02, -1.5822e-02, -5.8465e-02,
         -9.4279e-03, -2.4606e-02, -1.6206e-02,  6.8120e-03, -3.1115e-02,
         -2.9297e-02, -3.0197e-02, -2.0291e-02, -1.5730e-02, -2.9399e-02,
         -5.8700e-02, -4.9440e-02, -1.4964e-02, -1.4682e-02, -4.7326e-02,
          1.9171e-03, -2.7425e-02, -3.2663e-02, -4.0381e-02, -2.2076e-02,
         -7.2282e-03, -1.7059e-02, -1.3517e-02, -2.6359e-02, -4.3907e-03,
         -3.9467e-02, -6.9909e-02, -3.6269e-02, -3.8785e-02, -2.7625e-02,
         -3.0422e-02, -3.4326e-02, -4.1373e-03, -2.0417e-02, -2.2334e-02,
         -1.4535e-02, -1.3532e-02, -3.6567e-02, -2.2748e-02, -1.6989e-02,
          1.4371e-03, -4.1189e-02, -4.5399e-02, -3.9660e-02, -2.7661e-02,
         -2.3461e-02, -2.6766e-02, -3.6177e-02, -5.6810e-02, -2.0876e-02,
         -3.5100e-02, -4.1278e-02, -2.1627e-02, -3.7129e-03, -1.9762e-02,
         -1.7184e-02, -2.7223e-02, -2.7576e-02, -9.1357e-04, -1.6475e-02,
         -4.0762e-02, -2.2704e-02, -3.2532e-02, -2.5827e-02, -3.1545e-02,
         -1.7120e-02, -3.9241e-02, -2.4638e-02, -2.9520e-02, -3.0369e-02,
         -2.5346e-02, -2.1294e-02, -4.9278e-02, -2.7448e-02, -3.7034e-02,
         -6.7724e-03, -5.7087e-02, -2.8008e-02,  6.8865e-03, -4.9772e-02,
         -4.4891e-02, -3.4240e-02, -5.1939e-02, -2.3135e-02, -1.4994e-02,
         -3.6481e-02, -1.6013e-02, -4.1644e-02, -3.7349e-02, -1.8343e-02,
         -2.8021e-02, -2.3944e-02, -3.5851e-02, -4.4354e-02, -1.8169e-02,
         -2.3095e-02, -9.4431e-02, -3.8140e-02, -3.4660e-02, -3.6032e-02,
         -2.0042e-02, -2.4378e-02, -1.2028e-02, -2.0953e-02, -2.1721e-02,
         -3.2877e-02, -3.8856e-02, -4.7931e-02, -3.5312e-02, -2.8105e-02,
         -4.7969e-02, -1.0577e-02, -5.4178e-02, -1.9335e-02,  1.4594e-02,
         -5.6146e-03, -2.8620e-02, -3.7851e-02, -1.9913e-02, -4.2189e-02,
         -1.0320e-02, -2.1976e-02, -5.2133e-02, -4.3729e-02, -5.4553e-02,
         -3.5142e-02, -3.7726e-02, -2.6058e-02, -1.1231e-02, -3.2618e-02,
         -4.3355e-02, -1.7774e-02, -3.1622e-02, -2.8229e-02, -2.1421e-02,
         -2.9999e-02, -3.1010e-02, -2.5497e-02, -4.5435e-03, -4.1343e-02,
         -3.2268e-02, -2.0374e-02, -1.9872e-02, -4.6008e-02, -2.8307e-02,
         -1.1835e-02, -2.2528e-02, -2.8635e-02, -2.5755e-02, -2.2962e-02,
         -1.1313e-02, -3.7581e-02, -1.8534e-02, -1.6939e-02, -2.5694e-02,
         -4.5719e-02,  2.1832e-02, -1.5461e-02, -1.8565e-02, -2.3459e-02,
         -6.4967e-02, -2.7417e-02, -2.3490e-02, -2.3226e-02, -4.4696e-02,
         -6.2122e-03, -6.0652e-02, -5.4693e-02, -2.0045e-02, -3.9188e-02,
         -1.6182e-02, -1.6512e-02, -8.1976e-03, -3.2709e-02, -2.5799e-02,
         -2.4841e-03, -2.1700e-02,  4.9436e-03, -2.0033e-02, -1.6611e-02,
         -2.2917e-02, -3.5269e-02, -2.3938e-02, -2.5108e-02, -2.5692e-02,
         -1.4544e-02, -1.7141e-02, -1.6639e-02, -3.4002e-02, -2.0499e-02,
         -3.2127e-02, -6.7373e-02, -1.1025e-02, -3.1973e-02, -2.3749e-02,
         -9.4430e-03, -4.9020e-02, -4.0693e-02, -3.4095e-02, -3.2654e-02,
         -4.3039e-02, -3.7553e-02, -3.2732e-02, -2.8386e-02, -2.5889e-02,
         -4.1052e-02, -4.8210e-02, -3.5973e-02, -3.5697e-02, -3.5337e-02,
         -3.0920e-02, -8.5859e-03,  1.3807e-02, -2.3515e-02, -3.5362e-02,
         -2.4852e-02, -2.1957e-02, -1.4952e-02, -2.1925e-02, -3.4758e-02,
         -2.8220e-02, -3.7455e-02, -4.0865e-02, -3.8104e-02,  1.3347e-03,
         -5.2198e-02, -2.5467e-02, -5.1656e-02, -1.5240e-02, -1.6143e-02,
         -1.1116e-02, -2.9076e-02, -1.5411e-02, -3.7430e-02, -2.3534e-02,
         -3.0279e-02, -1.0146e-01, -2.3272e-02, -4.5229e-02, -3.8890e-02,
          1.7913e-03, -6.2969e-03, -4.1688e-02, -3.0044e-02, -9.7487e-03,
         -2.1045e-02, -1.4235e-02, -2.4313e-02, -1.7216e-02, -3.1402e-02,
         -3.4427e-02, -2.1556e-02, -2.8665e-02, -3.3832e-02, -3.4066e-02,
         -2.2086e-02, -2.8477e-02, -5.0919e-02, -3.4791e-02, -1.7713e-02,
         -1.8561e-02, -3.6231e-02, -3.8923e-02, -3.6720e-02, -1.8680e-02,
         -1.9310e-02, -5.3375e-02, -2.2816e-02, -2.2705e-02, -3.0119e-02,
         -1.6189e-02, -3.3022e-02, -3.1215e-02, -3.2107e-02, -3.4758e-02,
         -2.5874e-02, -5.6180e-02, -4.0951e-02, -2.7341e-02, -2.5415e-02,
         -3.5619e-02, -3.5732e-02, -2.5828e-02, -3.6025e-02, -4.4503e-02,
         -7.0487e-03, -8.6296e-03, -4.8478e-02, -3.6195e-02, -3.2900e-02,
         -3.9823e-02, -1.5362e-02, -5.5768e-03, -2.8645e-02, -2.9967e-02,
         -4.2924e-02, -3.2294e-02, -2.9039e-02, -3.4810e-02, -1.9517e-02,
         -2.9691e-02, -2.8602e-02, -4.0939e-02, -5.1788e-02, -2.9741e-02,
         -3.6167e-02, -2.9228e-02, -2.2982e-02, -5.7735e-02, -1.8834e-02,
         -1.7366e-02, -3.5482e-02, -2.1608e-02, -4.6328e-02, -1.2155e-02,
         -3.7046e-02, -4.9812e-02, -1.5587e-02, -4.5353e-02, -1.4188e-02,
         -4.2994e-02, -3.1072e-02, -4.7449e-02, -3.5341e-02, -2.4476e-02,
         -2.2945e-02, -1.8691e-02, -2.2915e-02, -3.1375e-02, -2.5264e-02,
         -2.0859e-02, -2.5641e-02, -3.1363e-02, -2.8384e-02, -4.3555e-02,
         -3.4732e-02, -3.9482e-02, -1.7701e-02, -2.6898e-02, -1.4156e-02,
         -1.7624e-02, -1.3957e-02, -2.4311e-02, -2.0646e-02, -2.5072e-02,
         -2.4137e-02, -1.8694e-02, -1.8910e-02, -1.0031e-02, -1.3634e-02,
          5.8649e-04, -2.2889e-02, -3.8469e-02, -2.8486e-02, -4.6490e-02,
         -1.9475e-02, -1.1686e-02, -3.8871e-02, -2.8555e-02, -3.2153e-02,
         -2.2332e-02, -1.1427e-02, -3.9309e-02, -2.2623e-02, -1.3303e-02,
         -5.9567e-03, -4.0263e-02, -2.7895e-02, -3.2989e-02, -2.7573e-02,
         -2.0798e-02, -4.4355e-02, -3.5247e-02, -4.0966e-02, -7.5861e-04,
         -2.7611e-02, -5.1424e-02, -4.2651e-02, -3.6131e-02, -1.9154e-02,
         -1.5637e-02, -2.3545e-02, -1.4531e-02, -3.4187e-02, -3.3429e-02,
         -2.7579e-02, -3.3237e-02, -1.5961e-02, -2.8258e-02, -2.0247e-02,
         -2.2522e-02, -3.1527e-02, -2.9972e-02, -2.4582e-02, -8.2861e-02,
         -2.8782e-02, -1.5376e-02, -3.8141e-02, -3.1824e-02, -3.6612e-02,
         -3.9245e-02, -1.9609e-02, -3.0501e-02, -7.7609e-03, -8.0570e-03,
         -2.3806e-02, -2.6526e-02, -2.4266e-02, -2.4878e-02, -3.3844e-02,
         -2.9566e-02, -3.6479e-02, -1.4832e-02, -2.4131e-02,  1.2522e-02,
         -3.0995e-02, -1.1293e-02, -2.4523e-02, -3.9244e-02, -3.0727e-02,
         -4.0406e-02, -2.8647e-02, -9.1868e-03, -4.6082e-02, -4.8844e-02,
         -4.1209e-02, -1.3117e-02, -2.7125e-02, -3.0641e-02, -6.2721e-02,
         -1.6724e-02, -1.2205e-02, -7.4066e-03, -2.2215e-02, -2.2350e-02,
         -1.5625e-02, -2.4046e-02, -1.9222e-02, -4.8427e-02, -2.3804e-02,
         -1.7038e-02, -8.9022e-03, -9.0834e-03, -9.2919e-03, -5.0812e-03,
         -2.9265e-02, -1.5873e-02, -1.5446e-02, -3.2083e-02, -5.7845e-02,
         -1.7572e-02, -5.2507e-02,  4.4114e-04, -4.0418e-02, -4.0858e-02,
         -2.4568e-02, -4.6892e-02, -2.0101e-02, -4.1925e-02, -1.5755e-02,
         -2.7231e-02, -2.4822e-02, -2.8439e-02]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.8000% F1: 0.2660
Applying ckpt from fold 1 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2644
Applying ckpt from fold 2 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.4000% F1: 0.2651
Applying ckpt from fold 3 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.8000% F1: 0.2693
Applying ckpt from fold 4 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.0000% F1: 0.2510
Applying ckpt from fold 5 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 56.0000% F1: 0.2817
Applying ckpt from fold 6 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.0000% F1: 0.2719
Applying ckpt from fold 7 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.8000% F1: 0.2779
Applying ckpt from fold 8 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.8000% F1: 0.2834
Applying ckpt from fold 9 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.6000% F1: 0.2825
Metrics by fold:
Fold 0 - Acc: 0.55 F1: 0.27
Fold 1 - Acc: 0.55 F1: 0.26
Fold 2 - Acc: 0.55 F1: 0.27
Fold 3 - Acc: 0.56 F1: 0.27
Fold 4 - Acc: 0.55 F1: 0.25
Fold 5 - Acc: 0.56 F1: 0.28
Fold 6 - Acc: 0.55 F1: 0.27
Fold 7 - Acc: 0.56 F1: 0.28
Fold 8 - Acc: 0.56 F1: 0.28
Fold 9 - Acc: 0.56 F1: 0.28
agg_acc: 0.5544 agg_f1: 0.2713
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-2.0626e-02, -4.4060e-02, -2.6161e-02, -5.2382e-02, -1.1801e-02,
         -2.1239e-02, -1.8071e-02, -3.0182e-02, -3.2382e-02, -2.0418e-02,
         -2.6720e-02, -4.3357e-02, -2.5472e-02,  5.5979e-03,  1.2318e-02,
         -3.4176e-02, -4.4977e-02, -2.8053e-02, -2.1231e-02, -6.0782e-02,
         -4.0279e-02, -3.8476e-02, -1.6334e-02, -3.2569e-02, -2.5926e-02,
         -2.7391e-02, -2.3964e-02, -3.0589e-02, -2.9190e-02, -3.3341e-02,
         -1.8691e-02, -3.5133e-02, -6.1570e-02, -1.4964e-02, -2.1376e-02,
         -3.1147e-02, -3.0501e-02,  1.4628e-03, -1.8252e-02, -1.9517e-02,
         -1.1622e-02, -3.5739e-02, -3.6812e-02, -1.9371e-02, -1.1859e-02,
         -8.8161e-03, -3.1636e-02, -2.0528e-02, -1.1131e-02, -3.5867e-02,
         -3.8365e-02, -2.5705e-02, -2.1792e-02, -4.4399e-02, -4.0270e-02,
         -5.4638e-02, -2.8454e-02, -2.5333e-02, -2.5547e-02, -1.5287e-02,
         -2.4182e-02, -3.0630e-02,  1.5069e-02, -3.6271e-02, -2.8401e-02,
         -1.5753e-02, -3.0542e-02, -4.4240e-02, -2.0518e-02,  1.3146e-02,
         -2.6623e-02, -5.8353e-03, -6.2991e-02, -2.9645e-02, -5.2723e-02,
         -6.1875e-03, -4.6658e-02, -1.1706e-02, -2.0831e-02, -2.1911e-02,
         -3.0621e-02, -3.0604e-02, -3.1597e-02, -1.4894e-02, -3.7422e-02,
         -1.8669e-02, -3.9261e-02, -2.2540e-02, -3.5005e-02, -1.8804e-02,
         -3.9859e-02, -2.3636e-02, -4.4098e-02, -2.2001e-02, -4.0159e-02,
         -4.1603e-02, -6.0479e-02, -3.4732e-02, -3.5348e-02, -1.1855e-02,
         -1.1457e-02, -1.8017e-02, -2.5695e-02, -3.2170e-02, -1.8815e-02,
          6.0778e-04, -2.9451e-02, -1.5095e-02, -3.4335e-02, -1.8684e-02,
         -5.2852e-02, -2.8976e-02, -4.0829e-02, -1.9680e-02, -1.9389e-02,
         -2.6357e-02, -1.0519e-02, -3.3680e-02, -3.3897e-02, -1.6169e-02,
         -2.5509e-02,  6.1193e-03, -2.6227e-02, -4.9142e-02, -5.1203e-02,
         -2.7614e-02, -2.7042e-02, -8.2370e-02, -3.2448e-02, -6.2488e-02,
         -2.4354e-02, -5.3159e-02,  2.3348e-02, -3.0051e-02, -2.0879e-02,
         -1.0396e-02, -1.9578e-02, -2.8474e-02, -2.0294e-02, -6.0514e-03,
         -3.1489e-02, -2.7566e-02, -8.3959e-03, -8.8849e-03, -3.2843e-02,
         -3.9592e-02, -2.8364e-02, -3.0351e-02, -3.9907e-02, -2.9026e-02,
         -4.1853e-02, -1.4049e-02, -5.6452e-02, -2.7035e-02, -3.0331e-02,
         -2.6986e-02, -1.8532e-02, -1.1369e-02, -4.2319e-02, -1.0535e-01,
         -2.5081e-02, -2.4970e-02, -1.3560e-02, -3.2619e-02, -2.3543e-02,
         -3.1439e-02, -1.0665e-02, -2.8571e-02, -2.4338e-02, -2.9927e-02,
         -2.2083e-02, -1.0367e-02, -3.6159e-02, -3.5902e-02, -3.8141e-02,
          2.2199e-02, -3.4954e-02, -4.2879e-02, -2.6929e-02, -6.4845e-03,
         -2.5604e-02, -2.3864e-02, -6.5536e-02, -1.1395e-02, -2.0720e-02,
         -1.9895e-02, -3.2456e-02, -4.2429e-02, -2.7246e-02, -7.3045e-03,
         -7.3728e-03, -4.4053e-02, -4.0074e-02, -3.2210e-02, -5.1612e-02,
         -3.5234e-02, -4.5111e-02, -1.9451e-02, -3.2387e-02, -4.2629e-02,
         -2.9188e-02, -9.1431e-03, -5.6937e-03, -3.6857e-02, -3.5655e-02,
         -1.4412e-02, -1.6586e-02, -4.8305e-02, -2.0054e-02, -2.2196e-03,
         -2.6737e-02, -2.1182e-02, -3.0844e-02, -2.2878e-02, -2.6762e-02,
         -2.2593e-02, -1.2894e-01, -2.6952e-03, -4.7206e-02, -1.9133e-02,
         -1.6194e-02, -3.4907e-02, -3.0068e-02, -8.7365e-03, -2.4353e-02,
         -1.0010e-01, -3.6861e-02, -4.0455e-02, -3.1136e-02, -5.0729e-02,
         -2.6141e-02, -2.6761e-02, -4.6217e-02, -3.6219e-02, -2.3151e-02,
         -1.7108e-02, -3.9074e-02, -1.9915e-02, -1.2001e-02, -3.7315e-02,
         -3.3087e-02, -2.6547e-02, -4.3930e-02, -4.6760e-02, -2.4470e-02,
          5.5595e-05, -4.3790e-02, -2.8079e-02, -3.8258e-02, -4.1491e-02,
         -3.3981e-02, -2.7939e-02, -2.7030e-02, -1.2909e-02, -4.0956e-02,
         -2.1886e-02, -2.3271e-02, -2.3112e-02, -2.3970e-02, -1.5977e-02,
         -1.6904e-02, -3.9638e-02, -1.4792e-02, -4.5347e-02, -3.1461e-02,
         -2.8825e-02, -1.2313e-02, -3.7781e-02,  2.4980e-03, -2.8167e-02,
         -3.1846e-02, -3.3554e-02, -2.1765e-02, -2.0045e-02, -4.7427e-02,
         -1.8519e-02, -2.8280e-02, -4.4778e-02, -1.3524e-02, -3.2319e-03,
         -2.9903e-02, -3.1917e-02, -2.2511e-02, -5.9006e-02,  1.5946e-03,
         -2.4006e-02, -1.7079e-02, -2.9951e-02, -2.5281e-02, -5.0775e-02,
         -4.3378e-02,  8.9525e-04, -1.6057e-02, -1.3209e-03, -1.9282e-02,
         -3.7466e-02, -7.5034e-02, -3.4903e-02, -2.6046e-02, -6.0244e-02,
         -2.3133e-02, -3.6307e-02, -1.1735e-02, -1.5822e-02, -5.8465e-02,
         -9.4279e-03, -2.4606e-02, -1.6206e-02,  6.8120e-03, -3.1115e-02,
         -2.9297e-02, -3.0197e-02, -2.0291e-02, -1.5730e-02, -2.9399e-02,
         -5.8700e-02, -4.9440e-02, -1.4964e-02, -1.4682e-02, -4.7326e-02,
          1.9171e-03, -2.7425e-02, -3.2663e-02, -4.0381e-02, -2.2076e-02,
         -7.2282e-03, -1.7059e-02, -1.3517e-02, -2.6359e-02, -4.3907e-03,
         -3.9467e-02, -6.9909e-02, -3.6269e-02, -3.8785e-02, -2.7625e-02,
         -3.0422e-02, -3.4326e-02, -4.1373e-03, -2.0417e-02, -2.2334e-02,
         -1.4535e-02, -1.3532e-02, -3.6567e-02, -2.2748e-02, -1.6989e-02,
          1.4371e-03, -4.1189e-02, -4.5399e-02, -3.9660e-02, -2.7661e-02,
         -2.3461e-02, -2.6766e-02, -3.6177e-02, -5.6810e-02, -2.0876e-02,
         -3.5100e-02, -4.1278e-02, -2.1627e-02, -3.7129e-03, -1.9762e-02,
         -1.7184e-02, -2.7223e-02, -2.7576e-02, -9.1357e-04, -1.6475e-02,
         -4.0762e-02, -2.2704e-02, -3.2532e-02, -2.5827e-02, -3.1545e-02,
         -1.7120e-02, -3.9241e-02, -2.4638e-02, -2.9520e-02, -3.0369e-02,
         -2.5346e-02, -2.1294e-02, -4.9278e-02, -2.7448e-02, -3.7034e-02,
         -6.7724e-03, -5.7087e-02, -2.8008e-02,  6.8865e-03, -4.9772e-02,
         -4.4891e-02, -3.4240e-02, -5.1939e-02, -2.3135e-02, -1.4994e-02,
         -3.6481e-02, -1.6013e-02, -4.1644e-02, -3.7349e-02, -1.8343e-02,
         -2.8021e-02, -2.3944e-02, -3.5851e-02, -4.4354e-02, -1.8169e-02,
         -2.3095e-02, -9.4431e-02, -3.8140e-02, -3.4660e-02, -3.6032e-02,
         -2.0042e-02, -2.4378e-02, -1.2028e-02, -2.0953e-02, -2.1721e-02,
         -3.2877e-02, -3.8856e-02, -4.7931e-02, -3.5312e-02, -2.8105e-02,
         -4.7969e-02, -1.0577e-02, -5.4178e-02, -1.9335e-02,  1.4594e-02,
         -5.6146e-03, -2.8620e-02, -3.7851e-02, -1.9913e-02, -4.2189e-02,
         -1.0320e-02, -2.1976e-02, -5.2133e-02, -4.3729e-02, -5.4553e-02,
         -3.5142e-02, -3.7726e-02, -2.6058e-02, -1.1231e-02, -3.2618e-02,
         -4.3355e-02, -1.7774e-02, -3.1622e-02, -2.8229e-02, -2.1421e-02,
         -2.9999e-02, -3.1010e-02, -2.5497e-02, -4.5435e-03, -4.1343e-02,
         -3.2268e-02, -2.0374e-02, -1.9872e-02, -4.6008e-02, -2.8307e-02,
         -1.1835e-02, -2.2528e-02, -2.8635e-02, -2.5755e-02, -2.2962e-02,
         -1.1313e-02, -3.7581e-02, -1.8534e-02, -1.6939e-02, -2.5694e-02,
         -4.5719e-02,  2.1832e-02, -1.5461e-02, -1.8565e-02, -2.3459e-02,
         -6.4967e-02, -2.7417e-02, -2.3490e-02, -2.3226e-02, -4.4696e-02,
         -6.2122e-03, -6.0652e-02, -5.4693e-02, -2.0045e-02, -3.9188e-02,
         -1.6182e-02, -1.6512e-02, -8.1976e-03, -3.2709e-02, -2.5799e-02,
         -2.4841e-03, -2.1700e-02,  4.9436e-03, -2.0033e-02, -1.6611e-02,
         -2.2917e-02, -3.5269e-02, -2.3938e-02, -2.5108e-02, -2.5692e-02,
         -1.4544e-02, -1.7141e-02, -1.6639e-02, -3.4002e-02, -2.0499e-02,
         -3.2127e-02, -6.7373e-02, -1.1025e-02, -3.1973e-02, -2.3749e-02,
         -9.4430e-03, -4.9020e-02, -4.0693e-02, -3.4095e-02, -3.2654e-02,
         -4.3039e-02, -3.7553e-02, -3.2732e-02, -2.8386e-02, -2.5889e-02,
         -4.1052e-02, -4.8210e-02, -3.5973e-02, -3.5697e-02, -3.5337e-02,
         -3.0920e-02, -8.5859e-03,  1.3807e-02, -2.3515e-02, -3.5362e-02,
         -2.4852e-02, -2.1957e-02, -1.4952e-02, -2.1925e-02, -3.4758e-02,
         -2.8220e-02, -3.7455e-02, -4.0865e-02, -3.8104e-02,  1.3347e-03,
         -5.2198e-02, -2.5467e-02, -5.1656e-02, -1.5240e-02, -1.6143e-02,
         -1.1116e-02, -2.9076e-02, -1.5411e-02, -3.7430e-02, -2.3534e-02,
         -3.0279e-02, -1.0146e-01, -2.3272e-02, -4.5229e-02, -3.8890e-02,
          1.7913e-03, -6.2969e-03, -4.1688e-02, -3.0044e-02, -9.7487e-03,
         -2.1045e-02, -1.4235e-02, -2.4313e-02, -1.7216e-02, -3.1402e-02,
         -3.4427e-02, -2.1556e-02, -2.8665e-02, -3.3832e-02, -3.4066e-02,
         -2.2086e-02, -2.8477e-02, -5.0919e-02, -3.4791e-02, -1.7713e-02,
         -1.8561e-02, -3.6231e-02, -3.8923e-02, -3.6720e-02, -1.8680e-02,
         -1.9310e-02, -5.3375e-02, -2.2816e-02, -2.2705e-02, -3.0119e-02,
         -1.6189e-02, -3.3022e-02, -3.1215e-02, -3.2107e-02, -3.4758e-02,
         -2.5874e-02, -5.6180e-02, -4.0951e-02, -2.7341e-02, -2.5415e-02,
         -3.5619e-02, -3.5732e-02, -2.5828e-02, -3.6025e-02, -4.4503e-02,
         -7.0487e-03, -8.6296e-03, -4.8478e-02, -3.6195e-02, -3.2900e-02,
         -3.9823e-02, -1.5362e-02, -5.5768e-03, -2.8645e-02, -2.9967e-02,
         -4.2924e-02, -3.2294e-02, -2.9039e-02, -3.4810e-02, -1.9517e-02,
         -2.9691e-02, -2.8602e-02, -4.0939e-02, -5.1788e-02, -2.9741e-02,
         -3.6167e-02, -2.9228e-02, -2.2982e-02, -5.7735e-02, -1.8834e-02,
         -1.7366e-02, -3.5482e-02, -2.1608e-02, -4.6328e-02, -1.2155e-02,
         -3.7046e-02, -4.9812e-02, -1.5587e-02, -4.5353e-02, -1.4188e-02,
         -4.2994e-02, -3.1072e-02, -4.7449e-02, -3.5341e-02, -2.4476e-02,
         -2.2945e-02, -1.8691e-02, -2.2915e-02, -3.1375e-02, -2.5264e-02,
         -2.0859e-02, -2.5641e-02, -3.1363e-02, -2.8384e-02, -4.3555e-02,
         -3.4732e-02, -3.9482e-02, -1.7701e-02, -2.6898e-02, -1.4156e-02,
         -1.7624e-02, -1.3957e-02, -2.4311e-02, -2.0646e-02, -2.5072e-02,
         -2.4137e-02, -1.8694e-02, -1.8910e-02, -1.0031e-02, -1.3634e-02,
          5.8649e-04, -2.2889e-02, -3.8469e-02, -2.8486e-02, -4.6490e-02,
         -1.9475e-02, -1.1686e-02, -3.8871e-02, -2.8555e-02, -3.2153e-02,
         -2.2332e-02, -1.1427e-02, -3.9309e-02, -2.2623e-02, -1.3303e-02,
         -5.9567e-03, -4.0263e-02, -2.7895e-02, -3.2989e-02, -2.7573e-02,
         -2.0798e-02, -4.4355e-02, -3.5247e-02, -4.0966e-02, -7.5861e-04,
         -2.7611e-02, -5.1424e-02, -4.2651e-02, -3.6131e-02, -1.9154e-02,
         -1.5637e-02, -2.3545e-02, -1.4531e-02, -3.4187e-02, -3.3429e-02,
         -2.7579e-02, -3.3237e-02, -1.5961e-02, -2.8258e-02, -2.0247e-02,
         -2.2522e-02, -3.1527e-02, -2.9972e-02, -2.4582e-02, -8.2861e-02,
         -2.8782e-02, -1.5376e-02, -3.8141e-02, -3.1824e-02, -3.6612e-02,
         -3.9245e-02, -1.9609e-02, -3.0501e-02, -7.7609e-03, -8.0570e-03,
         -2.3806e-02, -2.6526e-02, -2.4266e-02, -2.4878e-02, -3.3844e-02,
         -2.9566e-02, -3.6479e-02, -1.4832e-02, -2.4131e-02,  1.2522e-02,
         -3.0995e-02, -1.1293e-02, -2.4523e-02, -3.9244e-02, -3.0727e-02,
         -4.0406e-02, -2.8647e-02, -9.1868e-03, -4.6082e-02, -4.8844e-02,
         -4.1209e-02, -1.3117e-02, -2.7125e-02, -3.0641e-02, -6.2721e-02,
         -1.6724e-02, -1.2205e-02, -7.4066e-03, -2.2215e-02, -2.2350e-02,
         -1.5625e-02, -2.4046e-02, -1.9222e-02, -4.8427e-02, -2.3804e-02,
         -1.7038e-02, -8.9022e-03, -9.0834e-03, -9.2919e-03, -5.0812e-03,
         -2.9265e-02, -1.5873e-02, -1.5446e-02, -3.2083e-02, -5.7845e-02,
         -1.7572e-02, -5.2507e-02,  4.4114e-04, -4.0418e-02, -4.0858e-02,
         -2.4568e-02, -4.6892e-02, -2.0101e-02, -4.1925e-02, -1.5755e-02,
         -2.7231e-02, -2.4822e-02, -2.8439e-02]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.8000% F1: 0.3265
Applying ckpt from fold 1 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.4000% F1: 0.3100
Applying ckpt from fold 2 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.6000% F1: 0.3222
Applying ckpt from fold 3 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.0000% F1: 0.3203
Applying ckpt from fold 4 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.0000% F1: 0.3171
Applying ckpt from fold 5 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.6000% F1: 0.3220
Applying ckpt from fold 6 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.4000% F1: 0.3350
Applying ckpt from fold 7 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.8000% F1: 0.2396
Applying ckpt from fold 8 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.4000% F1: 0.3271
Applying ckpt from fold 9 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.6000% F1: 0.3280
Metrics by fold:
Fold 0 - Acc: 0.49 F1: 0.33
Fold 1 - Acc: 0.51 F1: 0.31
Fold 2 - Acc: 0.50 F1: 0.32
Fold 3 - Acc: 0.55 F1: 0.32
Fold 4 - Acc: 0.51 F1: 0.32
Fold 5 - Acc: 0.50 F1: 0.32
Fold 6 - Acc: 0.54 F1: 0.33
Fold 7 - Acc: 0.55 F1: 0.24
Fold 8 - Acc: 0.53 F1: 0.33
Fold 9 - Acc: 0.50 F1: 0.33
agg_acc: 0.5176 agg_f1: 0.3148
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-2.0626e-02, -4.4060e-02, -2.6161e-02, -5.2382e-02, -1.1801e-02,
         -2.1239e-02, -1.8071e-02, -3.0182e-02, -3.2382e-02, -2.0418e-02,
         -2.6720e-02, -4.3357e-02, -2.5472e-02,  5.5979e-03,  1.2318e-02,
         -3.4176e-02, -4.4977e-02, -2.8053e-02, -2.1231e-02, -6.0782e-02,
         -4.0279e-02, -3.8476e-02, -1.6334e-02, -3.2569e-02, -2.5926e-02,
         -2.7391e-02, -2.3964e-02, -3.0589e-02, -2.9190e-02, -3.3341e-02,
         -1.8691e-02, -3.5133e-02, -6.1570e-02, -1.4964e-02, -2.1376e-02,
         -3.1147e-02, -3.0501e-02,  1.4628e-03, -1.8252e-02, -1.9517e-02,
         -1.1622e-02, -3.5739e-02, -3.6812e-02, -1.9371e-02, -1.1859e-02,
         -8.8161e-03, -3.1636e-02, -2.0528e-02, -1.1131e-02, -3.5867e-02,
         -3.8365e-02, -2.5705e-02, -2.1792e-02, -4.4399e-02, -4.0270e-02,
         -5.4638e-02, -2.8454e-02, -2.5333e-02, -2.5547e-02, -1.5287e-02,
         -2.4182e-02, -3.0630e-02,  1.5069e-02, -3.6271e-02, -2.8401e-02,
         -1.5753e-02, -3.0542e-02, -4.4240e-02, -2.0518e-02,  1.3146e-02,
         -2.6623e-02, -5.8353e-03, -6.2991e-02, -2.9645e-02, -5.2723e-02,
         -6.1875e-03, -4.6658e-02, -1.1706e-02, -2.0831e-02, -2.1911e-02,
         -3.0621e-02, -3.0604e-02, -3.1597e-02, -1.4894e-02, -3.7422e-02,
         -1.8669e-02, -3.9261e-02, -2.2540e-02, -3.5005e-02, -1.8804e-02,
         -3.9859e-02, -2.3636e-02, -4.4098e-02, -2.2001e-02, -4.0159e-02,
         -4.1603e-02, -6.0479e-02, -3.4732e-02, -3.5348e-02, -1.1855e-02,
         -1.1457e-02, -1.8017e-02, -2.5695e-02, -3.2170e-02, -1.8815e-02,
          6.0778e-04, -2.9451e-02, -1.5095e-02, -3.4335e-02, -1.8684e-02,
         -5.2852e-02, -2.8976e-02, -4.0829e-02, -1.9680e-02, -1.9389e-02,
         -2.6357e-02, -1.0519e-02, -3.3680e-02, -3.3897e-02, -1.6169e-02,
         -2.5509e-02,  6.1193e-03, -2.6227e-02, -4.9142e-02, -5.1203e-02,
         -2.7614e-02, -2.7042e-02, -8.2370e-02, -3.2448e-02, -6.2488e-02,
         -2.4354e-02, -5.3159e-02,  2.3348e-02, -3.0051e-02, -2.0879e-02,
         -1.0396e-02, -1.9578e-02, -2.8474e-02, -2.0294e-02, -6.0514e-03,
         -3.1489e-02, -2.7566e-02, -8.3959e-03, -8.8849e-03, -3.2843e-02,
         -3.9592e-02, -2.8364e-02, -3.0351e-02, -3.9907e-02, -2.9026e-02,
         -4.1853e-02, -1.4049e-02, -5.6452e-02, -2.7035e-02, -3.0331e-02,
         -2.6986e-02, -1.8532e-02, -1.1369e-02, -4.2319e-02, -1.0535e-01,
         -2.5081e-02, -2.4970e-02, -1.3560e-02, -3.2619e-02, -2.3543e-02,
         -3.1439e-02, -1.0665e-02, -2.8571e-02, -2.4338e-02, -2.9927e-02,
         -2.2083e-02, -1.0367e-02, -3.6159e-02, -3.5902e-02, -3.8141e-02,
          2.2199e-02, -3.4954e-02, -4.2879e-02, -2.6929e-02, -6.4845e-03,
         -2.5604e-02, -2.3864e-02, -6.5536e-02, -1.1395e-02, -2.0720e-02,
         -1.9895e-02, -3.2456e-02, -4.2429e-02, -2.7246e-02, -7.3045e-03,
         -7.3728e-03, -4.4053e-02, -4.0074e-02, -3.2210e-02, -5.1612e-02,
         -3.5234e-02, -4.5111e-02, -1.9451e-02, -3.2387e-02, -4.2629e-02,
         -2.9188e-02, -9.1431e-03, -5.6937e-03, -3.6857e-02, -3.5655e-02,
         -1.4412e-02, -1.6586e-02, -4.8305e-02, -2.0054e-02, -2.2196e-03,
         -2.6737e-02, -2.1182e-02, -3.0844e-02, -2.2878e-02, -2.6762e-02,
         -2.2593e-02, -1.2894e-01, -2.6952e-03, -4.7206e-02, -1.9133e-02,
         -1.6194e-02, -3.4907e-02, -3.0068e-02, -8.7365e-03, -2.4353e-02,
         -1.0010e-01, -3.6861e-02, -4.0455e-02, -3.1136e-02, -5.0729e-02,
         -2.6141e-02, -2.6761e-02, -4.6217e-02, -3.6219e-02, -2.3151e-02,
         -1.7108e-02, -3.9074e-02, -1.9915e-02, -1.2001e-02, -3.7315e-02,
         -3.3087e-02, -2.6547e-02, -4.3930e-02, -4.6760e-02, -2.4470e-02,
          5.5595e-05, -4.3790e-02, -2.8079e-02, -3.8258e-02, -4.1491e-02,
         -3.3981e-02, -2.7939e-02, -2.7030e-02, -1.2909e-02, -4.0956e-02,
         -2.1886e-02, -2.3271e-02, -2.3112e-02, -2.3970e-02, -1.5977e-02,
         -1.6904e-02, -3.9638e-02, -1.4792e-02, -4.5347e-02, -3.1461e-02,
         -2.8825e-02, -1.2313e-02, -3.7781e-02,  2.4980e-03, -2.8167e-02,
         -3.1846e-02, -3.3554e-02, -2.1765e-02, -2.0045e-02, -4.7427e-02,
         -1.8519e-02, -2.8280e-02, -4.4778e-02, -1.3524e-02, -3.2319e-03,
         -2.9903e-02, -3.1917e-02, -2.2511e-02, -5.9006e-02,  1.5946e-03,
         -2.4006e-02, -1.7079e-02, -2.9951e-02, -2.5281e-02, -5.0775e-02,
         -4.3378e-02,  8.9525e-04, -1.6057e-02, -1.3209e-03, -1.9282e-02,
         -3.7466e-02, -7.5034e-02, -3.4903e-02, -2.6046e-02, -6.0244e-02,
         -2.3133e-02, -3.6307e-02, -1.1735e-02, -1.5822e-02, -5.8465e-02,
         -9.4279e-03, -2.4606e-02, -1.6206e-02,  6.8120e-03, -3.1115e-02,
         -2.9297e-02, -3.0197e-02, -2.0291e-02, -1.5730e-02, -2.9399e-02,
         -5.8700e-02, -4.9440e-02, -1.4964e-02, -1.4682e-02, -4.7326e-02,
          1.9171e-03, -2.7425e-02, -3.2663e-02, -4.0381e-02, -2.2076e-02,
         -7.2282e-03, -1.7059e-02, -1.3517e-02, -2.6359e-02, -4.3907e-03,
         -3.9467e-02, -6.9909e-02, -3.6269e-02, -3.8785e-02, -2.7625e-02,
         -3.0422e-02, -3.4326e-02, -4.1373e-03, -2.0417e-02, -2.2334e-02,
         -1.4535e-02, -1.3532e-02, -3.6567e-02, -2.2748e-02, -1.6989e-02,
          1.4371e-03, -4.1189e-02, -4.5399e-02, -3.9660e-02, -2.7661e-02,
         -2.3461e-02, -2.6766e-02, -3.6177e-02, -5.6810e-02, -2.0876e-02,
         -3.5100e-02, -4.1278e-02, -2.1627e-02, -3.7129e-03, -1.9762e-02,
         -1.7184e-02, -2.7223e-02, -2.7576e-02, -9.1357e-04, -1.6475e-02,
         -4.0762e-02, -2.2704e-02, -3.2532e-02, -2.5827e-02, -3.1545e-02,
         -1.7120e-02, -3.9241e-02, -2.4638e-02, -2.9520e-02, -3.0369e-02,
         -2.5346e-02, -2.1294e-02, -4.9278e-02, -2.7448e-02, -3.7034e-02,
         -6.7724e-03, -5.7087e-02, -2.8008e-02,  6.8865e-03, -4.9772e-02,
         -4.4891e-02, -3.4240e-02, -5.1939e-02, -2.3135e-02, -1.4994e-02,
         -3.6481e-02, -1.6013e-02, -4.1644e-02, -3.7349e-02, -1.8343e-02,
         -2.8021e-02, -2.3944e-02, -3.5851e-02, -4.4354e-02, -1.8169e-02,
         -2.3095e-02, -9.4431e-02, -3.8140e-02, -3.4660e-02, -3.6032e-02,
         -2.0042e-02, -2.4378e-02, -1.2028e-02, -2.0953e-02, -2.1721e-02,
         -3.2877e-02, -3.8856e-02, -4.7931e-02, -3.5312e-02, -2.8105e-02,
         -4.7969e-02, -1.0577e-02, -5.4178e-02, -1.9335e-02,  1.4594e-02,
         -5.6146e-03, -2.8620e-02, -3.7851e-02, -1.9913e-02, -4.2189e-02,
         -1.0320e-02, -2.1976e-02, -5.2133e-02, -4.3729e-02, -5.4553e-02,
         -3.5142e-02, -3.7726e-02, -2.6058e-02, -1.1231e-02, -3.2618e-02,
         -4.3355e-02, -1.7774e-02, -3.1622e-02, -2.8229e-02, -2.1421e-02,
         -2.9999e-02, -3.1010e-02, -2.5497e-02, -4.5435e-03, -4.1343e-02,
         -3.2268e-02, -2.0374e-02, -1.9872e-02, -4.6008e-02, -2.8307e-02,
         -1.1835e-02, -2.2528e-02, -2.8635e-02, -2.5755e-02, -2.2962e-02,
         -1.1313e-02, -3.7581e-02, -1.8534e-02, -1.6939e-02, -2.5694e-02,
         -4.5719e-02,  2.1832e-02, -1.5461e-02, -1.8565e-02, -2.3459e-02,
         -6.4967e-02, -2.7417e-02, -2.3490e-02, -2.3226e-02, -4.4696e-02,
         -6.2122e-03, -6.0652e-02, -5.4693e-02, -2.0045e-02, -3.9188e-02,
         -1.6182e-02, -1.6512e-02, -8.1976e-03, -3.2709e-02, -2.5799e-02,
         -2.4841e-03, -2.1700e-02,  4.9436e-03, -2.0033e-02, -1.6611e-02,
         -2.2917e-02, -3.5269e-02, -2.3938e-02, -2.5108e-02, -2.5692e-02,
         -1.4544e-02, -1.7141e-02, -1.6639e-02, -3.4002e-02, -2.0499e-02,
         -3.2127e-02, -6.7373e-02, -1.1025e-02, -3.1973e-02, -2.3749e-02,
         -9.4430e-03, -4.9020e-02, -4.0693e-02, -3.4095e-02, -3.2654e-02,
         -4.3039e-02, -3.7553e-02, -3.2732e-02, -2.8386e-02, -2.5889e-02,
         -4.1052e-02, -4.8210e-02, -3.5973e-02, -3.5697e-02, -3.5337e-02,
         -3.0920e-02, -8.5859e-03,  1.3807e-02, -2.3515e-02, -3.5362e-02,
         -2.4852e-02, -2.1957e-02, -1.4952e-02, -2.1925e-02, -3.4758e-02,
         -2.8220e-02, -3.7455e-02, -4.0865e-02, -3.8104e-02,  1.3347e-03,
         -5.2198e-02, -2.5467e-02, -5.1656e-02, -1.5240e-02, -1.6143e-02,
         -1.1116e-02, -2.9076e-02, -1.5411e-02, -3.7430e-02, -2.3534e-02,
         -3.0279e-02, -1.0146e-01, -2.3272e-02, -4.5229e-02, -3.8890e-02,
          1.7913e-03, -6.2969e-03, -4.1688e-02, -3.0044e-02, -9.7487e-03,
         -2.1045e-02, -1.4235e-02, -2.4313e-02, -1.7216e-02, -3.1402e-02,
         -3.4427e-02, -2.1556e-02, -2.8665e-02, -3.3832e-02, -3.4066e-02,
         -2.2086e-02, -2.8477e-02, -5.0919e-02, -3.4791e-02, -1.7713e-02,
         -1.8561e-02, -3.6231e-02, -3.8923e-02, -3.6720e-02, -1.8680e-02,
         -1.9310e-02, -5.3375e-02, -2.2816e-02, -2.2705e-02, -3.0119e-02,
         -1.6189e-02, -3.3022e-02, -3.1215e-02, -3.2107e-02, -3.4758e-02,
         -2.5874e-02, -5.6180e-02, -4.0951e-02, -2.7341e-02, -2.5415e-02,
         -3.5619e-02, -3.5732e-02, -2.5828e-02, -3.6025e-02, -4.4503e-02,
         -7.0487e-03, -8.6296e-03, -4.8478e-02, -3.6195e-02, -3.2900e-02,
         -3.9823e-02, -1.5362e-02, -5.5768e-03, -2.8645e-02, -2.9967e-02,
         -4.2924e-02, -3.2294e-02, -2.9039e-02, -3.4810e-02, -1.9517e-02,
         -2.9691e-02, -2.8602e-02, -4.0939e-02, -5.1788e-02, -2.9741e-02,
         -3.6167e-02, -2.9228e-02, -2.2982e-02, -5.7735e-02, -1.8834e-02,
         -1.7366e-02, -3.5482e-02, -2.1608e-02, -4.6328e-02, -1.2155e-02,
         -3.7046e-02, -4.9812e-02, -1.5587e-02, -4.5353e-02, -1.4188e-02,
         -4.2994e-02, -3.1072e-02, -4.7449e-02, -3.5341e-02, -2.4476e-02,
         -2.2945e-02, -1.8691e-02, -2.2915e-02, -3.1375e-02, -2.5264e-02,
         -2.0859e-02, -2.5641e-02, -3.1363e-02, -2.8384e-02, -4.3555e-02,
         -3.4732e-02, -3.9482e-02, -1.7701e-02, -2.6898e-02, -1.4156e-02,
         -1.7624e-02, -1.3957e-02, -2.4311e-02, -2.0646e-02, -2.5072e-02,
         -2.4137e-02, -1.8694e-02, -1.8910e-02, -1.0031e-02, -1.3634e-02,
          5.8649e-04, -2.2889e-02, -3.8469e-02, -2.8486e-02, -4.6490e-02,
         -1.9475e-02, -1.1686e-02, -3.8871e-02, -2.8555e-02, -3.2153e-02,
         -2.2332e-02, -1.1427e-02, -3.9309e-02, -2.2623e-02, -1.3303e-02,
         -5.9567e-03, -4.0263e-02, -2.7895e-02, -3.2989e-02, -2.7573e-02,
         -2.0798e-02, -4.4355e-02, -3.5247e-02, -4.0966e-02, -7.5861e-04,
         -2.7611e-02, -5.1424e-02, -4.2651e-02, -3.6131e-02, -1.9154e-02,
         -1.5637e-02, -2.3545e-02, -1.4531e-02, -3.4187e-02, -3.3429e-02,
         -2.7579e-02, -3.3237e-02, -1.5961e-02, -2.8258e-02, -2.0247e-02,
         -2.2522e-02, -3.1527e-02, -2.9972e-02, -2.4582e-02, -8.2861e-02,
         -2.8782e-02, -1.5376e-02, -3.8141e-02, -3.1824e-02, -3.6612e-02,
         -3.9245e-02, -1.9609e-02, -3.0501e-02, -7.7609e-03, -8.0570e-03,
         -2.3806e-02, -2.6526e-02, -2.4266e-02, -2.4878e-02, -3.3844e-02,
         -2.9566e-02, -3.6479e-02, -1.4832e-02, -2.4131e-02,  1.2522e-02,
         -3.0995e-02, -1.1293e-02, -2.4523e-02, -3.9244e-02, -3.0727e-02,
         -4.0406e-02, -2.8647e-02, -9.1868e-03, -4.6082e-02, -4.8844e-02,
         -4.1209e-02, -1.3117e-02, -2.7125e-02, -3.0641e-02, -6.2721e-02,
         -1.6724e-02, -1.2205e-02, -7.4066e-03, -2.2215e-02, -2.2350e-02,
         -1.5625e-02, -2.4046e-02, -1.9222e-02, -4.8427e-02, -2.3804e-02,
         -1.7038e-02, -8.9022e-03, -9.0834e-03, -9.2919e-03, -5.0812e-03,
         -2.9265e-02, -1.5873e-02, -1.5446e-02, -3.2083e-02, -5.7845e-02,
         -1.7572e-02, -5.2507e-02,  4.4114e-04, -4.0418e-02, -4.0858e-02,
         -2.4568e-02, -4.6892e-02, -2.0101e-02, -4.1925e-02, -1.5755e-02,
         -2.7231e-02, -2.4822e-02, -2.8439e-02]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 46.8000% F1: 0.3367
Applying ckpt from fold 1 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.6000% F1: 0.3272
Applying ckpt from fold 2 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.4000% F1: 0.3380
Applying ckpt from fold 3 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.2000% F1: 0.3292
Applying ckpt from fold 4 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.2000% F1: 0.3190
Applying ckpt from fold 5 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.6000% F1: 0.3307
Applying ckpt from fold 6 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.4000% F1: 0.3182
Applying ckpt from fold 7 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.8000% F1: 0.3057
Applying ckpt from fold 8 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.8000% F1: 0.3333
Applying ckpt from fold 9 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.8000% F1: 0.3498
Metrics by fold:
Fold 0 - Acc: 0.47 F1: 0.34
Fold 1 - Acc: 0.50 F1: 0.33
Fold 2 - Acc: 0.50 F1: 0.34
Fold 3 - Acc: 0.53 F1: 0.33
Fold 4 - Acc: 0.52 F1: 0.32
Fold 5 - Acc: 0.50 F1: 0.33
Fold 6 - Acc: 0.48 F1: 0.32
Fold 7 - Acc: 0.54 F1: 0.31
Fold 8 - Acc: 0.52 F1: 0.33
Fold 9 - Acc: 0.49 F1: 0.35
agg_acc: 0.5046 agg_f1: 0.3288
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-2.0626e-02, -4.4060e-02, -2.6161e-02, -5.2382e-02, -1.1801e-02,
         -2.1239e-02, -1.8071e-02, -3.0182e-02, -3.2382e-02, -2.0418e-02,
         -2.6720e-02, -4.3357e-02, -2.5472e-02,  5.5979e-03,  1.2318e-02,
         -3.4176e-02, -4.4977e-02, -2.8053e-02, -2.1231e-02, -6.0782e-02,
         -4.0279e-02, -3.8476e-02, -1.6334e-02, -3.2569e-02, -2.5926e-02,
         -2.7391e-02, -2.3964e-02, -3.0589e-02, -2.9190e-02, -3.3341e-02,
         -1.8691e-02, -3.5133e-02, -6.1570e-02, -1.4964e-02, -2.1376e-02,
         -3.1147e-02, -3.0501e-02,  1.4628e-03, -1.8252e-02, -1.9517e-02,
         -1.1622e-02, -3.5739e-02, -3.6812e-02, -1.9371e-02, -1.1859e-02,
         -8.8161e-03, -3.1636e-02, -2.0528e-02, -1.1131e-02, -3.5867e-02,
         -3.8365e-02, -2.5705e-02, -2.1792e-02, -4.4399e-02, -4.0270e-02,
         -5.4638e-02, -2.8454e-02, -2.5333e-02, -2.5547e-02, -1.5287e-02,
         -2.4182e-02, -3.0630e-02,  1.5069e-02, -3.6271e-02, -2.8401e-02,
         -1.5753e-02, -3.0542e-02, -4.4240e-02, -2.0518e-02,  1.3146e-02,
         -2.6623e-02, -5.8353e-03, -6.2991e-02, -2.9645e-02, -5.2723e-02,
         -6.1875e-03, -4.6658e-02, -1.1706e-02, -2.0831e-02, -2.1911e-02,
         -3.0621e-02, -3.0604e-02, -3.1597e-02, -1.4894e-02, -3.7422e-02,
         -1.8669e-02, -3.9261e-02, -2.2540e-02, -3.5005e-02, -1.8804e-02,
         -3.9859e-02, -2.3636e-02, -4.4098e-02, -2.2001e-02, -4.0159e-02,
         -4.1603e-02, -6.0479e-02, -3.4732e-02, -3.5348e-02, -1.1855e-02,
         -1.1457e-02, -1.8017e-02, -2.5695e-02, -3.2170e-02, -1.8815e-02,
          6.0778e-04, -2.9451e-02, -1.5095e-02, -3.4335e-02, -1.8684e-02,
         -5.2852e-02, -2.8976e-02, -4.0829e-02, -1.9680e-02, -1.9389e-02,
         -2.6357e-02, -1.0519e-02, -3.3680e-02, -3.3897e-02, -1.6169e-02,
         -2.5509e-02,  6.1193e-03, -2.6227e-02, -4.9142e-02, -5.1203e-02,
         -2.7614e-02, -2.7042e-02, -8.2370e-02, -3.2448e-02, -6.2488e-02,
         -2.4354e-02, -5.3159e-02,  2.3348e-02, -3.0051e-02, -2.0879e-02,
         -1.0396e-02, -1.9578e-02, -2.8474e-02, -2.0294e-02, -6.0514e-03,
         -3.1489e-02, -2.7566e-02, -8.3959e-03, -8.8849e-03, -3.2843e-02,
         -3.9592e-02, -2.8364e-02, -3.0351e-02, -3.9907e-02, -2.9026e-02,
         -4.1853e-02, -1.4049e-02, -5.6452e-02, -2.7035e-02, -3.0331e-02,
         -2.6986e-02, -1.8532e-02, -1.1369e-02, -4.2319e-02, -1.0535e-01,
         -2.5081e-02, -2.4970e-02, -1.3560e-02, -3.2619e-02, -2.3543e-02,
         -3.1439e-02, -1.0665e-02, -2.8571e-02, -2.4338e-02, -2.9927e-02,
         -2.2083e-02, -1.0367e-02, -3.6159e-02, -3.5902e-02, -3.8141e-02,
          2.2199e-02, -3.4954e-02, -4.2879e-02, -2.6929e-02, -6.4845e-03,
         -2.5604e-02, -2.3864e-02, -6.5536e-02, -1.1395e-02, -2.0720e-02,
         -1.9895e-02, -3.2456e-02, -4.2429e-02, -2.7246e-02, -7.3045e-03,
         -7.3728e-03, -4.4053e-02, -4.0074e-02, -3.2210e-02, -5.1612e-02,
         -3.5234e-02, -4.5111e-02, -1.9451e-02, -3.2387e-02, -4.2629e-02,
         -2.9188e-02, -9.1431e-03, -5.6937e-03, -3.6857e-02, -3.5655e-02,
         -1.4412e-02, -1.6586e-02, -4.8305e-02, -2.0054e-02, -2.2196e-03,
         -2.6737e-02, -2.1182e-02, -3.0844e-02, -2.2878e-02, -2.6762e-02,
         -2.2593e-02, -1.2894e-01, -2.6952e-03, -4.7206e-02, -1.9133e-02,
         -1.6194e-02, -3.4907e-02, -3.0068e-02, -8.7365e-03, -2.4353e-02,
         -1.0010e-01, -3.6861e-02, -4.0455e-02, -3.1136e-02, -5.0729e-02,
         -2.6141e-02, -2.6761e-02, -4.6217e-02, -3.6219e-02, -2.3151e-02,
         -1.7108e-02, -3.9074e-02, -1.9915e-02, -1.2001e-02, -3.7315e-02,
         -3.3087e-02, -2.6547e-02, -4.3930e-02, -4.6760e-02, -2.4470e-02,
          5.5595e-05, -4.3790e-02, -2.8079e-02, -3.8258e-02, -4.1491e-02,
         -3.3981e-02, -2.7939e-02, -2.7030e-02, -1.2909e-02, -4.0956e-02,
         -2.1886e-02, -2.3271e-02, -2.3112e-02, -2.3970e-02, -1.5977e-02,
         -1.6904e-02, -3.9638e-02, -1.4792e-02, -4.5347e-02, -3.1461e-02,
         -2.8825e-02, -1.2313e-02, -3.7781e-02,  2.4980e-03, -2.8167e-02,
         -3.1846e-02, -3.3554e-02, -2.1765e-02, -2.0045e-02, -4.7427e-02,
         -1.8519e-02, -2.8280e-02, -4.4778e-02, -1.3524e-02, -3.2319e-03,
         -2.9903e-02, -3.1917e-02, -2.2511e-02, -5.9006e-02,  1.5946e-03,
         -2.4006e-02, -1.7079e-02, -2.9951e-02, -2.5281e-02, -5.0775e-02,
         -4.3378e-02,  8.9525e-04, -1.6057e-02, -1.3209e-03, -1.9282e-02,
         -3.7466e-02, -7.5034e-02, -3.4903e-02, -2.6046e-02, -6.0244e-02,
         -2.3133e-02, -3.6307e-02, -1.1735e-02, -1.5822e-02, -5.8465e-02,
         -9.4279e-03, -2.4606e-02, -1.6206e-02,  6.8120e-03, -3.1115e-02,
         -2.9297e-02, -3.0197e-02, -2.0291e-02, -1.5730e-02, -2.9399e-02,
         -5.8700e-02, -4.9440e-02, -1.4964e-02, -1.4682e-02, -4.7326e-02,
          1.9171e-03, -2.7425e-02, -3.2663e-02, -4.0381e-02, -2.2076e-02,
         -7.2282e-03, -1.7059e-02, -1.3517e-02, -2.6359e-02, -4.3907e-03,
         -3.9467e-02, -6.9909e-02, -3.6269e-02, -3.8785e-02, -2.7625e-02,
         -3.0422e-02, -3.4326e-02, -4.1373e-03, -2.0417e-02, -2.2334e-02,
         -1.4535e-02, -1.3532e-02, -3.6567e-02, -2.2748e-02, -1.6989e-02,
          1.4371e-03, -4.1189e-02, -4.5399e-02, -3.9660e-02, -2.7661e-02,
         -2.3461e-02, -2.6766e-02, -3.6177e-02, -5.6810e-02, -2.0876e-02,
         -3.5100e-02, -4.1278e-02, -2.1627e-02, -3.7129e-03, -1.9762e-02,
         -1.7184e-02, -2.7223e-02, -2.7576e-02, -9.1357e-04, -1.6475e-02,
         -4.0762e-02, -2.2704e-02, -3.2532e-02, -2.5827e-02, -3.1545e-02,
         -1.7120e-02, -3.9241e-02, -2.4638e-02, -2.9520e-02, -3.0369e-02,
         -2.5346e-02, -2.1294e-02, -4.9278e-02, -2.7448e-02, -3.7034e-02,
         -6.7724e-03, -5.7087e-02, -2.8008e-02,  6.8865e-03, -4.9772e-02,
         -4.4891e-02, -3.4240e-02, -5.1939e-02, -2.3135e-02, -1.4994e-02,
         -3.6481e-02, -1.6013e-02, -4.1644e-02, -3.7349e-02, -1.8343e-02,
         -2.8021e-02, -2.3944e-02, -3.5851e-02, -4.4354e-02, -1.8169e-02,
         -2.3095e-02, -9.4431e-02, -3.8140e-02, -3.4660e-02, -3.6032e-02,
         -2.0042e-02, -2.4378e-02, -1.2028e-02, -2.0953e-02, -2.1721e-02,
         -3.2877e-02, -3.8856e-02, -4.7931e-02, -3.5312e-02, -2.8105e-02,
         -4.7969e-02, -1.0577e-02, -5.4178e-02, -1.9335e-02,  1.4594e-02,
         -5.6146e-03, -2.8620e-02, -3.7851e-02, -1.9913e-02, -4.2189e-02,
         -1.0320e-02, -2.1976e-02, -5.2133e-02, -4.3729e-02, -5.4553e-02,
         -3.5142e-02, -3.7726e-02, -2.6058e-02, -1.1231e-02, -3.2618e-02,
         -4.3355e-02, -1.7774e-02, -3.1622e-02, -2.8229e-02, -2.1421e-02,
         -2.9999e-02, -3.1010e-02, -2.5497e-02, -4.5435e-03, -4.1343e-02,
         -3.2268e-02, -2.0374e-02, -1.9872e-02, -4.6008e-02, -2.8307e-02,
         -1.1835e-02, -2.2528e-02, -2.8635e-02, -2.5755e-02, -2.2962e-02,
         -1.1313e-02, -3.7581e-02, -1.8534e-02, -1.6939e-02, -2.5694e-02,
         -4.5719e-02,  2.1832e-02, -1.5461e-02, -1.8565e-02, -2.3459e-02,
         -6.4967e-02, -2.7417e-02, -2.3490e-02, -2.3226e-02, -4.4696e-02,
         -6.2122e-03, -6.0652e-02, -5.4693e-02, -2.0045e-02, -3.9188e-02,
         -1.6182e-02, -1.6512e-02, -8.1976e-03, -3.2709e-02, -2.5799e-02,
         -2.4841e-03, -2.1700e-02,  4.9436e-03, -2.0033e-02, -1.6611e-02,
         -2.2917e-02, -3.5269e-02, -2.3938e-02, -2.5108e-02, -2.5692e-02,
         -1.4544e-02, -1.7141e-02, -1.6639e-02, -3.4002e-02, -2.0499e-02,
         -3.2127e-02, -6.7373e-02, -1.1025e-02, -3.1973e-02, -2.3749e-02,
         -9.4430e-03, -4.9020e-02, -4.0693e-02, -3.4095e-02, -3.2654e-02,
         -4.3039e-02, -3.7553e-02, -3.2732e-02, -2.8386e-02, -2.5889e-02,
         -4.1052e-02, -4.8210e-02, -3.5973e-02, -3.5697e-02, -3.5337e-02,
         -3.0920e-02, -8.5859e-03,  1.3807e-02, -2.3515e-02, -3.5362e-02,
         -2.4852e-02, -2.1957e-02, -1.4952e-02, -2.1925e-02, -3.4758e-02,
         -2.8220e-02, -3.7455e-02, -4.0865e-02, -3.8104e-02,  1.3347e-03,
         -5.2198e-02, -2.5467e-02, -5.1656e-02, -1.5240e-02, -1.6143e-02,
         -1.1116e-02, -2.9076e-02, -1.5411e-02, -3.7430e-02, -2.3534e-02,
         -3.0279e-02, -1.0146e-01, -2.3272e-02, -4.5229e-02, -3.8890e-02,
          1.7913e-03, -6.2969e-03, -4.1688e-02, -3.0044e-02, -9.7487e-03,
         -2.1045e-02, -1.4235e-02, -2.4313e-02, -1.7216e-02, -3.1402e-02,
         -3.4427e-02, -2.1556e-02, -2.8665e-02, -3.3832e-02, -3.4066e-02,
         -2.2086e-02, -2.8477e-02, -5.0919e-02, -3.4791e-02, -1.7713e-02,
         -1.8561e-02, -3.6231e-02, -3.8923e-02, -3.6720e-02, -1.8680e-02,
         -1.9310e-02, -5.3375e-02, -2.2816e-02, -2.2705e-02, -3.0119e-02,
         -1.6189e-02, -3.3022e-02, -3.1215e-02, -3.2107e-02, -3.4758e-02,
         -2.5874e-02, -5.6180e-02, -4.0951e-02, -2.7341e-02, -2.5415e-02,
         -3.5619e-02, -3.5732e-02, -2.5828e-02, -3.6025e-02, -4.4503e-02,
         -7.0487e-03, -8.6296e-03, -4.8478e-02, -3.6195e-02, -3.2900e-02,
         -3.9823e-02, -1.5362e-02, -5.5768e-03, -2.8645e-02, -2.9967e-02,
         -4.2924e-02, -3.2294e-02, -2.9039e-02, -3.4810e-02, -1.9517e-02,
         -2.9691e-02, -2.8602e-02, -4.0939e-02, -5.1788e-02, -2.9741e-02,
         -3.6167e-02, -2.9228e-02, -2.2982e-02, -5.7735e-02, -1.8834e-02,
         -1.7366e-02, -3.5482e-02, -2.1608e-02, -4.6328e-02, -1.2155e-02,
         -3.7046e-02, -4.9812e-02, -1.5587e-02, -4.5353e-02, -1.4188e-02,
         -4.2994e-02, -3.1072e-02, -4.7449e-02, -3.5341e-02, -2.4476e-02,
         -2.2945e-02, -1.8691e-02, -2.2915e-02, -3.1375e-02, -2.5264e-02,
         -2.0859e-02, -2.5641e-02, -3.1363e-02, -2.8384e-02, -4.3555e-02,
         -3.4732e-02, -3.9482e-02, -1.7701e-02, -2.6898e-02, -1.4156e-02,
         -1.7624e-02, -1.3957e-02, -2.4311e-02, -2.0646e-02, -2.5072e-02,
         -2.4137e-02, -1.8694e-02, -1.8910e-02, -1.0031e-02, -1.3634e-02,
          5.8649e-04, -2.2889e-02, -3.8469e-02, -2.8486e-02, -4.6490e-02,
         -1.9475e-02, -1.1686e-02, -3.8871e-02, -2.8555e-02, -3.2153e-02,
         -2.2332e-02, -1.1427e-02, -3.9309e-02, -2.2623e-02, -1.3303e-02,
         -5.9567e-03, -4.0263e-02, -2.7895e-02, -3.2989e-02, -2.7573e-02,
         -2.0798e-02, -4.4355e-02, -3.5247e-02, -4.0966e-02, -7.5861e-04,
         -2.7611e-02, -5.1424e-02, -4.2651e-02, -3.6131e-02, -1.9154e-02,
         -1.5637e-02, -2.3545e-02, -1.4531e-02, -3.4187e-02, -3.3429e-02,
         -2.7579e-02, -3.3237e-02, -1.5961e-02, -2.8258e-02, -2.0247e-02,
         -2.2522e-02, -3.1527e-02, -2.9972e-02, -2.4582e-02, -8.2861e-02,
         -2.8782e-02, -1.5376e-02, -3.8141e-02, -3.1824e-02, -3.6612e-02,
         -3.9245e-02, -1.9609e-02, -3.0501e-02, -7.7609e-03, -8.0570e-03,
         -2.3806e-02, -2.6526e-02, -2.4266e-02, -2.4878e-02, -3.3844e-02,
         -2.9566e-02, -3.6479e-02, -1.4832e-02, -2.4131e-02,  1.2522e-02,
         -3.0995e-02, -1.1293e-02, -2.4523e-02, -3.9244e-02, -3.0727e-02,
         -4.0406e-02, -2.8647e-02, -9.1868e-03, -4.6082e-02, -4.8844e-02,
         -4.1209e-02, -1.3117e-02, -2.7125e-02, -3.0641e-02, -6.2721e-02,
         -1.6724e-02, -1.2205e-02, -7.4066e-03, -2.2215e-02, -2.2350e-02,
         -1.5625e-02, -2.4046e-02, -1.9222e-02, -4.8427e-02, -2.3804e-02,
         -1.7038e-02, -8.9022e-03, -9.0834e-03, -9.2919e-03, -5.0812e-03,
         -2.9265e-02, -1.5873e-02, -1.5446e-02, -3.2083e-02, -5.7845e-02,
         -1.7572e-02, -5.2507e-02,  4.4114e-04, -4.0418e-02, -4.0858e-02,
         -2.4568e-02, -4.6892e-02, -2.0101e-02, -4.1925e-02, -1.5755e-02,
         -2.7231e-02, -2.4822e-02, -2.8439e-02]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.2000% F1: 0.3698
Applying ckpt from fold 1 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.0000% F1: 0.3704
Applying ckpt from fold 2 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.2000% F1: 0.3769
Applying ckpt from fold 3 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.2000% F1: 0.3708
Applying ckpt from fold 4 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 44.0000% F1: 0.3409
Applying ckpt from fold 5 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 44.6000% F1: 0.3551
Applying ckpt from fold 6 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.0000% F1: 0.3657
Applying ckpt from fold 7 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.6000% F1: 0.3697
Applying ckpt from fold 8 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.0000% F1: 0.3690
Applying ckpt from fold 9 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.8000% F1: 0.3687
Metrics by fold:
Fold 0 - Acc: 0.45 F1: 0.37
Fold 1 - Acc: 0.45 F1: 0.37
Fold 2 - Acc: 0.49 F1: 0.38
Fold 3 - Acc: 0.48 F1: 0.37
Fold 4 - Acc: 0.44 F1: 0.34
Fold 5 - Acc: 0.45 F1: 0.36
Fold 6 - Acc: 0.45 F1: 0.37
Fold 7 - Acc: 0.50 F1: 0.37
Fold 8 - Acc: 0.50 F1: 0.37
Fold 9 - Acc: 0.50 F1: 0.37
agg_acc: 0.4706 agg_f1: 0.3657
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
dtes[0]: tensor([[-2.0626e-02, -4.4060e-02, -2.6161e-02, -5.2382e-02, -1.1801e-02,
         -2.1239e-02, -1.8071e-02, -3.0182e-02, -3.2382e-02, -2.0418e-02,
         -2.6720e-02, -4.3357e-02, -2.5472e-02,  5.5979e-03,  1.2318e-02,
         -3.4176e-02, -4.4977e-02, -2.8053e-02, -2.1231e-02, -6.0782e-02,
         -4.0279e-02, -3.8476e-02, -1.6334e-02, -3.2569e-02, -2.5926e-02,
         -2.7391e-02, -2.3964e-02, -3.0589e-02, -2.9190e-02, -3.3341e-02,
         -1.8691e-02, -3.5133e-02, -6.1570e-02, -1.4964e-02, -2.1376e-02,
         -3.1147e-02, -3.0501e-02,  1.4628e-03, -1.8252e-02, -1.9517e-02,
         -1.1622e-02, -3.5739e-02, -3.6812e-02, -1.9371e-02, -1.1859e-02,
         -8.8161e-03, -3.1636e-02, -2.0528e-02, -1.1131e-02, -3.5867e-02,
         -3.8365e-02, -2.5705e-02, -2.1792e-02, -4.4399e-02, -4.0270e-02,
         -5.4638e-02, -2.8454e-02, -2.5333e-02, -2.5547e-02, -1.5287e-02,
         -2.4182e-02, -3.0630e-02,  1.5069e-02, -3.6271e-02, -2.8401e-02,
         -1.5753e-02, -3.0542e-02, -4.4240e-02, -2.0518e-02,  1.3146e-02,
         -2.6623e-02, -5.8353e-03, -6.2991e-02, -2.9645e-02, -5.2723e-02,
         -6.1875e-03, -4.6658e-02, -1.1706e-02, -2.0831e-02, -2.1911e-02,
         -3.0621e-02, -3.0604e-02, -3.1597e-02, -1.4894e-02, -3.7422e-02,
         -1.8669e-02, -3.9261e-02, -2.2540e-02, -3.5005e-02, -1.8804e-02,
         -3.9859e-02, -2.3636e-02, -4.4098e-02, -2.2001e-02, -4.0159e-02,
         -4.1603e-02, -6.0479e-02, -3.4732e-02, -3.5348e-02, -1.1855e-02,
         -1.1457e-02, -1.8017e-02, -2.5695e-02, -3.2170e-02, -1.8815e-02,
          6.0778e-04, -2.9451e-02, -1.5095e-02, -3.4335e-02, -1.8684e-02,
         -5.2852e-02, -2.8976e-02, -4.0829e-02, -1.9680e-02, -1.9389e-02,
         -2.6357e-02, -1.0519e-02, -3.3680e-02, -3.3897e-02, -1.6169e-02,
         -2.5509e-02,  6.1193e-03, -2.6227e-02, -4.9142e-02, -5.1203e-02,
         -2.7614e-02, -2.7042e-02, -8.2370e-02, -3.2448e-02, -6.2488e-02,
         -2.4354e-02, -5.3159e-02,  2.3348e-02, -3.0051e-02, -2.0879e-02,
         -1.0396e-02, -1.9578e-02, -2.8474e-02, -2.0294e-02, -6.0514e-03,
         -3.1489e-02, -2.7566e-02, -8.3959e-03, -8.8849e-03, -3.2843e-02,
         -3.9592e-02, -2.8364e-02, -3.0351e-02, -3.9907e-02, -2.9026e-02,
         -4.1853e-02, -1.4049e-02, -5.6452e-02, -2.7035e-02, -3.0331e-02,
         -2.6986e-02, -1.8532e-02, -1.1369e-02, -4.2319e-02, -1.0535e-01,
         -2.5081e-02, -2.4970e-02, -1.3560e-02, -3.2619e-02, -2.3543e-02,
         -3.1439e-02, -1.0665e-02, -2.8571e-02, -2.4338e-02, -2.9927e-02,
         -2.2083e-02, -1.0367e-02, -3.6159e-02, -3.5902e-02, -3.8141e-02,
          2.2199e-02, -3.4954e-02, -4.2879e-02, -2.6929e-02, -6.4845e-03,
         -2.5604e-02, -2.3864e-02, -6.5536e-02, -1.1395e-02, -2.0720e-02,
         -1.9895e-02, -3.2456e-02, -4.2429e-02, -2.7246e-02, -7.3045e-03,
         -7.3728e-03, -4.4053e-02, -4.0074e-02, -3.2210e-02, -5.1612e-02,
         -3.5234e-02, -4.5111e-02, -1.9451e-02, -3.2387e-02, -4.2629e-02,
         -2.9188e-02, -9.1431e-03, -5.6937e-03, -3.6857e-02, -3.5655e-02,
         -1.4412e-02, -1.6586e-02, -4.8305e-02, -2.0054e-02, -2.2196e-03,
         -2.6737e-02, -2.1182e-02, -3.0844e-02, -2.2878e-02, -2.6762e-02,
         -2.2593e-02, -1.2894e-01, -2.6952e-03, -4.7206e-02, -1.9133e-02,
         -1.6194e-02, -3.4907e-02, -3.0068e-02, -8.7365e-03, -2.4353e-02,
         -1.0010e-01, -3.6861e-02, -4.0455e-02, -3.1136e-02, -5.0729e-02,
         -2.6141e-02, -2.6761e-02, -4.6217e-02, -3.6219e-02, -2.3151e-02,
         -1.7108e-02, -3.9074e-02, -1.9915e-02, -1.2001e-02, -3.7315e-02,
         -3.3087e-02, -2.6547e-02, -4.3930e-02, -4.6760e-02, -2.4470e-02,
          5.5595e-05, -4.3790e-02, -2.8079e-02, -3.8258e-02, -4.1491e-02,
         -3.3981e-02, -2.7939e-02, -2.7030e-02, -1.2909e-02, -4.0956e-02,
         -2.1886e-02, -2.3271e-02, -2.3112e-02, -2.3970e-02, -1.5977e-02,
         -1.6904e-02, -3.9638e-02, -1.4792e-02, -4.5347e-02, -3.1461e-02,
         -2.8825e-02, -1.2313e-02, -3.7781e-02,  2.4980e-03, -2.8167e-02,
         -3.1846e-02, -3.3554e-02, -2.1765e-02, -2.0045e-02, -4.7427e-02,
         -1.8519e-02, -2.8280e-02, -4.4778e-02, -1.3524e-02, -3.2319e-03,
         -2.9903e-02, -3.1917e-02, -2.2511e-02, -5.9006e-02,  1.5946e-03,
         -2.4006e-02, -1.7079e-02, -2.9951e-02, -2.5281e-02, -5.0775e-02,
         -4.3378e-02,  8.9525e-04, -1.6057e-02, -1.3209e-03, -1.9282e-02,
         -3.7466e-02, -7.5034e-02, -3.4903e-02, -2.6046e-02, -6.0244e-02,
         -2.3133e-02, -3.6307e-02, -1.1735e-02, -1.5822e-02, -5.8465e-02,
         -9.4279e-03, -2.4606e-02, -1.6206e-02,  6.8120e-03, -3.1115e-02,
         -2.9297e-02, -3.0197e-02, -2.0291e-02, -1.5730e-02, -2.9399e-02,
         -5.8700e-02, -4.9440e-02, -1.4964e-02, -1.4682e-02, -4.7326e-02,
          1.9171e-03, -2.7425e-02, -3.2663e-02, -4.0381e-02, -2.2076e-02,
         -7.2282e-03, -1.7059e-02, -1.3517e-02, -2.6359e-02, -4.3907e-03,
         -3.9467e-02, -6.9909e-02, -3.6269e-02, -3.8785e-02, -2.7625e-02,
         -3.0422e-02, -3.4326e-02, -4.1373e-03, -2.0417e-02, -2.2334e-02,
         -1.4535e-02, -1.3532e-02, -3.6567e-02, -2.2748e-02, -1.6989e-02,
          1.4371e-03, -4.1189e-02, -4.5399e-02, -3.9660e-02, -2.7661e-02,
         -2.3461e-02, -2.6766e-02, -3.6177e-02, -5.6810e-02, -2.0876e-02,
         -3.5100e-02, -4.1278e-02, -2.1627e-02, -3.7129e-03, -1.9762e-02,
         -1.7184e-02, -2.7223e-02, -2.7576e-02, -9.1357e-04, -1.6475e-02,
         -4.0762e-02, -2.2704e-02, -3.2532e-02, -2.5827e-02, -3.1545e-02,
         -1.7120e-02, -3.9241e-02, -2.4638e-02, -2.9520e-02, -3.0369e-02,
         -2.5346e-02, -2.1294e-02, -4.9278e-02, -2.7448e-02, -3.7034e-02,
         -6.7724e-03, -5.7087e-02, -2.8008e-02,  6.8865e-03, -4.9772e-02,
         -4.4891e-02, -3.4240e-02, -5.1939e-02, -2.3135e-02, -1.4994e-02,
         -3.6481e-02, -1.6013e-02, -4.1644e-02, -3.7349e-02, -1.8343e-02,
         -2.8021e-02, -2.3944e-02, -3.5851e-02, -4.4354e-02, -1.8169e-02,
         -2.3095e-02, -9.4431e-02, -3.8140e-02, -3.4660e-02, -3.6032e-02,
         -2.0042e-02, -2.4378e-02, -1.2028e-02, -2.0953e-02, -2.1721e-02,
         -3.2877e-02, -3.8856e-02, -4.7931e-02, -3.5312e-02, -2.8105e-02,
         -4.7969e-02, -1.0577e-02, -5.4178e-02, -1.9335e-02,  1.4594e-02,
         -5.6146e-03, -2.8620e-02, -3.7851e-02, -1.9913e-02, -4.2189e-02,
         -1.0320e-02, -2.1976e-02, -5.2133e-02, -4.3729e-02, -5.4553e-02,
         -3.5142e-02, -3.7726e-02, -2.6058e-02, -1.1231e-02, -3.2618e-02,
         -4.3355e-02, -1.7774e-02, -3.1622e-02, -2.8229e-02, -2.1421e-02,
         -2.9999e-02, -3.1010e-02, -2.5497e-02, -4.5435e-03, -4.1343e-02,
         -3.2268e-02, -2.0374e-02, -1.9872e-02, -4.6008e-02, -2.8307e-02,
         -1.1835e-02, -2.2528e-02, -2.8635e-02, -2.5755e-02, -2.2962e-02,
         -1.1313e-02, -3.7581e-02, -1.8534e-02, -1.6939e-02, -2.5694e-02,
         -4.5719e-02,  2.1832e-02, -1.5461e-02, -1.8565e-02, -2.3459e-02,
         -6.4967e-02, -2.7417e-02, -2.3490e-02, -2.3226e-02, -4.4696e-02,
         -6.2122e-03, -6.0652e-02, -5.4693e-02, -2.0045e-02, -3.9188e-02,
         -1.6182e-02, -1.6512e-02, -8.1976e-03, -3.2709e-02, -2.5799e-02,
         -2.4841e-03, -2.1700e-02,  4.9436e-03, -2.0033e-02, -1.6611e-02,
         -2.2917e-02, -3.5269e-02, -2.3938e-02, -2.5108e-02, -2.5692e-02,
         -1.4544e-02, -1.7141e-02, -1.6639e-02, -3.4002e-02, -2.0499e-02,
         -3.2127e-02, -6.7373e-02, -1.1025e-02, -3.1973e-02, -2.3749e-02,
         -9.4430e-03, -4.9020e-02, -4.0693e-02, -3.4095e-02, -3.2654e-02,
         -4.3039e-02, -3.7553e-02, -3.2732e-02, -2.8386e-02, -2.5889e-02,
         -4.1052e-02, -4.8210e-02, -3.5973e-02, -3.5697e-02, -3.5337e-02,
         -3.0920e-02, -8.5859e-03,  1.3807e-02, -2.3515e-02, -3.5362e-02,
         -2.4852e-02, -2.1957e-02, -1.4952e-02, -2.1925e-02, -3.4758e-02,
         -2.8220e-02, -3.7455e-02, -4.0865e-02, -3.8104e-02,  1.3347e-03,
         -5.2198e-02, -2.5467e-02, -5.1656e-02, -1.5240e-02, -1.6143e-02,
         -1.1116e-02, -2.9076e-02, -1.5411e-02, -3.7430e-02, -2.3534e-02,
         -3.0279e-02, -1.0146e-01, -2.3272e-02, -4.5229e-02, -3.8890e-02,
          1.7913e-03, -6.2969e-03, -4.1688e-02, -3.0044e-02, -9.7487e-03,
         -2.1045e-02, -1.4235e-02, -2.4313e-02, -1.7216e-02, -3.1402e-02,
         -3.4427e-02, -2.1556e-02, -2.8665e-02, -3.3832e-02, -3.4066e-02,
         -2.2086e-02, -2.8477e-02, -5.0919e-02, -3.4791e-02, -1.7713e-02,
         -1.8561e-02, -3.6231e-02, -3.8923e-02, -3.6720e-02, -1.8680e-02,
         -1.9310e-02, -5.3375e-02, -2.2816e-02, -2.2705e-02, -3.0119e-02,
         -1.6189e-02, -3.3022e-02, -3.1215e-02, -3.2107e-02, -3.4758e-02,
         -2.5874e-02, -5.6180e-02, -4.0951e-02, -2.7341e-02, -2.5415e-02,
         -3.5619e-02, -3.5732e-02, -2.5828e-02, -3.6025e-02, -4.4503e-02,
         -7.0487e-03, -8.6296e-03, -4.8478e-02, -3.6195e-02, -3.2900e-02,
         -3.9823e-02, -1.5362e-02, -5.5768e-03, -2.8645e-02, -2.9967e-02,
         -4.2924e-02, -3.2294e-02, -2.9039e-02, -3.4810e-02, -1.9517e-02,
         -2.9691e-02, -2.8602e-02, -4.0939e-02, -5.1788e-02, -2.9741e-02,
         -3.6167e-02, -2.9228e-02, -2.2982e-02, -5.7735e-02, -1.8834e-02,
         -1.7366e-02, -3.5482e-02, -2.1608e-02, -4.6328e-02, -1.2155e-02,
         -3.7046e-02, -4.9812e-02, -1.5587e-02, -4.5353e-02, -1.4188e-02,
         -4.2994e-02, -3.1072e-02, -4.7449e-02, -3.5341e-02, -2.4476e-02,
         -2.2945e-02, -1.8691e-02, -2.2915e-02, -3.1375e-02, -2.5264e-02,
         -2.0859e-02, -2.5641e-02, -3.1363e-02, -2.8384e-02, -4.3555e-02,
         -3.4732e-02, -3.9482e-02, -1.7701e-02, -2.6898e-02, -1.4156e-02,
         -1.7624e-02, -1.3957e-02, -2.4311e-02, -2.0646e-02, -2.5072e-02,
         -2.4137e-02, -1.8694e-02, -1.8910e-02, -1.0031e-02, -1.3634e-02,
          5.8649e-04, -2.2889e-02, -3.8469e-02, -2.8486e-02, -4.6490e-02,
         -1.9475e-02, -1.1686e-02, -3.8871e-02, -2.8555e-02, -3.2153e-02,
         -2.2332e-02, -1.1427e-02, -3.9309e-02, -2.2623e-02, -1.3303e-02,
         -5.9567e-03, -4.0263e-02, -2.7895e-02, -3.2989e-02, -2.7573e-02,
         -2.0798e-02, -4.4355e-02, -3.5247e-02, -4.0966e-02, -7.5861e-04,
         -2.7611e-02, -5.1424e-02, -4.2651e-02, -3.6131e-02, -1.9154e-02,
         -1.5637e-02, -2.3545e-02, -1.4531e-02, -3.4187e-02, -3.3429e-02,
         -2.7579e-02, -3.3237e-02, -1.5961e-02, -2.8258e-02, -2.0247e-02,
         -2.2522e-02, -3.1527e-02, -2.9972e-02, -2.4582e-02, -8.2861e-02,
         -2.8782e-02, -1.5376e-02, -3.8141e-02, -3.1824e-02, -3.6612e-02,
         -3.9245e-02, -1.9609e-02, -3.0501e-02, -7.7609e-03, -8.0570e-03,
         -2.3806e-02, -2.6526e-02, -2.4266e-02, -2.4878e-02, -3.3844e-02,
         -2.9566e-02, -3.6479e-02, -1.4832e-02, -2.4131e-02,  1.2522e-02,
         -3.0995e-02, -1.1293e-02, -2.4523e-02, -3.9244e-02, -3.0727e-02,
         -4.0406e-02, -2.8647e-02, -9.1868e-03, -4.6082e-02, -4.8844e-02,
         -4.1209e-02, -1.3117e-02, -2.7125e-02, -3.0641e-02, -6.2721e-02,
         -1.6724e-02, -1.2205e-02, -7.4066e-03, -2.2215e-02, -2.2350e-02,
         -1.5625e-02, -2.4046e-02, -1.9222e-02, -4.8427e-02, -2.3804e-02,
         -1.7038e-02, -8.9022e-03, -9.0834e-03, -9.2919e-03, -5.0812e-03,
         -2.9265e-02, -1.5873e-02, -1.5446e-02, -3.2083e-02, -5.7845e-02,
         -1.7572e-02, -5.2507e-02,  4.4114e-04, -4.0418e-02, -4.0858e-02,
         -2.4568e-02, -4.6892e-02, -2.0101e-02, -4.1925e-02, -1.5755e-02,
         -2.7231e-02, -2.4822e-02, -2.8439e-02]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 42.8000% F1: 0.3570
Applying ckpt from fold 1 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 44.2000% F1: 0.3554
Applying ckpt from fold 2 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.8000% F1: 0.3632
Applying ckpt from fold 3 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.8000% F1: 0.3725
Applying ckpt from fold 4 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 41.6000% F1: 0.3452
Applying ckpt from fold 5 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 44.8000% F1: 0.3607
Applying ckpt from fold 6 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 44.6000% F1: 0.3575
Applying ckpt from fold 7 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.0000% F1: 0.3809
Applying ckpt from fold 8 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.4000% F1: 0.3554
Applying ckpt from fold 9 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 44.8000% F1: 0.3658
Metrics by fold:
Fold 0 - Acc: 0.43 F1: 0.36
Fold 1 - Acc: 0.44 F1: 0.36
Fold 2 - Acc: 0.46 F1: 0.36
Fold 3 - Acc: 0.46 F1: 0.37
Fold 4 - Acc: 0.42 F1: 0.35
Fold 5 - Acc: 0.45 F1: 0.36
Fold 6 - Acc: 0.45 F1: 0.36
Fold 7 - Acc: 0.49 F1: 0.38
Fold 8 - Acc: 0.47 F1: 0.36
Fold 9 - Acc: 0.45 F1: 0.37
agg_acc: 0.4508 agg_f1: 0.3613
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Replacing DTEs with random tensors...
dtes[0]: tensor([[8.4077e-01, 5.1036e-01, 9.6275e-01, 2.8351e-01, 7.0521e-01, 3.2116e-01,
         2.0959e-01, 3.3931e-01, 4.9508e-01, 8.7965e-01, 1.3649e-01, 4.0649e-01,
         9.8236e-01, 6.9041e-01, 9.6841e-01, 2.4840e-01, 3.2956e-01, 5.2490e-01,
         9.7115e-01, 1.0765e-01, 8.6621e-01, 4.0093e-01, 5.2678e-01, 8.3657e-01,
         7.2124e-02, 5.6553e-03, 9.2680e-01, 3.1546e-03, 6.1579e-01, 1.9229e-01,
         1.1334e-01, 4.3873e-01, 4.8120e-02, 1.6849e-01, 9.9434e-01, 4.7180e-01,
         8.9730e-01, 3.0789e-01, 7.5238e-01, 9.3884e-01, 5.5543e-01, 1.8762e-01,
         3.6433e-01, 2.5236e-01, 8.1972e-01, 5.3554e-01, 3.9500e-01, 7.0340e-01,
         5.4161e-01, 9.1765e-01, 2.6447e-01, 7.3649e-01, 9.6608e-01, 3.1574e-01,
         3.0263e-02, 4.6472e-01, 9.1909e-01, 2.0683e-01, 4.0726e-01, 9.8067e-01,
         6.1373e-01, 9.1745e-01, 1.0042e-01, 2.2417e-01, 9.2894e-01, 4.8054e-01,
         4.2542e-01, 3.7587e-02, 2.1988e-02, 3.9539e-01, 4.5425e-01, 2.8408e-01,
         4.0825e-01, 5.2509e-02, 7.3747e-01, 7.7579e-02, 7.7701e-01, 5.3571e-01,
         3.9563e-01, 7.0083e-01, 1.1167e-01, 1.1642e-02, 1.7030e-01, 1.5937e-01,
         9.6091e-01, 7.7201e-01, 2.6984e-01, 7.8780e-01, 7.8554e-01, 1.0772e-01,
         9.3248e-01, 7.8863e-01, 9.7079e-01, 6.9115e-01, 7.0308e-01, 7.0928e-02,
         5.5220e-01, 9.3071e-01, 9.3811e-02, 4.9347e-01, 3.6800e-01, 5.0425e-01,
         6.2740e-01, 9.8336e-01, 2.4419e-01, 3.1620e-01, 7.2539e-01, 3.8485e-01,
         7.4342e-01, 9.9952e-01, 4.8095e-01, 8.9442e-02, 1.1265e-01, 2.8629e-01,
         7.1369e-01, 4.5265e-01, 3.5597e-01, 4.0814e-01, 2.9477e-01, 2.1324e-01,
         5.2808e-01, 9.1592e-01, 8.6245e-01, 7.7737e-01, 8.9170e-01, 5.1678e-01,
         2.1205e-01, 7.2582e-01, 5.0337e-01, 4.8864e-01, 6.0689e-01, 5.6490e-01,
         5.3546e-01, 7.0876e-01, 9.9332e-01, 4.1455e-01, 8.3115e-01, 7.2150e-01,
         9.4597e-01, 5.2203e-01, 3.6266e-01, 1.5678e-01, 6.9160e-01, 6.3147e-01,
         7.5761e-01, 3.8460e-01, 4.5930e-01, 5.8058e-01, 6.1950e-01, 4.3240e-01,
         6.4285e-01, 3.7870e-01, 1.3735e-01, 8.4481e-01, 3.2683e-01, 1.8427e-01,
         1.9271e-01, 2.9135e-01, 4.6344e-01, 7.5441e-01, 3.7392e-01, 2.6826e-02,
         5.9216e-01, 7.1284e-01, 9.8659e-01, 4.4345e-01, 5.0912e-01, 8.1304e-01,
         6.8120e-01, 2.0819e-01, 9.0630e-01, 1.1888e-01, 5.5145e-01, 7.8041e-01,
         9.2280e-01, 1.0664e-01, 8.1929e-01, 6.6127e-01, 4.9677e-01, 6.5395e-01,
         8.0558e-01, 7.6182e-01, 6.9576e-01, 6.5079e-01, 7.3565e-01, 9.5611e-01,
         9.1451e-01, 6.4552e-02, 7.7233e-01, 2.8267e-01, 3.5084e-01, 4.1568e-01,
         6.5446e-01, 8.2555e-01, 2.4584e-01, 4.6434e-02, 7.9377e-01, 3.8083e-01,
         8.3815e-01, 3.3795e-01, 8.1285e-01, 3.0348e-01, 6.4911e-01, 8.1469e-01,
         5.6140e-01, 6.6121e-01, 8.2390e-01, 2.6983e-01, 6.8810e-01, 3.9487e-01,
         2.4007e-01, 1.6147e-01, 2.8896e-01, 8.7190e-02, 4.7582e-01, 5.6724e-01,
         7.6268e-01, 1.3477e-01, 7.4893e-01, 9.4013e-01, 6.1685e-01, 3.3345e-01,
         8.1418e-02, 3.9678e-01, 2.8266e-01, 6.4319e-02, 4.4445e-01, 3.7350e-01,
         1.2755e-01, 3.1779e-01, 5.5517e-01, 8.9442e-01, 2.2906e-01, 8.2095e-01,
         6.9992e-01, 5.1330e-01, 5.1506e-01, 1.7106e-01, 3.1090e-01, 7.6155e-01,
         7.6654e-01, 3.6194e-01, 8.9558e-01, 2.0303e-02, 8.9849e-01, 4.2144e-02,
         2.3243e-01, 5.8882e-01, 1.8504e-01, 8.5198e-01, 5.6536e-01, 3.5741e-01,
         2.5700e-01, 6.4333e-01, 7.8998e-01, 4.3329e-01, 4.0548e-02, 6.7151e-01,
         9.8790e-02, 8.9580e-01, 6.0228e-01, 8.7413e-01, 1.8222e-01, 2.9744e-01,
         1.6903e-03, 7.1992e-01, 2.9815e-01, 1.4146e-02, 8.1087e-01, 6.1025e-01,
         1.5823e-01, 2.3188e-01, 9.3048e-01, 6.7194e-01, 9.8362e-01, 4.8233e-01,
         8.1443e-01, 6.5706e-01, 3.6957e-01, 4.0912e-01, 5.3345e-01, 1.6723e-01,
         8.9232e-01, 9.4101e-01, 3.9303e-01, 7.7776e-01, 2.3125e-01, 7.6723e-01,
         5.0456e-01, 5.6347e-01, 7.5511e-02, 9.4161e-01, 5.8415e-01, 5.5370e-03,
         8.8414e-01, 2.0239e-01, 3.5051e-01, 8.5227e-01, 7.9687e-01, 7.3565e-02,
         3.3059e-01, 6.2251e-01, 5.9846e-01, 5.8316e-01, 8.8389e-01, 6.2795e-01,
         5.0186e-01, 3.7740e-01, 7.7493e-01, 9.6729e-01, 5.5107e-01, 5.3747e-01,
         2.3319e-01, 7.4546e-01, 3.3070e-01, 5.9953e-03, 2.3948e-01, 8.4576e-02,
         3.2852e-01, 2.0696e-02, 4.6828e-01, 5.7339e-01, 7.0413e-01, 2.4286e-01,
         4.7159e-01, 5.0594e-01, 1.3196e-01, 7.7206e-01, 3.4807e-02, 9.1912e-01,
         1.5250e-01, 5.5658e-02, 2.9865e-02, 4.0638e-01, 6.0001e-01, 8.5285e-01,
         3.3497e-01, 7.0004e-01, 1.2933e-01, 3.7296e-01, 8.0334e-01, 7.1521e-01,
         1.3736e-01, 5.0237e-01, 1.8013e-01, 3.2899e-01, 2.2786e-01, 2.9019e-01,
         6.4913e-01, 7.1996e-02, 2.8016e-02, 1.5751e-01, 3.6005e-01, 2.4244e-01,
         8.8161e-01, 4.6786e-01, 1.6381e-01, 1.4279e-01, 1.5328e-01, 1.5704e-01,
         8.7873e-01, 9.7292e-01, 7.2020e-01, 7.6907e-01, 6.8403e-02, 5.8571e-01,
         1.9103e-01, 5.1500e-01, 4.0350e-01, 4.6489e-01, 1.9499e-02, 9.6029e-02,
         3.2710e-01, 3.2643e-01, 8.0198e-01, 4.0787e-01, 2.2731e-01, 3.9382e-02,
         4.4284e-01, 5.2996e-01, 1.5833e-01, 5.8428e-01, 6.2645e-01, 3.4752e-01,
         4.5279e-01, 7.9384e-01, 6.2827e-01, 1.0593e-01, 5.5430e-01, 1.8765e-01,
         8.7253e-01, 7.1514e-01, 3.5489e-01, 7.1654e-01, 1.9664e-01, 3.8471e-01,
         4.2261e-01, 9.2625e-01, 3.5073e-01, 2.9007e-02, 4.0509e-01, 3.2137e-01,
         7.2910e-01, 8.2802e-01, 5.2521e-01, 3.9402e-01, 5.0559e-01, 3.4525e-02,
         1.5393e-01, 5.4243e-01, 2.4527e-01, 5.8104e-01, 1.2206e-01, 6.4441e-02,
         3.7043e-01, 8.2275e-01, 5.3594e-01, 5.3938e-01, 3.8122e-01, 8.8536e-01,
         8.0371e-01, 8.9005e-01, 1.7417e-01, 6.5978e-01, 5.1584e-01, 2.4206e-01,
         5.1549e-01, 8.8322e-01, 3.2211e-03, 7.6147e-01, 6.8973e-01, 2.6781e-01,
         7.9301e-01, 2.3789e-02, 4.9403e-01, 6.2527e-01, 4.2790e-01, 8.4509e-01,
         5.8506e-01, 3.7966e-01, 3.9601e-01, 1.4293e-01, 9.7062e-01, 8.6764e-01,
         6.6099e-01, 8.0886e-01, 1.2457e-01, 2.4137e-01, 5.0826e-01, 7.8679e-03,
         3.6905e-01, 7.1358e-01, 7.0429e-01, 5.9416e-01, 6.0103e-01, 6.3841e-01,
         7.9265e-02, 1.0179e-01, 3.0200e-01, 5.1029e-01, 1.4733e-01, 4.0767e-01,
         3.3479e-02, 5.9994e-01, 8.7995e-02, 1.7258e-01, 3.9196e-01, 8.9379e-01,
         4.9669e-01, 7.3269e-01, 6.5170e-02, 3.6210e-01, 8.9941e-02, 8.5514e-01,
         7.8429e-01, 9.5284e-01, 6.6591e-03, 7.5945e-01, 5.0182e-01, 3.3554e-01,
         5.4792e-01, 6.1776e-01, 5.1780e-01, 6.0536e-02, 4.0503e-01, 2.1713e-01,
         8.1968e-01, 7.4568e-01, 9.5790e-01, 8.0228e-01, 8.5014e-01, 3.8753e-01,
         6.6640e-01, 2.8031e-01, 6.0306e-01, 3.0204e-01, 9.9078e-01, 2.9558e-01,
         1.5954e-01, 9.7028e-01, 3.0733e-01, 5.9683e-01, 9.4784e-01, 4.7120e-01,
         6.0637e-01, 6.7372e-01, 9.4184e-02, 2.0526e-01, 9.8063e-01, 1.9903e-01,
         5.2500e-01, 5.3372e-01, 5.1846e-01, 1.3338e-01, 1.2719e-01, 1.4960e-01,
         7.1530e-01, 9.2774e-01, 4.1772e-01, 1.0833e-01, 3.5035e-01, 5.6886e-01,
         2.1235e-01, 4.7486e-01, 1.8169e-01, 5.6314e-01, 9.5469e-01, 4.6238e-01,
         7.1881e-01, 3.7515e-01, 7.0720e-02, 5.7204e-01, 1.1315e-01, 9.7936e-01,
         3.9637e-02, 5.8541e-01, 5.2792e-01, 6.9211e-01, 3.9398e-01, 7.4077e-01,
         4.7052e-01, 1.1481e-01, 5.1568e-01, 4.0270e-01, 7.7353e-02, 7.0841e-01,
         9.9739e-01, 6.7129e-01, 4.3256e-01, 7.1588e-01, 7.3123e-01, 7.3181e-01,
         4.6632e-01, 5.9847e-01, 4.3748e-01, 7.3089e-01, 7.8010e-01, 3.2180e-01,
         9.7377e-02, 6.2865e-01, 1.2232e-02, 6.3092e-01, 7.5851e-01, 9.8292e-01,
         5.7393e-01, 3.4940e-01, 8.3199e-01, 9.5366e-01, 5.6419e-01, 6.6528e-01,
         5.9008e-01, 5.8313e-01, 4.0059e-01, 7.2219e-01, 4.5495e-01, 6.2938e-01,
         8.2540e-01, 1.3324e-01, 3.9154e-01, 8.7834e-01, 8.0872e-01, 9.4445e-01,
         6.6654e-01, 8.6636e-01, 7.3876e-01, 2.7668e-01, 8.6012e-01, 3.1055e-01,
         5.1621e-01, 3.4436e-01, 8.3837e-01, 1.6730e-01, 5.5105e-01, 6.6194e-01,
         3.4312e-01, 1.6835e-01, 4.9416e-01, 8.7876e-01, 7.6903e-01, 2.9820e-01,
         9.1677e-01, 6.7857e-01, 7.7772e-01, 4.5444e-01, 5.6267e-01, 9.0081e-01,
         7.4471e-01, 3.3272e-01, 7.0589e-01, 4.1648e-01, 4.0891e-01, 5.2775e-01,
         1.1866e-01, 8.2388e-01, 6.7604e-01, 7.0745e-02, 9.6907e-01, 3.4713e-01,
         4.1187e-01, 2.1780e-01, 1.6170e-01, 5.9444e-01, 5.9210e-01, 2.4935e-01,
         2.3664e-01, 7.1558e-01, 4.6218e-01, 6.2575e-01, 4.4166e-01, 2.6955e-02,
         3.6562e-01, 3.7126e-01, 2.1116e-01, 1.5629e-01, 9.7384e-01, 6.3145e-02,
         2.5870e-01, 9.6225e-01, 9.5496e-01, 6.6819e-01, 9.6832e-01, 7.5374e-01,
         7.2514e-01, 1.4704e-01, 5.9617e-01, 7.5386e-01, 9.4414e-01, 7.6607e-01,
         2.8700e-01, 7.6662e-01, 3.3527e-01, 1.4575e-01, 2.8541e-01, 1.7691e-01,
         2.8589e-01, 8.0884e-01, 8.9478e-01, 2.7370e-01, 6.0130e-01, 9.3940e-01,
         7.0635e-01, 3.6461e-01, 4.0360e-01, 1.4241e-02, 6.7623e-01, 7.6683e-01,
         6.0772e-01, 8.7087e-01, 4.9767e-01, 1.6825e-01, 6.2275e-01, 1.3578e-01,
         3.4694e-01, 4.6884e-01, 8.0822e-02, 5.2100e-01, 6.3818e-01, 3.3649e-01,
         5.4453e-01, 9.9528e-01, 7.3155e-01, 8.7846e-01, 4.6653e-01, 1.3214e-01,
         5.3988e-01, 3.4465e-01, 3.4126e-02, 6.3644e-01, 4.2985e-01, 1.3171e-01,
         7.8462e-01, 9.1391e-01, 5.8199e-01, 4.4074e-01, 5.3193e-01, 1.4008e-01,
         5.6547e-01, 9.8880e-02, 7.8226e-01, 9.7378e-01, 8.3113e-01, 3.2602e-01,
         4.8107e-01, 4.2215e-01, 3.6757e-01, 1.1506e-02, 7.3650e-01, 6.5008e-01,
         6.0139e-02, 9.1024e-01, 7.5794e-01, 2.4776e-01, 6.6097e-02, 5.7688e-01,
         9.1678e-01, 6.0543e-01, 8.5242e-01, 4.9502e-02, 5.7727e-01, 2.7745e-01,
         1.6752e-01, 4.1162e-02, 8.7967e-01, 1.5086e-01, 4.9434e-01, 8.9513e-01,
         5.4848e-01, 6.0163e-01, 9.0093e-01, 2.2853e-01, 2.4714e-01, 8.0009e-01,
         5.2911e-01, 8.3676e-01, 8.1493e-01, 1.5361e-02, 6.2958e-01, 7.5222e-01,
         9.7057e-01, 6.0899e-01, 7.4139e-01, 3.0233e-01, 6.6561e-01, 2.9859e-01,
         3.5270e-01, 6.3323e-01, 1.9451e-01, 5.3150e-01, 8.8077e-01, 7.6266e-01,
         4.2542e-01, 1.6989e-01, 5.1798e-01, 9.7403e-01, 8.0854e-01, 7.8234e-01,
         9.7213e-01, 7.2746e-01, 7.1495e-01, 9.3899e-01, 1.3483e-01, 3.7845e-01,
         2.4251e-01, 3.5276e-01, 9.0652e-01, 5.4031e-02, 6.1510e-02, 3.0559e-04]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2374
Applying ckpt from fold 1 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2371
Applying ckpt from fold 2 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.0000% F1: 0.2366
Applying ckpt from fold 3 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.4000% F1: 0.2413
Applying ckpt from fold 4 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.0000% F1: 0.2408
Applying ckpt from fold 5 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.6000% F1: 0.2461
Applying ckpt from fold 6 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.2000% F1: 0.2444
Applying ckpt from fold 7 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 55.6000% F1: 0.2455
Applying ckpt from fold 8 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.6000% F1: 0.2431
Applying ckpt from fold 9 epoch 0...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.6000% F1: 0.2460
Metrics by fold:
Fold 0 - Acc: 0.55 F1: 0.24
Fold 1 - Acc: 0.55 F1: 0.24
Fold 2 - Acc: 0.55 F1: 0.24
Fold 3 - Acc: 0.55 F1: 0.24
Fold 4 - Acc: 0.55 F1: 0.24
Fold 5 - Acc: 0.56 F1: 0.25
Fold 6 - Acc: 0.55 F1: 0.24
Fold 7 - Acc: 0.56 F1: 0.25
Fold 8 - Acc: 0.55 F1: 0.24
Fold 9 - Acc: 0.55 F1: 0.25
agg_acc: 0.5514 agg_f1: 0.2418
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Replacing DTEs with random tensors...
dtes[0]: tensor([[0.3555, 0.2362, 0.3023, 0.2000, 0.4713, 0.3323, 0.2213, 0.8061, 0.6723,
         0.4475, 0.6888, 0.9647, 0.1553, 0.5898, 0.3307, 0.0051, 0.7989, 0.0536,
         0.8923, 0.5677, 0.6807, 0.5926, 0.0856, 0.6055, 0.4455, 0.7881, 0.8416,
         0.4430, 0.7500, 0.6473, 0.3758, 0.5591, 0.5684, 0.6321, 0.6807, 0.0908,
         0.2872, 0.9743, 0.9652, 0.3436, 0.0257, 0.1009, 0.5904, 0.9624, 0.8462,
         0.3029, 0.6422, 0.5454, 0.4906, 0.9288, 0.5768, 0.5555, 0.8499, 0.9143,
         0.8996, 0.8666, 0.1916, 0.4293, 0.2237, 0.2245, 0.7161, 0.0671, 0.2966,
         0.7455, 0.9209, 0.4509, 0.5286, 0.9142, 0.6550, 0.7526, 0.1173, 0.1836,
         0.1016, 0.1788, 0.1182, 0.6364, 0.7771, 0.4902, 0.7680, 0.8423, 0.8828,
         0.5223, 0.2428, 0.8329, 0.9729, 0.2346, 0.3063, 0.2371, 0.7771, 0.7758,
         0.4720, 0.7443, 0.2381, 0.0647, 0.9288, 0.2306, 0.7084, 0.3563, 0.6380,
         0.4492, 0.1328, 0.3928, 0.6879, 0.8124, 0.5442, 0.2900, 0.4414, 0.5589,
         0.3025, 0.8856, 0.8664, 0.7392, 0.6806, 0.4806, 0.3663, 0.0870, 0.3306,
         0.4159, 0.4736, 0.5159, 0.2414, 0.7307, 0.6677, 0.1535, 0.2834, 0.8784,
         0.8510, 0.6266, 0.1747, 0.9915, 0.9617, 0.5878, 0.1210, 0.9554, 0.6153,
         0.0274, 0.5798, 0.7913, 0.0377, 0.6061, 0.7687, 0.7057, 0.1659, 0.7428,
         0.8249, 0.4328, 0.1810, 0.2082, 0.8598, 0.1011, 0.4388, 0.0075, 0.6074,
         0.7359, 0.7999, 0.2801, 0.9222, 0.5057, 0.3192, 0.9678, 0.2669, 0.2373,
         0.4762, 0.9418, 0.9064, 0.8826, 0.5220, 0.3503, 0.7176, 0.2784, 0.2132,
         0.3229, 0.8486, 0.2976, 0.8345, 0.1737, 0.8833, 0.2022, 0.8790, 0.9828,
         0.0021, 0.3896, 0.3065, 0.1368, 0.7370, 0.1489, 0.6035, 0.6998, 0.2257,
         0.7918, 0.3899, 0.6433, 0.9386, 0.4816, 0.8200, 0.8571, 0.8075, 0.8403,
         0.4366, 0.1211, 0.4231, 0.6957, 0.5564, 0.5703, 0.3858, 0.8709, 0.9129,
         0.7189, 0.8649, 0.7220, 0.0432, 0.9585, 0.2089, 0.6314, 0.1638, 0.7676,
         0.2310, 0.3348, 0.6741, 0.8597, 0.6658, 0.5542, 0.3359, 0.9894, 0.5372,
         0.8282, 0.1455, 0.7823, 0.0619, 0.4171, 0.9138, 0.9620, 0.8957, 0.0163,
         0.3093, 0.1445, 0.5110, 0.2121, 0.1273, 0.9127, 0.2576, 0.3812, 0.9495,
         0.2879, 0.5196, 0.6273, 0.9431, 0.9611, 0.8285, 0.8303, 0.7617, 0.1939,
         0.6360, 0.2422, 0.1505, 0.6805, 0.3979, 0.1505, 0.3651, 0.6535, 0.3469,
         0.6785, 0.1152, 0.4538, 0.0386, 0.5218, 0.7829, 0.0323, 0.9161, 0.6972,
         0.8490, 0.7691, 0.3471, 0.1894, 0.4967, 0.2993, 0.8292, 0.2514, 0.9167,
         0.5667, 0.9540, 0.4892, 0.6273, 0.7090, 0.0950, 0.1499, 0.4913, 0.4196,
         0.1718, 0.2190, 0.8207, 0.5841, 0.9914, 0.7165, 0.2542, 0.7352, 0.2993,
         0.1238, 0.9471, 0.2352, 0.3708, 0.8105, 0.6341, 0.0088, 0.3331, 0.2383,
         0.1968, 0.4673, 0.4538, 0.3712, 0.1447, 0.3966, 0.8387, 0.3747, 0.1507,
         0.2210, 0.3870, 0.0670, 0.5026, 0.6333, 0.8063, 0.9829, 0.5309, 0.1577,
         0.7858, 0.7903, 0.1117, 0.0893, 0.5860, 0.6245, 0.3079, 0.1687, 0.4530,
         0.4514, 0.3785, 0.8301, 0.0559, 0.5919, 0.0900, 0.6092, 0.8696, 0.8344,
         0.4454, 0.1962, 0.0930, 0.0849, 0.9073, 0.4645, 0.2079, 0.6945, 0.2806,
         0.7584, 0.5696, 0.5239, 0.3532, 0.7390, 0.5704, 0.4929, 0.7636, 0.7458,
         0.2535, 0.9496, 0.2865, 0.6817, 0.5511, 0.7616, 0.2267, 0.8297, 0.1385,
         0.5535, 0.7117, 0.0223, 0.3594, 0.3077, 0.5686, 0.5708, 0.6948, 0.4806,
         0.1002, 0.9848, 0.4275, 0.5101, 0.3759, 0.5342, 0.3562, 0.9031, 0.4888,
         0.1048, 0.9160, 0.2402, 0.9141, 0.9937, 0.3210, 0.5656, 0.5883, 0.3521,
         0.0294, 0.3074, 0.9881, 0.9991, 0.3698, 0.2330, 0.7384, 0.2329, 0.1990,
         0.5983, 0.5551, 0.4422, 0.9179, 0.0695, 0.5787, 0.0264, 0.6652, 0.1485,
         0.6908, 0.3184, 0.5975, 0.7384, 0.0158, 0.4709, 0.1115, 0.6038, 0.1909,
         0.8142, 0.2065, 0.4152, 0.8527, 0.6511, 0.1552, 0.1704, 0.3608, 0.7898,
         0.2455, 0.6485, 0.6945, 0.9960, 0.4172, 0.5447, 0.0591, 0.9167, 0.0203,
         0.6620, 0.4111, 0.8726, 0.2800, 0.8514, 0.6583, 0.2121, 0.3260, 0.7925,
         0.2507, 0.2865, 0.7547, 0.0704, 0.8858, 0.4294, 0.9135, 0.4062, 0.6259,
         0.1194, 0.0178, 0.6136, 0.0180, 0.3268, 0.8146, 0.7984, 0.9269, 0.8986,
         0.1699, 0.4026, 0.1963, 0.3950, 0.8380, 0.6119, 0.1380, 0.2353, 0.7827,
         0.5966, 0.1963, 0.9578, 0.1880, 0.8304, 0.0021, 0.2718, 0.7804, 0.2032,
         0.5048, 0.9164, 0.1665, 0.0736, 0.1803, 0.1918, 0.8689, 0.0179, 0.8329,
         0.5955, 0.8439, 0.6183, 0.6134, 0.8937, 0.1755, 0.9425, 0.0131, 0.6802,
         0.8611, 0.8345, 0.9469, 0.1929, 0.1255, 0.7408, 0.7136, 0.4736, 0.4780,
         0.9564, 0.3205, 0.3099, 0.6376, 0.3811, 0.9392, 0.7990, 0.1454, 0.5649,
         0.5703, 0.5764, 0.2834, 0.6810, 0.4884, 0.5084, 0.2277, 0.8575, 0.8150,
         0.3997, 0.8260, 0.6869, 0.9984, 0.4860, 0.3330, 0.6449, 0.9200, 0.1648,
         0.3375, 0.1267, 0.8284, 0.1266, 0.6340, 0.9792, 0.8707, 0.5984, 0.5766,
         0.6083, 0.9496, 0.2208, 0.0954, 0.2289, 0.7745, 0.3575, 0.0636, 0.8181,
         0.2489, 0.8768, 0.6435, 0.5465, 0.9231, 0.4157, 0.9061, 0.6964, 0.5034,
         0.0894, 0.1038, 0.1741, 0.1876, 0.4132, 0.6236, 0.5691, 0.0732, 0.6968,
         0.7224, 0.1260, 0.4355, 0.5273, 0.8906, 0.0340, 0.8421, 0.2240, 0.9932,
         0.9624, 0.3589, 0.6705, 0.9756, 0.2908, 0.9474, 0.4430, 0.0739, 0.0837,
         0.8047, 0.4330, 0.0443, 0.2634, 0.8696, 0.8977, 0.7265, 0.5644, 0.9421,
         0.8638, 0.1176, 0.3176, 0.6315, 0.3525, 0.7173, 0.3167, 0.6689, 0.7709,
         0.4209, 0.3468, 0.7931, 0.0752, 0.2682, 0.6905, 0.9239, 0.6806, 0.9351,
         0.4058, 0.0507, 0.8365, 0.6815, 0.3566, 0.1797, 0.9730, 0.4864, 0.6957,
         0.0755, 0.2841, 0.1091, 0.1347, 0.9196, 0.9972, 0.5580, 0.3701, 0.7266,
         0.3975, 0.8393, 0.6562, 0.6735, 0.2482, 0.5549, 0.7448, 0.8875, 0.2470,
         0.8954, 0.3676, 0.0497, 0.9713, 0.0371, 0.3807, 0.4760, 0.2581, 0.4097,
         0.8805, 0.1726, 0.1498, 0.3833, 0.4877, 0.3647, 0.6805, 0.5293, 0.7169,
         0.2108, 0.2353, 0.1697, 0.0530, 0.9475, 0.7812, 0.8987, 0.0308, 0.4375,
         0.8499, 0.5164, 0.5875, 0.6159, 0.4722, 0.3639, 0.2626, 0.3254, 0.9540,
         0.3870, 0.1692, 0.9495, 0.6961, 0.4343, 0.2862, 0.9588, 0.5944, 0.7204,
         0.8452, 0.2056, 0.7904, 0.8478, 0.2108, 0.7543, 0.7869, 0.6561, 0.3786,
         0.7258, 0.4329, 0.0846, 0.5213, 0.8668, 0.1159, 0.0813, 0.8154, 0.5732,
         0.3422, 0.7332, 0.0074, 0.2114, 0.8041, 0.2135, 0.4978, 0.2677, 0.9877,
         0.0934, 0.1550, 0.2663, 0.0663, 0.0732, 0.2661, 0.0232, 0.9088, 0.9653,
         0.2110, 0.6466, 0.6789, 0.0762, 0.1942, 0.1174, 0.1719, 0.3709, 0.1099,
         0.8166, 0.8257, 0.3227, 0.1789, 0.8751, 0.4857, 0.3033, 0.0493, 0.8543,
         0.1344, 0.7141, 0.2496, 0.7895, 0.6332, 0.5109, 0.0099, 0.1079, 0.0474,
         0.1454, 0.4770, 0.1540, 0.5580, 0.1926, 0.1061, 0.7599, 0.0462, 0.1161,
         0.0707, 0.5594, 0.3501]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.2000% F1: 0.3032
Applying ckpt from fold 1 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.4000% F1: 0.2919
Applying ckpt from fold 2 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.4000% F1: 0.3029
Applying ckpt from fold 3 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 54.2000% F1: 0.3300
Applying ckpt from fold 4 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.0000% F1: 0.2906
Applying ckpt from fold 5 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.4000% F1: 0.3032
Applying ckpt from fold 6 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.8000% F1: 0.3051
Applying ckpt from fold 7 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.6000% F1: 0.2537
Applying ckpt from fold 8 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.8000% F1: 0.2902
Applying ckpt from fold 9 epoch 1...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.6000% F1: 0.2773
Metrics by fold:
Fold 0 - Acc: 0.51 F1: 0.30
Fold 1 - Acc: 0.52 F1: 0.29
Fold 2 - Acc: 0.52 F1: 0.30
Fold 3 - Acc: 0.54 F1: 0.33
Fold 4 - Acc: 0.53 F1: 0.29
Fold 5 - Acc: 0.52 F1: 0.30
Fold 6 - Acc: 0.53 F1: 0.31
Fold 7 - Acc: 0.54 F1: 0.25
Fold 8 - Acc: 0.51 F1: 0.29
Fold 9 - Acc: 0.54 F1: 0.28
agg_acc: 0.5264 agg_f1: 0.2948
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Replacing DTEs with random tensors...
dtes[0]: tensor([[0.9410, 0.1196, 0.8214, 0.9697, 0.0837, 0.3220, 0.5708, 0.4696, 0.5329,
         0.6692, 0.1995, 0.1197, 0.9907, 0.8691, 0.9683, 0.8746, 0.6935, 0.7339,
         0.7844, 0.6797, 0.2171, 0.8362, 0.4082, 0.7736, 0.5010, 0.2893, 0.9747,
         0.0802, 0.6067, 0.7696, 0.0964, 0.6348, 0.3416, 0.0387, 0.6018, 0.0497,
         0.6603, 0.9310, 0.7761, 0.1401, 0.2182, 0.6859, 0.0352, 0.8560, 0.5129,
         0.0307, 0.2883, 0.0338, 0.8370, 0.0231, 0.6714, 0.3270, 0.5083, 0.1200,
         0.5096, 0.0104, 0.9099, 0.3699, 0.2570, 0.7136, 0.9751, 0.0204, 0.7047,
         0.6926, 0.6637, 0.3432, 0.8493, 0.2745, 0.4499, 0.8330, 0.2692, 0.7178,
         0.2050, 0.7062, 0.1716, 0.5472, 0.8413, 0.3469, 0.4581, 0.6727, 0.5638,
         0.1390, 0.6921, 0.5097, 0.4913, 0.6259, 0.6793, 0.9005, 0.4340, 0.7866,
         0.2868, 0.9086, 0.0909, 0.2067, 0.2562, 0.4189, 0.8423, 0.3879, 0.6296,
         0.4996, 0.4411, 0.0723, 0.7783, 0.0677, 0.9316, 0.6748, 0.5021, 0.8118,
         0.7983, 0.4257, 0.2530, 0.3324, 0.9252, 0.9651, 0.1631, 0.5705, 0.6506,
         0.4925, 0.5673, 0.9518, 0.4478, 0.6025, 0.3727, 0.1476, 0.9985, 0.3779,
         0.0480, 0.9550, 0.5328, 0.9353, 0.0854, 0.4698, 0.6556, 0.8884, 0.8876,
         0.0073, 0.2091, 0.4908, 0.7248, 0.2690, 0.1857, 0.1653, 0.7560, 0.6249,
         0.2994, 0.4712, 0.1476, 0.6381, 0.3255, 0.0765, 0.8340, 0.4971, 0.1368,
         0.2181, 0.5111, 0.7180, 0.5609, 0.1424, 0.9382, 0.7753, 0.8275, 0.6424,
         0.1557, 0.4789, 0.5529, 0.9983, 0.3397, 0.4656, 0.6731, 0.1434, 0.3234,
         0.5157, 0.6761, 0.1058, 0.8955, 0.9886, 0.9420, 0.8199, 0.6253, 0.9252,
         0.9719, 0.3602, 0.4276, 0.5566, 0.6390, 0.6600, 0.5233, 0.6383, 0.6576,
         0.6098, 0.7043, 0.8672, 0.3147, 0.9404, 0.7459, 0.9142, 0.9376, 0.0374,
         0.2585, 0.5459, 0.7241, 0.3188, 0.6734, 0.8717, 0.5369, 0.5481, 0.6721,
         0.5272, 0.2952, 0.7523, 0.2199, 0.6331, 0.7604, 0.1606, 0.6311, 0.7887,
         0.2195, 0.0862, 0.3788, 0.0591, 0.5835, 0.5971, 0.7410, 0.6527, 0.6522,
         0.4097, 0.6616, 0.1517, 0.4581, 0.0557, 0.5743, 0.8002, 0.9811, 0.8848,
         0.3526, 0.6450, 0.1749, 0.7737, 0.9328, 0.3761, 0.7036, 0.0130, 0.1053,
         0.7388, 0.2021, 0.3889, 0.9389, 0.6102, 0.2628, 0.5362, 0.9709, 0.5080,
         0.1273, 0.5591, 0.7681, 0.7363, 0.9148, 0.4528, 0.5695, 0.9549, 0.0477,
         0.3992, 0.6347, 0.8841, 0.7095, 0.1525, 0.2454, 0.0771, 0.7901, 0.2770,
         0.3806, 0.0845, 0.7046, 0.1449, 0.6919, 0.6002, 0.5946, 0.8866, 0.8571,
         0.8354, 0.9616, 0.4859, 0.2426, 0.5474, 0.3931, 0.3229, 0.7754, 0.2567,
         0.7040, 0.0802, 0.2613, 0.5689, 0.5570, 0.8373, 0.2534, 0.4451, 0.2368,
         0.3141, 0.0149, 0.2708, 0.7065, 0.2115, 0.1749, 0.7991, 0.0903, 0.0049,
         0.8496, 0.7477, 0.6645, 0.5880, 0.7010, 0.4026, 0.6287, 0.1509, 0.3390,
         0.9596, 0.8022, 0.6782, 0.2990, 0.6856, 0.9509, 0.4551, 0.6838, 0.8454,
         0.4158, 0.0903, 0.0071, 0.5504, 0.6423, 0.2370, 0.1048, 0.9333, 0.1672,
         0.4003, 0.2579, 0.4934, 0.2393, 0.9639, 0.6808, 0.4252, 0.3126, 0.3432,
         0.9236, 0.2006, 0.6830, 0.9230, 0.4266, 0.4529, 0.4011, 0.0827, 0.4850,
         0.9031, 0.9149, 0.6489, 0.5628, 0.3088, 0.9155, 0.6220, 0.7153, 0.6983,
         0.5700, 0.6324, 0.6394, 0.7749, 0.6407, 0.7139, 0.2032, 0.7199, 0.8888,
         0.9916, 0.7264, 0.9094, 0.0054, 0.9231, 0.2219, 0.4375, 0.5394, 0.2412,
         0.0117, 0.5908, 0.9511, 0.1405, 0.8196, 0.3408, 0.3140, 0.1587, 0.7307,
         0.4227, 0.8598, 0.2538, 0.5434, 0.2481, 0.6893, 0.2613, 0.2331, 0.9044,
         0.2225, 0.4826, 0.5951, 0.4388, 0.6336, 0.6142, 0.2670, 0.0535, 0.2646,
         0.5892, 0.8774, 0.0646, 0.5863, 0.9149, 0.2556, 0.5194, 0.0361, 0.6961,
         0.5535, 0.5962, 0.2332, 0.9942, 0.0625, 0.9481, 0.5449, 0.3813, 0.9495,
         0.8148, 0.0685, 0.8269, 0.2900, 0.1863, 0.1394, 0.9024, 0.5214, 0.9881,
         0.8169, 0.4357, 0.5421, 0.2582, 0.3407, 0.8029, 0.5739, 0.0016, 0.9597,
         0.5564, 0.0533, 0.5725, 0.1405, 0.5687, 0.4887, 0.0567, 0.2159, 0.6202,
         0.0081, 0.4983, 0.3978, 0.3728, 0.2633, 0.7950, 0.7832, 0.9931, 0.7599,
         0.6623, 0.6902, 0.5307, 0.3295, 0.8063, 0.2415, 0.6782, 0.4862, 0.6010,
         0.3314, 0.2714, 0.6774, 0.0401, 0.8113, 0.5825, 0.5737, 0.6881, 0.9927,
         0.5201, 0.0997, 0.6195, 0.5070, 0.9401, 0.4568, 0.4426, 0.5219, 0.6625,
         0.5728, 0.3410, 0.3468, 0.0919, 0.8346, 0.0790, 0.4281, 0.8841, 0.7757,
         0.2296, 0.1718, 0.9213, 0.8373, 0.2532, 0.0683, 0.9789, 0.0532, 0.0248,
         0.2971, 0.0307, 0.3509, 0.1500, 0.3955, 0.5667, 0.6420, 0.9258, 0.5502,
         0.4714, 0.6889, 0.0104, 0.7124, 0.2504, 0.3072, 0.4477, 0.4761, 0.0243,
         0.1215, 0.0646, 0.7849, 0.9539, 0.2558, 0.6261, 0.6455, 0.1486, 0.4165,
         0.7144, 0.1031, 0.6071, 0.7805, 0.5757, 0.0523, 0.6484, 0.3854, 0.5945,
         0.5485, 0.4556, 0.0482, 0.6763, 0.3665, 0.5651, 0.9302, 0.1266, 0.7183,
         0.1110, 0.1687, 0.5830, 0.1499, 0.0660, 0.8374, 0.5465, 0.8564, 0.2067,
         0.7281, 0.8048, 0.6046, 0.7926, 0.3794, 0.3725, 0.8119, 0.1819, 0.9216,
         0.0208, 0.3060, 0.9321, 0.6724, 0.7568, 0.8810, 0.3407, 0.9976, 0.0189,
         0.5287, 0.3409, 0.0317, 0.9015, 0.2709, 0.1335, 0.6293, 0.1367, 0.1212,
         0.2925, 0.2431, 0.1853, 0.5429, 0.3582, 0.0430, 0.8849, 0.2075, 0.4507,
         0.4936, 0.6022, 0.1067, 0.6299, 0.0743, 0.3518, 0.9123, 0.6247, 0.6631,
         0.0962, 0.4685, 0.9107, 0.3358, 0.8065, 0.6057, 0.8493, 0.6630, 0.5225,
         0.4316, 0.7501, 0.0190, 0.6086, 0.7828, 0.7936, 0.3705, 0.1835, 0.8217,
         0.9242, 0.3876, 0.0060, 0.0137, 0.9703, 0.5884, 0.2162, 0.8130, 0.5174,
         0.8327, 0.9835, 0.8404, 0.5089, 0.0739, 0.7279, 0.5955, 0.8736, 0.7568,
         0.0699, 0.3596, 0.5491, 0.8354, 0.4879, 0.6652, 0.5561, 0.3420, 0.0065,
         0.5702, 0.5724, 0.0391, 0.6175, 0.3509, 0.5226, 0.5313, 0.7425, 0.9894,
         0.6016, 0.1287, 0.0227, 0.7809, 0.3658, 0.6067, 0.9327, 0.5968, 0.2794,
         0.0521, 0.6964, 0.0688, 0.6568, 0.2898, 0.2392, 0.4380, 0.9866, 0.4978,
         0.1514, 0.7378, 0.5470, 0.1889, 0.0752, 0.2829, 0.2973, 0.0261, 0.9395,
         0.9219, 0.6473, 0.1949, 0.3055, 0.2112, 0.0468, 0.4178, 0.2177, 0.5860,
         0.3572, 0.4643, 0.3036, 0.3785, 0.6599, 0.8214, 0.2951, 0.1377, 0.5413,
         0.9139, 0.2693, 0.8621, 0.3371, 0.9781, 0.9271, 0.7037, 0.4335, 0.2501,
         0.1079, 0.8257, 0.9934, 0.9269, 0.3545, 0.2159, 0.6124, 0.7123, 0.6765,
         0.3746, 0.0521, 0.7464, 0.8644, 0.9428, 0.5669, 0.0375, 0.3257, 0.8288,
         0.2018, 0.5375, 0.4415, 0.4322, 0.9334, 0.1114, 0.0327, 0.4125, 0.1021,
         0.0047, 0.9847, 0.0784, 0.0853, 0.3056, 0.5962, 0.1060, 0.5844, 0.6988,
         0.9626, 0.3447, 0.4719, 0.3011, 0.8161, 0.2769, 0.0381, 0.2339, 0.0841,
         0.9432, 0.5640, 0.0644, 0.5097, 0.7557, 0.9812, 0.8288, 0.9084, 0.9889,
         0.8719, 0.4321, 0.2309]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.4000% F1: 0.3138
Applying ckpt from fold 1 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.8000% F1: 0.2643
Applying ckpt from fold 2 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.6000% F1: 0.3268
Applying ckpt from fold 3 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 53.6000% F1: 0.3154
Applying ckpt from fold 4 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.8000% F1: 0.3010
Applying ckpt from fold 5 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.0000% F1: 0.3296
Applying ckpt from fold 6 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.8000% F1: 0.3252
Applying ckpt from fold 7 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.6000% F1: 0.2895
Applying ckpt from fold 8 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.6000% F1: 0.3067
Applying ckpt from fold 9 epoch 2...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 52.6000% F1: 0.2982
Metrics by fold:
Fold 0 - Acc: 0.50 F1: 0.31
Fold 1 - Acc: 0.51 F1: 0.26
Fold 2 - Acc: 0.51 F1: 0.33
Fold 3 - Acc: 0.54 F1: 0.32
Fold 4 - Acc: 0.51 F1: 0.30
Fold 5 - Acc: 0.51 F1: 0.33
Fold 6 - Acc: 0.49 F1: 0.33
Fold 7 - Acc: 0.51 F1: 0.29
Fold 8 - Acc: 0.49 F1: 0.31
Fold 9 - Acc: 0.53 F1: 0.30
agg_acc: 0.5078 agg_f1: 0.3070
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Replacing DTEs with random tensors...
dtes[0]: tensor([[0.2585, 0.3342, 0.5031, 0.0049, 0.9054, 0.2995, 0.6942, 0.1993, 0.3467,
         0.0551, 0.9502, 0.1642, 0.9655, 0.4497, 0.4126, 0.1734, 0.3988, 0.9837,
         0.0412, 0.6500, 0.8972, 0.7563, 0.3246, 0.0361, 0.7769, 0.2305, 0.9059,
         0.3578, 0.6378, 0.8821, 0.7356, 0.7117, 0.2421, 0.1267, 0.9151, 0.1053,
         0.0015, 0.9824, 0.3626, 0.7026, 0.7306, 0.8812, 0.9327, 0.9738, 0.4547,
         0.9212, 0.0280, 0.4865, 0.4547, 0.0627, 0.1774, 0.2586, 0.5417, 0.7206,
         0.4158, 0.8011, 0.0624, 0.1973, 0.4143, 0.6528, 0.8320, 0.3798, 0.0899,
         0.4786, 0.1185, 0.0717, 0.3474, 0.9510, 0.2194, 0.0466, 0.6125, 0.7958,
         0.6148, 0.0284, 0.8110, 0.6633, 0.0875, 0.1138, 0.1422, 0.4307, 0.4365,
         0.9001, 0.8829, 0.3526, 0.2231, 0.1915, 0.4473, 0.6528, 0.3674, 0.3230,
         0.9427, 0.7723, 0.5442, 0.4908, 0.4439, 0.7850, 0.8302, 0.7562, 0.4946,
         0.4473, 0.6338, 0.9149, 0.5952, 0.0632, 0.9116, 0.9982, 0.4168, 0.9729,
         0.9594, 0.6606, 0.3406, 0.2797, 0.9467, 0.8648, 0.7752, 0.5796, 0.0355,
         0.1614, 0.1642, 0.6951, 0.4826, 0.3965, 0.0170, 0.0177, 0.6508, 0.6954,
         0.1950, 0.9877, 0.2754, 0.6217, 0.4948, 0.0750, 0.3706, 0.0263, 0.4408,
         0.5952, 0.9797, 0.9164, 0.2150, 0.9759, 0.0705, 0.2556, 0.3436, 0.4858,
         0.6802, 0.6959, 0.6404, 0.7744, 0.6270, 0.8941, 0.0860, 0.5928, 0.6720,
         0.0011, 0.3973, 0.3193, 0.0164, 0.3014, 0.4995, 0.0801, 0.8704, 0.7296,
         0.2547, 0.2654, 0.1156, 0.9167, 0.8254, 0.7597, 0.6835, 0.2921, 0.7495,
         0.7719, 0.2757, 0.3300, 0.8586, 0.8472, 0.6629, 0.2527, 0.2968, 0.8262,
         0.6674, 0.7621, 0.9317, 0.5391, 0.3589, 0.6121, 0.5999, 0.7921, 0.8159,
         0.9026, 0.8148, 0.9830, 0.2642, 0.4179, 0.8907, 0.6839, 0.8225, 0.1345,
         0.1362, 0.2587, 0.0364, 0.4068, 0.8341, 0.7870, 0.8977, 0.9017, 0.5983,
         0.4763, 0.1371, 0.5472, 0.0787, 0.8334, 0.3599, 0.2384, 0.7608, 0.5693,
         0.8836, 0.4063, 0.7203, 0.3281, 0.5986, 0.4819, 0.6471, 0.8713, 0.2232,
         0.7138, 0.1204, 0.5803, 0.7569, 0.2839, 0.7624, 0.5446, 0.3290, 0.2102,
         0.1112, 0.1214, 0.2239, 0.4698, 0.3968, 0.3321, 0.0900, 0.7673, 0.8216,
         0.1516, 0.9696, 0.7247, 0.9194, 0.8071, 0.2599, 0.2153, 0.0970, 0.4679,
         0.9374, 0.1938, 0.7702, 0.2543, 0.5427, 0.1776, 0.2652, 0.7016, 0.2504,
         0.3044, 0.4429, 0.8130, 0.6813, 0.5149, 0.8324, 0.5891, 0.1536, 0.9798,
         0.6052, 0.1296, 0.3730, 0.1314, 0.9502, 0.2066, 0.6132, 0.2410, 0.9165,
         0.0093, 0.3997, 0.0864, 0.0683, 0.2795, 0.0398, 0.4081, 0.2071, 0.3172,
         0.9212, 0.4474, 0.3250, 0.9935, 0.9017, 0.9506, 0.4967, 0.2984, 0.4541,
         0.2340, 0.7565, 0.5346, 0.0099, 0.6417, 0.5450, 0.4978, 0.1914, 0.3513,
         0.9987, 0.4983, 0.8810, 0.8565, 0.1560, 0.3984, 0.6286, 0.6972, 0.6192,
         0.7116, 0.1076, 0.5343, 0.9291, 0.5726, 0.7760, 0.2488, 0.4098, 0.6367,
         0.7752, 0.0931, 0.2181, 0.0081, 0.6927, 0.3503, 0.5726, 0.8234, 0.0325,
         0.5530, 0.1180, 0.6693, 0.5603, 0.5622, 0.0401, 0.5217, 0.0981, 0.3538,
         0.1147, 0.6354, 0.0381, 0.9346, 0.4385, 0.7797, 0.9099, 0.1496, 0.6768,
         0.5161, 0.8902, 0.4245, 0.3215, 0.2591, 0.9252, 0.1924, 0.3067, 0.0638,
         0.8335, 0.7034, 0.3760, 0.7806, 0.1318, 0.0098, 0.4713, 0.0491, 0.9097,
         0.2969, 0.0351, 0.7421, 0.2238, 0.0680, 0.4702, 0.3217, 0.1721, 0.4451,
         0.7146, 0.2034, 0.2749, 0.2170, 0.0033, 0.5157, 0.7425, 0.2804, 0.4399,
         0.5484, 0.1275, 0.7756, 0.8223, 0.2676, 0.5704, 0.5723, 0.2762, 0.6791,
         0.6726, 0.4305, 0.1399, 0.8456, 0.7632, 0.9837, 0.2585, 0.2414, 0.5180,
         0.6100, 0.0461, 0.1355, 0.7328, 0.2727, 0.9945, 0.1341, 0.2959, 0.7599,
         0.2008, 0.5830, 0.8996, 0.8534, 0.6359, 0.7227, 0.7550, 0.7643, 0.8940,
         0.0872, 0.9385, 0.9927, 0.5872, 0.8304, 0.8966, 0.2129, 0.3120, 0.3196,
         0.2432, 0.3325, 0.5563, 0.1535, 0.3524, 0.8777, 0.0308, 0.5002, 0.4338,
         0.1395, 0.5429, 0.1572, 0.2605, 0.2415, 0.1287, 0.3031, 0.2624, 0.6383,
         0.6835, 0.1520, 0.3804, 0.3798, 0.9867, 0.1738, 0.5446, 0.5012, 0.1531,
         0.9879, 0.4915, 0.2440, 0.3865, 0.8829, 0.0602, 0.4601, 0.1550, 0.1830,
         0.2307, 0.6805, 0.0790, 0.4660, 0.3167, 0.5609, 0.0349, 0.8803, 0.4751,
         0.6073, 0.6723, 0.8032, 0.8469, 0.8106, 0.5489, 0.2179, 0.1694, 0.6623,
         0.7711, 0.7627, 0.9614, 0.3587, 0.3441, 0.3592, 0.0974, 0.2686, 0.2318,
         0.3712, 0.3867, 0.6721, 0.3717, 0.3996, 0.6179, 0.9278, 0.1320, 0.8715,
         0.0870, 0.8473, 0.0339, 0.1472, 0.6010, 0.3994, 0.2716, 0.8481, 0.2458,
         0.3841, 0.9332, 0.6617, 0.7760, 0.9277, 0.2763, 0.8678, 0.7956, 0.4726,
         0.1862, 0.3873, 0.3677, 0.0538, 0.0639, 0.2987, 0.4018, 0.6325, 0.3923,
         0.9894, 0.0522, 0.0306, 0.7813, 0.9471, 0.1980, 0.5719, 0.3369, 0.8650,
         0.3716, 0.2695, 0.8504, 0.4497, 0.9826, 0.5640, 0.5188, 0.6677, 0.3485,
         0.1370, 0.6142, 0.6449, 0.3920, 0.2758, 0.0040, 0.0791, 0.0975, 0.9652,
         0.0629, 0.1537, 0.7734, 0.7876, 0.1228, 0.2571, 0.3068, 0.8308, 0.0030,
         0.3201, 0.3090, 0.0332, 0.0566, 0.0236, 0.7503, 0.5497, 0.5111, 0.9007,
         0.2671, 0.3231, 0.9136, 0.4501, 0.1886, 0.3243, 0.0463, 0.5513, 0.2045,
         0.2582, 0.5001, 0.2806, 0.1920, 0.5201, 0.3061, 0.2037, 0.8453, 0.1179,
         0.3872, 0.5871, 0.0391, 0.9205, 0.2832, 0.9138, 0.1822, 0.0526, 0.9857,
         0.3681, 0.0452, 0.7305, 0.9010, 0.3052, 0.4873, 0.4077, 0.7534, 0.1533,
         0.5415, 0.5425, 0.8703, 0.8815, 0.6345, 0.5291, 0.3490, 0.2502, 0.6157,
         0.6057, 0.2845, 0.8787, 0.9170, 0.9844, 0.1072, 0.3629, 0.6138, 0.7788,
         0.5720, 0.1600, 0.6827, 0.0078, 0.2836, 0.5936, 0.5167, 0.9470, 0.9707,
         0.6795, 0.6295, 0.2093, 0.2970, 0.1632, 0.7773, 0.4261, 0.8790, 0.9804,
         0.7122, 0.3197, 0.6710, 0.0815, 0.1675, 0.1795, 0.7468, 0.4797, 0.1779,
         0.6889, 0.5778, 0.7080, 0.6502, 0.9404, 0.1254, 0.6727, 0.0058, 0.5687,
         0.5652, 0.4036, 0.6516, 0.8202, 0.9153, 0.8346, 0.9875, 0.1916, 0.4048,
         0.9153, 0.8584, 0.5032, 0.9313, 0.5884, 0.2279, 0.0367, 0.6743, 0.9759,
         0.3750, 0.1239, 0.5511, 0.5469, 0.8054, 0.5480, 0.3784, 0.9440, 0.1569,
         0.3924, 0.5481, 0.9418, 0.1269, 0.0649, 0.7344, 0.9197, 0.6453, 0.0146,
         0.7650, 0.2319, 0.1415, 0.2282, 0.7338, 0.9551, 0.3377, 0.8899, 0.0174,
         0.3811, 0.3253, 0.0054, 0.1266, 0.0583, 0.9946, 0.1061, 0.5275, 0.3346,
         0.4854, 0.7636, 0.3803, 0.0746, 0.8260, 0.5181, 0.8134, 0.9919, 0.3446,
         0.9432, 0.3419, 0.0316, 0.2963, 0.6548, 0.5293, 0.0595, 0.7577, 0.6222,
         0.7628, 0.6709, 0.0367, 0.2785, 0.1086, 0.6278, 0.0272, 0.8864, 0.9535,
         0.3466, 0.2593, 0.8731, 0.7834, 0.9057, 0.0789, 0.3416, 0.4952, 0.8001,
         0.3418, 0.7188, 0.5046, 0.0036, 0.6699, 0.8232, 0.5296, 0.5395, 0.5821,
         0.9444, 0.0797, 0.1068]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.0000% F1: 0.3068
Applying ckpt from fold 1 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.8000% F1: 0.2583
Applying ckpt from fold 2 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.6000% F1: 0.3060
Applying ckpt from fold 3 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.8000% F1: 0.3410
Applying ckpt from fold 4 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 50.2000% F1: 0.3185
Applying ckpt from fold 5 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 51.0000% F1: 0.3160
Applying ckpt from fold 6 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.8000% F1: 0.3631
Applying ckpt from fold 7 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.8000% F1: 0.3210
Applying ckpt from fold 8 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.6000% F1: 0.2823
Applying ckpt from fold 9 epoch 3...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 49.2000% F1: 0.2834
Metrics by fold:
Fold 0 - Acc: 0.51 F1: 0.31
Fold 1 - Acc: 0.50 F1: 0.26
Fold 2 - Acc: 0.49 F1: 0.31
Fold 3 - Acc: 0.50 F1: 0.34
Fold 4 - Acc: 0.50 F1: 0.32
Fold 5 - Acc: 0.51 F1: 0.32
Fold 6 - Acc: 0.49 F1: 0.36
Fold 7 - Acc: 0.49 F1: 0.32
Fold 8 - Acc: 0.50 F1: 0.28
Fold 9 - Acc: 0.49 F1: 0.28
agg_acc: 0.4968 agg_f1: 0.3096
Some weights of the model checkpoint at boychaboy/SNLI_roberta-base were not used when initializing RobertaModel: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at boychaboy/SNLI_roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Replacing DTEs with random tensors...
dtes[0]: tensor([[0.3962, 0.2075, 0.6438, 0.7697, 0.9166, 0.5812, 0.1029, 0.8627, 0.6699,
         0.8976, 0.1308, 0.9095, 0.0611, 0.1063, 0.8355, 0.2512, 0.5047, 0.4397,
         0.0900, 0.6994, 0.5391, 0.7052, 0.3441, 0.2247, 0.2137, 0.9276, 0.4806,
         0.7876, 0.4076, 0.4021, 0.4058, 0.6719, 0.8471, 0.2614, 0.6679, 0.4875,
         0.4288, 0.9543, 0.1359, 0.0522, 0.9628, 0.0258, 0.3778, 0.9472, 0.7012,
         0.5424, 0.2922, 0.3127, 0.4876, 0.0394, 0.8146, 0.6520, 0.0344, 0.0301,
         0.5375, 0.6676, 0.2639, 0.7166, 0.6244, 0.4642, 0.9650, 0.2058, 0.5649,
         0.8637, 0.3030, 0.4696, 0.0784, 0.4623, 0.6757, 0.2434, 0.4404, 0.1934,
         0.5374, 0.3006, 0.9697, 0.3802, 0.5106, 0.7872, 0.7022, 0.0922, 0.5692,
         0.6675, 0.8208, 0.3123, 0.3175, 0.7194, 0.4475, 0.9899, 0.9551, 0.0092,
         0.7227, 0.0973, 0.0435, 0.8959, 0.5024, 0.5603, 0.5680, 0.7668, 0.9786,
         0.3020, 0.2724, 0.5294, 0.4099, 0.1313, 0.9406, 0.7757, 0.7596, 0.2536,
         0.2468, 0.5401, 0.3605, 0.9793, 0.6529, 0.9708, 0.5616, 0.9823, 0.1941,
         0.2829, 0.1648, 0.0711, 0.3931, 0.8307, 0.9984, 0.0181, 0.6118, 0.7898,
         0.3411, 0.2684, 0.3434, 0.6662, 0.2579, 0.6648, 0.7283, 0.5096, 0.3932,
         0.1823, 0.6583, 0.2155, 0.3613, 0.6863, 0.7467, 0.9282, 0.3343, 0.2327,
         0.4333, 0.5092, 0.3636, 0.5880, 0.3800, 0.0760, 0.8669, 0.4983, 0.0986,
         0.7311, 0.1739, 0.1587, 0.5702, 0.0022, 0.6367, 0.1254, 0.1835, 0.8634,
         0.3854, 0.5198, 0.0989, 0.6227, 0.9787, 0.5850, 0.8756, 0.6022, 0.0076,
         0.6580, 0.2387, 0.7194, 0.5497, 0.8392, 0.7997, 0.1664, 0.4753, 0.2805,
         0.8679, 0.5118, 0.4045, 0.2502, 0.4859, 0.1687, 0.5421, 0.2828, 0.0124,
         0.2945, 0.8975, 0.2013, 0.9677, 0.6104, 0.6819, 0.1450, 0.6643, 0.1999,
         0.4387, 0.1012, 0.9530, 0.2112, 0.1100, 0.9520, 0.0514, 0.7391, 0.1202,
         0.1337, 0.6683, 0.9511, 0.0640, 0.6983, 0.0639, 0.5421, 0.8458, 0.6675,
         0.9739, 0.6526, 0.4864, 0.5033, 0.3957, 0.1146, 0.6879, 0.6428, 0.6353,
         0.3000, 0.1258, 0.5913, 0.0511, 0.6154, 0.0520, 0.6934, 0.5267, 0.8751,
         0.0966, 0.2110, 0.2981, 0.9943, 0.4831, 0.4097, 0.9016, 0.4747, 0.5995,
         0.6225, 0.8578, 0.1907, 0.2632, 0.9244, 0.8191, 0.0458, 0.0943, 0.8673,
         0.1461, 0.7291, 0.3307, 0.4212, 0.5997, 0.9080, 0.5115, 0.5855, 0.0037,
         0.8759, 0.5855, 0.4051, 0.0268, 0.0690, 0.4939, 0.7722, 0.3461, 0.9785,
         0.6479, 0.8121, 0.4825, 0.5987, 0.3534, 0.3267, 0.9884, 0.3764, 0.5244,
         0.8197, 0.4897, 0.9666, 0.1879, 0.9884, 0.1569, 0.0857, 0.6877, 0.0078,
         0.8069, 0.0255, 0.5577, 0.8554, 0.4649, 0.4921, 0.9948, 0.8537, 0.4909,
         0.1035, 0.1396, 0.7332, 0.1925, 0.7828, 0.4084, 0.3202, 0.5659, 0.3985,
         0.3053, 0.0436, 0.2593, 0.3465, 0.3046, 0.1629, 0.1875, 0.8485, 0.0346,
         0.9663, 0.5061, 0.8169, 0.4846, 0.5850, 0.7540, 0.0632, 0.0668, 0.8170,
         0.8915, 0.5592, 0.8916, 0.9104, 0.4689, 0.9847, 0.5660, 0.0427, 0.1428,
         0.5776, 0.0998, 0.9603, 0.4726, 0.7764, 0.6546, 0.9394, 0.1878, 0.8785,
         0.2714, 0.4974, 0.1954, 0.4552, 0.0771, 0.4372, 0.9774, 0.5553, 0.4232,
         0.9315, 0.6948, 0.0594, 0.6357, 0.4286, 0.2382, 0.8295, 0.0179, 0.5726,
         0.2778, 0.2355, 0.1288, 0.6715, 0.9836, 0.5902, 0.9007, 0.5435, 0.1504,
         0.7207, 0.5007, 0.4345, 0.8435, 0.1351, 0.4403, 0.3211, 0.9453, 0.1983,
         0.6367, 0.6358, 0.7713, 0.6318, 0.8564, 0.5845, 0.7315, 0.1841, 0.0982,
         0.6905, 0.7556, 0.9229, 0.6906, 0.9053, 0.7137, 0.5066, 0.3871, 0.4101,
         0.9272, 0.1205, 0.7540, 0.3156, 0.4720, 0.5724, 0.1298, 0.7820, 0.3615,
         0.0315, 0.9817, 0.4528, 0.6474, 0.8611, 0.7990, 0.2910, 0.4188, 0.3928,
         0.7759, 0.3413, 0.4614, 0.1866, 0.6759, 0.0990, 0.3523, 0.1398, 0.7947,
         0.9281, 0.6564, 0.1024, 0.1286, 0.8181, 0.1437, 0.9018, 0.9537, 0.6612,
         0.9688, 0.5808, 0.9149, 0.8960, 0.7891, 0.3934, 0.7092, 0.2510, 0.3209,
         0.0268, 0.3711, 0.0709, 0.1941, 0.4733, 0.6560, 0.2208, 0.5281, 0.6802,
         0.3695, 0.8539, 0.5458, 0.1032, 0.7569, 0.3945, 0.6270, 0.7628, 0.6908,
         0.8966, 0.2201, 0.2698, 0.5385, 0.5581, 0.0432, 0.6389, 0.9094, 0.3557,
         0.7388, 0.1706, 0.0581, 0.1013, 0.5930, 0.3321, 0.3128, 0.1352, 0.9973,
         0.2843, 0.2864, 0.5390, 0.3206, 0.5657, 0.0944, 0.5420, 0.4537, 0.6238,
         0.7905, 0.3317, 0.2883, 0.1917, 0.9743, 0.7356, 0.2959, 0.6734, 0.4149,
         0.2870, 0.7400, 0.5155, 0.1840, 0.1702, 0.7225, 0.4911, 0.4152, 0.7819,
         0.1544, 0.7895, 0.1185, 0.3809, 0.1059, 0.5029, 0.9391, 0.8422, 0.8174,
         0.5963, 0.6849, 0.7108, 0.1648, 0.6285, 0.5049, 0.0464, 0.8284, 0.2854,
         0.2011, 0.4735, 0.8768, 0.5292, 0.6050, 0.8846, 0.0246, 0.4541, 0.6264,
         0.6458, 0.6590, 0.3836, 0.3318, 0.7974, 0.4699, 0.0829, 0.2847, 0.4142,
         0.0121, 0.6874, 0.5434, 0.0064, 0.6975, 0.5812, 0.1103, 0.8182, 0.0721,
         0.4103, 0.5173, 0.6722, 0.6672, 0.5559, 0.6966, 0.6120, 0.5386, 0.7878,
         0.8105, 0.8327, 0.2991, 0.2346, 0.1617, 0.9917, 0.4464, 0.5472, 0.3615,
         0.1942, 0.3985, 0.5566, 0.8177, 0.4331, 0.8201, 0.8806, 0.8343, 0.3558,
         0.7170, 0.8167, 0.7863, 0.2800, 0.8397, 0.0547, 0.1146, 0.9254, 0.9754,
         0.4112, 0.2598, 0.1126, 0.4395, 0.8272, 0.0479, 0.7735, 0.4443, 0.1296,
         0.2348, 0.2290, 0.4128, 0.7243, 0.2710, 0.4134, 0.4703, 0.3969, 0.0427,
         0.6438, 0.0773, 0.1797, 0.3356, 0.9523, 0.2267, 0.4326, 0.8567, 0.5945,
         0.0703, 0.6027, 0.0597, 0.0479, 0.0971, 0.3923, 0.3921, 0.1921, 0.9348,
         0.1612, 0.6733, 0.2946, 0.1213, 0.5346, 0.8479, 0.9473, 0.2877, 0.4149,
         0.8979, 0.1541, 0.7447, 0.9537, 0.1960, 0.9519, 0.3366, 0.8382, 0.8775,
         0.6026, 0.9837, 0.0820, 0.7066, 0.3377, 0.3524, 0.2206, 0.8781, 0.5298,
         0.0292, 0.3214, 0.2303, 0.3277, 0.4813, 0.2661, 0.4130, 0.5665, 0.7820,
         0.5643, 0.1578, 0.5618, 0.4756, 0.9544, 0.0069, 0.4100, 0.2280, 0.2102,
         0.6793, 0.5767, 0.4388, 0.7826, 0.5928, 0.4069, 0.5195, 0.3293, 0.5734,
         0.1123, 0.9573, 0.0705, 0.4287, 0.6387, 0.5043, 0.9498, 0.8956, 0.8126,
         0.1836, 0.8956, 0.0963, 0.4450, 0.3862, 0.2097, 0.4011, 0.7060, 0.9837,
         0.4124, 0.8560, 0.5482, 0.0791, 0.6935, 0.5329, 0.1075, 0.5532, 0.5207,
         0.8409, 0.5639, 0.2688, 0.0949, 0.0635, 0.3584, 0.8814, 0.6692, 0.0838,
         0.3110, 0.4628, 0.1245, 0.0236, 0.3015, 0.8361, 0.6592, 0.0908, 0.1896,
         0.0631, 0.0784, 0.5482, 0.4879, 0.1872, 0.9810, 0.7772, 0.5529, 0.1252,
         0.7147, 0.8086, 0.7388, 0.2255, 0.5768, 0.2031, 0.2989, 0.1495, 0.0625,
         0.4833, 0.6250, 0.0016, 0.6864, 0.2920, 0.3691, 0.1980, 0.5916, 0.0644,
         0.1826, 0.1474, 0.8319, 0.0403, 0.3349, 0.2656, 0.4078, 0.6402, 0.6810,
         0.1824, 0.1250, 0.4167, 0.8123, 0.6349, 0.9550, 0.9127, 0.8011, 0.6752,
         0.5482, 0.5179, 0.5037]])
InputMaker reading metamap...
InputMaker reading DTE lookup table...
InputMaker creating model and tokenizer...
	model name: boychaboy/SNLI_roberta-base
Applying ckpt from fold 0 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 39.4000% F1: 0.3321
Applying ckpt from fold 1 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 42.8000% F1: 0.2794
Applying ckpt from fold 2 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 45.6000% F1: 0.3280
Applying ckpt from fold 3 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.4000% F1: 0.3540
Applying ckpt from fold 4 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 48.8000% F1: 0.3670
Applying ckpt from fold 5 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 44.4000% F1: 0.3643
Applying ckpt from fold 6 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 43.8000% F1: 0.3454
Applying ckpt from fold 7 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 46.4000% F1: 0.3319
Applying ckpt from fold 8 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 46.2000% F1: 0.3270
Applying ckpt from fold 9 epoch 4...
	Processing batch 0/6...
	Processing batch 1/6...
	Processing batch 2/6...
	Processing batch 3/6...
	Processing batch 4/6...
	Processing batch 5/6...
	Acc: 47.6000% F1: 0.3350
Metrics by fold:
Fold 0 - Acc: 0.39 F1: 0.33
Fold 1 - Acc: 0.43 F1: 0.28
Fold 2 - Acc: 0.46 F1: 0.33
Fold 3 - Acc: 0.48 F1: 0.35
Fold 4 - Acc: 0.49 F1: 0.37
Fold 5 - Acc: 0.44 F1: 0.36
Fold 6 - Acc: 0.44 F1: 0.35
Fold 7 - Acc: 0.46 F1: 0.33
Fold 8 - Acc: 0.46 F1: 0.33
Fold 9 - Acc: 0.48 F1: 0.34
agg_acc: 0.4534 agg_f1: 0.3364
