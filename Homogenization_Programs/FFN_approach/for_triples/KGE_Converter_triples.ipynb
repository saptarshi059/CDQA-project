{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ef6a2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Loading trained model & setting it to eval mode\n",
    "from MyNN import FFNN\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "BERT_variant = 'phiyodr/bert-base-finetuned-squad2'\n",
    "\n",
    "UMLS_KGE_path = os.path.abspath('../../../UMLS_KG')\n",
    "\n",
    "ent_embeddings = pd.read_csv(os.path.join(UMLS_KGE_path,\\\n",
    "                                          os.path.relpath('embeddings/distmult/ent_embedding.tsv')),\\\n",
    "                                          sep='\\t', header=None)\n",
    "\n",
    "with open(os.path.join(UMLS_KGE_path, 'entity2idx.pkl'), 'rb') as f:\n",
    "    entity2id = pickle.load(f)\n",
    "\n",
    "input_dimension = len(ent_embeddings.columns)\n",
    "output_dimension = AutoTokenizer.from_pretrained(BERT_variant).vocab_size\n",
    "number_of_hidden_layers = 5\n",
    "hidden_dimension = 768\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model = FFNN(input_dimension, output_dimension, number_of_hidden_layers, hidden_dimension)\n",
    "model.load_state_dict(torch.load('Homogenizer.pt', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f'Model loaded on device: {device} ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380c7f2a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Converting entity KGE's to target model equivalents\n",
    "from tqdm import tqdm\n",
    "\n",
    "entity_names = []\n",
    "converted_embeddings = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for e_name, index in tqdm(entity2id.items()):\n",
    "        entity_names.append(e_name)\n",
    "        ent_embed = torch.FloatTensor(ent_embeddings.iloc[index].values).reshape(1,-1)\n",
    "        #Discarding softmax output\n",
    "        _, homogenized_embedding = model(ent_embed.to(device))\n",
    "        converted_embeddings.append(homogenized_embedding)\n",
    "        \n",
    "print('Saving Homogenized Embeddings...')\n",
    "pd.DataFrame(zip(entity_names, converted_embeddings),\\\n",
    "             columns = ['Entity', 'Embedding']).to_pickle(f\"NN-DTE-to-{BERT_variant.replace('/','-')}.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
