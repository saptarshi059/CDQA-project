# -*- coding: utf-8 -*-
"""COVID-QA Baseline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b7ZeerisjbX0P9IPZAwbeI1AUjEudkqg
"""

# !pip install transformers
# !pip install transformers[sentencepiece]


# url = "https://raw.githubusercontent.com/deepset-ai/COVID-QA/master/data/question-answering/COVID-QA.json"

import os
import re
import torch
import string
import argparse
import collections

import numpy as np
import pandas as pd
import torch.nn as nn
import pickle5 as pickle

from tqdm import tqdm
from input_maker import InputMaker
# from custom_qa_pipeline import CustomQuestionAnsweringPipeline
from transformers import AutoTokenizer, AutoModelForQuestionAnswering, QuestionAnsweringPipeline


def str2bool(v):
    if isinstance(v, bool):
        return v
    if v.lower() == 'none':
        return None
    if v.lower() in ('yes', 'true', 't', 'y', '1'):
        return True
    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
        return False
    else:
        raise argparse.ArgumentTypeError('Boolean value expected.')


def normalize_answer(s):
    """Lower text and remove punctuation, articles and extra whitespace."""

    def remove_articles(text):
        regex = re.compile(r'\b(a|an|the)\b', re.UNICODE)
        return re.sub(regex, ' ', text)

    def white_space_fix(text):
        return ' '.join(text.split())

    def remove_punc(text):
        exclude = set(string.punctuation)
        return ''.join(ch for ch in text if ch not in exclude)

    def lower(text):
        return text.lower()

    return white_space_fix(remove_articles(remove_punc(lower(s))))
    # return white_space_fix(remove_punc(lower(s)))


def get_tokens(s):
    if not s: return []
    return normalize_answer(s).split()


def compute_f1(a_gold, a_pred):
    gold_toks = get_tokens(a_gold)
    pred_toks = get_tokens(a_pred)
    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)
    num_same = sum(common.values())
    if len(gold_toks) == 0 or len(pred_toks) == 0:
        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise
        return int(gold_toks == pred_toks)
    if num_same == 0:
        return 0
    precision = 1.0 * num_same / len(pred_toks)
    recall = 1.0 * num_same / len(gold_toks)
    f1 = (2 * precision * recall) / (precision + recall)
    return f1


def compute_EM(a_gold, a_pred):
    return int(normalize_answer(a_gold) == normalize_answer(a_pred))


def gen_answers(tokenizer, model, pred_fp, max_len, n_stride, my_maker=None):
    print('$$$ Creating QA Pipeline $$$')
    nlp = QuestionAnsweringPipeline(model=model, tokenizer=tokenizer, device=torch.cuda.current_device())

    questions = []
    true_answers = []
    predicted_answers = []
    final_df = pd.DataFrame(columns=['question', 'true_answer', 'predicted_answer'])
    start_index = 0

    for i in tqdm(range(len(df))):
        context = df['data'][i]['paragraphs'][0]['context']
        number_of_questions = 0

        for q in df['data'][i]['paragraphs'][0]['qas']:
            questions.append(q['question'])
            true_answers.append(q['answers'][0]['text'])
            number_of_questions += 1

        for n in range(start_index, start_index + number_of_questions):
            QA_input = {
                'question': questions[n] if my_maker is None else my_maker.convert_questions_to_kge(questions[n]),
                'context': context,
            }

            predicted_answers.append(nlp(QA_input, max_seq_len=max_len, doc_stride=n_stride)['answer'])

        start_index = start_index + number_of_questions

    final_df['question'] = questions
    final_df['true_answer'] = true_answers
    final_df['predicted_answer'] = predicted_answers

    final_df.to_csv(pred_fp)
    return final_df


if __name__ == '__main__':
    parser = argparse.ArgumentParser()

    parser.add_argument('--model_name',
                        default='phiyodr/bert-base-finetuned-squad2',
                        # default='ktrapeznikov/biobert_v1.1_pubmed_squad_v2',
                        # default='ktrapeznikov/scibert_scivocab_uncased_squad_v2',
                        )
    parser.add_argument('--use_kge', default=False, type=str2bool)
    parser.add_argument('--concat_kge', default=False, type=str2bool)

    parser.add_argument('--n_stride', default=164, type=int)
    parser.add_argument('--max_len', default=384, type=int)
    parser.add_argument('--dte_lookup_table_fp',
                        default='DTE_to_phiyodr_bert-base-finetuned-squad2.pkl',
                        # default='DTE_to_ktrapeznikov_biobert_v1.1_pubmed_squad_v2.pkl',
                        # default='DTE_to_ktrapeznikov_scibert_scivocab_uncased_squad_v2.pkl',
                        )
    parser.add_argument('--out', default='baselines', help='Directory to put output')

    args = parser.parse_args()

    if not os.path.exists(args.out):
        os.makedirs(args.out)

    model_name = args.model_name
    effective_model_name = model_name.replace("/", "_")
    pred_filename = '{}_{}maxlen_{}stride{}{}_results.csv'.format(effective_model_name,
                                                                  args.max_len, args.n_stride,
                                                                  '_kge' if args.use_kge else '',
                                                                  '_concat' if args.concat_kge else '')
    pred_fp = os.path.join(args.out, pred_filename)

    results_filename = '{}_{}maxlen_{}stride{}{}_results.txt'.format(effective_model_name,
                                                                     args.max_len, args.n_stride,
                                                                     '_kge' if args.use_kge else '',
                                                                     '_concat' if args.concat_kge else '')
    results_fp = os.path.join(args.out, results_filename)

    # df = pd.read_json('200423_covidQA.json')
    df = pd.read_json('data/COVID-QA_cleaned.json')
    # model_name = 'navteca/roberta-base-squad2'
    print('Creating model and tokenizer...')
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForQuestionAnswering.from_pretrained(model_name)
    my_maker = None
    if args.use_kge:
        print('Updating model and tokenizer to use KGEs...')
        DTE_Model_Lookup_Table = pickle.load(open(args.dte_lookup_table_fp, 'rb'))
        domain_terms = DTE_Model_Lookup_Table['Entity'].tolist()
        custom_domain_term_tokens = ['[{}]'.format(dt) for dt in domain_terms]
        print('Adding {} custom domain tokens to tokenizer...'.format(len(custom_domain_term_tokens)))
        print('\tcustom_domain_term_tokens[:6]: {}'.format(custom_domain_term_tokens[:6]))
        tokenizer.add_tokens(custom_domain_term_tokens)

        print('Updating model embedding table...')
        dtes = DTE_Model_Lookup_Table['Embedding'].tolist()
        dtes = torch.cat(dtes, dim=0).to('cpu')
        print('\tdtes: {}'.format(dtes.shape))
        initial_input_embeddings = model.get_input_embeddings().weight
        print('\tinitial_input_embeddings: {}'.format(initial_input_embeddings.shape))
        new_input_embedding_weights = torch.cat([initial_input_embeddings, dtes], dim=0)
        print('\tnew_input_embedding_weights: {}'.format(new_input_embedding_weights.shape))
        new_input_embeddings = nn.Embedding.from_pretrained(new_input_embedding_weights, freeze=False)
        model.set_input_embeddings(new_input_embeddings)

        my_maker = InputMaker(args)

    with torch.no_grad():
        final_df = gen_answers(tokenizer=tokenizer, model=model, pred_fp=pred_fp, max_len=args.max_len,
                               n_stride=args.n_stride, my_maker=my_maker)

    F1 = []
    EM = []
    # final_df = pd.read_csv(pred_fp)
    for i in range(len(final_df)):
        a_gold = final_df['true_answer'][i]
        a_pred = final_df['predicted_answer'][i]
        F1.append(compute_f1(a_gold, a_pred))
        EM.append(compute_EM(a_gold, a_pred))

    avg_f1 = np.mean(F1)
    avg_em = np.mean(EM)
    print(f"Avg. F1: {avg_f1}")
    print(f"Total EM: {avg_em}")

    with open(results_fp, 'w+') as f:
        f.write('Avg F1: {}'.format(avg_f1))
        f.write('Avg EM: {}'.format(avg_em))

    print('All done :)')
